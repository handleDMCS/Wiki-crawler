[
    {
        "ID": 1,
        "URL": "https://machinelearningcoban.com/lifesofar2/",
        "Title": "Machine Learning cơ bản",
        "Content": "Chuyện muốn đi du học của tôi đã nhen nhóm từ ngày lớp 9, nhưng tôi chưa từng có một kết hoạch đầy đủ cho tới khi tốt nghiệp đại học. Tôi chỉ biết rằng mình có học lực tốt và nhiều người khuyên tôi nên đi học nước ngoài. Nhưng học từ bậc nào, học ở đâu, học chuyên ngành nào thì tới tận khi tốt nghiệp đại học tôi mới định hình được.\n\n\nTôi học chương trình Kỹ sư tài năng (KSTN) chuyên ngành Điện tử viễn thông ở Đại học Bách Khoa Hà Nội (BKHN). Trong những năm đầu, tôi được dạy tiếng Anh để thi TOEFL PBT – chỉ để có một chứng chỉ tiếng Anh giúp ích cho tương lai sau này. Ngữ pháp của tôi khá tốt, nhưng kỹ năng nghe và nói rất tệ.\nNăm thứ tư đại học, chương trình có thay đổi và yêu cầu để tốt nghiệp với bằng KSTN, chúng tôi cần có chứng chỉ TOEFL hoặc IELTS. Sau ba năm học TOEFL mà không thấy mình tiến bộ, tôi tình cờ tham gia học IELTS cùng một bạn và thấy mình phù hợp với chứng chỉ này hơn. Sau một năm ôn tập, tôi đạt 6.5 IELTS vào tháng 3/2012. Một số điểm vừa đủ để nộp hồ sơ vào các trường đại học ở Mỹ.\nSau khi có điểm IELTS, thầy Nam – thầy hướng dẫn tôi ở BKHN – khuyến khích tôi nộp hồ sơ vào chương trình PhD của các trường đại học tại Mỹ và nhắc tôi tìm hiểu VEF.\nTôi có nghe tới chương trình VEF từ lâu nhưng chưa bao giờ dám tìm hiểu xem họ yêu cầu những gì vì cho rằng chương trình này quá tầm với. Khi có điểm IELTS, tôi vẫn chưa có điểm GRE nên không thể hoàn thành hồ sơ VEF đúng hạn. Tôi đã nghĩ tới việc tìm học bổng ở Châu Âu, Hàn Quốc, hoặc Nhật vì nghĩ rằng các nơi đó phù hợp với khả năng của mình hơn. Tuy nhiên, thầy Nam nói vui với tôi rằng: “Hồ sơ của em đủ để đi Mỹ, thầy sẽ chỉ viết thư giới thiệu cho em nếu em chọn đi Mỹ”. Tôi tự tin hơn một chút và bắt đầu quyết tâm từ đó. Tuy vậy, tôi vẫn chưa thể toàn tâm làm hồ sơ được vì còn đề tài tốt nghiệp chưa làm xong.\n\nTháng Sáu năm 2012 tôi tốt nghiệp BKHN. Thầy còn một dự án quan trọng nữa nên tôi tiếp tục làm cùng thầy tới giữa tháng Tám mới có thể tập trung cho việc nộp hồ sơ đi Mỹ. Tôi chỉ còn bốn tháng cho đợt nộp hồ sơ giữa tháng 12. Tôi thực sự lo lắng khi biết những người khác thường dành hai ba năm để chuẩn bị hồ sơ.\nTôi mới chỉ có điểm IELTS, chưa có GRE, chưa có bài báo khoa học, và cũng chưa có một hướng nghiên cứu rõ rệt ngoài việc sẽ theo Xử lý ảnh/tín hiệu số. Các kiến thức tôi học được về phần cứng ở đại học lại dường như không giúp hồ sơ của tôi mạnh thêm. Tôi gần như không có gì ngoài niềm tin của thầy cô, bạn bè, và của chính mình.\nBước đầu tiên là phải lấy chứng chỉ GRE. Tôi tìm được một nhóm bạn khoảng mười lăm người đang ôn tập GRE. Nhóm học ba buổi một tuần ở một quán cà phê sách trong ngõ 30 Tạ Quang Bửu, Hà Nội. Ngày đầu đến tôi thấy các anh chị em học thực sự nghiêm túc và bài bản. Tôi thấy mình may mắn, vì sau khi thi GRE xong cả nhóm còn tập trung cùng nhau nộp hồ sơ và đã giúp đỡ nhau rất nhiều. Nhóm vẫn liên lạc và giúp đỡ nhau trong nhiều năm sau đó.\nLúc đó ra trường rồi nên tôi hạn chế xin trợ cấp từ gia đình, thu nhập kiếm được chủ yếu từ việc dạy thêm. Tôi khá lo lắng vì mỗi buổi đi học thường tốn 20k cho cà phê, và sau đó là các loại phí gửi hồ sơ sang Mỹ và phí ứng tuyển vào các trường. Bố mẹ đã đầu tư cho tôi học tiếng Anh rất nhiều trong những năm trước nên tôi cũng không muốn họ mang thêm gánh nặng. Bố mẹ cũng không hiểu được khả năng được đi học của tôi và thường lo lắng khuyên tôi cân nhắc việc đi làm.\nTôi nộp hồ sơ lấy học bổng Honda YES năm 2012 với kỳ vọng cao nhưng không thành. Lúc đó tôi khá khủng hoảng về mặt tài chính. May mắn thay, tôi luôn được quý nhân giúp đỡ trong lúc khó khăn. Chị Phương trong nhóm GRE đưa tôi một phong bì $500 và nói rằng: “Chị tin em sẽ thành công, khi nào sang Mỹ trả lại chị cũng được”. Thầy Nam gọi tôi lên văn phòng và đưa tôi một phong bì dày: “Em làm cùng thầy hai dự án quan trọng, thầy có một chút trả công cho em, thầy cũng hỗ trợ thêm cho em trong việc nộp hồ sơ. Chúc em thành công”. Tôi thực sự xúc động, càng xúc động hơn khi về nhà mở phong bì thấy một số tiền lớn. Những khoản tiền này cực kỳ quan trọng với tôi thời điểm đó, chắc chắn tôi không bao giờ quên! Thời gian này anh Long – anh trai tôi – giúp đỡ tôi nhiều, mặc dù anh cũng lo lắng về khả năng thành công của tôi.\n\nTháng 9/2012 tôi vừa ôn GRE và bắt đầu tìm hiểu thông tin các trường bên Mỹ. Tôi vào trang web USNews xem thứ hạng các trường có ngành Kỹ thuật điện tử (Electrical Engineering, EE). Sau đó bỏ hết các trường trong top 10 vì biết chắc mình không đủ khả năng đỗ. Với mỗi trường trong danh sách từ 10 đến 50, tôi vào trang web của khoa EE tìm các giáo sư làm về xử lý tín hiệu số và gửi email tìm cơ hội. Tôi cũng gửi thư cho một số giáo sư người Việt ở các trường top trên.\nHầu hết các giáo sư không trả lời. Thầy Minh Đỗ ở UIUC có trả lời tôi nói rằng hồ sơ của tôi khá tốt, tuy nhiên thầy không có ý định tuyển thêm sinh viên năm đó và gợi ý tôi nộp cho các thầy khác trong khoa. Một vài giáo sư khác trả lời nhưng nói rằng họ có thể nhận nhưng không có hỗ trợ tài chính. Chỉ duy nhất thầy Vishal Monga ở Penn State trả lời tích cực, chỉ một ngày sau khi tôi gửi email:\n“Your application seems interesting. I certainly like students with a strong foundation in linear algebra and probability.\nPlease just apply to Penn State EE.”\nEmail này khiến tôi rất vui và tìm mọi cách tạo hồ sơ tốt nhất gửi vào Penn State.\nTôi thi GRE ngày 17/11/2012. Điểm vừa đủ để nộp hồ sơ (Verbal 145, Toán 167, Viết 3.0). Tôi biết có cố gắng thêm nữa thì điểm GRE cũng không cải thiện được nhiều nên dành thời gian tập trung cho việc chuẩn bị các văn bản khác.\nTôi chỉ đủ kinh phí nộp hồ sơ vào năm trường, trong đó Penn State là trường tôi hy vọng nhất. Cuộc phỏng vấn duy nhất của tôi là với thầy Vishal Monga vào 28 Tết năm 2013.\nBốn trường kia báo trượt, thầy Vishal Monga email cuối cùng báo sẽ nhận tôi vào ngày 21/03/2013.\nTrong cả quá trình làm hồ sơ, tôi nhận được sự giúp đỡ nhiệt tình của nhiều bạn bè. Tôi đặc biệt cảm ơn anh Phạm Toàn Thắng (PhD UC Berkeley) – người đã giúp tôi sửa hồ sơ, phỏng vấn thử và cách email cho giáo sư.\n\n\nTôi đặt chân tới nước Mỹ đầu tháng 8 năm 2013.\nTôi vào lab cùng năm với một bạn Yuelong Li người Trung Quốc. Việc đầu tiên tôi phải làm là thi một bài thi tiếng Anh xem có phải học thêm phần trình bày không. Vì tiếng Anh giao tiếp ít quan trọng trong ngành kỹ thuật hơn nên dù tiếng Anh nói còn kém, thầy vẫn nhận tôi vào lab.\nKết quả là Yuelong chỉ phải học thêm một khóa, trong khi tôi phải học ba khóa trình bày và một khóa viết học thuật – con số tối đa cho một sinh viên quốc tế tại Penn State.\nNgoài môn tiếng Anh, kỳ đầu tiên tôi lấy thêm khóa Đại số tuyến tính và khóa Xác suất Thống kê. Yuelong cũng học cùng lớp với tôi cả hai lớp này và điểm quá trình rất tốt, thường nhỉnh hơn tôi đôi chút. Sau bao năm không học toán, tôi lại cảm thấy niềm đam mê trở lại khi được học hai môn này. Trên lớp tôi phát biểu rất nhiều dù tiếng Anh còn tệ. Tôi gần như là ngôi sao trong lớp Xác suất Thống kê vì nhiều lần là người duy nhất có thể trả lời câu hỏi của thầy.\nTrong kỳ đầu tiên này, tôi được thầy hướng dẫn nhắc nhiều tới chuyện chuẩn bị cho một kỳ thi quan trọng tên là candidacy exam. Tôi chỉ có thể tiếp tục học PhD nếu vượt qua kỳ thi này. Khoa cho phép tôi thi hai lần nhưng thầy chỉ cho một lần. Thầy luôn nhắc rằng các bạn trước trong lab không những thi qua mà còn thường đạt kết quả cao nhất khoa, rằng chúng tôi phải chuẩn bị thực sự nghiêm túc.\nKỳ thi candidacy có nội dung lấy chủ yếu từ khóa Xác suất thống kê nên trong quá trình ôn thi cuối kỳ môn học này, tôi cũng đã tích lũy được khá nhiều kiến thức. Rất tiếc đây là một trong hai môn đạt điểm A-.\nKỳ nghỉ đông năm 2013, sau khi đi du lịch cùng nhóm GRE về (nhóm GRE của tôi được đi Mỹ gần hết năm đó, có hai anh chị còn lại đi năm 2014), tôi tập trung ôn tập cho kỳ thi candidacy. Tôi được 49.5/50, đứng thứ nhất khoa và nhiều hơn Yuelong 0.5 điểm (điều đầu tiên tôi nhỉnh hơn Yuelong). Kết quả kỳ thi này khiến tôi tự tin hơn nhiều. Tôi dường như đã tìm lại được đam mê bị mất hồi đại học của mình.\nTôi chính thức trở thành ứng viên PhD (PhD candidate). Việc còn lại của PhD là kỳ thi comprehensive và ba bài tạp chí khoa học (transaction papers) để có thể tốt nghiệp. Đây là một nhiệm vụ khó khăn nhưng tôi luôn tin rằng mình có thể làm được.\n\nKỳ mùa xuân năm 2014 tôi học môn Nhận dạng vật thể (Pattern Recognition) và bắt đầu thấy thích machine learning. Tôi tự tìm học thêm khóa Machine Learning của Andrew Ng và sau đó là khóa Tối ưu lồi của Stephen Boyd. Tôi chọn machine leanring vì yêu thích, và chọn học Tối ưu lồi vì đó là thế mạnh của lab. Các công trình nghiên cứu của lab đều có phần tối ưu.\nLúc đó lab tôi chủ yếu giải quyết các bài toán phân loại dựa trên việc xây dựng mô hình thưa (sparse model). Các thuật toán đó thường không yêu cầu học nhưng yêu cầu giải một bài toán tối ưu tương đối khó khi đưa ra quyết định. Tôi khá thích các mô hình thưa và các thuật toán học nên chọn hướng nghiên cứu về học từ điển (dictionary leanring).\nHè 2014 tôi được giao đề tài đầu tiên về phân loại và dò tìm các tế bào ung thư trong ảnh y tế. Bài toán này đã được giải quyết phần nào bởi một anh trong lab đã tốt nghiệp. Tôi được giao nhiệm vụ cải thiện độ chính xác của thuât toán phân loại.\nVới kiến thức hạn chế của mình hồi đó, tôi chỉ nghĩ ra được một ý tưởng rất đơn giản. Ý tưởng đó đơn giản đến mức tôi không tin chưa có bài báo nào sử dụng. Đôi khi tôi không nghĩ có thể được viết thành một bài báo khoa học với ý tưởng này.\nTôi cố gắng biến ý tưởng đó phức tạp hơn bằng nhiều cách khác nhau và lập trình tất cả các ý tưởng tôi có được. Tôi thay đổi thuật toán hàng ngày, đến mức đồng nghiệp gần như phải gắt lên: “Tại sao bạn lại luôn luôn thay đổi ý tưởng như vậy” (I don’t know why you keep changing ideas). Cuối cùng khi hạn nộp bài đến gần, tôi không còn cách nào khác phải quay lại ý tưởng đơn giản đầu tiên. Sau một vài thay đổi nhỏ, thuật toán đó làm việc rất tốt.\nBài báo bốn trang đầu tiên được tôi viết rồi sửa đi sửa lại theo ý kiến đóng góp của thầy và đồng nghiệp trong hơn ba tuần. Tôi nộp bài mà trong lòng luôn lo lắng, đến mức tôi từng mơ thấy bài báo bị từ chối vì ý tưởng đó đã được sử dụng trước đó. Rất may, chuyện đó không xảy ra và tôi có bài báo hội nghị đầu tiên được chấp nhận.\nSự tự tin trong tôi tăng lên một chút.\n\nNhư đã nhắc ở phần trên, có một quy tắc ở lab tôi là phải có ba bài báo ở các tạp chí lớn thì mới được tốt nghiệp. (Bạn có thể xem thêm Quá trình viết và nhận xét các bài báo khoa học.)\nThầy yêu cầu tôi chuẩn bị mọi thứ để mở rộng bài báo hội thảo vừa được nhận. Trong lab tôi, thường thì tại hội thảo chúng tôi sẽ trình bày các kết quả của bài tạp chí tương ứng. Vừa tự thúc mình có kết quả sớm, vừa trình bày và xin ý kiến của đồng nghiệp tại hội thảo.\nSau khi dự hội thảo vào tháng 4/2015, tôi về viết bài và tới tháng 6/2015 nộp bản thảo đầu tiên cho một tạp chí khá lớn về xử lý ảnh y tế (Transaction on Medical Imaging). Thật may mắn, tôi nhận được phản hồi vào đầu tháng Tám, nộp bản sửa vào cuối tháng Chín và nhận email báo được chấp nhận vào cuối tháng Mười. Tổng thời gian xử lý là hơn bốn tháng – rất nhanh so với trung bình.\nTôi cảm thấy PhD của mình có vẻ suôn sẻ hơn so với các bạn khác.\nSau khi có bài tạp chí đầu tiên, tôi phải chuẩn bị cho kỳ thi thứ hai trong chương trình học – comprehensive exam. Trong kỳ thi này, tôi phải trình bày ý tưởng cho đề tài tốt nghiệp trước một hội đồng gồm bốn giáo sư. Mọi thứ diễn ra suôn sẻ vì tôi có một bài tạp chí và đề xuất một ý tưởng mới cũng cho bài toán phân loại. Khi có một công trình được chấp nhận, việc bảo vệ đề xuất này trở nên đơn giản hơn  nhiều.\nSau dấu mốc này, tôi nhận thấy sự thay đổi trong cách thầy hướng dẫn nói chuyện với mình và tôi cũng thấy tự tin hơn rất nhiều khi nói chuyện với thầy.\nThực ra, tôi biết rằng nhiều ứng viên PhD có thể tốt nghiệp với chỉ một bài tạp chí khoa học. Tất nhiên, tôi không muốn dừng lại ở đó.\nTháng 2/2016, sau khi nộp thêm một bài báo hội nghị, tôi thảnh thơi về Việt Nam ăn Tết. Trước đó tôi nhận được tin một học giả người Mỹ gốc Việt tại Phòng nghiên cứu lục quân Hoa Kỳ (U.S. Army Research Lab) – một người bạn của thầy hướng dẫn – đã nhận tôi vào làm thực tập mùa hè năm 2016. Tôi cũng quay lại thực tập lần hai vào năm 2017.\nTới bây giờ, tôi thấy đáng tiếc vì lẽ ra nên tìm một chương trình thực tập tại một công ty công nghệ lớn …\nSau kỳ thi comprehensive, tôi có thêm hai bài tạp chí nữa và đang viết thêm một bài. Tôi cũng có một vài bài hội nghị, trong đó có một bài được vào danh sách ‘Finalist for the best student paper award’ tại ICASSP 2017 (hội thảo này có hơn 1000 bài báo được chấp nhận, khoảng 20 trong số đó được đề xuất cho giải thưởng bài báo xuất sắc nhất).\nThầy khá tự hào về tôi vì đây là hội thảo lớn trong ngành. Thấy thầy tự hào, tôi cũng tự hào lây.\nVới số lượng bài báo và trích dẫn cao, tôi được nhận giải luận án xuất sắc trong khoa vào tháng 4/2018 trước khi bảo vệ PhD thành công ngày 11/9/2018.\n\nPhD là một quá trình dài. Vì tôi chưa có bằng thạc sĩ khi bắt đầu nên chương trình sẽ kéo dài ít nhất năm năm. Trong thời gian này, tôi cần phải tìm cho mình nhiều thú vui khác ngoài việc nghiên cứu.\nĐầu tiên là phải tìm bạn. Tôi thấy may mắn vì Penn State có khá nhiều sinh viên Việt Nam. Có một số gia đình người Việt ở đây nên tôi cũng sớm tìm được người chơi. Những năm đầu, khi tuổi tôi gần với các bạn sinh viên đại học, tôi thường xuyên tham gia các hoạt động của hội sinh viên Việt Nam. Nhưng các bạn ấy tốt nghiệp dần và thay vào đó là các bạn trẻ hơn mình khoảng bảy tám tuổi. Tôi dần thấy mình không phù hợp với thế hệ đó nữa. Cũng may rằng tôi thuộc thế hệ cuối 8x nhưng vẫn nói chuyện được với các anh chị đầu 8x thậm chí cả 7x, và chơi rất thân. Tôi may mắn làm bạn với hai gia đình anh Quang chị Hằng và anh Long chị Duy. Những kỷ niệm đẹp cùng hai gia đình này tôi sẽ không bao giờ quên.\nTiếp theo là việc nấu ăn. Việc này tôi đã làm nhiều vì sống xa nhà từ năm chín tuổi (xem thêm Con đường học Toán của tôi). Tuy nhiên, câu chuyện nấu ăn khi học PhD lại hoàn toàn khác. Ở Việt Nam, tôi có nhiều lựa chọn nếu không có thời gian nấu ăn. Ở Mỹ thì khác, vùng tôi ở đồ ăn Việt rất hạn chế. Đồ ăn nói chung đắt và một suất ăn thường không ngon và không đủ. Rất may trong thị trấn tôi ở có nhiều người châu Á nên có hai chợ châu Á nho nhỏ, có đủ đồ đề mình kho cá, nấu bún riêu hay bất cứ món gì mà tôi nhớ đến. Youtube, trí nhớ và trí tưởng tượng đã giúp tôi nấu được nhiều món ăn. Sau này tôi và vợ có thể thay nhau nấu ăn hàng ngày được.\nTôi có khá nhiều thời gian rảnh trong những năm đầu. Thời gian đầu còn gọi điện về nói chuyện với bạn bè ở Việt Nam nhiều. Sau rồi các bạn bận việc gia đình và giờ giấc lệch nhau nên tôi ít nói chuyện dần. Tôi mua kindle và download các tiểu thuyết và sách lịch sử về đọc. Tôi quay lại niềm vui đọc sách như hồi cấp ba, có một năm tôi đọc được tới 30 cuốn sách. Thời gian cuối PhD tôi ít đọc hơn vì bận nhiều việc trong đó có việc viết blog này.\nMột thú vui quan trọng khác là chơi thể thao. Sang bên này thấy ai cũng chơi thể thao, nhiều người đẹp trong khi mình hồi đầu thì hơi còi. Tôi chơi rất nhiều môn: chạy, đá bóng, đạp xe, bơi, leo núi, trèo tường (bouldering). Có thể chất tốt rồi tinh thần cũng thoải mái hơn và có sức chạy đường dài PhD.\nĐừng để mình bị ốm ở nước Mỹ. Bạn phải tự chăm sóc vì ai cũng có việc riêng của mình. Thuốc lại rất đắt và bạn vẫn phải đi làm khi bị ốm nhẹ.\nHè năm 2016 khi đang thực tập tại Phòng nghiên cứu lục quân Hoa Kỳ, tôi có khá nhiều thời gian rảnh vì đã nộp bài tạp chí thứ hai. Tôi tạo một kênh Youtube Hướng dẫn LaTex cơ bản. Vì lab tôi yêu cầu các báo cáo, bài báo và slide phải được làm bằng LaTex, sau ba năm làm việc, tôi tự tin với kỹ năng sử dụng LaTex của mình. Tất cả các hình vẽ trong PhD của tôi cũng được vẽ bằng LaTex với chất lượng cao. Vì vậy tôi muốn chia sẽ những gì mình biết thông qua kênh Youtube này.\nTuy nhiên, tôi sớm nhận ra rằng việc tạo các clip tốn quá nhiều thời gian và rất khó khăn nếu muốn chỉnh sửa về sau. Lượng khán giả cũng ít vì LaTex kén người học. Tôi dừng việc ra clip sau khoảng hai tháng.\nKỳ nghỉ đông cuối năm 2016, lúc đó tôi đang ở năm thứ tư của chương trình PhD, tôi bắt đầu lên kế hoạch chuẩn bị cho xin việc sau khi ra trường. Lúc đó machine leanring/deep learning đã nở rộ và nhà nhà người người nói về nó. Tôi thấy rằng mình cần phải chuẩn bị kỹ các kiến thức về lĩnh vực này. Tôi có tham gia một nhóm nhỏ ở Việt Nam dịch cuốn Deep learning nhưng sớm rời nhóm. Tôi nhận thấy nhóm này làm việc chưa hiệu quả và nhiều thành viên chưa nắm vững các khái niệm cơ bản. Tôi bắt đầu nhen nhóm ý tưởng tự viết lại các thuật toán theo cách hiểu của mình.\nVà blog ‘Machine Learning cơ bản’ ra đời. Sau đó là facebook page, facebook group, fundaml, ebook, sách giấy (đang in) và gần đây nhất là diễn đàn Machine Learning cơ bản.\n\nNăm cuối cùng của chương trình PhD tôi gần như không có công trình khoa học nào mới. Phần vì tôi dành khá nhiều thời gian cho Machine Learning cơ bản, phần vì tôi biết mình đã đủ điều kiện để tốt nghiệp, phần còn lại là tôi phải tập trung xin việc.\nKhông giống các thành viên khác trong lab, việc xuất bản các bài báo của tôi khá suôn sẻ. Tất cả các bài có tên tôi đều được chấp nhận.\nVà cũng không giống những bạn đã tốt nghiệp trước đó, quá trình xin việc của tôi trắc trở hơn rất nhiều. Trước tôi, các bạn tốt nghiệp xin được việc ở Apple, Microsoft và nhiều phòng nghiên cứu khác. Tôi tự tin cho rằng mình cũng có thể xin được việc trong hai ba tháng và có thể tốt nghiệp vào mùa hè năm 2018.\nNhững năm trước khi xin thầy hướng dẫn đi thực tập ở các công ty, thầy hướng dẫn luôn nói rằng tôi không nên lo quá sớm về công việc, rằng tôi cần bình tĩnh, rằng khả năng của tôi tốt nên sẽ có việc tốt.\nQuá trình xin việc của tôi kéo dài nửa năm, từ cuối tháng Hai đến cuối tháng Tám năm 2018. Tôi thực hiện khoảng 50 cuộc phỏng vấn qua điện thoại, đi phỏng vấn onsite tại tám công ty. Bay khoảng hai ba chục chuyến và lái xe hàng ngàn dặm trong mùa hè. Tôi rất thích Seattle nhưng ba công ty mời tôi đến phỏng vấn đều cho rằng tôi thiếu kinh nghiệm thực tế. Điều tương tự xảy ra với hai công ty ở bờ Đông nước Mỹ. Tới tận gần ngày bảo vệ tốt nghiệp tôi mới nhận được hai thư chấp nhận tại hai công ty khởi nghiệp tại Sillicon Valley. Sau khi hỏi ý kiến nhiều bạn bè, tôi quyết định nhận vị trí ‘Deep Learning and Computer Vision Researcher’ của một công ty làm về xe tự lái. Tôi là nhân viên thứ 13 của công ty.\nThầy tôi nói vui rằng không ai có nhiều phỏng vấn onsite như tôi, và luôn động viên tôi tự tin vì có nhiều công ty gọi phỏng vấn như thế. \nTheo tôi chuyện này dễ hiểu vì những người khác có việc sau khi phỏng vấn với hai hoặc ba công ty nên họ dừng lại. Tôi có buồn sau khi nhận được những email từ chối đầu nhưng sau tôi không còn thời gian để mà buồn vì còn phải lo quá nhiều việc, cả việc cá nhân, trong mùa hè năm 2018. Tôi buồn nhưng không bao giờ mất hy vọng.\n\nLịch bảo vệ của tôi là cuối tháng Năm nhưng phải lùi lại tới đầu tháng Chín. Tôi không thể bảo vệ khi chưa có việc vì visa không cho phép tôi ở lại quá lâu mà không có việc. Tôi phải lên lịch bảo vệ trước khi có việc vì lúc đó đã quá muộn. Từ tháng Tám tôi không còn được nhận lương, tháng Chín phải nộp học phí và bảo hiểm cho kỳ mùa thu. Tôi biết mình không còn nhiều thời gian và số tiền tiết kiệm chỉ có thể giúp tôi sống ba tháng ở Mỹ. Thật may mắn, mọi chuyện tốt đẹp cuối cùng xảy đến cùng nhau.\nLuôn hy vọng, nhưng đừng kỳ vọng quá cao. Phải hy vọng và lạc quan vì suy nghĩ tiêu cực không bao giờ khiến vấn đề tốt lên. Đừng kỳ vọng cao để khi kết quả không như ý muốn mình không bị suy sụp.\nNước Mỹ dạy tôi phải luôn cố gắng, phải giữ niềm tin và sức khỏe cho những mục tiêu dài hơi.\nBest things come to those who wait.\n\n[1] Con đường học Toán của tôi\n[2] Học PhD để làm gì\n[3] Viết và nhận xét các bài báo khoa học\n[4] Chúng tôi đã apply và học tiến sĩ như thế nào?"
    },
    {
        "ID": 2,
        "URL": "https://machinelearningcoban.com/2018/10/03/conv2d",
        "Title": "Machine Learning cơ bản",
        "Content": "Tích chập đóng một vai trò quan trọng và xuất hiện từ sớm \ntrong lịch sử xử lý tín hiệu số. Việc tìm ra các bộ lọc phù hợp cho mỗi loại tín hiệu \nvà mỗi bài toán đã được nghiên cứu và giảng dạy rất nhiều trong các giáo trình kỹ thuật.\nCuối những năm 1980s, Yann Lecunn đề xuất một mô hình tích chập hai chiều cho dữ\nliệu ảnh và thu lại thành công lớn trong bài toán phân loại chữ số viết tay.\nBằng việc sử dụng rất nhiều dữ liệu và thay các tầng nối kín (fully connected\nlayer) trong mạng perceptron đa tầng bởi tích chập hai chiều, các bộ lọc phù hợp\nvới bài toán và dữ liệu có thể được học để mang lại kết quả phân lớp tốt nhất.\nTrong bài viết này, tôi sẽ trình bày cơ sở toán học của tích chập một chiều và\ntích chập hai chiều. Kiến trục mạng neuron tích chập sẽ được trình bày cụ thể trong bài tiếp theo.\n\n\nXét tín hiệu một chiều x_clean có dạng hình sin như trong Hình 1a):\nTín hiệu này bị tác động bởi nhiễu Gauss:\nLúc này, tín hiệu không mượt nữa mà có dạng răng cưa như Hình 1b).\nChỉ với một bộ lọc trung bình đơn giản, ta có thể thu được tín hiệu ít nhiễu hơn\nnhư trong Hình 1c):\nỞ đây, hàm conv1d thực hiện việc lấy tích chập giữa tín hiệu x_noisy và bộ\nlọc trung bình w. Hàm số này sẽ được trình bày ở phần dưới. Trước hết, chúng\nta nhắc lại công thức tính tích chập một chiều trong xử lý tín hiệu số.\nXét tín hiệu một chiều \\(a(n)\\) và bộ lọc (filter) \\(w(n)\\). Tích chập của tín hiệu và bộ lọc\nlà một tín hiệu một chiều mới \\(b(n)\\) được xác định theo công thức:\nTrong mạng neuron tích chập, tích chập được định nghĩa khác đi một chút. Cho tín\nhiệu đầu vào và bộ lọc lần lượt là các vector \\(\\mathbf{a}\\in \\mathbb{R}^N\\) và\n\\(\\mathbf{w} \\in \\mathbb{R}^f\\) (\\(f\\) có thể là một số tự nhiên bất kỳ nhưng thường\nlà số lẻ). Khi đó đầu ra là một vector \\(\\mathbf{y}\\) với từng phần tử được tính bởi:\nvới \\(n\\) thỏa mãn \\(0 \\leq n+i < N, ~\\forall i = 0, 1, \\dots, f-1\\). Điều này tương\nđương với \\(0 \\leq n < N - f + 1\\). Vậy \\(\\mathbf{y} \\in \\mathbb{R}^{N-f + 1}\\).\nTừ đây, khi đề cập tới khái niệm tích chập, chúng ta sẽ ngầm hiểu công thức\n(2) đang được sử dụng.\nCách tính tín hiệu đầu ra \\(\\mathbf{y}\\) được minh họa trong Hình 2.\nQuá trình tính đầu ra \\(\\mathbf{y}\\) có thể được thực hiện như sau:\nĐặt bộ lọc \\(\\mathbf{w}\\) vào vị trí tương ứng với \\(f\\) phần tử đầu tiên của\n\\(\\mathbf{a}\\).\nNhân từng phần tử tương ứng của \\(\\mathbf{w}\\) và \\(\\mathbf{a}\\) rồi cộng các kết\nquả lại để được phẩn tử tương ứng của \\(\\mathbf{y}\\).\nTrượt bộ lọc \\(\\mathbf{w}\\) một bước sang bên phải. Nếu phần tử cuối cùng của\nbộ lọc không vượt ra ngoài phần tử cuối cùng của tín hiệu, quay lại Bước 2.\nNgược lại, dừng các bước tính toán.\nTrong ví dụ này:\n\nNhận thấy rằng kích thước của đầu ra \\(\\mathbf{y}\\) nhỏ hơn kích thước của đầu vào\n\\(\\mathbf{x}\\) vì ta đang giả sử cả bộ lọc phải nằm trọn vẹn trong tín hiệu đầu\nvào.\nTrong trường hợp muốn tín hiệu đầu ra có kích thước bằng tín hiệu đầu vào, ta\ncó thể giả sử giả sử tín hiệu đầu vào có thêm các giá trị bằng không ở hai phía.\nKỹ thuật này được gọi là thêm lề (padding). Để có kích thước bằng nhau, tín\nhiệu đầu vào cần được thêm \\(f-1\\) giá trị bằng không. Khi \\(f\\) là một số lẻ, mỗi\nphía của tín hiệu vào thường được thêm \\(P = (f-1)/2\\) giá trị bằng không.\nGiá trị \\(P\\) có thể là một số tự nhiên bất kỳ tùy thuộc vào từng trường hợp, \\(P\\)\nkhông nhất thiết phải đảm bảo kích thước đầu ra và đầu vào của tín hiệu là như\nnhau. Khi không sử dụng thêm lề, \\(P = 0\\).\nViệc thêm lề được minh họa trong Hình 3. Khi \\(f = 3\\), ta thêm \\(P=1\\) ô bằng không vào mỗi phía của \\(\\mathbf{a}\\). Khi đó \\(\\mathbf{y}\\) và \\(\\mathbf{a}\\) có kích thước như nhau.\n\nTrong Hình 2, bộ lọc \\(\\mathbf{w}\\) được dịch sang phải một ô sau mỗi phép tính.\nTrong một số trường hợp, ta có thể dịch bộ lọc đi nhiều ô sau mỗi phép tính. Số\nlượng ô được dịch này được gọi là bước trượt (stride), ký hiệu là \\(S\\). Lúc\nnày, công thức tổng quát của (2) trở thành:\nTrong trường hợp có sử dụng thêm lề với độ rộng lề mỗi phía là \\(P\\), kích thước\nđầu vào là \\(N + 2P\\), giá trị \\(n\\) trong \\((3)\\) cần thỏa mãn:\nThông thường, \\(P\\) và \\(S\\) được chọn sao cho \\(\\frac{N+2P - f}{S}\\) là số nguyên.\nĐiều này kéo theo kích thước tổng quát của đầu ra khi có thêm lề \\(P\\) và bước trượt\n\\(S\\) là:\nCông thức (4) rất quan trọng, chúng ta cần nhớ để thiết kế kích thước của các bộ\nlọc, kích thước lề và bước trượt trong các mạng neuron tích chập.\nTích chập một chiều có thể được thực hiện bằng numpy như dưới đây. Ở đây, hệ số\nđiều chỉnh b được thêm vào cho trường hợp tổng quát:\n\nTích chập được mở rộng ra cho trường hợp dữ liệu nhiều chiều. Trong phạm vi bài\nviết, \nchúng ta sẽ dừng lại ở phép tính tích chập hai chiều với dữ liệu đầu vào chủ yếu\nlà ảnh.\nCách tính tích chập hai chiều với các trường hợp thêm lề và bước trượt khác nhau\nđược minh họa trên Hình 4. Các ảnh động này được lấy từ tài khoản Github\nvdumoulin.\nVề cơ bản, bộ lọc (màu xám) trượt khắp tín hiệu hai chiều đầu vào (màu lam) theo thứ tự từ\ntrái qua phải, từ trên xuống dưới. Tại mỗi vị trí, các giá trị của bộ lọc và đầu\nvào tương ứng được nhân với nhau rồi cộng lại để thu được kết quả đầu ra. Hệ số\nđiều chỉnh cũng có thể được thêm vào.\n\nTrong trường hợp tín hiệu đầu vào và bộ lọc là các ma trận hai chiều đơn kênh\n(ảnh màu có thể được cọi là tín hiệu hai chiều với ba kênh, ảnh xám là tín hiệu\nhai chiều đơn kênh). \nCách tính tích chập có thể được thực hiện như sau:\nỞ đây ta giả sử rằng mỗi phía của tín hiệu hai chiều được thêm một đại lượng lề pad bằng nhau. Đoạn mã này có thể dễ \ndàng được mở rộng ra cho trường hợp thêm lề không đều. Tương tự, bộ \nlọc không nhất thiết vuông. Tuy nhiên, các trường hợp này ít xuất hiện trên thực tế.\nGiảm nhiễu, làm mờ ảnh\nTiếp theo, chúng ta cùng xem việc áp dụng các bộ lọc khác nhau vào bức ảnh trong\nHình 4b). Hình 4b) là ảnh xám tương ứng với Hình 4a).\nQuan sát một ví dụ với việc khử nhiễu trong Hình 5.\nHình 5a) được tạo bằng cách thêm nhiễu Gauss vào ảnh xám:\nHình 5b) thu được bằng cách sử dụng bộ lọc trung bình với \\(f = 3\\):\nBộ lọc được sử dụng là \\(w = \\frac{1}{9}\\left[\\begin{matrix} 1 & 1 & 1 \\\\ 1 & 1 & 1 \\\n1& 1 & 1\\end{matrix}\\right]\\). Điều này nghĩa là giá trị của một điểm ảnh đầu ra\nbằng trung bình cộng của hình vuông \\(3\\times3\\) có tâm tại vị trí tương ứng của\nđiểm ảnh đầu vào. Việc lấy trung bình giúp mỗi điểm ảnh đầu ra có giá trị không\nquá khác biệt so với các giá trị xung quanh. Điều này gián tiếp giúp giảm\nnhiễu (denoise). Một hiệu ứng phụ của bộ lọc trung bình là nó khiến bức ảnh ban đầu bị mờ\nđi.\nNếu thay một bộ lọc lớn hơn với \\(f = 7\\), ta sẽ thu được kết quả như Hình 5c). Ta\nquan sát thấy rằng các đường nét trên khuôn mặt không còn rõ ràng như hình 4b).\nBộ lọc này gián tiếp làm mờ thêm hậu cảnh ở vị trí ánh đèn phía sau cô gái.\nDò cạnh\nDò cạnh của vật thể là một nhiệm vụ quan trọng trong xử lý ảnh. Hình 6 biểu diễn\nkết quả dò cạnh thẳng đứng và nằm ngang trong ảnh bằng hai bộ lọc đơn giản.\nBộ lọc được sử dụng trong Hình 6b) là \\(w = \\left[\\begin{matrix} -1 & 0 & 1 \\\\ -1\n& 0 & 1 \\\\ -1 & 0 & 1\\end{matrix}\\right]\\). Giá trị điểm ảnh đầu ra (điểm tương ứng với\nvị trí chính giữa bộ lọc) bằng tổng các điểm liền kề ở bên phải trừ đi tổng các\nđiểm liền kề ở bên trái. Giá trị này sẽ có trị tuyệt đối lớn nếu sự chênh lệch\ngiữa các điểm hai bên lớn. Điều này đồng nghĩa với việc giá trị ảnh đầu ra lớn\ntại cạnh thẳng đứng của vật thể. Đồng thời, nếu bộ lọc đang ở vị trí mà các điểm trong hình\nvuông \\(3\\times 3\\) xấp xỉ nhau, giá trị điểm ảnh đầu ra tương ứng sẽ xấp xỉ\nkhông. Trong Hình 6, các bức ảnh được hiển thị sau khi lấy trị tuyệt đối của ảnh\nđầu ra. Các điểm ảnh màu đen (giá trị gần không) tương ứng với các khu vực đồng\nnhất. Các điểm ảnh màu trắng (giá trị lớn) tương ứng với các cạnh thẳng đứng. Trong trường\nhợp này, chỉ các cạnh có phương thẳng đứng được tìm thấy.\nĐể tìm các cạnh có phương nằm ngang, ta sử dụng bộ lọc \\(w = \\left[\\begin{matrix}\n-1 & -1 & -1 \\\\ 0 & 0 & 0 \\\\ 1 & 1 & 1\\end{matrix}\\right]\\) để thu được kết quả\nnhư Hình 6c).\nViệc tìm các cạnh có hướng bất kỳ cũng có thể được thực hiện bằng các bộ lọc phù hợp.\nNhư vậy, chúng ta có thể thu được các phép biến đổi với ảnh thông qua các bộ lọc\nđơn giản được xác định từ trước. Các bộ lọc này hoàn toàn có thể được tối ưu tùy\ntheo dữ liệu và bài toán.\n\nTrong trường hợp tín hiệu đầu vào đa kênh, ví dụ ảnh màu bao gồm ba kênh: đỏ,\nlục, lam; mỗi kênh là một ma trận hai chiều. Giả sử kích thước của đầu vào là\n\\((H_0, W_0, C_0)\\) với \\(C_0\\) là số kênh. Khi đó, bộ lọc cũng có thể được mở rộng\nra với số kênh tương ứng để có kích thước \\((f, f, C_0)\\) (các kênh của bộ lọc không nhất thiết bằng nhau). Để\ntính đầu ra, ta cũng trượt bộ lọc đi khắp ảnh, tính tích từng thành phần tương\nứng và lấy tổng toàn bộ các tích đó. Các tính với tín hiệu đa kênh được minh\nhọa trong Hình 7b).\nTổng quát, giả sử đầu vào là một mini-batch của tín hiệu có kích thước \\((m,\nH_0, W_0, C_0)\\).  Bộ lọc cũng ở dạng tổng quát với kích thước \\((f, f, C_0, C_1)\\)\n(\\(C_1\\) bộ lọc đa kênh). Khi đó, đầu ra sẽ là một mảng bốn chiều với kích thước\n\\((m, H_1, W_1, C_1)\\).\nVí dụ, nếu đầu vào là \\(m\\) bức ảnh màu ba kênh với kích thước \\((m, H_0, W_0, 3)\\)\nthì đầu ra sẽ là \\(m\\) bức ảnh, mỗi bức ảnh có kích thước \\((H_1, W_1)\\) và có\n\\(C_1\\) kênh.\nViệc tính tích chập hai chiều tổng quát có thể được thực hiện như sau:\n\nTích chập hai chiều tổng quát và các biến thể đóng vai trò quan trọng trong việc\nxây dựng các mạng neuron tích chập. Các thành phần cơ bản của một mạng\nneuron tích chập sẽ được đề cập trong bài tiếp theo. Mời các bạn đón đọc.\nMã nguồn trong bài này có thể được tìm thấy tại đây.\n\nImage kernels explained visually\nA technical report on convolution arithmetic in the context of deep learning"
    },
    {
        "ID": 3,
        "URL": "https://machinelearningcoban.com/2018/09/11/forum/",
        "Title": "Machine Learning cơ bản",
        "Content": "Chào các bạn,\nSau một khảo sát nhỏ trên Facebook Group ‘Forum Machine Learning cơ bản’, tôi thấy nhiều ý kiến cho rằng nên chọn một nền tảng thảo luận khác tốt hơn Facebook. Nền tảng này nên hỗ trợ việc trình bày các ý tưởng một cách chuyêu sâu và sắp xếp các câu hỏi/hướng dẫn theo đề mục.\nTôi và một vài người bạn đã quyết định tạo Diễn đàn Machine Learning cơ bản cho cộng đồng. Về lâu dài, đây sẽ là một nền tảng tốt cho việc thảo luận. Hiện đã có trên 1000 thành viên đăng ký và nhiều chủ để thú vị.\nMời các bạn tham gia chia sẻ ý kiến và đặt các câu hỏi.\nChúc một ngày tốt lành"
    },
    {
        "ID": 4,
        "URL": "https://machinelearningcoban.com/2018/07/06/deeplearning/",
        "Title": "Machine Learning cơ bản",
        "Content": "Bài viết này được thực hiện với sự đóng góp của Nguyễn Tiến Cường, Cao Thanh Hà, Đinh Duy Khánh, và Nguyễn Văn Tài. Các bạn này cũng sẽ giúp tôi trong các bài về deep learning tiếp theo.\nTrong trang này: \n\n\nKể từ 2012 khi deep learning có bước đột phá lớn, hàng loạt các thư viện hỗ trợ deep learning ra đời. Cùng với đó, ngày càng nhiều kiến trúc deep learning ra đời, khiến cho số lượng ứng dụng và các bài báo liên quan tới deep learning tăng lên chóng mặt.\nCác thư viện deep learning thường được ‘chống lưng’ bởi những hãng công nghệ lớn: Google (Keras, TensorFlow), Facebook (Caffe2, Pytorch), Microsoft (CNTK), Amazon (Mxnet), Microsoft và Amazon cũng đang bắt tay xây dựng Gluon (phiên bản tương tự như Keras). (Các hãng này đều có các dịch vụ cloud computing và muốn thu hút người dùng).\nVậy thư viện nào là tốt nhất? Câu trả lời tuỳ thuộc vào việc bạn quen với hệ điều hành, ngôn ngữ lập trình nào, bạn sử dụng deep learning vào mục đích nghiên cứu hay ra sản phẩm, bạn sử dụng trên nền tảng phần cứng nào, v.v.\nNhìn chung, một thư viện deep learning tốt cần có các đặc điểm sau:\nHỗ trợ tính toán với GPU và các hệ thống phân tán. Điều này là tối quan trọng vì việc huấn luyện các mô hình deep learning yêu cầu khả năng tính toán rất mạnh.\nHỗ trợ các ngôn ngữ lập trình phổ biến: C/C++, Python, Java, R, …\nCó thể chạy được trên nhiều hệ điều hành.\nThời gian từ ý tưởng tới xây dựng và huấn luyện mô hình ngắn.\nCó thể chạy trên trình duyệt và các thiết bị di động.\nCó khả năng giúp người lập trình can thiệp sâu vào mô hình và tạo ra các mô hình phức tạp.\nChứa nhiều model zoo, tức các mô hình deep learning thông dụng đã được huấn luyện.\nHỗ trợ tính toán backpropagation tự động.\nCó cộng đồng hỏi đáp lớn.\nThật khó có thể chỉ ra một thư viện đáp ứng tốt tất cả các yêu cầu phía trên. Các bạn có thể xem các bài so sánh các thư viện này ở phần Tài liệu tham khảo. Tôi chỉ xin giới thiệu một vài thống kê giúp các bạn có cái nhìn nhanh nhất về thư viện nào được sử dụng nhiều nhất.\nNhững so sánh trên đây chỉ ra rằng TensorFlow, Keras và Caffe là các thư viện được sử dụng nhiều nhất (gần đây có thêm PyTorch rất dễ sử dụng và đang thu hút thêm nhiều người dùng).\nKeras được coi là một thư viện ‘high-level’ với phần ‘low-level’ (còn được gọi là backend) có thể là TensorFlow, CNTK, hoặc Theano (sắp tới Theano sẽ không được duy trì nâng cấp nữa). Keras có cú pháp đơn giản hơn TensorFlow rất nhiều. Với mục đích giới thiệu về các mô hình nhiều hơn là các sử dụng các thư viện deep learning, tôi sẽ chọn Keras với TensorFlow là ‘backend’.\n(Bản thân tôi khi làm nghiên cứu thường dùng TensorFlow và Pytorch.)\nCác bạn có thể đọc thêm bài Why use Keras? trên trang chủ của Keras (Tất nhiên trên trang chủ của thư viện nào cũng sẽ có một bài tương tự kiểu ‘Why use …?’). Tôi xin nêu lại một vài gạch đầu dòng:\nKeras ưu tiên  trải nghiệm của người lập trình\nKeras đã được sử dụng rộng rãi trong doanh nghiệp và cộng đồng nghiên cứu\nKeras giúp dễ dàng biến các thiết kế thành sản phẩm\nKeras hỗ trợ huấn luyện trên nhiều GPU phân tán\nKeras hỗ trợ đa backend engines và không giới hạn bạn vào một hệ sinh thái\nAmazon hiện cũng đang làm việc để phát triển MXNet backend cho Keras.\nMô hình Keras có thể được huấn luyện trên một số nền tảng phần cứng khác nhau ngoài CPU:\nHy vọng chừng đó đã đủ để chúng ta cùng bắt đầu với Keras. Cách cài đặt Keras có thể được tìm thấy trên trang chủ của nó.\nTiếp theo, chúng ta sẽ làm quen với Keras qua ba ví dụ đơn giản: linear regression, logistic regression, và multi-layer perceptron.\n\nViệc huấn luyện một mô hình deep learning hay neural network nói chung bao gồm các bước:\nChúng ta cùng xem Keras thực hiện các bước này thông qua hai ví dụ dưới đây.\n\nTa cùng làm một ví dụ đơn giản. Dữ liệu đầu X vào có số chiều là 2, đầu ra y = 2*X[0] + 3*X[1] + 4 + e với e là nhiễu tuân theo một phân phối chuẩn có kỳ vọng bằng 0, phương sai bằng 0.2.\nDưới đây là đoạn code ví dụ về huấn luyện mô hình linear regression bằng Keras:\nKết quả:\nTa thấy răng thuật toán hội tụ khá nhanh và MSE loss khá nhỏ sau khi huấn luyện xong.\nChúng ta cùng xem xét từng bước:\nSequantial([<a list>]) là thể hiện việc các layer được xây dựng theo đúng thứ tự trong [<a list>]. Phần tử đầu tiên của list thể hiện kết nối giưa input layer và layer tiếp theo, các phần tử tiếp theo của list thể hiện kết nối của các layer tiếp theo.\nDense thể hiện một fully connected layer, tức toàn bộ các unit của layer trước đó được nối với toàn bộ các unit của layer hiện tại. Giá trị đầu tiên trong Dense bằng 1 thể hiện việc chỉ có 1 unit ở layer này (đầu ra của linear regression trong trường hợp này bằng 1). input_shape = (2,) chính là kích thước của dữ liệu đầu vào. Kích thước này là một tuple nên ta cần viết dưới dạng (2,). Về sau, khi làm việc với dữ liệu nhiều chiều, ta sẽ có các tuple nhiều chiều. Ví dụ, nếu input là ảnh RGB với kích thước 224x224x3 pixel thì input_shape = (224, 224, 3).\nCác layer cũng có thể được thêm lần lượt vào model bằng cách sử dụng hàm .add(). Đoạn code phía trên và đoạn code ngay dưới đây là tương đương.\nActivation cũng có thể được tách ra thành riêng một layer như sau:\nBạn đọc có thể đọc về các activation của Keras tại đây.\nĐoạn code tiếp theo:\nThể hiện việc chọn phương pháp cập nhật nghiệm, ở đâu ta sử dụng Stochastic Gradient Descent (SGD) với learning rate lr=0.1. Các phương pháp cập nhật nghiệm khác có thể được tìm thấy tại Keras-Usage of optimizers.\nloss='mse' chính là mean squared error, là hàm mất mát của linear regression.\nSau khi xây dựng được mô hình và chỉ ra phương pháp cập nhật cũng như hàm mất mát, ta huấn luyện mô hình bằng:\n(Keras khá giống với scikit-learn ở chỗ cùng huấn luyện các mô hình bằng phương thức .fit()). Ở đây, epochs chính là số lượng epoch và batch_size chính là kích thước của một mini-batch.\nĐể xem hệ số tìm được của linear regression, ta sử dụng:\nKết quả:\nở đó, phần tử thứ nhất của list này chính là hệ số tìm được, phẩn tử thứ hai chính là bias. Kết quả này gần với nghiệm mong đợi của bài toán (y = 2*X[0] + 3*X[1] + 4).\nTương đối đơn giản.\n\nQuay lại ví dụ về mối liên hệ giữa số giờ ôn tập và kết quả thi trong bài logistic regression, bài toán có thể được giải quyết bằng keras như sau:\nCó hai sự khác biệt ở Activation và loss vì logistic regression sử dụng hàm activation là sigmoid, hàm mất mát là trường hợp đặc biệt của cross entropy với hai class.\nKết quả tìm được tương đối giống với kết quả tìm được trước đó với numpy.\nvà ta có y ~ 1.51*x - 4.12.\n\nChúng ta cùng xây dựng một mạng MLP đơn giản với Keras để giải quyết một bài toán phân loại ảnh.\n\nCơ sở dữ liệu ảnh được dùng là Fashion-MNIST.\nChúng ta đã quá quen với việc sử dụng MNIST. MNIST là cơ sở dữ liệu về chữ số viết tay, được sử dụng rất rộng rãi trong cồng đồng AI/ML. MNIST thường được thử đầu tiên khi có một thuật toán phân loại ảnh mới. Một số người nói “If it doesn’t work on MNIST, it won’t work at all”. Nhưng đồng thời, “Well, if it does work on MNIST, it may still fail on others.”\nFashion-MNIST được tạo ra gần đây với kích thước tương tự như MNIST nhưng các ảnh là các ảnh xám của trang phục với các nhãn: (0) T-shirt/top, (1) Trouser, (2) Pullover, (3) Dress, (4) Coat, (5) Sandal, (6) Shirt, (7) Sneaker, (8) Bag, (9) Ankle boot. Fashion-MNIST cũng có 10 class, 60000 ảnh cho training, 10000 ảnh cho test, mỗi ảnh có kích thước 28x28 pixel và là các ảnh xám với chỉ một channel. Dưới đây là một ví dụ về ảnh của class (2) Pullover.\nTác giả của Fashion-MNIST cho rằng cần phải thay thế MNIST vì:\nMNIST đã trở nên quá dễ. Rất nhiều thuật toán deep learning đã đạt được độ chính xác lên tới 99.7%, ngay cả KNN cũng đạt được trên 96%. Rất khó để đánh bại con số 99.7%, và nếu mô hình của bạn đạt được con số này, ta vẫn khó có thể kết luận ngay đó là một mô hình tốt.\nMNIST được sử dụng quá nhiều đến mức nhàm chán.\nMNIST không đại diện cho các bài toán computer vision hiện đại.\nCơ sở dữ liệu Fashion-MNIST có thể được tải về thông qua keras.datasets\nỞ đây, x_train, x_test mang các giá trị nguyên từ 0 đến 255, y_train, y_test chứa các số nguyên từ 0 đến 9 thể hiện class của x tương ứng. Nếu sử dụng một neural network với softmax layer ở cuối, ta cần chuẩn hoá dữ liệu đầu vào x_train, x_test về đoạn [0, 1] và chuyển y_train, y_test về dạng one-hot coding.\nViệc này có thể được thực hiện như sau:\n\nTa đã thực hiện bước đầu tiên trong bài toán xây dựng mô hình neural network cho bài toán classification – bước chuẩn bị dữ liệu.\nTrong mục này, chúng ta sẽ đi xây dựng một neural network đơn giản. Một mô hình đủ đơn giản giúp chúng ta tiếp tục làm quen với Keras là multi-layer perceptron.\nTa sẽ xây dựng một MLP với 3 hidden layers. Các layer cụ thể như sau:\nHàm mất mát là cross entropy, ta tạm thời chưa quan tâm đến regularization (ở đây là weight decay).\nPhương pháp đánh giá hệ thống phân lớp này là 'accuracy', tức số lượng điểm được phân loại đúng trong toàn bộ số điểm.\nNetwork đơn giản này được thực hiện trên Keras như sau:\nỞ đây có một hàm mới là Flatten(), hàm này biến mỗi điểm dữ liểu ở dạng một mảng nhiều chiều thành một mảng một chiều. Vì ta đang sử dụng MLP nên ta cần làm công việc này. Về sau, khi sử dụng CNN, việc giữ nguyên mảng hai chiều sẽ cho kết quả tốt hơn.\nKết quả sau khi thực hiện đoạn code trên\nSau 20 epochs, mô hình cho độ chính xác trên tập huấn luyện x_train khá cao.\nNếu chúng ta muốn đánh giá mô hình trên tập x_test, ta có thể thực hiện như sau:\nNhư vậy, độ chính xác của mô hình trên tập kiểm thử đạt 88.4%.\nBạn đọc có thể thử giải quyết bài toán này bằng các thuật toán phân loại khác và so sánh kết quả.\n\nDữ liệu đầu vào chỉ là 784 chiều và đặc trưng cho dữ liệu thời trang cũng không quá phức tạp trên nền là một màu đen và ảnh đã được căn chỉnh đúng tâm, đúng kích thước. MLP mặc dù cho kết quả tương đối tốt trong bài toán này, nó không phải là một mô hình tối ưu cho dữ liệu dạng ảnh vì ít nhất, dữ liệu ảnh hai chiều ban đầu đã được dàn phẳng ra thành dữ liệu một chiều, làm mất đi những thông tin về không gian trong ảnh (spatial information). Convolutional neural network thông thường sẽ cho kết quả tốt hơn. Tôi sẽ sớm giới thiệu với bạn đọc về kiến trúc này.\nMạng MLP đơn giản này chưa dùng nhiều kỹ thuật của deep learning, chúng ta sẽ dần làm quen với các kỹ thuật giúp tăng độ chính xác và giảm thời gian huấn luyện trong các bài sau.\n\nKeras là một thư viện tương đối dễ sử dụng đối với người mới bắt đầu. Nó cung cấp các hàm số cần thiết với cú pháp đơn giản.\nKhi đi sâu hơn vào deep learning trong các bài sau, chúng ta sẽ dần làm quen với các kỹ thuật lập trình với Keras. Mời các bạn đón đọc.\nSource code trong bài này có thể được tìm thấy tại đây.\n\n[1] Battle of the Deep Learning frameworks — Part I: 2017, even more frameworks and interfaces\n[2] Keras hompage\n[3] Comparison of deep learning software – Wikipedia"
    },
    {
        "ID": 5,
        "URL": "https://machinelearningcoban.com/2018/06/22/deeplearning/",
        "Title": "Machine Learning cơ bản",
        "Content": "Tôi xin tạm dừng các bài viết về Decision Tree để chuyển sang Deep Learning.\nTôi sẽ quay lại với các thuật toán Machine Learning cổ điển khi có dịp\nTrong trang này: \n\n\nNhư đã một lần nhắc đến trong bài đầu tiên của blog,\ntrí tuệ nhân tạo đang len lỏi vào trong cuộc sống và ảnh hưởng sâu rộng tới mỗi\nchúng ta. Kể từ khi tôi viết bài đầu tiên, tần suất chúng ta nghe thấy các cụm\ntừ ‘artificial intelligence’, ‘machine learning’, ‘deep learning’ cũng ngày một\ntăng lên. Nguyên nhân chính dẫn đến việc này (và việc ra đời blog này) là sự\nxuất hiện của deep learning trong 5-6 năm gần đây.\nMột lần nữa xin được dùng lại hình vẽ mô tả mối quan hệ giữa artificial\nintelligence, machine learning, và deep learning:\nTrong bài viết này, tôi sẽ trình bày sơ lược về lịch sử deep learning. Trong các\nbài tiếp theo, tôi có tham vọng viết thật kỹ về các thành phần cơ bản của các hệ\nthống deep learning. Xa hơn nữa, blog sẽ có thêm các bài hướng dẫn cho nhiều bài\ntoán thực tế.\nBlog luôn đón nhận những đóng góp để chất lượng các bài viết được tốt hơn. Nếu\nbạn có đóng góp nào, vui lòng để lại trong phần comment, tôi sẽ cập nhật bài\nviết cho phù hợp. Cảm ơn bạn.\n\nDeep learning được nhắc đến nhiều trong những năm gần đây, nhưng những nền tảng cơ bản đã xuất hiện từ rất lâu …\nChúng ta cùng quan sát hình dưới đây:\n\nMột trong những nền móng đầu tiên của neural network và deep learning là\nperceptron learning algorithm (hoặc gọn là\nperceptron). Perceptron là một thuật toán supervised learning giúp giải quyết\nbài toán phân lớp nhị phân, được khởi nguồn bởi Frank\nRosenblatt năm 1957 trong một\nnghiên cứu được tài trợ bởi Văn phòng nghiên cứu hải quân Hoa Kỳ (U.S Office of\nNaval Research – từ một cơ quan liên quan đến quân sự). Thuật toán perceptron\nđược chứng minh là hội tụ nếu hai lớp dữ liệu là linearly separable. Với thành\ncông này, năm 1958, trong một hội thảo, Rosenblatt đã có một phát biểu gây tranh\ncãi. Từ phát biểu này, tờ New York Times đã có một bài báo cho rằng perceptron\nđược Hải quân Hoa Kỳ mong đợi “có thể đi, nói chuyện, nhìn, viết, tự sinh sản,\nvà tự nhận thức được sự tồn tại của mình”. (Chúng ta biết rằng cho tới giờ các\nhệ thống nâng cao hơn perceptron nhiều lần vẫn chưa thể).\nMặc dù thuật toán này mang lại nhiều kỳ vọng, nó nhanh chóng được chứng minh không thể giải quyết những bài toán đơn giản. Năm 1969, Marvin Minsky và Seymour Papert trong cuốn sách nổi tiếng Perceptrons đã chứng minh rằng không thể ‘học’ được hàm số XOR khi sử dụng perceptron. Phát hiện này làm choáng váng giới khoa học thời gian đó (bây giờ chúng ta thấy việc này khá hiển nhiên). Perceptron được chứng minh rằng chỉ hoạt động nếu dữ liệu là linearly separable.\nPhát hiện này khiến cho các nghiên cứu về perceptron bị gián đoạn gần 20 năm. Thời kỳ này còn được gọi là Mùa đông AI thứ nhất (The First AI winter).\nCho tới khi…\n\nGeoffrey Hinton tốt nghiệp PhD ngành neural networks năm 1978. Năm 1986, ông cùng với hai tác giả khác xuất bản một bài báo khoa học trên Nature với tựa đề “Learning representations by back-propagating errors”. Trong bài báo này, nhóm của ông chứng minh rằng neural nets với nhiều hidden layer (được gọi là multi-layer perceptron hoặc MLP) có thể được huấn luyện một cách hiệu quả dựa trên một quy trình đơn giản được gọi là backpropagation (backpropagation là tên gọi mỹ miều của quy tắc chuỗi – chain rule – trong tính đạo hàm. Việc tính được đạo hàm của hàm số phức tạp mô tả quan hệ giữa đầu vào và đầu ra của một neural net là rất quan trọng vì hầu hết các thuật toán tối ưu đều được thực hiện thông qua việc tính đạo hàm, gradient descent là một ví dụ). Việc này giúp neural nets thoát được những hạn chế của perceptron về việc chỉ biểu diễn được các quan hệ tuyến tính. Để biểu diễn các quan hệ phi tuyến, phía sau mỗi layer là một hàm kích hoạt phi tuyến, ví dụ hàm sigmoid hoặc tanh. (ReLU ra đời năm 2012). Với hidden layers, neural nets được chứng minh rằng có khả năng xấp xỉ hầu hết bất kỳ hàm số nào qua một định lý được gọi là universal approximation theorem. Neurel nets quay trở lại cuộc chơi.\nThuật toán này mang lại một vài thành công ban đầu, nổi trội là convolutional neural nets (convnets hay CNN) (còn được gọi là LeNet) cho bài toán nhận dạng chữ số viết tay được khởi nguồn bởi Yann LeCun tại AT&T Bell Labs (Yann LeCun là sinh viên sau cao học của Hinton tại đại học Toronto năm 1987-1988). Dưới đây là bản demo được lấy từ trang web của LeNet, network là một CNN với 5 layer, còn được gọi là LeNet-5 (1998).\nMô hình này được sử dụng rộng rãi trong các hệ thống đọc số viết tay trên các check (séc ngân hàng) và mã vùng bưu điện của nước Mỹ.\nLeNet là thuật toán tốt nhất thời gian đó cho bài toán nhận dạng ảnh chữ số viết\ntay. Nó tốt hơn MLP thông thường (với fully connected layer) vì nó có khả năng\ntrích xuất được đặc trưng trong không gian hai chiều của ảnh thông qua các\nfilters (bộ lọc) hai chiều. Hơn nữa, các filter này nhỏ nên việc lưu trữ và tính\ntoán cũng tốt hơn so với MLP thông thường. (Yan LeCun có xuất phát từ\nElectrical Engineering nên rất quen thuộc với các bộ lọc.)\n\nCác mô hình tương tự được kỳ vọng sẽ giải quyết nhiều bài toán image\nclassification khác. Tuy nhiên, không như các chữ số, các loại ảnh khác lại rất\nhạn chế vì máy ảnh số chưa phổ biến tại thời điểm đó. Ảnh được gán nhãn lại càng\nhiếm. Trong khi để có thể huấn luyện được mô hình convnets, ta cần rất nhiều dữ\nliệu huấn luyện. Ngay cả khi dữ liệu có đủ, một vấn đề nan giải khác là khả năng\ntính toán của các máy tính thời đó còn rất hạn chế.\nMột hạn chế khác của các kiến trúc MLP nói chung là hàm mất mát không phải là\nmột hàm\nlồi.\nViệc này khiến cho việc tìm nghiệm tối ưu toàn cục cho bài toán tối ưu hàm mất\nmát trở nên rất khó khăn. Một vấn đề khác liên quan đến giới hạn tính toán của\nmáy tính cũng khiến cho việc huấn luyện MLP không hiệu quả khi số lượng hidden\nlayers lớn lên. Vấn đề này có tên là vanishing gradient.\nNhắc lại rằng hàm kích hoạt được sử dụng thời gian đó là sigmoid hoặc tanh – là\ncác hàm bị chặn trong khoảng (0, 1) hoặc (-1, 1) (Nhắc lại đạo hàm của hàm sigmoid \\(\\sigma(z)\\) là \\(\\sigma(z)(1 - \\sigma(z))\\) là tích của hai số nhỏ\nhơn 1). Khi sử dụng backpropagation để tính đạo hàm cho các ma trận hệ số ở các\nlớp đầu tiên, ta cần phải nhân rất nhiều các giá trị nhỏ hơn 1 với nhau. Việc\nnày khiến cho nhiều đạo hàm thành phần bằng 0 do xấp xỉ tính toán. Khi đạo hàm\ncủa một thành phần bằng 0, nó sẽ không được cập nhật thông qua gradient descent!\nNhững hạn chế này khiến cho neural nets một lần nữa rơi vào thời kỳ băng giá. Vào thời điểm những năm 1990 và đầu những năm 2000, neural nets dần\nđược thay thế bởi support vector machines\n–SVM. SVMs có ưu điểm là bài toán tối ưu để tìm các tham số của nó là một bài toán lồi – có\nnhiều các thuật toán tối ưu hiệu quả giúp tìm nghiệm của nó. Các kỹ thuật về\nkernel cũng phát triển\ngiúp SVMs giải quyết được cả các vấn đề về việc dữ liệu không phân biệt tuyến\ntính.\nNhiều nhà khoa học làm machine learning chuyển sang nghiên cứu SVM trong thời gian đó, trừ một vài nhà khoa học cứng đầu…\n\nNăm 2006, Hinton một lần nữa cho rằng ông biết bộ não hoạt động như thế nào, và giới thiệu ý tưởng của tiền huấn luyện không giám sát (unsupervised pretraining) thông qua deep belief nets (DBN). DBN có thể được xem như sự xếp chồng các unsupervised networks đơn giản như restricted Boltzman machine hay autoencoders.\nLấy ví dụ với autoencoder. Mỗi autoencoder là một neural net với một hidden\nlayer. Số hidden unit ít hơn số input unit, và số\noutput unit bằng với số input unit. Network này đơn giản được huấn luyện để kết\nquả ở output layer giống với kết quả ở input layer (và vì vậy được gọi là\nautoencoder). Quá trình dữ liệu đi từ input layer tới hidden layer có thể coi là\nmã hoá, quá trình dữ liệu đi từ hidden layer ra output layer có thể được coi\nlà giải mã. Khi output giống với input, ta có thể thấy rằng hidden layer với\nít unit hơn có để mã hoá input khá thành công, và có thể được coi mang những\ntính chất của input. Nếu ta bỏ output layer, cố định (freeze) kết nối giữa\ninput và hidden layer, coi đầu ra của hidden layer là một input mới, sau đó huấn\nluyện một autoencoder khác, ta được thêm một hidden layer nữa. Quá trình này\ntiếp tục kéo dài ta sẽ được một network đủ sâu mà output của network lớn này\n(chính là hidden layer của autoencoder cuối cùng) mang thông tin của input ban\nđầu. Sau đó ta có thể thêm các layer khác tuỳ thuộc vào bài toán (chẳng hạn thêm\nsoftmax layer ở cuối cho bài toán classification). Cả network được huấn luyện\nthêm một vài epoch nữa. Quá trình này được gọi là tinh chỉnh (fine tuning).\nTại sao quá trình huấn luyện như trên mang lại nhiều lợi ích?\nMột trong những hạn chế đã đề cập của MLP là vấn đề vanishing gradient. Những\nma trận trọng số ứng với các layer đầu của network rất khó được huấn luyện vì\nđạo hàm của hàm mất mát theo các ma trận này nhỏ. Với ý tưởng của DBN, các ma\ntrận trọng số ở những hidden layer đầu tiên được tiền huấn luyện\n(pretrained). Các trọng số được tiền huấn luyện này có thể coi là giá trị khởi\ntạo tốt cho các hidden layer phía đầu. Việc này giúp phần nào tránh được sự\nphiền hà của vanishing gradient.\nKể từ đây, neural networks với nhiều hidden layer được đổi tên thành deep learning.\nVấn đề vanishing gradient được giải quyết phần nào (vẫn chưa thực sự triệt\nđể), nhưng vẫn còn những vấn đề khác của deep learning: dữ liệu huấn luyện quá\nít, và khả năng tính toán của CPU còn rất hạn chế trong việc huấn luyện các deep\nnetworks.\nNăm 2010, giáo sư Fei-Fei Li, một giáo sư ngành computer vision đầu ngành tại\nStanford, cùng với nhóm của bà tạo ra một cơ sở dữ liệu có tên\nImageNet với hàng triệu bức ảnh thuộc 1000 lớp dữ\nliệu khác nhau đã được gán nhãn. Dự án này được thực hiện nhờ vào sự bùng nổ của\ninternet những năm 2000 và lượng ảnh khổng lồ được upload lên internet thời gian\nđó. Các bức ảnh này được gán nhãn bởi rất nhiều người (được trả công).\nXem thêm How we teach computers to understand pictures. Fei-Fei Li\nBộ cơ sở dữ liệu này được cập nhật hàng năm, và kể từ năm 2010, nó được dùng\ntrong một cuộc thi thường niên có tên ImageNet Large Scale Visual Recognition\nChallenge (ILSVRC). Trong cuộc thi\nnày, dữ liệu huấn luyện được giao cho các đội tham gia. Mỗi đội cần sử dụng dữ\nliệu này để huấn luyện các mô hình phân lớp, các mô hình này sẽ được áp dụng để\ndự đoán nhãn của dữ liệu mới (được giữ bởi ban tổ chức). Trong hai năm 2010 và\n2011, có rất nhiều đội tham gia. Các mô hình trong hai năm này chủ yếu là sự kết\nhợp của SVM với các feature được xây dựng bởi các bộ hand-crafted descriptors\n(SIFT, HoG, v.v.). Mô hình giành chiến thắng có top-5 error rate là 28% (càng\nnhỏ càng tốt). Mô hình giành chiến thắng năm 2011 có top-5 error rate là 26%.\nCải thiện không nhiều!\nNgoài lề: top-5 error rate được tính như sau. Mỗi mô hình dự đoán 5 nhãn của\nmột bức ảnh. Nếu nhãn thật của bức ảnh nằm trong 5 nhãn đó, ta có một điểm được\nphân lớp chính xác. Ngoài ra, bức ảnh đó được coi là một error. Top-5 error rate\nlà tỉ lệ số bức ảnh error trong toàn bộ số ảnh kiểm thử với error được tính theo\ncách này. Top-1 error cộng với classification accuracy (phần trăm) chính bằng\n100 phần trăm.\n\nNăm 2012, cũng tại ILSVRC, Alex Krizhevsky, Ilya Sutskever, và Geoffrey Hinton\n(lại là ông) tham gia và đạt kết quả top-5 error rate 16%. Kết quả này làm sững\nsờ giới nghiên cứu thời gian đó. Mô hình là một Deep Convolutional Neural\nNetwork, sau này được gọi là AlexNet.\nTrong bài báo này, rất nhiều các kỹ thuật mới được giới thiệu. Trong đó hai đóng\ngóp nổi bật nhất là hàm\nReLU và dropout. Hàm\nReLU (\\(\\text{ReLU}(x) = \\max(x, 0)\\)) với cách tính và đạo hàm đơn giản (bằng 1 khi\nđầu vào không âm, bằng 0 khi ngược lại) giúp tốc độ huấn luyện tăng lên đáng kể.\nNgoài ra, việc ReLU không bị chặn trên bởi 1 (như softmax hay tanh) khiến cho\nvấn đề vanishing gradient cũng được giải quyết phần nào. Dropout cũng là một kỹ\nthuật đơn giản và cực kỳ hiệu quả. Trong quá trình training, nhiều hidden unit\nbị tắt ngẫu nhiên và mô hình được huấn luyện trên các bộ tham số còn lại.\nTrong quá trình test, toàn bộ các unit sẽ được sử dụng. Cách làm này khá là có\nlý khi đối chiếu với con người. Nếu chỉ dùng một phần năng lực đã đem lại hiệu\nquả thì dùng toàn bộ năng lực sẽ mang lại hiệu quả cao hơn. Việc này cũng giúp\ncho mô hình tránh được\noverfitting và cũng\nđược coi giống với kỹ thuật\nensemble trong các hệ thống\nmachine learning khác. Với mỗi cách tắt các unit, ta có một mô hình khác nhau.\nVới nhiều tổ hợp unit bị tắt khác nhau, ta thu được nhiều mô hình. Việc kết hợp\nở cuối cùng được coi như sự kết hợp của nhiều mô hình (và vì vậy, nó giống với\nensemble learning).\nMột trong những yếu tố quan trọng nhất giúp AlexNet thành công là việc sử dụng\nGPU (card đồ hoạ) để huấn luyện mô hình. GPU được tạo ra cho game thủ, với khả\nnăng chạy song song nhiều lõi, đã trở thành một công cụ cực kỳ phù hợp với các\nthuật toán deep learning, giúp tăng tốc thuật toán lên nhiều lần so với CPU.\nSau AlexNet, tất cả các mô hình giành giải cao trong các năm tiếp theo đều là\ncác deep networks (ZFNet 2013, GoogLeNet 2014, VGG 2014, ResNet 2015). Tôi sẽ\ngiành một bài của blog để viết về các kiến trúc quan trọng này. Xu thế chung có\nthể thấy là các mô hình càng ngày càng deep. Xem hình dưới đây.\nNhững công ty công nghệ lớn cũng để ý tới việc phát triển các phòng nghiên cứu\ndeep learning trong thời gian này. Rất nhiều các ứng dụng công nghệ đột phá đã\nđược áp dụng vào cuộc sống hàng ngày. Cũng kể từ năm 2012, số lượng các bài báo\nkhoa học về deep learning tăng lên theo hàm số mũ. Các blog về deep learning\ncũng tăng lên từng ngày.\n\nRất nhiều những ý tưởng cơ bản của deep learning được đặt nền móng từ những năm\n80-90 của thế kỷ trước, tuy nhiên deep learning chỉ đột phá trong khoảng 5-6 năm\nnay. Vì sao?\nCó nhiều nhân tố dẫn đến sự bùng nổ này:\nSự ra đời của các bộ dữ liệu lớn được gán nhãn.\nKhả năng tính toán song song tốc độ cao của GPU.\nSự ra đời của ReLU và các hàm kích hoạt liên quan làm hạn chế vấn đề vanishing gradient.\nSự cải tiến của các kiến trúc: GoogLeNet, VGG, ResNet, … và các kỹ thuật transfer learning, fine tuning.\nNhiều kỹ thuật regularization mới: dropout, batch normalization, data augmentation.\nNhiều thư viện mới hỗ trợ việc huấn luyện deep network với GPU: theano, caffe, mxnet, tensorflow, pytorch, keras, …\nNhiều kỹ thuật tối ưu mới: Adagrad, RMSProp, Adam, …\n\nRất nhiều bạn đọc có yêu cầu tôi viết về deep learning từ lâu. Tuy nhiên, trước\nđó tôi tự nhận rằng mình chưa đủ kiến thức về lĩnh vực này để viết cho độc giả.\nChỉ khi có những bài cơ bản về machine learning và bản thân đã tích luỹ được một\nlượng kiến thức nhất định tôi mới quyết định bắt đầu vào chủ đề được nhiều bạn\nquan tâm này.\nCác thuật toán machine learning cổ điển khác vẫn có thể xuất hiện trong các bài sau của blog.\n\n\n[1] Deep Learning 101 - Part 1: History and Background\n[2] autoencoders\n[3] CNN Architectures: LeNet, AlexNet, VGG, GoogLeNet, ResNet and more …\n[4] A ‘Brief’ History off Neural Nets and Deep Learning\n[5] A Concise History of Neural Networks"
    },
    {
        "ID": 6,
        "URL": "https://machinelearningcoban.com/2018/03/22/phuonghoagiang/",
        "Title": "Machine Learning cơ bản",
        "Content": "Bạn Giang Phương Hoa từng học Đại học Ngoại Thương Hà Nội, học Thạc sỹ tại Imperial College London, hiện đang làm việc tại Microsoft AI Research London chia sẻ về con đường trở thành Data Scientist của mình.\nChào cả nhà,\nCảm ơn anh Tiệp đã tạo cơ hội cho mình viết bài này để chia sẻ. Follow Forum Machine Learning cơ bản đã lâu mà chưa đóng góp được gì nhiều.\nDạo gần đây mình có gặp nhiều bạn trẻ muốn theo nghề Data Science và PM mình hỏi về con đường mình đến với Data Science và bắt đầu học Machine Learning như thế nào. Vì thế mình đã xin phép anh Tiệp để viết bài ở đây, chia sẻ cùng mọi người và hy vọng sẽ giúp ích cho các bạn đang tự học Data Science, hoặc có background trái ngành trái nghề và muốn làm Data Science một cách nghiêm túc. Bài viết sẽ rất vớ vẩn với các chuyên gia 😊.\nĐây là con đường không hề dễ dàng nếu bạn không học Khoa học máy tính hay Toán từ bậc ĐH nhưng cũng không có nghĩa là không thể. Everything is impossible until you do it.\nCon đường mình đến với Data Science không hề bằng phẳng và mình tin nhiều bạn ở đây cũng vậy. Mình học Ngoại Thương chuyên ngành Tài chính. Cũng tự coi là có chút background về Toán Cao Cấp và Xác suất thống kê nhưng sẽ chỉ là muối bỏ bể so với các bạn học bài bản về Toán Lý Thuyết hay Xác suất thống kê. Rất may là trong quá trình học Ngoại Thương thì mình nhận ra môn học mà mình yêu thích nhất là môn Phân tích dữ liệu tài chính. Cảm giác nhìn những con số rồi tìm tòi ra một ý tưởng gì đó mới rồi trình bày bảng biểu vô cùng hấp dẫn (mãi sau này mình mới biết khái niệm đó gọi là insights 😊). Vì thế mình có tham gia một số cuộc thi sinh viên về phân tích dữ liệu.\nHồi đó hình như chỉ có Nielsen Case Competition–cuộc thi dành cho sinh viên của Nielsen, một công ty data consulting khá lớn tại Mỹ. Mình cũng may mắn cùng với các bạn trong nhóm giành giải của cuộc thi đó và bắt đầu đầu quân cho Nielsen để làm Chuyên viên phân tích dữ liệu 😊–Insight Analyst. Thời gian làm việc cho Nielsen là thời gian mình luôn cảm thấy là thời gian tạo một nền tảng vững chắc cho bản thân trong nghề làm Analyst. Nếu bạn google Nielsen thì Nielsen là một công ty nghiên cứu thị trường truyền thống, dữ liệu cung cấp chủ yếu bằng survey và phỏng vấn người tiêu dùng. Thời đó khái niệm Dữ liệu lớn hay là Khoa học máy tính vẫn còn xa vời với mình. Nhưng chính từ thời gian làm việc giống như một nhân viên tư vấn dữ liệu đã giúp mình hiểu được ứng dụng thực sự của dữ liệu là gì? Làm sao để dữ liệu có ích cho doanh nghiệp? Mình cũng học được cách từ một câu hỏi lớn và mơ hồ, làm sao để chia nhỏ câu hỏi đó thành những câu hỏi nhỏ hơn mà bạn có thể translate (phiên dịch) thành một câu hỏi có thể trả lời bằng dữ liệu sẵn có? Mình cũng hiểu khái niệm connecting the dots (xâu chuỗi) dữ liệu là gì? Vì vậy, đừng tự nghĩ rằng công việc mình đang làm không có gì hấp dẫn, không có gì liên quan đến Machine Learning hay Dữ liệu lớn mà nản lòng. Nhiều lúc bạn sẽ ngạc nhiên về những gì bạn học được từ các dirty jobs trong cuộc sống.\nSau một thời gian làm việc ở Nielsen thì mình nhận thấy hạn chế của các phương pháp nghiên cứu truyền thống (limited samples, biased trong cách đặt câu hỏi và trả lời). Vì thế mình bắt đầu tìm hiểu phương pháp mới để có thể thực sự phân tích user behavior mà không cần phải “hỏi” họ. Và thế là mình khám phá ra một thế giới mới là Khoa học dữ liệu (Data Science-DS). Thời điểm mình bắt đầu tìm hiểu về DS và học về DS thì mọi thứ còn khá mới mẻ (2013) cũng chưa có nhiều các khóa học open source như bây giờ. Mình hoàn toàn tự học mọi thứ từ xác suất thống kê (may mà trong công việc cũng có dùng), toán, lập trình, hệ thống dữ liệu. Mình hiểu là với các bạn không có nền tảng về Khoa học máy tính như mình, việc các bạn làm một cách bản năng là cố gắng lấp đầy lỗ hổng về lĩnh vực này càng nhiều càng tốt. Vì thế, các bạn sẽ cố gắng học Python, học R hay học các ngôn ngữ lập trình. Điều này dẫn đến một hệ quả là các bạn bị tool-driven. Học Python không khó, bỏ ra 6 tháng học một cách tập trung, các bạn sẽ viết được những dòng codes như mẫu. Nhưng điều mình hay gặp đó là các bạn học Python hay R như Kinh Thánh vậy. Nhiều bạn nghĩ rằng chỉ cần biết Python hay R là có thể làm được phân tích dữ liệu rồi. Thực ra thì không phải. Mình rất may mắn là trong thời kỳ đầu bắt đầu học, cảm thấy hoang mang quá thì một lần đi gặp khách hàng, gặp một bạn đã làm quantitative analyst ở Wall Street nhiều năm. Bạn ấy thấy mình ôm một quyển Python Fundamentals dầy cộp thì mới bảo “Mày nên học cách nghĩ, đừng học cách làm vội”. Chỉ một câu nói nhỏ mà mình nghĩ là có thể trao thưởng huy chương cho bạn ấy vì đã cứu rỗi cuộc đời mình. 😊. \nVà quyển sách đã thay đổi cuộc đời mình là How to think like a Computer Scientist.\nMình đã có dịp gặp tác giả của cuốn sách này và nói với anh ấy là “You saved my life. 😊”.\nThực sự thì đối với người học trái ngành, trái nghề, vấn đề lớn nhất là thay đổi cách suy nghĩ và sự tự ti. Bạn có xuất phát điểm không giống người khác và thế là tìm mọi cách để làm được NHƯ người ta mà quên mất mục đích ban đầu của mình là gì. Sau khi đọc cuốn sách trên thì mình hiểu ra vấn đề vì sao mình học Python đến hai tháng mà vẫn rất thụ động, chỉ có thể viết những gì code mẫu mà gặp vấn đề mới thì chịu. Đó là vì mình không suy nghĩ theo cách máy tính có thể suy nghĩ. Vì không think the language nên mình cũng không thể speak the language. Điều này cũng giống như lúc bạn học Tiếng Anh hay ngoại ngữ vậy, không hiểu cách tư duy của ngôn ngữ thì bạn sẽ thành học vẹt. Vì thế mình dành hẳn ba tháng chỉ để học computational thinking và computer logic, về những thứ như directory, class, variables, binary operations, algorithmic thinking, big O notation, v.v.. Điểm này sẽ không thể nào so sánh được với các bạn học Khoa học máy tính trong 3-4 năm nhưng cũng đủ để mình học lập trình một cách đúng hướng (programming in the right way). Mình đã nói chuyện với nhiều bạn tự học programming và nhiều bạn bị cuốn theo cách học Google knowledge–có vấn đề gì thì google–stackoverflows có câu trả lời sẵn. Cuối cùng thì chương trình cũng vẫn chạy, các bạn vẫn thấy hạnh phúc, nhưng lần sau gặp vấn đề khác các bạn không tự trả lời được. Cũng giống như hồi nhỏ ở trường học “How are you?” và trả lời “I’m fine, thank you”. Đến lúc người ta hỏi “How do you feel today?” thì không biết trả lời thế nào.\nLập trình cũng chỉ là công cụ. Cái cốt lõi của Data Science và Machine Learning (ML) vẫn là Toán và Xác suất thống kê. Về điểm này thì forum và cuốn sách của anh Tiệp sẽ rất hữu ích. Nền tảng Toán của mình không tệ vì cũng từng học chuyên Toán. Tuy nhiên, cũng giống như câu chuyện lập trình thì mình cảm thấy cũng cần học ML bằng cách think in ML ways. Các thuật toán quan trọng trong ML hầu như đều đã được viết và tạo thành thư viện nên vài bạn có thể lười chỉ cần from sckitlearn import * và thế là ung dung chạy một cái chương trình ML. Nhưng để thực sự làm DS/ML thì nhiều khi nên bắt đầu ôn lại khái niệm đạo hàm, ma trận và toán cơ bản.\nMột điểm nữa mà nhiều bạn rất hay quên hoặc bỏ qua khi học DS vì nghĩ nó nhàm chán đó là database structure và data manipulation. Mình cũng vấp phải vấn đề tương tự khi mình bắt đầu học Thạc sỹ về Data Science ở Imperial College London. Ngay Kỳ 1 thì trong chương trình có một môn học mà rất nhiều bạn bỏ lớp (mình cũng cúp cua mấy lần) đó là Database Admin. Môn này phải nói là cực kỳ chán vì nó sẽ không có kết quả ngay cho bạn như khi bạn chạy môt chương trình máy tính hay vẽ biểu đồ, đem lại cảm giác cực kỳ cool vì I did something. Tuy nhiên khi bắt đầu thực sự làm dự án nghiên cứu ở Data Science Institute in Imperial College (mình làm cộng tác viên) thì mình có thể thực sự hiểu được tầm quan trọng kinh khủng của môn này. Bạn không thể thi triển được thuật toán hay tối ưu hóa thuật toán nếu không hiểu cấu trúc dữ liệu hay database relation, handle missing values, organizing the table in long/wide format, normalization of the database, etc.** Những việc nhỏ nhặt, *dirty jobs, tốn thời gian vậy thực ra là vô cùng quan trọng. Khi bạn hiểu cấu trúc dữ liệu thì bạn mới quay lại bước 1 được: Từ câu hỏi lớn làm sao để thi triển ra nhiều câu hỏi nhỏ và trả lời? Rốt cuộc thì DS chính là công cụ để trả lời câu hỏi mà thôi. Đừng quên mục đích ban đầu!\nSau rất nhiều chông gai thì bây giờ mình được gọi là data scientist tại Microsoft AI Research. Chặng đường học thì vẫn còn rất dài, bây giờ mình vẫn phải đọc forum Machine Learning thường xuyên để hiểu thêm. Dưới đây là một ít bài học mình đã đúc kết sau 4 năm ròng rã mất nhiều máu (ngã cầu thang mấy lần vì mải nghĩ) và nước mắt (khó quá làm thế nào), hy vọng sẽ giúp ích cho nhiều bạn có nền tảng giống mình.\nĐừng chạy theo buzzwords, cuộc sống nhiều cám dỗ, hãy bắt đầu từ những thứ căn bản nhất. Thinking và mindset là những thứ quan trọng nhất. Python hay R hay Java cũng chỉ là công cụ.\nMachine Learning là học máy, trước khi làm ML nếu bạn không có nền tảng về Computer Science thì hãy thử tìm hiểu về Computational thinking và computer logic.\nData science rất rộng lớn. Hãy thử nghĩ về một mảng nhỏ mà bạn muốn theo đuổi: nhiều người có thể theo đuổi Optimization, mình thì chọn cho mình con đường đã đưa mình đến với DS ngay từ đầu: User Behavior Analytics. Điều này sẽ giúp các bạn định hình và tập trung vào những mảng lý thuyết liên quan mật thiết đến mảng này. Nghe có vẻ thực dụng nhưng mình chủ yếu tìm hiểu về các mô hình/thuật toán liên quan đến time series, sequential pattern mining, pattern recognition, clustering/classification, association mining, etc. vì đây sẽ là những thứ giúp bạn tìm hiểu về User Behavior. Các thuật toán simulation như Monte Carlo hay các thuật toán tối ưu khác mình không biết quá sâu.\nChúc mọi người học Machine Learning vui. 😊"
    },
    {
        "ID": 7,
        "URL": "https://machinelearningcoban.com/2018/01/14/id3/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\nSắp đến kỳ thi, một cậu sinh viên tự đặt ra quy tắc học hay\nchơi của mình như sau. Nếu còn nhiều hơn hai ngày tới ngày thi, cậu ra\nsẽ đi chơi.\nNếu còn không quá hai ngày và đêm hôm đó có một trận bóng đá, cậu sẽ sang nhà\nbạn chơi và cùng xem bóng đêm đó. Cậu sẽ chỉ học trong các trường hợp còn lại. \nViệc ra quyết định của cậu sinh viên này có thể được mô tả trên sơ đồ trong\nHình 1. Hình ellipse nền vàng thể hiện quyết định cần được đưa\nra. Quyết định này phụ thuộc vào các câu trả lời của các câu hỏi trong các ô\nhình chữ nhật màu xám. Dựa trên các câu trả lời, quyết định cuối cùng được cho\ntrong các hình tròn màu lục (chơi) và đỏ (học).\nSơ đồ trong Hình 1 còn được gọi là một cây quyết định.\nViệc quan sát, suy nghĩ và ra các quyết định của con người thường được bắt đầu\ntừ các câu hỏi. Machine learning cũng có một mô hình ra quyết định dựa trên các\ncâu hỏi. Mô hình này có tên là cây quyết định (decision tree).\nXét ví dụ trên Hình 2a với hai class màu lục và đỏ trên không\ngian hai chiều. Nhiệm vụ là đi tìm ranh giới đơn giản giúp phân chia hai class\nnày. Hay nói cách khác, đây là một bài toán classification, ta cần xây dựng một\nbộ phân lớp để quyết định việc một điểm dữ liệu mới thuộc vào class nào. Quan\nsát hình ta thấy rằng ranh giới cho hai class trong bài toán này khá đơn\ngiản–chúng là các đường song song với các trục toạ độ. Nếu một điểm có thành\nphần thứ nhất, \\(x_1\\), nhỏ hơn ngưỡng \\(t_1\\), ta quyết định ngay được rằng nó\nthuộc class lục. Ngoài ra, nếu thành phần thứ hai, \\(x_2\\) lớn hơn ngưỡng \\(t_2\\),\nta quyết định nó cũng thuộc vào class lục. Xét tiếp, nếu thành phần thứ nhất,\n\\(x_1\\), lớn hơn ngưỡng \\(t_3\\), ta quyết định nó thuộc vào class lục. Các điểm\nkhông thoả mãn các điều kiện trên được xếp vào class đỏ. Việc ra quyết định một\nđiểm thuộc class nào được mô tả trên decision tree trên Hình 2b.\n\nTrong decision tree, các ô màu xám, lục, đỏ trên Hình 2 được gọi là các node.\nCác node thể hiện đầu ra (màu lục và đỏ) được gọi là node lá (leaf node\nhoặc terminal node). Các node thể hiện câu hỏi là các non-leaf node.\nNon-leaf node trên cùng (câu hỏi đầu tiên) được gọi là node gốc (root\nnode). Các non-leaf node thường có hai hoặc nhiều node con (child node).\nCác child node này có thể là một leaf node hoặc một non-leaf node khác.\nCác child node có cùng bố mẹ được gọi là sibling node. Nếu tất cả các\nnon-leaf node chỉ có hai child node, ta nói rằng đó là một binary decision\ntree (cây quyết định nhị phân). Các câu hỏi trong binary decision tree đều có\nthể đưa được về dạng câu hỏi đúng hay sai. Các decision tree mà một leaf\nnode có nhiều child node cũng có thể được đưa về dạng một binary decision\ntree. Điều này có thể đạt được vì hầu hết các câu hỏi đều có thể được đưa về\ndạng câu hỏi đúng sai.\nVí dụ, ta có thể xác định được tuổi của một người dựa trên nhiều câu hỏi đúng\nsai dạng: tuổi của bạn lớn hơn \\(x\\) đúng không? (Đây chính là thuật toán\ntìm kiếm nhị phân – binary search.)\nDecision tree là một mô hình supervised learning, có thể được áp dụng vào cả hai\nbài toán classification và regression. Việc xây dựng một decision tree trên dữ\nliệu huấn luyện cho trước là việc đi xác định các câu hỏi và thứ tự của\nchúng. Một điểm đáng lưu ý của decision tree là nó có thể làm việc với các đặc\ntrưng (trong các tài liệu về decision tree, các đặc trưng thường được gọi là\nthuộc tính – attribute) dạng categorical, thường là rời rạc và không có thứ\ntự. Ví dụ, mưa, nắng hay xanh, đỏ, v.v. Decision tree cũng làm việc với dữ\nliệu có vector đặc trưng bao gồm cả thuộc tính dạng categorical và liên tục\n(numeric). Một điểm đáng lưu ý nữa là decision tree ít yêu cầu việc chuẩn hoá\ndữ liệu.\nTrong bài viết này, chúng ta sẽ làm quen với một thuật toán xây dựng decision\ntree ra đời từ rất sớm và rất phổ biến: Iterative Dichotomiser 3\n(ID3).\nQuay trở lại với nhiệm vụ chính của việc xây dựng một decision tree: các\ncâu hỏi nên được xây dựng như thế nào, và thứ tự của chúng ra sao. Các\ncâu hỏi này thường được áp dụng lên từng thuộc tính, hoặc một tổ hợp tuyến tính\ncủa các thuộc tính. Cách thứ nhất, áp dụng lên từng thuộc tính, được sử dụng\nnhiều hơn vì tính đơn giản của nó. Với các thuộc tính dạng categorical, câu hỏi\nsẽ là Nó rơi vào category nào? hoặc Nó có rơi vào category nào đó không?\nvới trường hợp nhị phân. Với các thuộc tính dạng liên tục, câu hỏi có thể là\nNó nằm vào khoảng giá trị nào? hoặc Nó có lớn hơn một ngưỡng nào đó\nkhông?.\nID3 là một thuật toán decision tree được áp dụng cho các bài toán classification\nmà tất cả các thuộc tính đều ở dạng categorical. Trong bài tiếp theo, chúng ta\nsẽ làm quen với một thuật toán khác có tên là Classification and Regression Tree\n(CART)–có thể được áp dụng vào cả hai loại classification và regression, như\ntên gọi của nó–làm việc với cả thuộc tính dạng categorical và liên tục.\n\n\nTrong ID3, chúng ta cần xác định thứ tự của thuộc tính cần được xem xét tại mỗi\nbước. Với các bài toán có nhiều thuộc tính và mỗi thuộc tính có nhiều giá trị\nkhác nhau, việc tìm được nghiệm tối ưu thường là không khả thi. Thay vào đó, một\nphương pháp đơn giản thường được sử dụng là tại mỗi bước, một thuộc tính\ntốt nhất sẽ được chọn ra dựa trên một tiêu chuẩn nào đó (chúng ta sẽ\nbàn sớm). Với mỗi thuộc tính được chọn, ta chia dữ liệu vào các child\nnode tương ứng với các giá trị của thuộc tính đó rồi tiếp tục áp dụng phương\npháp này cho mỗi child node. Việc chọn ra thuộc tính tốt nhất\nở mỗi bước như thế này được gọi là cách chọn greedy (tham\nlam). Cách chọn này có thể không phải là tối ưu, nhưng trực giác cho chúng ta\nthấy rằng cách làm này sẽ gần với cách làm tối ưu. Ngoài ra, cách làm này khiến\ncho bài toán cần giải quyết trở nên đơn giản hơn.\nSau mỗi câu hỏi, dữ liệu được phân chia vào từng child node\ntương ứng với các câu trả lời cho câu hỏi đó. Câu hỏi ở đây chính là\nmột thuộc tính, câu trả lời chính là giá trị của thuộc tính đó. Để đánh giá\nchất lượng của một cách phân chia, chúng ta cần đi tìm một phép đo.\nTrước hết, thế nào là một phép phân chia tốt? Bằng trực giác, một phép phân chia\nlà tốt nhất nếu dữ liệu trong mỗi child node hoàn toàn thuộc vào một\nclass–khi đó child node này có thể được coi là một leaf node, tức ta không\ncần phân chia thêm nữa. Nếu dữ liệu trong các child node vẫn lẫn vào nhau theo\ntỉ lệ lớn, ta coi rằng phép phân chia đó chưa thực sự tốt. Từ nhận xét này, ta\ncần có một hàm số đo độ tinh khiết (purity), hoặc độ vẩn đục (impurity)\ncủa một phép phân chia. Hàm số này sẽ cho giá trị thấp nhất nếu dữ liệu trong\nmỗi child node nằm trong cùng một class (tinh khiết nhất), và cho giá trị cao\nnếu mỗi child node có chứa dữ liệu thuộc nhiều class khác nhau.\nMột hàm số có các đặc điểm này và được dùng nhiều trong lý thuyết thông tin là\nhàm entropy.\n\nCho một phân phối xác suất của một biến rời rạc \\(x\\) có thể nhận \\(n\\) giá trị\nkhác nhau \\(x_1, x_2, \\dots, x_n\\). Giả sử rằng xác suất để \\(x\\) nhận các giá trị\nnày là \\(p_i = p(x = x_i)\\) với \\(0 \\leq p_i \\leq 1, \\sum_{i=1}^n p_i = 1\\). Ký hiệu\nphân phối này là \\(\\mathbf{p} = (p_1, p_2, \\dots, p_n)\\). Entropy của phân phối này được\nđịnh nghĩa là\n\\[\n    H(\\mathbf{p}) = -\\sum_{i=1}^n p_i \\log(p_i)\\quad\\quad (1)\n\\]\ntrong đó \\(\\log\\) là logarit tự nhiên (Một số tài liệu dùng logarit cơ số\n2, nhưng giá trị của \\(H(\\mathbf{p})\\) chỉ khác đi bằng cách nhân với một hằng số.) và\nquy ước \\(0 \\log(0) = 0\\).\nXét một ví dụ với \\(n = 2\\) được cho trên Hình 3. Trong trường hợp \\(\\mathbf{p}\\)\nlà tinh khiết nhất, tức một trong hai giá trị \\(p_i\\) bằng 1, giá trị kia\nbằng 0, entropy của phân phối này là \\(H(\\mathbf{p}) = 0\\). Khi \\(\\mathbf{p}\\) là vẩn\nđục nhất, tức cả hai giá trị \\(p_i = 0.5\\), hàm entropy đạt giá trị cao nhất.\nTổng quát lên với \\(n > 2\\), hàm entropy đạt giá trị nhỏ nhất nếu có một giá trị \\(p_i = 1\\), đạt giá trị lớn nhất nếu tất cả các \\(p_i\\) bằng nhau ((việc này có thể được chứng minh bằng phương pháp nhân tử Lagrange).\nNhững tính chất này của hàm entropy khiến nó được sử dụng trong việc đo\nđộ vẩn đục của một phép phân chia của ID3. Vì lý do này, ID3 còn được\ngọi là entropy-based decision tree.\n\nTrong ID3, tổng có trọng số của entropy tại các leaf-node sau khi xây\ndựng decision tree được coi là hàm mất mát của decision tree đó. Các trọng số ở\nđây tỉ lệ với số điểm dữ liệu được phân vào mỗi node. Công việc của ID3 là tìm\ncác cách phân chia hợp lý (thứ tự chọn thuộc tính hợp lý) sao cho hàm mất mát\ncuối cùng đạt giá trị càng nhỏ càng tốt. Như đã đề cập, việc này đạt được bằng\ncách chọn ra thuộc tính sao cho nếu dùng thuộc tính đó để phân chia, entropy tại\nmỗi bước giảm đi một lượng lớn nhất. Bài toán xây dựng một decision tree bằng\nID3 có thể chia thành các bài toán nhỏ, trong mỗi bài toán, ta chỉ cần chọn ra\nthuộc tính giúp cho việc phân chia đạt kết quả tốt nhất. Mỗi bài toán nhỏ này\ntương ứng với việc phân chia dữ liệu trong một non-leaf node. Chúng ta\nsẽ xây dựng phương pháp tính toán dựa trên mỗi node này.\nXét một bài toán với \\(C\\) class khác nhau. Giả sử ta đang làm việc với một\nnon-leaf node với các điểm dữ liệu tạo thành một tập \\(\\mathcal{S}\\) với số\nphần tử là \\(|\\mathcal{S}| = N\\). Giả sử thêm rằng trong số \\(N\\) điểm dữ\nliệu này, \\(N_c, c= 1, 2, \\dots, C\\) điểm thuộc vào class \\(c\\). Xác suất để\nmỗi điểm dữ liệu rơi vào một class \\(c\\) được xấp xỉ bằng \\(\\frac{N_c}{N}\\)\n(maximum likelihood estimation). Như vậy, entropy tại node này được tính bởi:\n\\[ H(\\mathcal{S}) = -\\sum_{c=1}^C \\frac{N_c}{N} \\log\\left(\\frac{N_c}{N}\\right) \\quad\\quad\n    (2)\n\\]\nTiếp theo, giả sử thuộc tính được chọn là \\(x\\). Dựa trên \\(x\\), các điểm dữ liệu\ntrong \\(\\mathcal{S}\\) được phân ra thành \\(K\\) child node \\(\\mathcal{S}_1, \\mathcal{S}_2, \\dots, \\mathcal{S}_K\\) với số\nđiểm\ntrong mỗi child node lần lượt là \\(m_1, m_2, \\dots, m_K\\). Ta định nghĩa\n\\[\n    H(x, \\mathcal{S}) = \\sum_{k=1}^K \\frac{m_k}{N} H(\\mathcal{S}_k) \\quad\\quad (3)\n\\]\nlà tổng có trọng số entroy của mỗi child node–được tính tương tự\nnhư (2). Việc lấy trọng số này là quan trọng vì các\nnode thường có số lượng điểm khác nhau.\nTiếp theo, ta định nghĩa information gain dựa trên thuộc tính \\(x\\):\n\\[\n    G(x, \\mathcal{S}) = H(\\mathcal{S}) - H(x, \\mathcal{S})\n\\]\nTrong ID3, tại mỗi node, thuộc tính được chọn được xác định dựa trên:\n\\[\n    x^* = \\arg\\max_{x} G(x, \\mathcal{S}) = \\arg\\min_{x} H(x, \\mathcal{S})\n\\]\ntức thuộc tính khiến cho information gain đạt giá trị lớn nhất.\nCâu hỏi tiếp theo là khi nào thì dừng cách phân chia? Câu trả\nlời sẽ được đề cập sau mục ví dụ dưới đây.\n\nĐể mọi thứ được rõ ràng hơn, chúng ta cùng xem ví dụ với dữ liệu huấn luyện\nđược cho trong Bảng dưới đây. Bảng dữ liệu này được lấy\ntừ cuốn sách Data Mining: Practical Machine Learning Tools and Techniques, trang 11. Đây là một bảng dữ liệu được sử\ndụng rất nhiều trong các bài giảng về decision tree. Bảng dữ liệu này mô tả mối\nquan hệ giữa thời tiết trong 14 ngày (bốn cột đầu, không tính cột id) và việc một đội bóng có chơi bóng hay\nkhông (cột cuối cùng). Nói cách khác, ta phải dự đoán giá trị ở cột cuối cùng nếu biết giá trị của bốn cột còn lại.\nCó bốn thuộc tính thời tiết:\nOutlook nhận một trong ba giá trị: sunny, overcast, rainy.\nTemperature nhận một trong ba giá trị: hot, cool, mild.\nHumidity nhận một trong hai giá trị: high, normal.\nWind nhận một trong hai giá trị: weak, strong.\n(Tổng cộng có \\(3\\times 3 \\times 2 \\times 2 = 36\\) loại thời tiết khác nhau,\ntrong đó 14 loại được thể hiện trong bảng.)\nĐây có thể được coi là một bài toán dự đoán liệu đội bóng có chơi bóng không\ndựa trên các quan sát thời tiết. Ở đây, các quan sát đều ở dạng categorical.\nCách dự đoán dưới đây tương đối đơn giản và khá chính xác, có thể không phải là\ncách ra quyết định tốt nhất:\nNếu outlook = sunny và humidity = high thì\nplay = no.\nNếu outlook = rainy và windy = true thì\nplay = no.\nNếu outlook = overcast thì play = yes.\nNgoài ra, nếu humidity = normal thì play = yes.\nNgoài ra, play = yes.\nChúng ta sẽ cùng tìm thứ tự các thuộc tính bằng thuật toán ID3.\nTrong 14 giá trị đầu ra ở Bảng trên, có năm giá trị bằng no và chín giá trị\nbằng yes. Entroy tại root node của bài toán là:\n\\[\n    H(\\mathcal{S}) = - \\frac{5}{14}\\log\\left(\\frac{5}{14}\\right) - \\frac{9}{14}\\log\\left(\\frac{9}{14}\\right)\n    \\approx 0.65 \n\\]\nTiếp theo, chúng ta tính tổng có trọng số entropy của các child node nếu chọn\nmột trong các thuộc tính outlook, temperature, humidity, wind, play để phân\nchia dữ liệu.\nXét thuộc tính outlook. Thuộc tính này có thể nhận một trong ba giá trị\nsunny, overcast, rainy. Mỗi một giá trị sẽ tương ứng với một\nchild node. Gọi tập hợp các điểm trong mỗi child node này lần lượt là\n\\(\\mathcal{S}_s, \\mathcal{S}_o, \\mathcal{S}_r\\) với tương ứng \\(m_s, m_o,\nm_r\\) phần tử. Sắp xếp lại Bảng ban đầu theo thuộc tính outlook ta đạt được ba\nBảng nhỏ sau đây.\nQuan sát nhanh ta thấy rằng child node ứng với outlook = overcast sẽ có\nentropy bằng 0 vì tất cả \\(m_o = 4\\) output đều là yes. Hai child node còn\nlại với \\(m_s = m_r = 5\\) có entropy khá cao vì tần suất output bằng yes\nhoặc no là xấp xỉ nhau. Tuy nhiên, hai child node này có thể được phân chia\ntiếp dựa trên hai thuộc tính humidity và wind.\nBạn đọc có thể kiểm tra được rằng\n\\[ \n\\begin{eqnarray}\n    H(\\mathcal{S}_s) &=&-\\frac{2}{5}\\log\\left(\\frac{2}{5}\\right) - \\frac{3}{5}\\log\\left(\\frac{3}{5}\\right)\n            \\approx 0.673 \\\\ \n    H(\\mathcal{S}_o) &=& 0  \\\\ \n    H(\\mathcal{S}_r) &=& -\\frac{3}{5}\\log\\left(\\frac{2}{5}\\right) - \\frac{3}{5}\\log\\left(\\frac{3}{5}\\right) \n    \\approx 0.673 \\\\ \n    H({outlook}, \\mathcal{S}) &=& \\frac{5}{14}H(\\mathcal{S}_s) + \\frac{4}{14}H(\\mathcal{S}_o) +\n    \\frac{5}{14}H(\\mathcal{S}_r) \\approx 0.48\n \\end{eqnarray}\n\\]\nXét thuộc tính temperature, ta có phân chia như các Bảng dưới đây.\nGọi \\(\\mathcal{S}_h, \\mathcal{S}_m, \\mathcal{S}_c\\) là ba tập con tương ứng với temperature bằng hot, mild, cool. Bạn đọc có thể tính được\n\\[\n\\begin{eqnarray}\n    H(\\mathcal{S}_h) &=& -\\frac{2}{4}\\log\\left(\\frac{2}{4}\\right)-\\frac{2}{4}\\log\\left(\\frac{2}{4}\\right)\n    \\approx 0.693 \\\\ \n    H(\\mathcal{S}_m) &=& - \\frac{4}{6}\\log\\left(\\frac{4}{6}\\right) - \\frac{2}{6}\\log\\left(\\frac{2}{6}\\right)\n    \\approx 0.637 \\\\ \n    H(\\mathcal{S}_c) &=& - \\frac{3}{4}\\log\\left(\\frac{3}{4}\\right) - \\frac{1}{4}\\log\\left(\\frac{1}{4}\\right)\n    \\approx 0.562 \\\\ \n    H(temperature, \\mathcal{S}) &=& \\frac{4}{14}H(\\mathcal{S}_h) + \\frac{6}{14}H(\\mathcal{S}_m) +\n    \\frac{4}{14}H(\\mathcal{S}_c) \\approx 0.631\n\\end{eqnarray}\n\\]\nViệc tính toán với hai thuộc tính còn lại được dành cho bạn đọc. Nếu các kết\nquả là giống nhau, chúng sẽ bằng: \n\\[\n    H(humidity, \\mathcal{S}) \\approx 0.547, \\quad H(wind, \\mathcal{S}) \\approx 0.618\n\\]\nNhư vậy, thuộc tính cần chọn ở bước đầu tiên là outlook vì\n\\(H(outlook, \\mathcal{S})\\) đạt giá trị nhỏ nhất (information gain là lớn nhất).\nSau bước phân chia đầu tiên này, ta nhận được ba child node với các phần tử như\ntrong ba Bảng phân chia theo outlook. Child node thứ hai không cần phân chia tiếp vì nó\nđã tinh khiết. Với child node thứ nhất, ứng với outlook =\nsunny, kết quả tính được bằng ID3 sẽ cho chúng ta thuộc tính humidity\nvì tổng trọng số của entropy sau bước này sẽ bằng 0 với output bằng yes\nkhi và chỉ khi humidity = normal. Tương tự, child node ứng với\noutlook = wind sẽ được tiếp tục phân chia bởi thuộc tính wind\nvới output bằng yes khi và chỉ khi wind = weak.\nNhư vậy, cây quyết định cho bài toán này dựa trên ID3 sẽ có dạng như trong\nHình 4.\n\nTrong các thuật toán decision tree nói chung và ID3 nói riêng, nếu ta tiếp tục\nphân chia các node chưa tinh khiết, ta sẽ thu được một tree mà mọi điểm\ntrong tập huấn luyện đều được dự đoán đúng (giả sử rằng không có hai input giống\nnhau nào cho output khác nhau). Khi đó, tree có thể sẽ rất phức tạp (nhiều node)\nvới nhiều leaf node chỉ có một vài điểm dữ liệu. Như vậy, nhiều khả năng\noverfitting sẽ xảy ra.\nĐể tránh overfitting, một trong số các phương pháp sau có thể được sử dụng. Tại một node,\nnếu một trong số các điều kiện sau đây xảy ra, ta không tiếp tục phân chia node đó và coi nó\nlà một leaf node:\nnếu node đó có entropy bằng 0, tức mọi điểm trong node đều thuộc một\n  class.\nnếu node đó có số phần tử nhỏ hơn một ngưỡng nào đó. Trong trường\n  hợp này, ta chấp nhận có một số điểm bị phân lớp sai để tránh overfitting.\n  Class cho leaf node này có thể được xác định dựa trên class chiếm đa số\n  trong node.\nnếu khoảng cách từ node đó đến root node đạt tới một giá trị nào đó.\n  Việc hạn chế chiều sâu của tree này làm giảm độ phức tạp của tree và phần nào giúp tránh overfitting.\nnếu tổng số leaf node vượt quá một ngưỡng nào đó.\nnếu việc phân chia node đó không làm giảm entropy quá nhiều\n  (information gain nhỏ hơn một ngưỡng nào đó).\nNgoài các phương pháp trên, một phương pháp phổ biến khác được sử dụng để tránh\noverfitting là pruning, tạm dịch là cắt tỉa.\n\nPruning là một kỹ thuật regularization để tránh overfitting cho decision tree\nnói chung. Trong pruning, một decision tree sẽ được xây dựng tới khi mọi điểm\ntrong training set đều được phân lớp đúng. Sau đó, các leaf node có chung một\nnon-leaf node sẽ được cắt tỉa và non-leaf node đó trở thành một\nleaf-node, với class tương ứng với class chiếm đa số trong số mọi điểm được\nphân vào node đó. Việc cắt tỉa cây quyết định này có thể được xác định dựa\nvào các cách sau.\nDựa vào một validation set. Trước tiên, training set được tách ra\nthành một training set nhỏ hơn và một validation set. Decision tree được\nxây dựng trên training set cho tới khi mọi điểm trong training set được\nphân lớp đúng. Sau đó, đi ngược từ các leaf node, cắt tỉa các sibling node\ncủa nó và giữ lại node bố mẹ nếu độ chính xác trên validation set\nđược cải thiện. Khi nào độ chính xác trên validation set không được cải\nthiện nữa, quá trình pruning dừng lại. Phương pháp này còn được gọi là\nreduced error pruning.\nDựa vào toàn bộ data set. Trong phương pháp này, ta không tách tập\ntraining ban đầu ra mà sử dụng toàn bộ dữ liệu trong tập này cho việc xây\ndựng decision tree. Một ví dụ cho việc này là cộng thêm một đại lượng\nregularization vào hàm mất mát. Đại lượng regularization sẽ lớn nếu số leaf\nnode là lớn. Cụ thể, giả sử decision tree cuối cùng có \\(K\\) leaf node, tập\nhợp các điểm huấn luyện rơi vào mỗi leaf node lần lượt là \\(\\mathcal{S}_1, \\dots,\n\\mathcal{S}_K\\). Khi đó, regularized loss của ID3 có thể được tính tương tự\nnhư (3):\n\\[\n \\mathcal{L} = \\sum_{k = 1}^K \\frac{|\\mathcal{S}_k|}{|\\mathcal{S}|}\n H(\\mathcal{S}_k) + \\lambda K \\quad\\quad (5)\n\\]\nvới \\(|\\mathcal{S}_k|\\) ký hiệu số phần tử của tập hợp \\(\\mathcal{S}_k\\) và \\(H(\\mathcal{S}_k)\\) chính là\nentropy của leaf node tương ứng với \\(\\mathcal{S}_k\\), được tính tương tự\nnhư (2), và \\(\\lambda\\) là một số thực dương không\nquá lớn. Giá trị của hàm số này nhỏ nếu cả data loss–số hạng thứ nhất–nhỏ (entropy tại mỗi\nnode là thấp) và regularization–số hạng thứ hai–cũng nhỏ (số leaf node là ít).\nVì hàm mất mát trong (5) là một hàm rời rạc, rất khó để\ntrực tiếp tối ưu hàm này. Việc tối ưu có thể được thực hiện thông qua\npruning như sau. Trước hết, xây dựng một decision tree mà mọi điểm trong tập\nhuấn luyện đều được phân loại đúng (toàn bộ các entopy của các node bằng 0).\nLúc này data loss bằng 0 nhưng regularization có thể lớn, khiến cho\n\\(\\mathcal{L}\\) lớn. \nSau đó, ta có thể tỉa dần các leaf node sao cho \\(\\mathcal{L}\\) giảm.\nViệc cắt tỉa được lặp lại đến khi \\(\\mathcal{L}\\) không thể giảm được nữa.\nCác kỹ thuật pruning khác có thể được tìm thấy tại đây.\n\nModule DecisionTree trong sklearn không thực hiện thuật toán ID3 mà là một\nthuật toán khác được đề cập trong bài tiếp theo. Phiên bản hiện tại trong\nsklearn chưa hỗ trợ các thuộc tính ở dạng categorical. Với dữ liệu có thuộc\ntính categorical, cách thường dùng là chuyển đổi các thuộc tính đó sang dạng\nnumerical (1, 2, 3 cho mỗi giá trị). Chẳng hạn, các giá trị hot, mild,\ncool có thể lần lượt được thay bằng 1, 2, 3. Cách làm  này có hạn chế\nvì trong cách chuyển đổi này, mild là trung bình cộng của hot\nvà cool, nhưng nếu thứ tự các giá trị được đặt khác đi, việc chuyển\nđổi có thể ảnh hưởng lớn tới kết quả. Nhắc lại rằng các thuộc tính\ncategorical, ví dụ màu sắc, thường không có tính thứ tự.\nDưới đây là cách lập trình của tôi cho ID3, làm việc với cả dữ liệu ở dạng\ncategorical. (Source code có thể được tìm thấy tại đây)\nXây dựng class TreeNode\nHàm tính entropy dựa trên tần suất\nTrong hàm này, chúng ta phải chú ý bỏ các tần suất bằng 0 đi vì logarit tại đây\nkhông xác định.\nPhần còn lại của source code (bao gồm class DecisionTreeID3) có\nthể được tìm thấy tại đây.\nDữ liệu trong trong ví dụ được được lưu trong file\nweather.csv. Việc huấn luyện decision tree dựa trên ID3 cho tập\ndữ liệu này và đầu ra dự đoán cho training set được cho bởi\nKết quả\nKhông có gì bất ngờ, decision tree dự đoán đúng 100% các điểm trong training\nset.\n\nNếu một thuộc tính có thể nhận rất nhiều giá trị, decision tree thu\nđược có thể sẽ có rất nhiều node. Xét một ví dụ về các triệu chứng của các\nbệnh nhân trong một bệnh viện và đầu ra là mắc bệnh hay không. Mỗi bệnh nhân\ncó một mã số (id) khác nhau. Nếu ta sử dụng thuộc tính này cho việc huấn\nluyện, ta rất có thể sẽ thu được mộ decision tree mà mỗi leaf node ứng với\nmột bệnh nhân. Lúc đó mô hình này là vô dụng, vì không thể dự đoán được việc\nmắc bệnh hay không của một bệnh nhân mới.\nKhi một thuộc tính nhận giá trị liên tục, chẳng hạn\ntemperature không còn là hot, mild, cool nữa mà là các\ngiá trị thực liên tục, vẫn có một cách để áp dụng ID3. Ta có thể chia\nkhoảng giá trị của thuộc tính này thành nhiều phần, mỗi phần có số lượng\nđiểm tương đương, hoặc cũng có thể dùng các thuật toán clustering đơn giản\ncho một chiều dữ liệu để chia thuộc tính thành các cluster nhỏ. Lúc này,\nthuộc tính liên tục được chuyển về thuộc tính dạng categorical.\nHạn chế lớn nhất của ID3 và decision tree nói chung là việc nếu một\nđiểm dữ liệu mới rơi vào nhầm nhánh ở ngay những lần phân chia đầu\ntiên, kết quả cuối cùng sẽ khác đi rất nhiều. Việc rơi vào nhầm nhánh này\nrất dễ xảy ra trong trường hợp thuộc tính liên tục được chia thành nhiều\nnhóm nhỏ, vì hai điểm có thuộc tính tương ứng rất gần nhau có thể rơi vào\nhai nhóm khác nhau.\n\n[1] CSE5230 Tutorial: The ID3 Decision Tree Algorithm.\n[2] Hands-On Machine Learning with Scikit-Learn and TensorFlow"
    },
    {
        "ID": 8,
        "URL": "https://machinelearningcoban.com/2017/08/31/evaluation/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\nBạn có thể download toàn bộ source code dưới dạng Jupyter Notebook tại đây.\n\nKhi xây dựng một mô hình Machine Learning, chúng ta cần một phép đánh giá để xem mô hình sử dụng có hiệu quả không và để so sánh khả năng của các mô hình. Trong bài viết này, tôi sẽ giới thiệu các phương pháp đánh giá các mô hình classification.\nHiệu năng của một mô hình thường được đánh giá dựa trên tập dữ liệu kiểm thử (test data). Cụ thể, giả sử đầu ra của mô hình khi đầu vào là tập kiểm thử được mô tả bởi vector y_pred - là vector dự đoán đầu ra với mỗi phần tử là class được dự đoán của một điểm dữ liệu trong tập kiểm thử. Ta cần so sánh giữa vector dự đoán y_pred này với vector class thật của dữ liệu, được mô tả bởi vector y_true.\nVí dụ với bài toán có 3 lớp dữ liệu được gán nhãn là 0, 1, 2. Trong bài toán thực tế, các class có thể có nhãn bất kỳ, không nhất thiết là số, và không nhất thiết bắt đầu từ 0. Chúng ta hãy tạm giả sử các class được đánh số từ 0 đến C-1 trong trường hợp có C lớp dữ liệu.  Có 10 điểm dữ liệu trong tập kiểm thử với các nhãn thực sự được mô tả bởi y_true = [0, 0, 0, 0, 1, 1, 1, 2, 2, 2]. Giả sử bộ phân lớp chúng ta đang cần đánh giá dự đoán nhãn cho các điểm này là y_pred = [0, 1, 0, 2, 1, 1, 0, 2, 1, 2].\nCó rất nhiều cách đánh giá một mô hình phân lớp. Tuỳ vào những bài toán khác nhau mà chúng ta sử dụng các phương pháp khác nhau. Các phương pháp thường được sử dụng là: accuracy score, confusion matrix, ROC curve, Area Under the Curve, Precision and Recall, F1 score, Top R error, etc.\nTrong Phần 1 này, tôi sẽ trình bày về accuracy score, confusion matrix, ROC curve, và Area Under the Curve. Các phương pháp còn lại sẽ được trình bày trong Phần 2.\n\nCách đơn giản và hay được sử dụng nhất là accuracy (độ chính xác). Cách đánh giá này đơn giản tính tỉ lệ giữa số điểm được dự đoán đúng và tổng số điểm trong tập dữ liệu kiểm thử.\nTrong ví dụ này, ta có thể đếm được có 6 điểm dữ liệu được dự đoán đúng trên tổng số 10 điểm. Vậy ta kết luận độ chính xác của mô hình là 0.6 (hay 60%). Để ý rằng đây là bài toán với chỉ 3 class, nên độ chính xác nhỏ nhất đã là khoảng 1/3, khi tất cả các điểm được dự đoán là thuộc vào một class nào đó.\nVà đây là cách tính bằng thư viên:\n\nCách tính sử dụng accuracy như ở trên chỉ cho chúng ta biết được bao nhiêu phần trăm lượng dữ liệu được phân loại đúng mà không chỉ ra được cụ thể mỗi loại được phân loại như thế nào, lớp nào được phân loại đúng nhiều nhất, và dữ liệu thuộc lớp nào thường bị phân loại nhầm vào lớp khác. Để có thể đánh giá được các giá trị này, chúng ta sử dụng một ma trận được gọi là confusion matrix.\nVề cơ bản, confusion matrix thể hiện có bao nhiêu điểm dữ liệu thực sự thuộc vào một class, và được dự đoán là rơi vào một class. Để hiểu rõ hơn, hãy xem bảng dưới đây:\nCó tổng cộng 10 điểm dữ liệu. Chúng ta xét ma trận tạo bởi các giá trị tại vùng 3x3 trung tâm của bảng.\nMa trận thu được được gọi là confusion matrix. Nó là một ma trận vuông với kích thước mỗi chiều bằng số lượng lớp dữ liệu. Giá trị tại hàng thứ i, cột thứ j là số lượng điểm lẽ ra thuộc vào class i nhưng lại được dự đoán là thuộc vào class j. Như vậy, nhìn vào hàng thứ nhất (0), ta có thể thấy được rằng trong số bốn điểm thực sự thuộc lớp 0, chỉ có hai điểm được phân loại đúng, hai điểm còn lại bị phân loại nhầm vào lớp 1 và lớp 2.\nChú ý: Có một số tài liệu định nghĩa ngược lại, tức giá trị tại cột thứ i, hàng thứ j là số lượng điểm lẽ ra thuộc vào class i nhưng lại được dự đoán là thuộc vào class j. Khi đó ta sẽ được confusion matrix là ma trận chuyển vị của confusion matrix như cách tôi đang làm. Tôi chọn cách này vì đây chính là cách thư viện sklearn sử dụng.\nChúng ta có thể suy ra ngay rằng tổng các phần tử trong toàn ma trận này chính là số điểm trong tập kiểm thử. Các phần tử trên đường chéo  của ma trận là số điểm được phân loại đúng của mỗi lớp dữ liệu. Từ đây có thể suy ra accuracy chính bằng tổng các phần tử trên đường chéo chia cho tổng các phần tử của toàn ma trận. Đoạn code dưới đây mô tả cách tính confusion matrix:\nCách biểu diễn trên đây của confusion matrix còn được gọi là unnormalized confusion matrix, tức ma confusion matrix chưa chuẩn hoá. Để có cái nhìn rõ hơn, ta có thể dùng normalized confuion matrix, tức confusion matrix được chuẩn hoá. Để có normalized confusion matrix, ta lấy mỗi hàng của unnormalized confusion matrix sẽ được chia cho tổng các phần tử trên hàng đó. Như vậy, ta có nhận xét rằng tổng các phần tử trên một hàng của normalized confusion matrix luôn bằng 1. Điều này thường không đúng trên mỗi cột. Dưới đây là cách tính normalized confusion matrix:\nVà cách tính sử dụng thư viện:\nConfusion matrix thường được minh hoạ bằng màu sắc để có cái nhìn rõ ràng hơn. Đoạn code dưới đây giúp hiển thị confusion matrix ở cả hai dạng (Nguồn: Confusion matrix):\nVới các bài toán với nhiều lớp dữ liệu, cách biểu diễn bằng màu này rất hữu ích. Các ô màu đậm thể hiện các giá trị cao. Một mô hình tốt sẽ cho một confusion matrix có các phần tử trên đường chéo chính có giá trị lớn, các phần tử còn lại có giá trị nhỏ. Nói cách khác, khi biểu diễn bằng màu sắc, đường chéo có màu càng đậm so với phần còn lại sẽ càng tốt. Từ hai hình trên ta thấy rằng confusion matrix đã chuẩn hoá mang nhiều thông tin hơn. Sự khác nhau được thấy ở ô trên cùng bên trái. Lớp dữ liệu 0 được phân loại không thực sự tốt nhưng trong unnormalized confusion matrix, nó vẫn có màu đậm như hai ô còn lại trên đường chéo chính.\n\n\nCách đánh giá này thường được áp dụng cho các bài toán phân lớp có hai lớp dữ liệu. Cụ thể hơn, trong hai lớp dữ liệu này có một lớp nghiêm trọng hơn lớp kia và cần được dự đoán chính xác. Ví dụ, trong bài toán xác định có bệnh ung thư hay không thì việc không bị sót (miss) quan trọng hơn là việc chẩn đoán nhầm âm tính thành dương tính. Trong bài toán xác định có mìn dưới lòng đất hay không thì việc bỏ sót nghiêm trọng hơn việc báo động nhầm rất nhiều. Hay trong bài toán lọc email rác thì việc cho nhầm email quan trọng vào thùng rác nghiêm trọng hơn việc xác định một email rác là email thường.\nTrong những bài toán này, người ta thường định nghĩa lớp dữ liệu quan trọng hơn cần được xác định đúng là lớp Positive (P-dương tính), lớp còn lại được gọi là Negative (N-âm tính). Ta định nghĩa True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN) dựa trên confusion matrix chưa chuẩn hoá như sau:\nNgười ta thường quan tâm đến TPR, FNR, FPR, TNR (R - Rate) dựa trên normalized confusion matrix như sau:\nFalse Positive Rate còn được gọi là False Alarm Rate (tỉ lệ báo động nhầm), False Negative Rate còn được gọi là Miss Detection Rate (tỉ lệ bỏ sót). Trong bài toán dò mìn, thà báo nhầm còn hơn bỏ sót, tức là ta có thể chấp nhận False Alarm Rate cao để đạt được Miss Detection Rate thấp.\nChú ý::\nViệc biết một cột của confusion matrix này sẽ suy ra được cột còn lại vì tổng các hàng luôn bằng 1 và chỉ có hai lớp dữ liệu.\nVới các bài toán có nhiều lớp dữ liệu, ta có thể xây dựng bảng True/False Positive/Negative cho mỗi lớp nếu coi lớp đó là lớp Positive, các lớp còn lại gộp chung thành lớp Negative, giống như cách làm trong one-vs-rest. Bạn có thể xem thêm ví dụ tại đây.\n\nTrong một số bài toán, việc tăng hay giảm FNR, FPR có thể được thực hiện bằng việc thay đổi một ngưỡng (threshold) nào đó. Lấy ví dụ khi ta sử dụng thuật toán Logistic Regression, đầu ra của mô hình có thể là các lớp cứng 0 hay 1, hoặc cũng có thể là các giá trị thể hiện xác suất để dữ liệu đầu vào thuộc vào lớp 1. Khi sử dụng thư viện sklearn Logistic Regression, ta có thể lấy được các giá trị xác xuất này bằng phương thức predict_proba(). Mặc định, ngưỡng được sử dụng là 0.5, tức là một điểm dữ liệu x sẽ được dự đoán rơi vào lớp 1 nếu giá trị predict_proba(x) lớn hơn 0.5 và ngược lại.\nNếu bây giờ ta coi lớp 1 là lớp Positive, lớp 0 là lớp Negative, câu hỏi đặt ra là làm thế nào để tăng mức độ báo nhầm (FPR) để giảm mức độ bỏ sót (FNR)? Chú ý rằng tăng FNR đồng nghĩa với việc giảm TPR vì tổng của chúng luôn bằng 1.\nMột kỹ thuật đơn giản là ta thay giá trị threshold từ 0.5 xuống một số nhỏ hơn. Chẳng hạn nếu chọn threshold = 0.3, thì mọi điểm được dự đoán có xác suất đầu ra lớn hơn 0.3 sẽ được dự đoán là thuộc lớp Positive. Nói cách khác, tỉ lệ các điểm được phân loại là Positive sẽ tăng lên, kéo theo cả False Positive Rate và True Positive Rate cùng tăng lên (cột thứ nhất trong ma trận tăng lên). Từ đây suy ra cả FNR và TNR đều giảm.\nNgược lại, nếu ta muốn bỏ sót còn hơn báo nhầm, tất nhiên là ở mức độ nào đó, như bài toán xác định email rác chẳng hạn, ta cần tăng threshold lên một số lớn hơn 0.5. Khi đó, hầu hết các điểm dữ liệu sẽ được dự đoán thuộc lớp 0, tức Negative, và cả TNF và FNR đều tăng lên, tức TPR và FPR giảm xuống.\nNhư vậy, ứng với mỗi giá trị của threshold, ta sẽ thu được một cặp (FPR, TPR). Biểu diễn các điểm (FPR, TPR) trên đồ thị khi thay đổi threshold từ 0 tới 1 ta sẽ thu được một đường được gọi là Receiver Operating Characteristic curve hay ROC curve. (Chú ý rằng khoảng giá trị của threshold không nhất thiết từ 0 tới 1 trong các bài toán tổng quát. Khoảng giá trị này cần được đảm bảo có trường hợp TPR/FPR nhận giá trị lớn nhất hay nhỏ nhất mà nó có thể đạt được).\nDưới đây là một ví dụ với hai lớp dữ liệu. Lớp thứ nhất là lớp Negative có 20 điểm dữ liệu, 30 điểm còn lại thuộc lớp Positive. Giả sử mô hình đang xét cho các đầu ra của dữ liệu (xác suất) được lưu ở biến scores.\nNhìn chung, các điểm thuộc lớp 1 có score cao hơn. Thư viện sklearn sẽ giúp chúng ta tính các thresholds cũng như FPR và TPR tương ứng:\nNhư vậy, ứng với threshold = 0.69637251, fpr = 0 và tpr = 0.03. Đây không phải là một ngưỡng tốt vì mặc dụ False Positive Rate thấp, True Positive Rate cũng rất thấp. Chúng ta luôn muốn rằng FPR thấp và TPR cao.\nROC cho bài toán này được minh hoạ như dưới đây:\n\nDựa trên ROC curve, ta có thể chỉ ra rằng một mô hình có hiệu quả hay không. Một mô hình hiệu quả khi có FPR thấp và TPR cao, tức tồn tại một điểm trên ROC curve gần với điểm có toạ độ (0, 1) trên đồ thị (góc trên bên trái). Curve càng gần thì mô hình càng hiệu quả.\nCó một thông số nữa dùng để đánh giá mà tôi đã sử dụng ở trên được gọi là Area Under the Curve hay AUC. Đại lượng này chính là diện tích nằm dưới ROC curve màu cam. Giá trị này là một số dương nhỏ hơn hoặc bằng 1. Giá trị này càng lớn thì mô hình càng tốt.\nChú ý: Cross validation cũng có thể được thực hiện bằng cách xác định ROC curve và AUC lên [validation set].\n\n\nVới bài toán phân loại mà tập dữ liệu của các lớp là chênh lệch nhau rất nhiều, có một phép đó hiệu quả thường được sử dụng là Precision-Recall.\nTrước hết xét bài toán phân loại nhị phân. Ta cũng coi một trong hai lớp là positive, lớp còn lại là negative.\nXét Hình 3 dưới đây:\n\nVới một cách xác định một lớp là positive, Precision được định nghĩa là tỉ\nlệ số điểm true positive trong số những điểm được phân loại là\npositive (TP + FP).\nRecall được định nghĩa là tỉ lệ số điểm true positive trong số những\nđiểm thực sự là positive (TP + FN).\nMột cách toán học, Precison và Recall là hai phân số có tử số bằng nhau nhưng\nmẫu số khác nhau:\n\\[\n\\begin{eqnarray}\n\\text{Precision} &=& \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \\\n\\text{Recall} &=& \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n\\end{eqnarray}\n\\]\nBạn đọc có thể nhận thấy rằng TPR và Recall là hai đại lượng bằng nhau. Ngoài\nra, cả Precision và Recall đều là các số không âm nhỏ hơn hoặc bằng một.\nPrecision cao đồng nghĩa với việc độ chính xác của các điểm tìm được là cao. Recall cao đồng nghĩa với việc True Positive Rate cao, tức tỉ lệ bỏ sót các điểm thực sự positive là thấp.\nVí dụ nhỏ dưới đây thể hiện cách tính Precision và Recall dựa vào Confusion Matrix cho bài toán phân loại nhị phân.\nKhi Precision = 1, mọi điểm tìm được đều thực sự là positive, tức không có điểm negative nào lẫn vào kết quả. Tuy nhiên, Precision = 1 không đảm bảo mô hình là tốt, vì câu hỏi đặt ra là liệu mô hình đã tìm được tất cả các điểm positive hay chưa. Nếu một mô hình chỉ tìm được đúng một điểm positive mà nó chắc chắn nhất thì ta không thể gọi nó là một mô hình tốt.\nKhi Recall = 1, mọi điểm positive đều được tìm thấy. Tuy nhiên, đại lượng này lại không đo liệu có bao nhiêu điểm negative bị lẫn trong đó. Nếu mô hình phân loại mọi điểm là positive thì chắc chắn Recall = 1, tuy nhiên dễ nhận ra đây là một mô hình cực tồi.\nMột mô hình phân lớp tốt là mô hình có cả Precision và Recall đều cao, tức càng gần một càng tốt. Có hai cách đo chất lượng của bộ phân lớp dựa vào Precision và Reall: Precision-Recall curve và F-score.\n\nTương tự như ROC curve, chúng ta cũng có thể đánh giá mô hình dựa trên việc thay đổi một ngưỡng và quan sát giá trị của Precision và Recall. Khái niệm Area Under the Curve (AUC) cũng được định nghĩa tương tự. Với Precision-Recall Curve, AUC còn có một tên khác là Average precision (AP).\nGiả sử có \\(N\\) ngưỡng để tính precision và recall, với mỗi ngưỡng cho một cặp giá trị precision, recall là \\(P_n, R_n,~ n= 1, 2, \\dots, N\\). Precision-Recall curve được vẽ bằng cách vẽ từng điểm có toạ độ \\((R_n, P_n)\\) trên trục toạ độ và nối chúng với nhau. AP được xác định bằng: \n\\[\n\\text{AP} = \\sum_{n}(R_{n} - R_{n-1})P_n\n\\]\nở đó \\((R_{n} - R_{n-1})P_n\\) chính là diện tích hình chữ nhật có chiều rộng \\((R_{n} - R_{n-1})\\) và chiều cao \\(P_n\\), đây cũng gần với cách tính tích phân dựa trên cách tính diện tích của từng hình chữ nhật nhỏ. (Nếu bạn đọc còn nhớ khái niệm diện tích hình thang cong thì sẽ tưởng tượng ra.)\nXem thêm Precision-Recall–scikit-learn.\n\n$F_1$ score, hay F1-score, là harmonic mean của precision và recall (giả sử rằng hai đại lượng này khác không):\n\\[\n\\frac{2}{F_1} = \\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}} ~ \\text{hay} ~ F_1 = 2\\frac{1}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}} = 2\\frac{\\text{precion}\\cdot{recall}}{\\text{precision} + \\text{recall}}\n\\]\n\\(F-1\\)-score có giá trị nằm trong nửa khoảng \\((0, 1]\\). \\(F_1\\) càng cao, bộ phân lớp càng tốt. Khi cả recall và precision đều bằng 1 (tốt nhất có thể), \\(F_1 = 1\\). Khi cả recall và precision đều thấp, ví dụ bằng 0.1, \\(F_1 = 0.1\\). Dưới đây là một vài ví dụ về \\(F_1\\)\nNhư vậy, một bộ phân lớp với precision = recall = 0.5 tốt hơn một bộ phân lớp\nkhác với precision = 0.3, recall = 0.8 theo cách đo này.\nTrường hợp tổng quát của \\(F_1\\) score là \\(F_{\\beta}\\) score: \n\\[\nF_{\\beta} = ( 1 + \\beta^2)\\frac{\\text{precision}\\cdot\\text{recall}}{\\beta^2\\cdot\\text{precision} + \\text{recall}}\n\\]\n\\(F_1\\) chính là một trường hợp đặc biệt của \\(F_{\\beta}\\) khi \\(\\beta =\n1\\). Khi \\(\\beta >1\\), recall được coi trọng hơn precision, khi \\(\\beta <\n1\\), precision được coi trọng hơn. Hai đại lượng \\(\\beta\\) thường được sử\ndụng là \\(\\beta = 2\\) và \\(\\beta = 0.5\\).\n\nCũng giống như ROC curve, precision-recall curve ban đầu được định nghĩa cho bài\ntoán phân lớp nhị phân. Để có thể áp dụng các phép đo này cho bài toán\nmulti-class classification, các đại lượng đầu ra (ground truth và predicted\noutput) cần được đưa về dạng nhị phân.\nBằng trực giác, ta có thể đưa bài toán phân lớp nhiều lớp về bài toán phân lớp\nnhị phân bằng cách xem xét từng lớp. Với mỗi lớp, ta coi dữ liệu thuộc lớp đó có\nlabel là positive, tất cả các dữ liệu còn lại có label là negative. Sau đó,\ngiá trị Precision, Recall, và PR curve được áp dụng lên từng lớp. Với mỗi lớp,\nta sẽ nhận được một cặp giá trị  precision và recall. Với các bài toán có ít lớp\ndữ liệu, ta có thể minh hoạ PR curve cho từng lớp trên cùng một đồ thị. Tuy\nnhiên, với các bài toán có rất nhiều lớp dữ liệu, việc này đôi khi không khả\nthi. Thay vào đó, hai phép đánh giá dựa trên Precision-Recall được sử dụng là\nmicro-average và macro-average.\n\nXét ví dụ bài toán với 3 lớp dữ liệu, bộ phân lớp cho các tham số FP, TP, FN của\nmỗi lớp là:\nMicro-average precision và Micro-average recall đơn giản được tính bằng: \n\\[\n\\begin{eqnarray}\n\\text{micro-average precision} &=& \\frac{\\sum_{c=1}^C\\text{TP}c}{\\sum_{c=1}^C(\\text{TP}c + \\text{FP}c)}\\\n\\text{micro-average recall} &=& \\frac{\\sum_{c=1}^C\\text{TP}c}{\\sum_{c=1}^C(\\text{TP}c + \\text{FN}c)}\n\\end{eqnarray}\n\\]\nvới \\(\\text{TP}c, \\text{FP}c, \\text{FN}c\\) lần lượt là TP, FP, FN của class \\(c\\).\nTức TP được tính là tổng của toàn bộ TP của mỗi lớp. Tương tự với FP và FN. Với\nví dụ trên, micro-average precision và recall tính được là:\nMicro-average F-Score cũng được tính tương tự như F-score nhưng dựa trên\nmicro-average precision và micro-average recall.\n\nMacro-average precision là trung bình cộng của các precision theo class, tương\ntự với Macro-average recall. Với ví dụ trên, ta có\nMacro-average F-Score cũng được tính tương tự như F-score nhưng dựa trên macro-average precision và macro-average recall.\n\nAccuracy là tỉ lệ giữa số điểm được phân loại đúng và tổng số điểm. Accuracy chỉ phù hợp với các bài toán mà kích thước các lớp dữ liệu là tương đối như nhau.\nConfusion matrix giúp có cái nhìn rõ hơn về việc các điểm dữ liệu được phân loại đúng/sai như thế nào.\nTrue Positive (TP): số lượng điểm của lớp positive được phân loại đúng là positive.\nTrue Negative (TN): số lượng điểm của lớp negative được phân loại đúng là negative.\nFalse Positive (FP): số lượng điểm của lớp negative bị phân loại nhầm thành positive.\nFalse Negative (FN): số lượng điểm của lớp positiv bị phân loại nhầm thành negative\nTrue positive rate (TPR), false negative rate (FNR), false positive rate (FPR), true negative rate (TNR):\nKhi kích thước các lớp dữ liệu là chênh lệch (imbalanced data hay skew data), precision và recall thường được sử dụng: \n\\[\n\\begin{eqnarray}\n\\text{Precision} &=& \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \\\n\\text{Recall} &=& \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}\n\\end{eqnarray}\n\\]\n\\(F_1\\) score: \n\\[\nF_1 = 2\\frac{1}{\\frac{1}{\\text{precision}} + \\frac{1}{\\text{recall}}} = 2\\frac{\\text{precion}\\cdot\\text{recall}}{\\text{precision} + \\text{recall}}\n\\]\nMicro-average precision, micro-average recall: \n\\[\n\\begin{eqnarray}\n\\text{micro-average precision} &=& \\frac{\\sum_{c=1}^C\\text{TP}c}{\\sum_{c=1}^C(\\text{TP}c + \\text{FP}c)}\\\n\\text{micro-average recall} &=& \\frac{\\sum_{c=1}^C\\text{TP}c}{\\sum_{c=1}^C(\\text{TP}c + \\text{FN}c)}\n\\end{eqnarray}\n\\]\nvới \\(\\text{TP}c, \\text{FP}c, \\text{FN}c\\) lần lượt là TP, FP, FN của class \\(c\\).\nMicro-average precision, macro-average recall là trung bình cộng của các precision, recall cho từng lớp. Micro-average (macro-average) \\(F_1\\) scores cũng được tính dựa trên các micro-average (macro-average) precision, recall tương ứng.\n\n[1] Sklearn: Receiver Operating Characteristic (ROC) \n[2] Receiver Operating Characteristic (ROC) with cross validation\n[3] A systematic analysis of performance measures for classification tasks"
    },
    {
        "ID": 9,
        "URL": "https://machinelearningcoban.com/2017/10/20/fundaml_vectors/",
        "Title": "Machine Learning cơ bản",
        "Content": "Tất cả các bài tập trong bài viết này có thể được thực hiện trực tiếp trên trình duyện qua trang web FundaML\nCác số ngẫu nhiên đóng một vài trò cực kỳ quan trọng trong lập trình nói chung và lập trình Machine Learning nói riêng.\nTrong bài học này, chúng ta cùng làm quen với các hàm tạo các số ngẫu nhiên cơ bản.\nMột trong những điều quan trọng nhất khi lập trình một ngôn ngữ bất kỳ là cách\nsử dụng các hàm ngẫu nhiên. Trong bài này, chúng ta sẽ làm quen tới các hàm\nngẫu nhiên trong Numpy và các cách sử dụng chúng trong các bài toán Machine\nLearning.\nHàm numpy.random.rand trả về một mảng các số ngẫu nhiên mà mỗi phần tử là một\nsố ngẫu nhiên có phân bố đều (uniform distribution) trong nửa đoạn [0, 1):\nNếu số lượng input là 0, hàm trả về một số vô hướng.\nNếu có inputs (là các số nguyên dương), hàm này trả về một mảng ngẫu nhiên\ncó số chiều bằng với số inputs, kích thước mỗi chiều bằng với giá trị của các inputs.\nCác ngôn ngữ lập trình nói chung không tạo ra các giá trị ‘thực sự ngẫu nhiên’.\nThật vậy, nếu bạn mở python và bắt đầu với:\nthì kết quả luôn là các số giống nhau ở mỗi lần thử (bạn hãy thoát python và thử\nlại nhiều lần xem). Như trên máy tính của tôi, kết quả lúc nào cũng là\n0.38919680466308004. Như vậy, hàm ngẫu nhiên không thực sự sinh ra các giá trị ngẫu nhiên. Tuy nhiên, nếu thực hiện hàm này rất nhiều lần, chúng ta sẽ thu được các các số\nnằm trong khoảng [0, 1) mà xác suất để một điểm nằm trong đoạn [a, b] với\n0 <= a < b < 1 bằng b - a.\nHàm np.random.seed() là một hàm được coi như giúp khởi tạo các bộ sinh số ngẫu\nnhiên (random generator). Biến số trong seed thường là một số nguyên không\nâm 32 bit. Với các giá trị của biến số khác nhau thì sẽ cho ra các số ngẫu\nnhiên khác nhau.\nHàm số này được dùng để đối chiều kết quả trong các lần chạy khác nhau trong\ncác bài toán Machine Learning. Rất nhiều các thuật toán Machine Learning chạy\ndựa trên việc tính toán ngẫu nhiên (ví dụ, Stochastic Gradient Descent\nđược sử dụng rất nhiều trong các thuật toán tối ưu Neural Networks). Để đối\nchiếu kết quả trong nhiều lần chạy trên, người ta thường khởi tạo các random\ngenerator với các seed như nhau.\nCác bạn có thể để ý thấy rằng trong các bài trước tôi thường dùng\nnp.random.seed(). Việc đó để đảm bảo rằng kết quả bạn tìm được giống với kết\nquả trong code mẫu.\nBài tập: Cho các số a, b, m, n trong đó a < b là hai số thực bất kỳ; \nm, n là các số nguyên dương. Viết hàm số tạo một mảng hai chiều có \nshape = (m, n), các phần tử là các số ngẫu nhiên phân bố đều trong \nnửa đoạn [a, b).\nChú ý:\nLưu ý rằng đây chỉ là điều kiện cần, không phải điều kiện đủ.\nPhân phối chuẩn \n(normal distribution) hay phân bố Gassian (Gassian distribution)\nrất quan trọng trong thực tế và các bài toán kỹ thuật.\nHàm numpy.random.randn() (chữ n ở cuối là viết tắt của normal) có chức \nnăng tương tự như hàm np.random.rand nhưng kết quả trả về là mảng có các phần \ntử phân bố theo phân phối chuẩn có kỳ vọng bằng 0 và phương sai bằng 1.\nBài tập: \nCho các số a, s, m, n với:\nXây dựng một mảng ngẫu nhiên hai chiều có shape = (m, n) mà các phần tử của nó \ntuần theo phân phối chuẩn có kỳ vọng bằng a và phương sai là s.\nChú ý: Ký hiệu \\(\\mathcal{N}(\\mu, \\sigma^2)\\) để chỉ một phân phối chuẩn có \nkỳ vọng \\(\\mu\\) và phương sai \\(\\sigma^2\\). Một biến ngẫu nhiên \\(X\\) tuân theo \nphân phối chuẩn có kỳ vọng \\(\\mu\\), phương sai \\(\\sigma^2\\) sẽ được ký hiệu là \n\\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\).\nNếu \\(X \\sim \\mathcal{N}(\\mu, \\sigma^2)\\) thì:\nHàm tạo mảng các số tự nhiên ngẫu nhiên. Bạn đọc có thể tham khảo trực tiếp\ncách sử dụng trong numpy document:\nChú ý cụm \"discrete uniform\" distribution. Điều này tức là mỗi số nguyên\ntrong nửa đoạn [low, high) sẽ xuất hiện với xác suất bằng nhau.\nVí dụ:\nPhần này không có bài tập.\nVí dụ trên đây có mục đích là tạo ra một mảng có 10 phần tử bao gồm các số tự\nnhiên từ 0 đến 9 sắp xếp theo thứ tự ngẫu nhiên. Mảng này còn được gọi là một\nhoán vị của các số từ 0 đến 9.\nHoán vị ngẫu nhiên được sử dụng rất nhiều khi xử lý dữ liệu trong Machine\nLearning. Dưới đây là hai ví dụ điển hình.\nTrong Stochastic Gradient Descent,\nviệc quan trọng nhất là ở mỗi epoch, chúng ta cần trộn lẫn thứ tự của dữ liệu \nvà lấy ra từng mini-batch trong đó. Cụ thể, nếu coi toàn bộ dữ liệu là một ma \ntrận, mỗi hàng là một điểm dữ liệu và có tổng cộng \\(N\\) điểm. Tại mỗi \niteration, ta sẽ lấy ra một tập con \\(k\\) điểm dữ liệu, với \\(k \\ll N\\) để \ncập nhật nghiệm. Trong một epoch, ta cần đảm bảo rằng tất cả các điểm dữ liệu \nđều được lấy ra tại một minibatch nào đó và không có điểm nào được lấy quá một \nlần (giả sử rằng \\(N\\) chia hết cho \\(k\\)). Và hơn nữa, việc lấy ra các \nminibatch ở mỗi epoch là khác nhau.\nViệc này có thể được thực hiện bằng cách tạo ra một hoán vị ngẫu nhiên của các \nsố từ \\(0\\)( đến \\(N-1\\) và coi chúng như chỉ số của các điểm dữ liệu. Tại \nminibatch thứ nhất, ta lấy ra các hàng có chỉ số tương ứng với \\(k\\) số đầu \ntiên trong hoán vị tìm được. Lần lượt như vậy cho tới khi minibatch cuối cùng \nđược lấy ra. Sau đó ta lại trộn lẫn dữ liệu bằng một hoán vị ngẫu nhiên khác.\n(Bạn đọc có thể tham khảo cách trực tiếp sử dụng thư viện tại đây)\nKhi kiểm tra một thuật toán Machine Learning, người ta thường chia tập dữ liệu\nthu được thành hai phần: training và test (có thể có thêm validation). Một điều\nquan trọng là phần phân chia này phải được tạo một cách ngẫu nhiên để tránh việc\ndữ liệu được phân chia một cách quá thiên lệch (biased). Và đây là lúc chúng\nta có thể sử dụng các hoán vị ngẫu nhiên.\nGiả sử có 100 điểm dữ liệu, ta cần lấy ngẫu nhiên ra 70 điểm làm training test,\n30 điểm còn lại làm test set. Cách đơn giản nhất là tạo một hoán vị ngẫu nhiên\ncủa các số từ 0 đến 99. Sau đó 70 điểm có chỉ số là 70 phần tử đầu tiên của mảng\nhoán vị được dùng làm training set, 30 điểm còn lại được dùng làm test set.\nBài tập:\nCho hai số tự nhiên N > k > 0 viết hàm số sample_no_replace(N, k) trả về\nngẫu nhiên k số tự nhiên nằm trong tập {0, 1, ..., N-1} sao cho không có hai\nsố nào trùng nhau.\nViệc ngẫu nhiên ở đây sẽ được kiểm chứng bằng cách gọi hàm \nsample_no_replace(N, k) nhiều lần. Trong toàn bộ các kết quả trả về, tần suất \nxuất hiện của mỗi số trong tập {0, 1, ..., N-1} phải gần bằng nhau.\nGiả sử X là ma trận chứa N điểm dữ liệu theo hàng. Nếu \nidx =sample_no_replace(N, k) là kết quả trả về của hàm bạn đã viết, k điểm \nngẫu nhiên của X có thể được lấy ra bằng X[idx, :].\n(còn nữa)"
    },
    {
        "ID": 10,
        "URL": "https://machinelearningcoban.com/2017/10/20/fundaml_matrices/",
        "Title": "Machine Learning cơ bản",
        "Content": "Tất cả các bài tập trong bài viết này có thể được thực hiện trực tiếp trên trình duyệt qua trang web FundaML\n\nTrong Numpy, người ta thường dùng mảng numpy hai chiều để thể hiện một ma trận. Mảng hai chiều có thể coi là một mảng của các mảng một chiều. Trong đó, mỗi mảng nhỏ một chiều tương ứng với một hàng của ma trận.\nNói cách khác, ma trận có thể được coi là mảng của các vector hàng - mỗi vector hàng được biểu diễn bằng một mảng numpy một chiều.\nVí dụ, nếu một mảng numpy hai chiều a mô tả ma trận:\n\\(\\left[\n\\begin{matrix} 1 & 2 \\\\ 3 & 4 \\end{matrix} \\right]\n\\), khi được in ra nó sẽ có dạng:\nỞ đây chúng ta có thể nhìn thấy ba mảng, mỗi mảng được thể hiện bằng một cặp \nđóng mở ngoặc vuông []:\nhai mảng [1, 2] và [3, 4] thể hiện các hàng của ma trận. Chúng là các \nmảng một chiều.\nmảng [[1, 2], [3, 4]] có hai phân tử, mỗi phần tử là một hàng của ma trận.\nTheo quy ước của Numpy, chúng ta cần đi từ mảng ngoài cùng tới các mảng trong:\nmảng lớn nhất là [[1, 2], [3, 4]] được coi là mảng ứng với axis = 0. \nTrong mảng này, thành phần thứ nhất là [1, 2], thành phần thứ hai là [3, 4].\nhai mảng lớn thứ hai là [1, 2] và [3, 4] được coi là các mảng ứng với axis = 1.\n(Xem thêm hình vẽ bên.)\nChú ý:\nMột mảng numpy hoàn toàn có thể có nhiều hơn hai chiều. Khi đó ta vẫn đi từ \ncặp ngoặc vuông ngoài cùng vào tới trong cùng, axis cũng đi từ 0, 1, ... \ntheo thứ tự đó.\nMỗi mảng con phải có số phần tử bằng nhau, thể hiện cho việc mỗi hàng của \nma trận phải có số chiều như nhau, không có hàng nào thò ra thụt vào.\nKhi làm việc với các thư viện cho Machine Learning, mỗi điểm dữ liệu thường \nđược coi là một mảng một chiều. Tập hợp các điểm dữ liệu thường được lưu trong \nmột ma trận - tức mảng của các mảng một chiều. Trong ma trận này, mỗi hàng \ntương ứng với một điểm dữ liệu.\nViệc này hơi ngược với cách xây dựng toán học của các thuật toán, nơi mà mỗi \nđiểm dữ liệu thường được coi là một vector cột - tức mỗi cột của ma trận là \nmột điểm dữ liệu. Khi đọc các tài liệu và làm việc với các thư viện, bạn đọc cần \nchú ý.\nGiống như bài “Cơ bản về vector”, trong bài học này, chúng ta sẽ cùng làm quen \nvới các cách xử lý ma trận trong Numpy: Khởi tạo, truy cập, thay đổi, ma trận \nđặc biệt, …\n\n\nCách đơn giản nhất để khởi tạo một ma trận là nhập vào từng phần tử của ma trận \nđó. Cách làm này, tất nhiên, chỉ phù hợp với các ma trận nhỏ.\nNếu bạn mới chuyển từ Matlab qua Python, bạn sẽ thấy cách khai báo của Matlab dễ chịu hơn rất nhiều. Chúng ta sẽ phải quen dần thôi :).\nKhi khai báo một mảng numpy nói chung, nếu ít nhất một phần tử của mảng là \nfloat, type của mọi phần tử trong mảng sẽ được coi là 'numpy.float64' \n(số thực 64 bit).\nNgược lại, nếu toàn bộ các phần tử là số nguyên (không có dấu . xuất hiện),\ntype của mọi phần tử trong mảng sẽ được coi là 'numpy.int64' (số nguyên 64 bit).\nNếu muốn chỉ định type của các phần tử trong mảng, ta cần đặt giá trị cho dtype. \nVí dụ:\nBài tập:\nKhai báo một mảng numpy hai chiều A mô tả ma trận:\n\\[\\mathbf{A} = \\left[\n\\begin{matrix}\n1 & 2 & 3 \\\\ 4 & 5 & 6 \\\\ 7 & 8 & 9\n\\end{matrix}\n\\right]\n\\]\n\n\nĐể tạo một ma trận đơn vị có số chiều bằng n (ma trận đơn vị là một ma trận vuông có tất cả các phần tử trên đường chéo bằng 1), chúng ta sử dụng hàm np.eye():\nHàm np.eye() cũng được dùng để tạo các ma trận toàn 1 ở một đường chéo phụ nào đó, các thành phần còn lại bằng 0. Ví dụ:\nk = 1 sẽ tương ứng với đường chéo phụ ngay trên đường chéo chíh. k = -2 sẽ tương ứng với đường chéo phụ thứ hai bên dưới đường chéo chính.\nBạn đọc có thể đọc thêm về cách sử dụng hàm ‘np.eye()’ tại đây.\nXin nhắc lại rằng bạn đọc luôn có thể xem cách sử dụng một hàm trên terminal bằng cách gõ help(func) trong đó func là tên hàm bạn muốn tra cứu. Ví dụ, help(np.eye).\n\nĐể khai báo một ma trận đường chéo, hoặc muốn trích xuất đường chéo của một ma trận, ta dùng hàm np.diag.\nNếu đầu vào là một mảng một chiều, trả về một mảng hai chiều thể hiện ma trận có đường chéo là các phần tử thuộc mảng đó.\nNếu đầu vào là một mảng hai chiều (có thể không vuông), trả về mảng một chiều chứa các giá trị ở hàng thứ i, \ncột thứ i với 0 <= i <= min(m, n). Trong đó m, n lần lượt là số hàng và số cột của ma trận được biểu diễn bằng mảng hai chiều ban đầu.\nĐường chéo phụ của một ma trận cũng có thể được lấy bằng cách sử dụng hàm này và chỉ ra giá trị của k:\nBài tập:\nVới một số tự nhiên n, hãy viết hàm trả về ma trận có dạng: \n\\[\n\\left[\n\\begin{matrix}\n0 & 0 & 0 & 0 & \\dots & 0 & 0 \\\\ 1 & 0 & 0 & 0 & \\dots & 0 & 0 \\\\ 0 & 2 & 0 & 0 & \\dots & 0 & 0 \\\\ \\dots & \\dots & \\dots & \\dots & \\ddots & \\dots \\\\ 0 & 0 & 0 & 0 & \\dots & 0 & 0 \\\\ 0 & 0 & 0 & 0 & \\dots & n & 0 \n\\end{matrix}\n\\right]\n\\]\ntức đường chéo phụ ngay dưới đường chéo chính nhận các giá trị từ 1 đến \\(n\\). Các thành phần là kiểu số nguyên.\n\nGiống như cách tìm kích thước của mảng một chiểu, để tìm kích thước của mảng hai chiều, ta cũng sử dụng thuộc tính shape:\nỞ đây, kết quả trả về là một tuple. Số phần tử của tuple này chính là số \nchiều của mảng. Nếu coi mảng hai chiều như ma trận, số hàng và số cột của ma \ntrận có thể được tính bằng:\nVới mảng numpy nhiều chiều, ta cũng dùng thuộc tính shape để tìm kích thước \ncủa mỗi chiều.\n\n\nCó hai cách để truy cập vào mỗi phần tử của mảng hai chiều:\n\nĐể truy cập vào phần tử ở hàng thứ i, cột thứ j của ma trận (chỉ số bắt đầu \ntừ 0), ta có thể coi phần tử đó là phần tử thứ j của mảng i trong mảng hai \nchiều ban đầu.\nVí dụ:\nở đây A[1] chính lả mảng một chiều [4, 5, 6], trong mảng này, ta lấy phần \ntử có chỉ số là 2, phần tử đó có giá trị là 6. Vậy A[1][2] = 6.\n\nTrong Matlab, để truy cập vào phần tử ở hàng đầu tiên, cột đầu tiên của một ma \ntrận A, ta sử dụng A(1, 1). Trong Numpy, có một chút thay đổi:\nVí dụ\n\nĐể truy cập vào hàng có chỉ số i của một ma trận A, ta chỉ cần dùng A[i] \nhoặc A[i,:] hoặc A[i][:]:\nĐể truy cập vào cột có chỉ số j, ta dùng A[:,j]:\nChú ý:\nTrong Numpy, kết quả trả về của một cột hay hàng đều là một mảng một chiều, \nkhông phải là một vector cột như trong Matlab. Tuy nhiên, khi lấy một ma trận \nnhân với nó, nó vẫn được coi là một vector cột. Thông tin chi tiết sẽ có trong \ncác bài sau.\nNếu sử dụng A[:][1], kết quả trả về là hàng có chỉ số 1 chứ không \nphải cột có chỉ số 1. Trong trường hợp này, A[:] vẫn được hiểu là cả ma \ntrận A, vì vậy nên A[:][1] tương đương với A[1].\nCó sự khác nhau căn bản giữa A và A[:], chúng ta sẽ quay lại trong một \nbài nào đó ở sau.\nBài tập:\nCho một ma trận A, viết hàm myfunc tính tổng các phần tử trên các cột \ncó chỉ số chẵn (0, 2, 4, ...) của ma trận đó. \nVí dụ:\nGiải thích: cột có chỉ số 0 của ma trận là mảng [1, 3], tổng các phần tử \ncủa mảng này là 4.\n\n\nViệc truy cập vào nhiều phần tử trong một hàng tương tự như với mảng một chiều:\ntrong đó, range(0, A.shape[1], 2) tạo ra một list các phần tử là cấp số cộng với công sai là 2, \nbắt đầu từ 0 và kết thúc tại số lớn nhất có thể không vượt quá số cột của A. Số cột của A chính là A.shape[1].\n\nTương tự với nhiều phần tử trong cùng một cột:\n\nNếu muốn trích một ma trận con từ ma trận ban đầu, giả sử lấy ma trận được \ntạo bởi hàng có chỉ số 1 và 2, cột có chỉ số 0 và 3, ta làm như sau:\nChú ý: Một cách tự nhiên, bạn đọc có thể suy ra rằng câu lệnh nên là A[[1, \n2], [0, 3]] (giống như cách làm trong Matlab). Tuy nhiên, câu lệnh này sẽ cho \nra một kết quả khác (xem mục 4).\nA[[1, 2]][:, [0,3]] có thể hiểu được là: đầu tiên lấy hai hàng có chỉ số 1 \nvà 2 bằng A[[1, 2]], ta được một ma trận, sau đó lấy hai cột có chỉ số 0 \nvà 3 của ma trận mới này.\n\nXét câu lệnh:\nCâu lệnh này sẽ trả về một mảng một chiều gồm các phần tử: A[1][0] và A[2][3]\n, tức [1, 2] và [0, 3] là list các toạ độ theo mỗi chiều. Hai list này \nphải có độ dài bằng nhau hoặc một list có độ dài bằng 1. \nKhi một list có độ dài bằng 1, nó sẽ được cặp với mọi phần tử của list \ncòn lại. Ví dụ:\nBài tập: \nViết hàm myfunc tính tổng tất cả các phần tử có cả hai chỉ số đều chẵn của \nmột ma trận A bất kỳ. Ví dụ:\nGợi ý: bạn đọc tìm đọc trước cách sử dụng np.sum cho mảng nhiều chiều.\n\nXin nhắc lại về cách quy ước axis của ma trận. axis = 0 là tính theo chiều \ntừ trên xuống dưới, nghĩa là phương của nó cùng với phương của các cột. Tương \ntự axis = 1 sẽ có phương cùng với phương của các hàng. Hãy quan sát hình dưới \nđây và ghi nhớ cách quy ước quan trọng này.\nXét một ma trận:\nVà các hàm np.sum(), np.min(), np.max(), np.mean() tác động lên A theo axis = 0 (tức các cột của A), kết quả sẽ là:\nCác giá trị theo các hàm trê lần lượt là tổng, giá trị nhỏ nhất, giá trị lớn nhất, trung bình theo mỗi cột. Kết quả trả về là các mảng một chiều có số phần tử bằng số cột của A.\nTương tự như thế khi thay axis = 1:\nKết quả trả về được tính theo hàng. Kết quả trả về cũng là các mảng một \nchiều có số phần tử bằng với số hàng của A.\nKhi không đề cập tới axis, kết quả được tính trên toàn bộ ma trận:\n\nĐôi khi, để thuận tiện cho việc tính toán về sau, chúng ta muốn kết quả trả về khi axis = 0 là các vector hàng thực sự, khi axis = 1 là các vector cột thực sự.\nĐể làm được việc đó, Numpy cung cấp thuộc tính keepdims = True (mặc định là False). Khi keepdims = True, nếu sử dụng axis = 0, kết quả sẽ là một mảng hai chiều có chiều thứ nhất bằng 1 (coi như ma trận một hàng). \nTương tự, nếu sử dụng axis = 1, kết quả sẽ là một mảng hai chiều có chiều thứ hai bằng 1 (một ma trận có số cột bằng 1). Việc này, về sau chúng ta sẽ thấy, quan trọng trong nhiều trường hợp đặc biệt:\nBài tập:\nCho một ma trận A bất kỳ. Trong mỗi hàng, ta định nghĩa độ biến động của nó \nlà sự khác nhau giữa giá trị lớn nhất và nhỏ nhất của các phần tử trong hàng \nđó. Hãy viết hàm myfunc trả về tổng độ biến động của tất cả các hàng trong \nma trận đó.\nVí dụ với ma trận A trong bài học, độ biến động của mỗi hàng lần lượt là \n2.0, 4.0, 3.0. Vậy myfunc(A) = 9.0.\n\n\nKhi tính toán giữa một số vô hướng và một mảng hai chiều, ví dụ:\nTa nhận thấy rằng từng phần tử của mảng sẽ được kết hợp với số vô hướng bằng \ncác phép toán tương ứng để tạo ra một mảng mới cùng kích thước. Việc này, như \ncũng đã trình bày trong khi làm việc với mảng một chiều,\nđúng với các mảng numpy với số chiều bất kỳ.\n\nBạn đọc cũng có thể dự đoán được rằng các hàm số này cũng tác động lên từng \nphần tử của mảng và trả về một mảng cùng kích thước với mảng ban đầu.\nBài tập: Frobenious norm\nFrobenius norm của \nmột ma trận được định nghĩa là căn bậc hai của tổng bình phương các phần tử của \nma trận. \nFrobenius norm được sử dụng rất nhiều trong các thuật toán Machine Learning vì \ncác tính chất toán học đẹp của nó, trong đó quan trọng nhất là việc đạo hàm của \nbình phương của nó rất đơn giản. \nFrobenius norm của một ma trận \\(\\mathbf{A}\\)\nđược ký hiệu là \\(||\\mathbf{A}||_F\\)\nNumpy có sẵn hàm tính toán norm này, tuy nhiên, chúng ta nên học cách tự tính \nnó trước. \nViết hàm norm_fro(A) tính Frobenius norm của một ma trận bất kỳ.\nVí dụ:\nthì norm_fro(A) = 6.2449979983983983 \\(= \\sqrt{1^2 + 3^2 + 2^2 + 5^2}\\).\nGợi ý: Sử dụng hàm np.sqrt.\n\nCác phép toán cộng, trừ, nhân, chia, luỹ thừa (+, -, *, /, **) giữa hai mảng \ncùng kích thước cũng được thực hiện dựa trên từng cặp phần tử. Kết quả trả \nvề là một mảng cùng chiều với hai mảng đã cho:\nChú ý: tích của hai ma trận như định nghĩa trong Đại số tuyến tính được thực hiện dựa trên hàm số khác. Cách viết A*B được thực hiện trên từng cặp phần tử của A và B\nBài tập:\nTrong khi làm việc với Machine Learning, chúng ta thường xuyên phải so sánh hai ma trận. Xem xem liệu chúng có gần giống nhau không. Một cách phổ biến để làm việc này là tính bình phương của Frobineous norm\ncủa hiệu hai ma trận đó. Cụ thể, để xem ma trận \\(\\mathbf{A}\\) có gần ma trận \\(\\mathbf{B}\\) hay không, người ta thường tính \\(||\\mathbf{A} - \\mathbf{B}||_F^2\\).\nCho hai mảng hai chiều có cùng kích thước A và B. Viết hàm dist_fro tính bình phương Frobenious norm của hiệu hai ma trận được mô tả bởi hai mảng đó.\n\n\nCó hai cách để lấy chuyển vị của một ma trận: dùng thuộc tính .T hoặc dùng hàm np.transpose:\n\nKhi làm việc với ma trận, chúng ta sẽ phải thường xuyên làm việc với các phép biến đổi kích thước của ma trận. Phép biến đổi kích thước có thể coi là việc sắp xếp lại các phần tử của một \nma trận vào một ma trận khác có tổng số phần tử như nhau.\nTrong numpy, để làm được việc này chúng ta dùng phương thức .reshape hoặc hàm np.reshape. Cùng xem ví dụ:\nSố chiều của mảng mới không nhất thiết phải bằng 2, nó có thể bằng bất kỳ giá trị nào (lớn hơn hoặc bằng 1) nhưng phải đảm bảo tổng số phần tử của hai mảng là như nhau. Khi biến thành mảng \nmột chiều, ta không dùng tuple (như (3,2)) nữa mà chỉ dùng một số tự nhiên:\nTa có thể nhận thấy rằng nếu biến thành một mảng hai chiều mới, ta không nhất thiết phải biết kích thước của mỗi chiều mà chỉ cần kích thước của một chiều. Kích thước còn lại được suy ra\ntừ việc tổng số phần tử của hai mảng là như nhau. Tương tự, nếu biến thành một mảng ba chiều mới, ta chỉ cần biết hai trong ba kích thước. Kích thước còn lại sẽ được python tự tính ra, và ta\nchỉ cần gán nó bằng -1:\n\nCó một điểm quan trọng cần nhớ là thứ tự của phép toán reshape: các phần tử trong mảng mới được sắp xếp như thế nào. Có hai cách sắp xếp chúng ta cần lưu ý: mặc định là 'C'-order, và một cách khác là 'F'-order (xem hình).\nTrong 'C'-order, các thành phần của mảng nguồn được quét từ axis trong ra ngoài (axis = 1 rồi mới tới axis = 0 trong mảng hai chiều, tức từng hàng một), sau đó chúng được xếp vào mảng đích cũng theo thứ tự đó.\nTrong 'F'-oder (Fortran) các thành phần của mảng nguồn được quét từ axis ngoài vào trong (trong mảng hai chiều là từng cột một), sau đó chúng được sắp xếp vào mảng đích cũng theo thứ tự đó - từng cột một.\n(Đọc thêm numpy.reshape.)\nBài tập: \nHãy tạo ma trận A sau một cách nhanh nhất, không dùng cách thủ công ghi từng phần tử ra.\n\\[\n\\left[\n\\begin{matrix}\n1 &5&9&2\\\\6&10&3&7 \\\\11&4&8&12\n\\end{matrix}\n\\right]\n\\]\nGợi ý:\nBạn có thể nhận được phản hồi ‘Kết quả thành công’ nhưng hãy thử cố nghĩ quy luật của ma trận này rồi dùng các phép transpose, reshape thích hợp.\n\nChúng ta đã qua các bài về phép toán giữa một mảng hai chiều và một số vô hướng, giữa hai mảng hai chiều cùng kích thước. Trong bài này, chúng ta cùng làm quen với các phép toán giữa một mảng hai chiều \nvà một mảng một chiều. Trước tiên, hãy thử vài ví dụ:\nNhận thấy rằng kết quả của phép toán A + b thu được bằng cách lấy từng hàng của A cộng với b. Kết quả của A*b thu được bằng cách lấy tích của từng hàng của A và b - tích ở đây là tích theo từng phần tử \ncủa hai mảng một chiều, không phải tích vô hướng của hai vector. Nói cách khác, kết quả của A*b thu được bằng cách lấy từng cột của A nhân với phần tử tương ứng của b. Quy luật tương tự xảy ra \nvới cả phép -, / và **:\nBài tập\nGiả sử tập dữ liệu bao gồm nhiều điểm dữ liệu có cùng chiều, được sắp xếp thành một mảng hai chiều mô tả một ma trận - được gọi là ma trận dữ liệu. Mỗi hàng của ma trận này là một điểm dữ liệu. \nMột trong các kỹ thuật quan trọng trước khi áp dụng các thuật toán Machine Learning lên dữ liệu là chuẩn hoá dữ liệu.\nTrong các phương pháp chuẩn hoá dữ liệu, một phương pháp thường được sử dụng là đưa dữ liệu về dạng zero-mean, tức trung bình cộng của toàn bộ dữ liệu là một vector có toàn bộ các thành phần bằng 0.\nCách chuẩn hoá này có thể được thực hiện bằng cách trước tiên tính vector trung bình của toàn bộ dữ liệu (ở đây là vector trung bình của toàn bộ các hàng), \nsau đó lấy từng điểm dữ liệu trừ đi vector trung bình. Khi đó, ma trận mới sẽ có trung bình cộng các hàng bằng vector 0, và ta nói rằng ma trận dữ liệu mới này là zero-mean.\nCho một mảng hai chiều X mô tả dữ liệu, trong đó X[i] là một mảng một chiều mô tả dữ liệu có chỉ số i. Hãy viết hàm zero_mean trả về ma trận dữ liệu đã chuẩn hoá theo zero-mean.\n\n\nTrong Đại Số Tuyến Tính (ĐSTT), tích của hai ma trận \\(\\mathbf{A} \\in \\mathbb{R}^{m\\times n}\\) và \\(\\mathbf{B} \\in \\mathbb{R}^{n \\times p}\\) được ký hiệu là \\(\\mathbf{C = AB} \\in \\mathbb{R}^{m \\times p}\\) \ntrong đó phần tử ở hàng thứ \\(i\\) cột thứ \\(j\\) (tính từ \\(0\\)) của \\(\\mathbf{C}\\) được tính theo công thức: \n\\[\nc_{ij} = \\sum_{k=0}^{n-1}a_{ik}b_{kj}\n\\]\nChú ý rằng để phép nhân thực hiện được, số cột của ma trận thứ nhất phải bằng với số hàng của ma trận thứ hai (ở đây đều bằng \\(n\\)). Và phép nhân ma trận không có tính chất giao hoán, nhưng có tính chất kết hợp, tức: \n\\[\n\\mathbf{ABC} = \\mathbf{(AB)C} = \\mathbf{A}(\\mathbf{BC})\n\\]\nTrong numpy, ký hiệu * không thực sự để chỉ tích hai ma trận theo nghĩa này mà là tích theo từng cặp phần tử (element-wise). Phép toán * trong numpy yêu cầu hai mảng phải có cùng kích thước, và phép toán này có tính chất giao hoán vì phép nhân\ncủa hai số vô hướng có tính chất giao hoán.\nCho hai mảng numpy hai chiều A, B trong đó A.shape[1] == B.shape[0] (đừng quên điều kiện này). Nếu hai mảng này mô tả hai ma trận thì tích của hai ma trận (theo ĐSTT) có thể được thực hiện bằng thuộc tính \n.dot hoặc hàm np.dot:\n\nTrong ĐSTT, tích giữa một ma trận và một vector cột được coi là một trường hợp đặc biệt của tích giữa một ma trận và một ma trận có số cột bằng một. Khi làm việc với numpy, ma trận được mô tả bởi\nmảng hai chiều, vector được mô tả bởi các mảng một chiều.\nXem ví dụ dưới đây:\nTích của mảng hai chiều A và mảng một chiều b với A.shape[1] == b.shape[0] theo ĐSTT được thực hiện bằng phương thức .dot() của mảng numpy A. Kết quả trả về là một mảng một chiều có shape[0] == 4. \nChúng ta cần chú ý một chút ở đây là kết quả trả về là một mảng một chiều chứ không phải một vector cột (được biểu diễn bởi một mảng hai chiều có shape[1] = 1) như trên lý thuyết. Kết quả\ncủa A*b cũng được chỉ ra để nhắc các bạn phân biệt hai phép nhân này.\nTiếp tục quan sát:\nta thấy rằng nếu đặt b lên trước A thì có lỗi xảy ra vì xung đột chiều. Tuy nhiên nếu mảng một chiều c có kích thước bằng 4 thì lại có thể nhân với mảng hai chiều A được. \nKết quả thu được chính là vector hàng c nhân với ma trận A. (Bạn có thể tự kiểm tra lại).\nCó một chút cần lưu ý ở đây: Nếu mảng một chiều được nhân vào sau một mảng hai chiều, nó được coi như một vector cột. Nếu nó được nhân vào trước một mảng hai chiều, nó lại được coi là một vector hàng. \nDù sao thì nó vẫn là một vector, và vẫn được lưu bởi một mảng một chiều :). Đây cũng chính là một trong những lý o mà những người ban đầu làm quen với numpy gặp nhiều khó khăn.\nBài tập: Quay lại với Frobineus norm. Có một cách khác để tính bình phương của Frobineus norm của một ma trận dựa trên công thức: \n\\[\n||\\mathbf{A}||_F^2 = \\text{trace}(\\mathbf{AA}^T) = \\text{trace}(\\mathbf{A}^T\\mathbf{A})\n\\]\ntrong đó \\(\\text{trace}()\\) là hàm tính tổng các phần tử trên đường chéo của một ma trận vuông.\nCho một mảng hai chiều A, hãy viết hàm fro_trace tính bình phương của Frobineus norm của ma trận này dựa vào công thức trên.\nGợi ý:\nHy vọng các bạn gặp khó khăn chút với Compiler và nhận ra lý do của việc đó ;).\n\nChúng ta đã làm quen với Phiên bản ổn định của hàm Softmax\nvới một một mảng một chiều \\(\\mathbf{z}\\):\nBây giờ, chúng ta tiếp tục tổng quát hàm số này để áp dụng cho nhiều phần tử \ncùng lúc. Giả sử ma trận \\(\\mathbf{Z}\\) là ma trận scores của \\(N\\) điểm dữ \nliệu, mỗi hàng \\(\\mathbf{z}_i\\) của ma trận này ứng với score của một điểm dữ liệu. \nHãy viết một hàm số trên python để tính softmax cho từng hàng của \\(\\mathbf{Z}\\). \nKết quả thu được là một ma trận \\(\\mathbf{A}\\) cùng chiều với \\(\\mathbf{Z}\\) mà \nmỗi hàng của \\(\\mathbf{A}\\) là kết quả khi áp dụng hàm Softmax lên một hàng tương \nứng của \\(\\mathbf{Z}\\).\nBạn đọc cần viết hàm dưới dạng vectorization, tức không sử dụng vòng for.\nGợi ý: Lời giải có thể không vượt quá 2 dòng lệnh."
    },
    {
        "ID": 11,
        "URL": "https://machinelearningcoban.com/2017/10/12/fundaml_vectors/",
        "Title": "Machine Learning cơ bản",
        "Content": "Tất cả các bài tập trong bài viết này có thể được thực hiện trực tiếp trên trình duyện qua trang web FundaML\n\n\nMặc dù các bài học trong khoá này có thể được thực hiện trực tiếp trên trình\nduyệt, tôi vẫn khuyến khích các bạn cài đặt Python và Numpy vào trong máy\ntính cá nhân để việc lập trình được thuận tiện hơn.\nTôi giả sử các bạn đã từng sử dụng Python và có kiến thức cơ bản về Python.\nNếu bạn chưa học Python bao giờ, dưới đây là một vài khoá học và trang web mà\ntôi thấy có chất lượng tốt:\nChú ý rằng phiên bản Python được sử dụng ở đây là Python 3.\n\nNumpy là một thư viện của Python hỗ trợ cho việc tính toán các mảng nhiều\nchiều, có kích thước lớn với các hàm số đã được tối ưu áp dụng lên các mảng\nnhiều chiều đó. Numpy đặc biệt hữu ích khi thực hiện các hàm số liên quan tới\nĐại Số Tuyến Tính.\nBạn đọc có thể tham khảo tài liệu về\nnumpy.\nĐể cài đặt Numpy và các thư viện thường dùng trong Machine Learning, bạn có\nthể tham khảo các bài hướng dẫn bằng Tiếng Việt dưới đây:\nSau khi cài đặt xong, trong Python, chúng ta cần khai báo:\nđể có thể bắt đầu sử dụng các hàm số của numpy.\nVì numpy là thư viện được sử dụng thường xuyên nên nó thường được khai báo\ngọn lại thành np:\nnp có thể thay bằng các từ khác (không phải từ khoá), tuy nhiên, bạn được\nkhuyến khích đặt là np vì các tài liệu hướng dẫn đều ngầm quy ước với nhau\nnhư thế.\nCó một điểm đặc biệt cần lưu ý: biến numpy là các biến mutable. Bạn cần phân biệt rõ biến mutable và immutable trong Python.\nTiếp theo, chúng ta sẽ làm quen với cách sử dụng numpy từ đơn giản tới ít đơn\ngiản hơn. Các bạn có thể di chuyển giữa các bài học thông qua nút “Lesson\nOutline” và hai nút điều hướng ở đầu trang FundaML.\n\n\nTrong Numpy, vector được hiểu là một mảng 1 chiều.\nVí dụ: để có một vector x = [1, 2, 3], chúng ta thực hiện như sau:\nChúng ta ngầm hiểu rằng thư viện numpy đã được khai báo bởi: import numpy as np.\nCác dòng không bắt đầu với >>> là các dòng hiển thị đầu ra.\nXin nhắc lại, Numpy không quy ước vector hàng hay vector cột mà chỉ coi một vector là một mảng một chiều. Nếu bạn thực sự muốn có một vector cột, bạn cần phải coi nó là một\nma trận có số chiều thứ hai bằng 1, và khi đó phải khai báo với numpy rằng đó là một mảng hai chiều. Chúng ta sẽ quay lại vấn đề này trong bài Ma trận.\nĐể hiểu thêm về hàmnp.array, bạn có thể xem thêm numpy.array, hoặc gõ trực tiếp vào cửa sổ dòng lệnh:\nCú pháp help(func) khi được thực hiện trên cửa sổ dòng lệnh (terminal), với func là tên hàm số, sẽ hiển thị hướng dẫn sử dụng hàm số đó.\nBài tập: Khởi tạo một vector x = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]. Chú ý chỉ sửa code giữa các dòng bắt đầu bởi # TODO: và # -- end TODO --.\n\n\nNếu khai báo:\nta sẽ thấy các thành phần của a mặc định là kiểu số nguyên numpy.int64. Chú ý rằng type(var) trả về kiểu dữ liệu của biến var.\nĐể khai báo a là mảng với các thành phần là thực, ta cần viết đưới dạng:\nTa cũng có thể ép kiểu, ví dụ kiểu dữ liệu thực numpy.float64, ta có thể sử dụng từ khoá dtype như dưới đây:\nPhần này không có bài tập.\n\n\nVector \\(\\mathbf{0}\\) là một vector đặc biệt được dùng rất thường xuyên để khởi tạo. Để tạo một vector \\(\\mathbf{0}\\) có số phần tử là d, ta dùng hàm numpy.zeros.\nTương tự như thế, với mảng toàn giá trị 1, ta sẽ dùng hàm numpy.ones:\nNgoài ra, numpy còn cung cấp hai hàm đặc biệt numpy.zeros_like và numpy.ones_like giúp tạo các mảng 0 và mảng 1 có số chiều giống như chiều của biến số.\n\nĐể tạo mảng các số nguyên từ 0 đến n-1 (n số tổng cộng) ta dùng hàm np.arange(n):\nĐể tạo mảng các số nguyên từ m đến n-1, ta cũng dùng hàm này ở dạng np.arange(m, n):\nĐể tạo một cấp số cộng với phần tử đầu là a, công sai d dương, phần tử cuối là số lớn nhất nhỏ hơn b, ta dùng np.arange(a, b, d).\nNếu d là 1 số âm và b < a thì phần tử cuối là phần tử nhỏ nhất của cấp số cộng lớn hơn b:\nBài tập 1:\nXây dựng mảng các luỹ thừa của 2 nhỏ hơn 1025, bao gồm cả 1 = 2**0.\nGợi ý: Nếu a là một mảng và b là một số thì b**a sẽ trả về một mảng cùng kích thước với a mà phần tử có chỉ số i bằng b**a[i], với ** là toán tử luỹ thừa.\nBài tập 2:\nXây dựng mảng gồm 10 phần tử, trong đó 9 phần tử đầu bằng 3, phần tử cuối cùng bằng 1.5.\n\n\nKích thước của một mảng numpy x nói chung được xác định bằng numpy.array.shape. Ví dụ:\nKết quả trả về là một tuple. \nNếu x là một mảng một chiều, kết quả trả về sẽ có dạng (d,) trong đó d, là phần tử đầu tiên-và duy nhất- của tuple này, \nlà số phẩn tử của x. Chú ý rằng sau số 3 còn dấu , nữa để chắc chắn rằng kết quả là 1 tuple.\nĐể lấy giá trị d này, ta dùng:\n\nMỗi thành phần trong mảng 1 chiều tương ứng với một chỉ số. Chỉ số trong numpy, cũng giống như chỉ số trong python, bắt đầu bằng 0. Nếu mảng 1 chiều có d phần tử thì các chỉ số chạy từ 0 đến d - 1\n\nGiả sử:\nthì thành phần đầu tiên (bằng 1) được truy cập bằng x[0]:\nCác thành phần tiếp theo được truy cập bằng x[1] và x[2], theo thứ tự đó.\n\nTrong Python có một điểm đặc biệt là Chỉ số ngược. Cho một mảng 1 chiều x có d phần tử. \nĐể truy cập vào phần tử cuối cùng của mảng này, không cần biết d là bao nhiêu, ta có thể dùng chỉ số -1.\nTương tự như thế, phần từ thứ hai từ cuối sẽ được truy cập bằng chỉ số -2, …\nChú ý: Nếu một mảng một chiều x có số chiều là d thì chỉ số i trong x[i] phải là một số nguyên thoả mãn -d <= i <= d-1. Nếu i nằm ngoài khoảng này, khi sử dụng x[i] sẽ có lỗi index ... is out of bound....\n\nĐể thay giá trị một phần tử của mảng, ta dùng câu lệnh đơn giản:\nBài tập: Thay toàn bộ các phần tử của mảng bằng trung bình cộng các phần tử trong mảng đó, sử dụng vòng for. Hàm này không trả về \nbiến nào mà chỉ thay đổi các giá trị của biến đầu vào x.\n\nĐể truy cập nhiều phần tử của một mảng một chiều một lúc, chúng ta có nhiều cách khác nhau:\n\nVí dụ:\nTrong ví dụ này, ids là một list trong Python, các phần tử của nó đều là các số nguyên nằm trong khoảng [-10, 9] nên chúng có thể coi là các chỉ số của mảng a được. \na[ids] trả về một mảng numpy, là mảng con của a với các phần tử có chỉ số được chỉ ra trong list các chỉ số ids.\nids cũng có thể là một mảng numpy chứa các số nguyên khac là chỉ số hợp lệ của a.\nNgoài ra, cách đánh chỉ số của mảng numpy cũng sử dụng các quy tắc khác giống như cách đánh chỉ số của một list:\n\nTa cũng có thể thay đổi giá trị của nhiều phần tử trong mảng. Ví dụ:\n\nNumpy Indexing and Slicing\nBài tập:\nCho trước một số tự nhiên n. Tạo một mảng có n phần tử mà các phần tử có chỉ số chẵn (bắt đầu từ 0) là một cấp số cộng bắt đầu từ 2, công sai bằng -0.5; các phần tử có chỉ số lẻ bằng -1.\nVí dụ:\nVới n=4, kết quả trả về là mảng [ 2.  -1.   1.5 -1. ].\nVới n=5, kết quả trả về là mảng [ 2.  -1.   1.5 -1.   1. ].\n\n\nĐể cộng/trừ/nhân/chia/luỹ thừa mọi phần tử một mảng 1 chiều x với một số vô hướng a ta chỉ cần lấy x ? a, hoặc a ? x trong đó ? có thể thay bằng các phép tính cộng +, trừ -, nhân *, chia /, và luỹ thừa **.\nChú ý rằng về mặt toán học, không có phép chia cho vector. Tuy nhiên, trong Python, ta vẫn hiểu phép chia một số cho một mảng sẽ tương đương với lấy số đó chia cho từng phần tử trong mảng.\n\nĐể có thể tính toán được hai mảng một chiều, số phần tử của hai mảng phải như nhau. Kết quả cũng là một mảng một chiều cùng chiều với hai mảng đó. Các phép toán +, -, *, /, ** sẽ được thực hiện theo kiểu element-wise, tức lấy từng cặp phần tử tương ứng của hai mảng để tính toán rồi lấy kết quả. Ví dụ:\n\nCác hàm toán học trong numpy như: np.abs, np.log, np.exp, np.sin, np.cos, np.tan cũng áp dụng lên từng phần tử của mảng. Hàm np.log là logarit tự nhiên, hàm np.exp là hàm \\(e^x\\).\nHàm np.sum(x) sẽ trả về tổng các phần tử của mảng một chiều x.\nBài tập: Cho một mảng 1 chiều x, tính mảng y và z sao cho y[i] = pi/2 - x[i] và z[i] = cos(x[i]) - sin(x[i]). Sau đó trả về tổng các phần tử của z\n\nNorm 1 của một vector \\(\\mathbf{x} \\in \\mathbb{R}^d\\), kỹ hiệu là \\(||\\mathbf{x}||_1\\), được định nghĩa tổng trị tuyệt đối các phần tử của vector đó: \n\\[\n||\\mathbf{x}||_1 = |x_0| + |x_1| + \\dots + |x_{d-1}| = \\sum_{i = 0}^{d-1} |x_i |\n\\]\nBài tập:\nViết hàm số tính tổng trị tuyệt đối các phần tử của một mảng một chiều.\n(Gợi ý: np.abs.)\n\nSoftmax Regression là một trong số những thuật toán được sử dụng nhiều nhất trong các bài toán Classification. \nKhi triển khai mô hình này, chúng ta cần lập trình hàm softmax. Cho một vector \\(\\mathbf{z} \\in \\mathbb{R}^d\\). Hàm softmax khi áp dụng lên vector \\(\\mathbf{z}\\) sẽ \ntạo ra một vector \\(\\mathbf{a}\\) cùng chiều với \\(\\mathbf{z}\\) và phần tử thứ \\(i\\) (tính từ 0) của nó được xác định bởi: \n\\[\na_i = \\frac{\\exp(z_i)}{\\sum_{j=0}^{d-1} \\exp(z_j)}\n\\]\nvới:\n\\[\n\\exp(u) = e^u\n\\]\nBạn đọc có thể chứng minh được các phần tử của \\(\\mathbf{a}\\) đều nằm trong khoảng \\((0, 1)\\) và có tổng bằng 1. Vì vậy, vector \\(\\mathbf{a}\\) còn được coi là vector\nxác suất, mỗi phần tử ứng với xác suất của một điểm dữ liệu thuộc vào một class nào đó.\nBài tập: \nHãy lập trình hàm softmax.\nGợi ý: Sử dụng hàm np.exp().\n\nTích vô hướng (inner product) của hai vectors x và y có cùng số phần tử được định nghĩa như là: np.sum(x*y), tức lấy x nhân với y theo element-wise rồi tính tổng các phần tử:\nTrong numpy, còn hai cách khác để tính tích vô hướng:\nBài tập: Tính norm 2 của một vector - vector này được biểu diễn dưới dạng mảng numpy một chiều. Norm 2 của một vector \\(\\mathbf{x}\\), được ký hiệu là \\(||\\mathbf{x}||_2\\), được định nghĩa là căn bậc hai của tổng bình phương các phần tử của nó. \n\\[\n||\\mathbf{x}||_2 = \\sqrt{x_0^2 + x_1^2 + \\dots + x_{d-1}^2}\n\\]\ntrong đó: \\(x_1, \\dots, x_{d-1}\\) là các phần tử của vector \\(\\mathbf{x} \\in \\mathbb{R}^d\\).\nNorm 2 được sử dụng rất nhiều trong Machine Learning. Có một hàm khác giúp trực tiếp tính norm, chúng ta sẽ tìm hiểu sau.\nTìm hiểu thêm: Norm của vector và ma trận\n\n\nĐể tìm giá trị lớn nhất hay nhỏ nhất của mảng một chiều, chúng ta đơn giản sử dụng hàm np.min hoặc np.max. Ví dụ:\nhoặc:\n\nĐể tìm chỉ số mà tại đó mảng một chiều đạt giá trị nhỏ nhất hay lớn nhất, ta có thể sử dụng np.argmin, hoặc np.argmax:\nhoặc:\nBài tập:\nTrong bài toán classification, sử dụng Softmax Regression, giả sử ta đã tính \nđược xác suất để một điểm dữ liệu thuộc vào mỗi class. Các xác suất này được lưu dưới dạng một mảng một chiều mà phần tử thứ i là \nxác suất để điểm dữ liệu rơi vào lớp i. Nhãn của dữ liệu được dự đoán là chỉ số của lớp mà điểm dữ liệu rơi vào với xác suất cao nhất. \nHãy viết một hàm số xác định chỉ số đó.\nChú ý: Mảng chứa xác suất này thường được tính bằng cách áp dụng hàm softmax vào score vector. Hàm softmax giữ nguyên thứ tự của vector \nđầu vào, vì vậy chỉ số của lớp có xác suất cao nhất cũng là chỉ số của lớp có score cao nhất. (Mời bạn đọc thêm \nbài Softmax Regression để biết thêm chi tiết).\n\nNhắc lại công thức tính softmax của một vector \\(\\mathbf{z} \\in \\mathbb{R}^C\\) (ở đây \\(C\\) là số lượng lớp trong bài toán phân lớp):\n\\[\na_i = \\frac{\\exp(z_i)}{\\sum_{j=0}^{C-1} \\exp(z_j)}, ~~ \\forall i = 0, 1, \\dots, C-1\\]\n(Xem lại Hàm Softmax cho mảng một chiều.)\nKhi một trong các \\(z_i\\) quá lớn, việc tính toán \\(\\exp(z_i)\\) có thể gây ra hiện tượng tràn số (overflow), ảnh hưởng lớn tới kết quả của hàm softmax. \nCó một cách khắc phục hiện tượng này bằng cách dựa trên quan sát sau:\n\\[\n\\begin{eqnarray}\n\\frac{\\exp(z_i)}{\\sum_{j=0}^{C-1} \\exp(z_j)} = \\frac{\\exp(-b)\\exp(z_i)}{\\exp(-b)\\sum_{j=0}^{C-1} \\exp(z_j)}\n= \\frac{\\exp(z_i-b)}{\\sum_{j=0}^{C-1} \\exp(z_j-b)}\n\\end{eqnarray}\n\\]\nvới \\(b\\) là một hằng số bất kỳ.\nVậy một phương pháp đơn giản giúp khắc phục hiện tượng overflow là trừ tất cả các \\(z_i\\) đi một giá trị đủ lớn. \nTrong thực nghiệm, giá trị đủ lớn này thường được chọn là \\(c = \\max_i z_i\\), tức giá trị lớn nhất của \\(z_i\\).\nVậy chúng ta có thể viết lại hàm softmax phía trên bằng cách trừ mỗi phần tử của \\(\\mathbf{z}\\) đi giá trị lớn nhất giữa chúng. Ta có phiên bản ổn định hơn được gọi là softmax_stable.\nĐọc thêm Softmax Regression.\nBài tập: \nDựa vào công thức phía trên, hay viết hàm softmax_stable, lấy đầu vào là một mảng một chiều (là score vector \\(\\mathbf{z}\\)), trả về một mảng một chiều bao gồm toàn bộ các \\(a_i\\) theo công thức.\nSo sánh kết quả tìm được với kết quả của hàm softmax đã thực hiện trước đây.\nSau khi đã ‘Nộp bài’ và nhận được kết quả chính xác, bạn hãy thử làm một thí nghiệm nhỏ dưới đây:\nNói cách khác, hàm softmax_stable stable hơn hàm softmax.\nChú ý: Bạn có thể nhìn thấy thông báo ‘Kết quả không chính xác’, đừng quan tâm. Đây là câu trả về khi đáp án của bạn khác với đáp án ban đầu, tức khi offset = 1000."
    },
    {
        "ID": 12,
        "URL": "https://machinelearningcoban.com/2017/09/24/fundaml/",
        "Title": "Machine Learning cơ bản",
        "Content": "Giới thiệu trang web FundaML.com.\nTôi vẫn thường nói rằng: Đại Số Tuyến Tính, Xác Suất Thống Kê và lập trình là ba vấn đề quan trọng nhất các bạn cần nắm vững nếu muốn đi sâu vào Machine Learning.\nVề lập trình, hiện có rất nhiều ngôn ngữ khác nhau có các thư viện hỗ trợ Machine Learning. Tuy nhiên, dựa trên kinh nghiệm cá nhân, tôi thấy rằng Python là ngôn ngữ được sử dụng phổ biến nhất vì có nhiều thư viện hỗ trợ rất tốt cho Machine Learning và Data Science:\nĐó cũng là lý do mà các bài viết trong blog machinelearningcoban.com đều sử dụng các ví dụ được viết bằng Python.\nTheo dõi comment của các bạn trên cả blog, page và forum, tôi nhận thấy rằng rất nhiều bạn còn gặp khó khăn trong Đại Số Tuyến Tính và lập trình Python. Việc này thôi thúc tôi tạo một trang web giúp các bạn làm quen dần với lập trình Python cho Machine Learning thông qua việc thực hành các bài tập nhỏ trực tiếp trên trình duyệt. Ban đầu, tôi xin bắt đầu với thư viện Numpy của Python. Đây là một thư viện quan trọng, được sử dụng rất nhiều cho việc xử lý các mảng dữ liệu nhiều chiều. Trong đây tôi cũng nhắc lại nhiều vấn đề của Đại Số Tuyến Tính thường được sử dụng trong Machine Learning.\nHiện tại, tôi đã xây dựng được những bài học đầu tiên và sẽ tiếp tục thêm các bài trong thời gian tới. Rất hy vọng các bạn có thể vào học thử và đánh giá nội dung cũng như trang web. Tôi hy vọng trang web ngày một hoàn thiện và giúp đỡ được nhiều sinh viên, kỹ sư Việt Nam khác.\nFundaML.com cũng nằm trong dự án viết ebook Machine Learning cơ bản của tôi.\nMột phần kinh phí trong dự án đã được dùng để xây dựng và duy trì trang web mới này.\nTôi xin chân thành cảm ơn Huy Hoàng, Linh Nguyễn (Đại học Waterloo - Canada) đã nhiệt tình giúp đỡ xây dựng FundaML.com để nó được ra mắt ngày hôm nay.\nChúc các bạn cuối tuần vui vẻ."
    },
    {
        "ID": 13,
        "URL": "https://machinelearningcoban.com/2017/08/08/nbc/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\nBạn được khuyến khích đọc Bài 31: Maximum Likelihood và Maximum A Posteriori estimation trước khi đọc bài này\n\nXét bài toán classification với \\(C\\) classes \\(1, 2, \\dots, C\\). Giả sử có một điểm dữ liệu \\(\\mathbf{x} \\in \\mathbb{R}^d\\). Hãy tính xác suất để điểm dữ liệu này rơi vào class \\(c\\). Nói cách khác, hãy tính:\n\\[\np(y = c |\\mathbf{x}) ~~~ (1)\n\\]\nhoặc viết gọn thành \\(p(c|\\mathbf{x})\\).\nTức tính xác suất để đầu ra là class \\(c\\) biết rằng đầu vào là vector \\(\\mathbf{x}\\).\nBiểu thức này, nếu tính được, sẽ giúp chúng ta xác định được xác suất để điểm dữ liệu rơi vào mỗi class. Từ đó có thể giúp xác định class của điểm dữ liệu đó bằng cách chọn ra class có xác suất cao nhất:\n\\[\nc = \\arg\\max_{c \\in \\{1, \\dots, C\\}} p(c | \\mathbf{x}) ~~~~ (2)\n\\]\nBiểu thức \\((2)\\) thường khó được tính trực tiếp. Thay vào đó, quy tắc Bayes thường được sử dụng:\n\\[\n\\begin{eqnarray}\n  c & = & \\arg\\max_c p(c | \\mathbf{x}) & (3) \\\n      & = & \\arg\\max_c \\frac{p(\\mathbf{x} | c) p(c)}{p(\\mathbf{x})} ~~~& 4)\\\n      & = & \\arg\\max_c p(\\mathbf{x} | c) p(c) & (5)\\\n\\end{eqnarray}\n\\]\nTừ \\((3)\\) sang \\((4)\\) là vì quy tắc Bayes. Từ \\((4)\\) sang \\((5)\\) là vì mẫu số \\(p(\\mathbf{x})\\) không phụ thuộc vào \\(c\\).\nTiếp tục xét biểu thức \\((5)\\), \\(p(c)\\) có thể được hiểu là xác suất để một điểm rơi vào class \\(c\\). Giá trị này có thể được tính bằng MLE, tức tỉ lệ số điểm dữ liệu trong tập training rơi vào class này chia cho tổng số lượng dữ liệu trong tập training; hoặc cũng có thể được đánh giá bằng MAP estimation. Trường hợp thứ nhất thường được sử dụng nhiều hơn.\nThành phần còn lại \\(p(\\mathbf{x} | c)\\), tức phân phối của các điểm dữ liệu trong class \\(c\\), thường rất khó tính toán vì \\(\\mathbf{x}\\) là một biến ngẫu nhiên nhiều chiều, cần rất rất nhiều dữ liệu training để có thể xây dựng được phân phối đó. Để giúp cho việc tính toán được đơn giản, người ta thường giả sử một cách đơn giản nhất rằng các thành phần của biến ngẫu nhiên \\(\\mathbf{x}\\) là độc lập với nhau, nếu biết \\(c\\) (given \\(c\\)). Tức là:\n\\[\np(\\mathbf{x} | c) = p(x_1, x_2, \\dots, x_d | c) =  \\prod_{i = 1}^d p(x_i | c) ~~~~~ (6)\n\\]\nGiả thiết các chiều của dữ liệu độc lập với nhau, nếu biết \\(c\\), là quá chặt và ít khi tìm được dữ liệu mà các thành phần hoàn toàn độc lập với nhau. Tuy nhiên, giả thiết ngây ngô này lại mang lại những kết quả tốt bất ngờ. Giả thiết về sự độc lập của các chiều dữ liệu này được gọi là Naive Bayes (xin không dịch). Cách xác định class của dữ liệu dựa trên giả thiết này có tên là Naive Bayes Classifier (NBC).\nNBC, nhờ vào tính đơn giản một cách ngây thơ, có tốc độ training và test rất nhanh. Việc này giúp nó mang lại hiệu quả cao trong các bài toán large-scale.\nỞ bước training, các phân phối \\(p(c)\\) và \\(p(x_i | c), i = 1, \\dots, d\\) sẽ được xác định dựa vào training data. Việc xác định các giá trị này có thể dựa vào Maximum Likelihood Estimation hoặc Maximum A Posteriori.\nỞ bước test, với một điểm dữ liệu mới \\(\\mathbf{x}\\), class của nó sẽ được xác đinh bởi:\n\\[\nc = \\arg\\max_{c \\in \\{1, \\dots, C\\}} p(c) \\prod_{i=1}^d p(x_i | c) ~~~~~ (7)\n\\]\nKhi \\(d\\) lớn và các xác suất nhỏ, biểu thức ở vế phải của \\((7)\\) sẽ là một số rất nhỏ, khi tính toán có thể gặp sai số. Để giải quyết việc này, \\((7)\\) thường được viết lại dưới dạng tương đương bằng cách lấy \\(\\log\\) của vế phải: \n\\[\nc = \\arg\\max_{c \\in \\{1, \\dots, C\\}} = \\log(p(c)) + \\sum_{i=1}^d \\log(p(x_i | c)) ~~~~ (7.1)\n\\]\nViệc này không ảnh hưởng tới kết quả vì \\(\\log\\) là một hàm đồng biến trên tập các số dương.\nMặc dù giả thiết mà Naive Bayes Classifiers sử dụng là quá phi thực tế, chúng vẫn hoạt động khá hiệu quả trong nhiều bài toán thực tế, đặc biệt là trong các bài toán phân loại văn bản, ví dụ như lọc tin nhắn rác hay lọc email spam. Trong phần sau của bài viết, chúng ta cùng xây dựng một bộ lọc email spam tiếng Anh đơn giản.\nCả việc training và test của NBC là cực kỳ nhanh khi so với các phương pháp classification phức tạp khác. Việc giả sử các thành phần trong dữ liệu là độc lập với nhau, nếu biết class, khiến cho việc tính toán mỗi phân phối \\(p(\\mathbf{x}_i|c)\\) trở nên cực kỳ nhanh.\nMỗi giá trị \\(p(c), c = 1, 2, \\dots, C\\) có thể được xác định như là tần suất xuất hiện của class \\(c\\) trong training data.\nViệc tính toán \\(p(\\mathbf{x_i} | c) \\) phụ thuộc vào loại dữ liệu. Có ba loại được sử dụng phổ biến là: Gaussian Naive Bayes, Multinomial Naive Bayes, và Bernoulli Naive .\n\nMục này chủ yếu được dịch từ tài liệu của thư viện sklearn.\n\nMô hình này được sử dụng chủ yếu trong loại dữ liệu mà các thành phần là các biến liên tục.\nVới mỗi chiều dữ liệu \\(i\\) và một class \\(c\\), \\(x_i\\) tuân theo một phân phối chuẩn có kỳ vọng \\(\\mu_{ci}\\) và phương sai \\(\\sigma_{ci}^2\\):\n\\[\np(x_i|c) = p(x_i | \\mu_{ci}, \\sigma_{ci}^2) =  \\frac{1}{\\sqrt{2\\pi \\sigma_{ci}^2}} \\exp\\left(- \\frac{(x_i - \\mu_{ci})^2}{2 \\sigma_{ci}^2}\\right) ~~~~ (8)\n\\]\nTrong đó, bộ tham số \\(\\theta = \\{\\mu_{ci}, \\sigma_{ci}^2\\}\\) được xác định bằng Maximum Likelihood:\n\\[\n(\\mu_{ci}, \\sigma_{ci}^2) = \\arg\\max_{\\mu_{ci}, \\sigma_{ci}^2} \\prod_{n = 1}^N p(x_i^{(n)} | \\mu_{ci}, \\sigma_{ci}^2) ~~~~ (9)\n\\]\nĐây là cách tính của thư viện sklearn. Chúng ta cũng có thể đánh giá các tham số bằng MAP nếu biết trước priors của \\(\\mu_{ci}\\) và \\(\\sigma^2_{ci}\\)\n\nMô hình này chủ yếu được sử dụng trong phân loại văn bản mà feature vectors được tính bằng Bags of Words. Lúc này, mỗi văn bản được biểu diễn bởi một vector có độ dài \\(d\\) chính là số từ trong từ điển. Giá trị của thành phần thứ \\(i\\) trong mỗi vector chính là số lần từ thứ \\(i\\) xuất hiện trong văn bản đó.\nKhi đó, \\(p(x_i |c) \\) tỉ lệ với tần suất từ thứ \\(i\\) (hay feature thứ \\(i\\) cho trường hợp tổng quát) xuất hiện trong các văn bản của class \\(c\\). Giá trị này có thể được tính bằng cách: \n\\[\n\\lambda_{ci} = p(x_i | c) = \\frac{N_{ci}}{N_c} ~~~~ (10)\n\\]\nTrong đó:\n\\(N_{ci}\\) là tổng số lần từ thứ \\(i\\) xuất hiện trong các văn bản của class \\(c\\), nó được tính là tổng của tất cả các thành phần thứ \\(i\\) của các feature vectors ứng với class \\(c\\).\n\\(N_c\\) là tổng số từ (kể cả lặp) xuất hiện trong class \\(c\\). Nói cách khác, nó bằng tổng độ dài của toàn bộ các văn bản thuộc vào class \\(c\\). Có thể suy ra rằng \\(N_c = \\sum_{i = 1}^d N_{ci}\\), từ đó \\(\\sum_{i=1}^d \\lambda_{ci} = 1\\).\nCách tính này có một hạn chế là nếu có một từ mới chưa bao giờ xuất hiện trong class \\(c\\) thì biểu thức \\((10)\\) sẽ bằng 0, điều này dẫn đến vế phải của \\((7)\\) bằng 0 bất kể các giá trị còn lại có lớn thế nào. Việc này sẽ dẫn đến kết quả không chính xác (xem thêm ví dụ ở mục sau).\nĐể giải quyết việc này, một kỹ thuật được gọi là Laplace smoothing được áp dụng:\n\\[\n\\hat{\\lambda}_{ci} = \\frac{N_{ci} + \\alpha}{N_{c} + d\\alpha} ~~~~~~ (11)\n\\]\nVới \\(\\alpha\\) là một số dương, thường bằng 1, để tránh trường hợp tử số bằng 0. Mẫu số được cộng với \\(d\\alpha\\) để đảm bảo tổng xác suất \\(\\sum_{i=1}^d \\hat{\\lambda}_{ci} = 1\\).\nNhư vậy, mỗi class \\(c\\) sẽ được mô tả bởi bộ các số dương có tổng bằng 1: \\(\\hat{\\lambda}_c = \\{\\hat{\\lambda}_{c1}, \\dots, \\hat{\\lambda}_{cd}\\}\\).\n\nMô hình này được áp dụng cho các loại dữ liệu mà mỗi thành phần là một giá trị binary - bẳng 0 hoặc 1. Ví dụ: cũng với loại văn bản nhưng thay vì đếm tổng số lần xuất hiện của 1 từ trong văn bản, ta chỉ cần quan tâm từ đó có xuất hiện hay không.\nKhi đó, \\(p(x_i | c) \\) được tính bằng: \n\\[\np(x_i | c) = p(i | c)^{x_i} (1 - p(i | c) ^{1 - x_i}\n\\]\nvới \\(p(i | c)\\) có thể được hiểu là xác suất từ thứ \\(i\\) xuất hiện trong các văn bản của class \\(c\\).\n\n\nGiả sử trong tập training có các văn bản \\(\\text{d1, d2, d3, d4}\\) như trong bảng dưới đây. Mỗi văn bản này thuộc vào 1 trong 2 classes: \\(\\text{B}\\) (Bắc) hoặc \\(\\text{N}\\) (Nam). Hãy xác định class của văn bản \\(\\text{d5}\\).\n\nTa có thể dự đoán rằng \\(\\text{d5}\\) thuộc class Bắc.\nBài toán này có thể được giải quyết bởi hai mô hình: Multinomial Naive Bayes và Bernoulli Naive Bayes. Tôi sẽ làm ví dụ minh hoạ với mô hình thứ nhất và thực hiện code cho cả hai mô hình. Việc mô hình nào tốt hơn phụ thuộc vào mỗi bài toán. Chúng ta có thể thử cả hai để chọn ra mô hình tốt hơn.\nNhận thấy rằng ở đây có 2 class \\(\\text{B}\\) và \\(\\text{N}\\), ta cần đi tìm \\(p(\\text{B})\\) và \\(p(\\text{N})\\). à dựa trên tần số xuất hiện của mỗi class trong tập training. Ta sẽ có:\n\\[\np(\\text{B}) = \\frac{3}{4}, ~~~~~ p(\\text{N}) = \\frac{1}{4} ~~~~~~ (8)\n\\]\nTập hợp toàn bộ các từ trong văn bản, hay còn gọi là từ điển, là: \\(V = \\{\\text{hanoi, pho, chaolong, buncha, omai, banhgio, saigon, hutiu, banhbo}\\}\\). Tổng cộng số phần tử trong từ điển là \\(|V| = 9\\).\nHình dưới đây minh hoạ quá trình Training và Test cho bài toán này khi sử dụng Multinomial Naive Bayes, trong đó có sử dụng Laplace smoothing với \\(\\alpha = 1\\).\nChú ý, hai giá trị tìm được \\(1.5\\times 10^{-4}\\) và \\(1.75\\times 10^{-5}\\) không phải là hai xác suất cần tìm mà chỉ là hai đại lượng tỉ lệ thuận với hai xác suất đó. Để tính cụ thể, ta có thể làm như sau:\n\\[\np(\\text{B} | \\text{d5}) = \\frac{1.5\\times 10^{-4}}{1.5\\times 10^{-4} + 1.75\\times 10^{-5}} \\approx 0.8955, ~~~~ p(\\text{N} | \\text{d5}) = 1 - p(\\text{B} | \\text{d5}) \\approx 0.1045\n\\]\nBạn đọc có thể tự tính với ví dụ khác: \\(\\text{d6 = pho hutiu banhbo}\\). Nếu bạn và tôi tính ra kết quả giống nhau, chúng ta sẽ thu được:\n\\[\np(\\text{B} | \\text{d6}) \\approx 0.29, ~~~~ p(\\text{N} | \\text{d6}) \\approx 0.71\n\\]\nvà suy ra \\(\\text{d6}\\) thuộc vào class Nam.\n\nĐể kiểm tra lại các phép tính toán phía trên, chúng ta cùng giải quyết bài toán này với sklearn.\nKết quả:\nNếu sử dụng mô hình Bernoulli Naive Bayes, chúng ta cần thay đổi một chút về feature vectors. Lúc này, các giá trị khác không sẽ đều được đưa về 1 vì ta chỉ quan tâm đến việc từ đó có xuất hiện trong văn bản không.\nKết quả:\nTa thấy rằng, với bài toán nhỏ này, cả hai mô hình đều cho kết quả giống nhau (xác suất tìm được khác nhau nhưng không ảnh hưởng tới quyết định cuối cùng).\n\nDữ liệu trong ví dụ này được lấy trong Exercise 6: Naive Bayes - Machine Learning - Andrew Ng.\nTrong ví dụ này, dữ liệu đã được xử lý, và là một tập con của cơ sở dữ liệu Ling-Spam Dataset.\nMô tả dữ liệu:\nTập dữ liệu này bao gồm tổng cộng 960 emails tiếng Anh, được tách thành tập training và test theo tỉ lệ 700:260, 50% trong mỗi tập là các spam emails.\nDữ liệu trong cơ sở dữ liệu này đã được xử lý khá đẹp. Các quy tắc xử lý như sau:\nLoại bỏ stop words: Những từ xuất hiện thường xuyên như ‘and’, ‘the’, ‘of’, … được loại bỏ.\nLemmatization: Những từ có cùng ‘gốc’ được đưa về cùng loại. Ví dụ, ‘include’, ‘includes’, ‘included’ đều được đưa chung về ‘include’. Tất cả các từ cũng đã được đưa về dạng ký tự thường (không phải HOA).\nLoại bỏ non-words: Số, dấu câu, ký tự ‘tabs’, ký tự ‘xuống dòng’ đã được loại bỏ.\nDưới đây là một ví dụ của 1 email không phải spam, trước khi được xử lý:\nvà sau khi được xử lý:\nVà đây là một ví dụ về spam email sau khi được xử lý:\nChúng ta thấy rằng trong đoạn này có các từ như: financial, extraordinary, earn, opportunity, … là những từ thường thấy trong các email spam.\nTrong ví dụ này, chúng ta sẽ sử dụng Multinomial Naive Bayes.\nĐể cho bài toán được đơn giản hơn, tôi tiếp tục sử dụng dữ liệu đã được xử lý, có thể được download ở đây: ex6DataPrepared.zip. Trong folder sau khi giải nén, chúng ta sẽ thấy các files:\ntương ứng với các file chứa dữ liệu của tập training và tập test. File train-features-50.txt chứa dữ liệu của tập training thu gọn với chỉ có tổng cộng 50 training emails.\nMỗi file *labels*.txt chứa nhiều dòng, mỗi dòng là một ký tự 0 hoặc 1 thể hiện email là non-spam hoặc spam.\nMỗi file *features*.txt chứa nhiều dòng, mỗi dòng có 3 số, ví dụ:\ntrong đó số đầu tiên là chỉ số của email, bắt đầu từ 1; số thứ hai là thứ tự của từ trong từ điển (tổng cộng 2500 từ); số thứ ba là số lượng của từ đó trong email đang xét. Dòng đầu tiên nói rằng trong email thứ nhất, từ thứ 564 trong từ điển xuất hiện 1 lần. Cách lưu dữ liệu như thế này giúp tiết kiệm bộ nhớ vì 1 email thường không chứa hết tất cả các từ trong từ điển mà chỉ chứa một lượng nhỏ, ta chỉ cần lưu các giá trị khác không.\nNếu ta biểu diễn feature vector của mỗi email là một vector hàng có độ dài bằng độ dài từ điển (2500) thì dòng thứ nhất nói rằng thành phần thứ 564 của vector này bằng 1. Tương tự, thành phần thứ 19 của vector này bằng 1. Nếu không xuất hiện, các thành phần khác được mặc định bằng 0.\nDựa trên các thông tin này, chúng ta có thể tiến hành lập trình với thư viện sklearn.\nKhai báo thư viện và đường dẫn tới files:\nHàm số đọc dữ liệu từ file data_fn với labels tương ứng label_fn. Chú ý rằng số lượng từ trong từ điển là 2500.\nDữ liệu sẽ được lưu trong một ma trận mà mỗi hàng thể hiện một email. Ma trận này là một ma trận sparse nên chúng ta sẽ sử dụng hàm scipy.sparse.coo_matrix.\nĐọc training data và test data, sử dụng class MultinomialNB trong sklearn để xây dựng mô hình và dự đoán đầu ra cho test data.\nVậy là có tới 98.08% các email được phân loại đúng. Chúng ta tiếp tục thử với các bộ dữ liệu training nhỏ hơn:\nTa thấy rằng thậm chí khi tập training là rất nhỏ, 50 emails tổng cộng, kết quả đạt được đã rất ấn tượng.\nNếu bạn muốn tiếp tục thử mô hình BernoulliNB:\nTa thấy rằng trong bài toán này, MultinomialNB hoạt động hiệu quả hơn.\n\nNaive Bayes Classifiers (NBC) thường được sử dụng trong các bài toán Text Classification.\nNBC có thời gian training và test rất nhanh. Điều này có được là do giả sử về tính độc lập giữa các thành phần, nếu biết class.\nNếu giả sử về tính độc lập được thoả mãn (dựa vào bản chất của dữ liệu), NBC được cho là cho kết quả tốt hơn so với SVM và logistic regression khi có ít dữ liệu training.\nNBC có thể hoạt động với các feature vector mà một phần là liên tục (sử dụng Gaussian Naive Bayes), phần còn lại ở dạng rời rạc (sử dụng Multinomial hoặc Bernoulli).\nKhi sử dụng Multinomial Naive Bayes, Laplace smoothing thường được sử dụng để tránh trường hợp 1 thành phần trong test data chưa xuất hiện ở training data.\nSource code.\n\n[1] Text Classification and Naive Bayes - Stanford\n[2] Exercise 6: Naive Bayes - Machine Learning - Andrew Ng\n[3] sklearn.naive_bayes\n[4] 6 Easy Steps to Learn Naive Bayes Algorithm (with code in Python)"
    },
    {
        "ID": 14,
        "URL": "https://machinelearningcoban.com/2017/08/05/phdlife/",
        "Title": "Machine Learning cơ bản",
        "Content": "\nKhi học PhD, chúng tôi có thể phải làm một nhiệm vụ là review các paper được viết bởi các tác giả khác.\nDạo này chậm ra bài, tôi xin chia sẻ với các bạn một chút về cuộc sống PhD của mình. Hy vọng giúp các bạn hiểu thêm về cuộc sống của những người làm nghiên cứu như tôi. Một chút xíu thôi.\n\nThông thường, khi nộp một paper lên các tạp chí, paper đó sẽ được chuyển tới một Associate Editor (AE). AE này sẽ ‘nhờ’ khoảng 3 reviewers để ‘chấm điểm’ cho paper này. Giáo sư hướng dẫn của tôi là AE cho một vài tạp chí lớn. Và tôi đã bị ‘chỉ định’ làm reviewer cho khoảng trên dưới 30 bài transaction. Một vài trong số đó là các paper hay, phần lớn là các paper tệ. Tỉ lệ acceptance của các tạp chí này cũng thấp (1/6-1/4) nên đó cũng là chuyện dễ hiểu. Vì thế, tôi cũng không thích review lắm vì khá mất thời gian.\nNhững reviewers được AE ‘mời’ sẽ được giấu tên, chỉ có AE mới biết mỗi reviewer này ai. Sau khi hoàn tất review một bài báo, AE sẽ rate các reviewers. Như vậy là sẽ có một bảng ranking của các reviewer ở đâu đó. Lần tới, một AE khác sẽ lựa chọn từ bảng ranking đó và tìm các reviewers có background liên quan để mời review.\nĐể có những nhận xét đa chiều, giáo sư của tôi thường chọn 3 đối tượng reviewers: 1. Senior PhDs, tức những sinh viên PhD như tôi đã có bài báo được published; 2. Những sinh viên PhD mới tốt nghiệp được vài năm, thường là Postdoc; 3. Các giáo sư khác hoặc những người làm nghiên cứu lâu năm. Ba nhóm reviewers này thường có những cách đánh giá khác nhau.\nNhóm thứ nhất thường để ý tới các phương trình toán, kiểm tra chính tả ngữ pháp các kiểu. Ban đầu vì chưa có kinh nghiệm nên tôi kiểm tra các phương trình rất kỹ xem có lỗi gì không. Vì chẳng lẽ mình review mà không viết được cái gì :D. Một điểm cũng rất lo lắng là liệu quyết định của mình có lệch quá so với các reviewers khác không (mình cho Chấp nhận mà những người khác cho Từ chối thì cũng không được).\nNhóm thứ ba thường quan tâm tới bức tranh lớn (big picture). Họ thường quan tâm tới ý tưởng chính của paper và đưa ra nhận xét. Họ cũng biết nhiều các paper khác nên việc kiểm chứng novelty của paper cũng là việc tương đối đơn giản. Các bác này có lẽ không đọc các phương trình làm gì.\nNhớm thứ hai thì có cái nhìn ở giữa nhóm thứ nhất và thứ ba.\n\nDựa trên bình luận và quyết định của các reviewer, AE sẽ ra quyết định cuối cùng, thường có mấy lựa chọn sau:\nRất ít khi có một paper được A ngay ở lần nộp đầu tiên, thậm chí là AQ. Các reviewer bao giờ cũng cố tìm ra một điểm nào đó để ‘khuyên’ tác giả thay đổi một chút. Cũng gọi là có công của mình trong quá trình review.\nTần số để 1 paper nhận R ngay từ lần đầu cao hơn một chút nếu paper không có điểm gì mới, tiếng Anh tệ, các công thức toán không rõ ràng, hoặc/và hình vẽ không rõ ràng.\nChủ yếu các paper sẽ nhận được RQ từ vòng đầu, tức yêu cầu thay đổi và trả lời các câu hỏi của reviewers trước khi có quyết định ở vòng tiếp theo từ AE. Các tạp chí lớn thường không cho phép 2 lần RQ liên tiếp. RQ hai lần liên tiếp là sẽ coi như bị R.\n\nCác tiêu chí để đánh giá một paper thường là:\nTiêu chuẩn mà tôi thấy khó đánh giá nhất là Novelty. Ranh giới giữa ‘simple but effective’ và ‘minor novelty/ not original’ là rất mong manh. Nhiều khi việc cải tiến một chút xíu làm cho một mô hình nổi tiếng khác đơn giản hơn làm cho hệ thống hoạt động khá hiệu quả. Nhưng ngược lại, việc đó cũng có thể được coi là ‘không có tính sáng tạo, không có gì mới’. Việc này tuỳ thuộc rất nhiều vào trạng thái tâm lý tình cảm của reviewer.\nNgày mới làm review, tôi thường đọc bài rất kỹ. Tôi xem ý tưởng có bị lặp không, các công thức có sai sót gì không, hình vẽ có đẹp không :D, tiếng Anh có phải sửa không, … Thậm chí, tôi còn quan tâm tới việc paper có được soạn thảo bằng LaTeX hay không (đọc các công thức toán được soạn bằng Word rất là nản, xin lỗi các bạn). Và tôi từng là một ‘tough reviewer’, cho rất nhiều bài RQ hoặc R. Thật là có lỗi.\nHôm nay tôi review một bài ở một tạp chí cũng tương đối lớn (một bài Signal Processing Letter). Bài này tôi đã từng review và cho R. Đây là bài nộp lại kèm theo phản hồi tới những comments của tôi ở lần review trước.\nÝ tưởng của bài này rất đơn giản, chỉ sửa một chút và việc sửa này cũng không có gì là sáng tạo, chỉ là vay mượn từ các mô hình khác. Quả thật, nghĩ ra một cái hoàn toàn mới là cực kỳ khó! Ở lần review thứ nhất cách đây 2 tháng, tôi đã cho R cũng vì tính ‘not novel’ này. Nhưng hôm nay nhân một ngày mát trời, sau khi đọc lại rất kỹ paper này, tôi đã quyết định cho AQ. Tôi cũng nói riêng với AE rằng tôi thay đổi quyết định từ R lên AQ vì ý tưởng của bài báo rất đơn giản nhưng đã giúp cho mô hình linh hoạt và thời gian huấn luyện giảm đi khá nhiều, đồng thời kết quả cũng tốt. Tôi chưa cho A vì kết quả chưa được mô tả đẹp lắm. Có một vài bảng kết quả nên được vẽ dưới dạng biểu đồ cột.\nCác tác giả đã may mắn vì hôm nay chỗ tôi có một cơn mưa rào lớn lúc chập tối.\nRanh giới giữa Chấp nhận và Từ chối đôi khi rất mong manh, có thể phụ thuộc vào thời tiết. Cùng một ý tưởng, cùng một kết quả nhưng cách viết thế nào cũng rất quan trọng.\n\nĐiều kiện để chúng tôi tốt nghiệp bậc học PhD là phải có một lượng các bài báo khoa học. Tuỳ từng trường, tuỳ từng thầy mà yêu cầu về số lượng tối thiểu các bài báo là khác nhau. Trong lab của tôi, chúng tôi cần ba bài journal papers. Tại thời điểm bảo vệ tốt nghiệp, chúng tôi cần có ít nhất hai bài đã được chấp nhận và một bài đã được nộp chờ phản hồi.\nCó hai loại bài báo khoa học chính: conference papers và journal/transaction papers. Hiểu một cách đơn giản, conference papers là các papers được nộp vào các hội nghị khoa học. Sau khi bài báo được chấp nhận, chúng tôi cần đến tham dự hội nghị đó và trình bày về bài báo, thường dưới dạng poster hoặc lecture presentation. Tôi sẽ nói về hài loại presentations này khi có dịp. Về độ dài, thường có hai loại: 4 trang + 1 trang references hoặc 8 trang + 1 trang references. Trong bài viết này, tôi sẽ viết về loại 4 trang + 1. Loại 8 trang + 1 hoặc dài hơn sẽ khó hơn nhiều, thậm chí còn khó hơn journal.\nJournal papers là các bài được nộp vào các tạp chí khoa học. Chúng tôi không cần đến dự hội nghị nào mà chỉ cần nộp và qua một vài lần nhận xét. Sau đó AE ra quyết định xem bài có được chấp nhận hay không.\nBảng dưới đây mô tả sự khác nhau cơ bản giữa loại conference paper (4 trang + 1) và journal paper.\n\nVới mỗi một ý tưởng, cái đích cuối cùng của chúng tôi là viết một journal paper. Trên đường tới đích, chúng tôi cần viết 1 bài conference cho cùng ý tưởng đó.\nCho tới khi viết journal paper, chúng tôi thường phải trình bày ý tưởng của mình nhiều lần trong và ngoài lab.\nQuá trình viết một journal paper thường gồm 3 giai đoạn.\n\nỞ trong lab, chúng tôi có Group Meetings (GM) được tổ chức hàng tuần vào chiều Thứ Sáu. Mỗi tuần sẽ có 1-2 thành viên trong lab trình bày về công việc mình đang làm trước giáo sư và toàn lab. Trừ người trình bày, chúng tôi thường rất thích các buổi GM này vì cả lab được gặp nhau và ngồi dưới bắt nạt người trình bày. Chúng tôi được khuyến khích đặt câu hỏi để sự tương tác giữa các thành viên vào 1 vấn đề lớn hơn.\nNgay khi có ý tưởng, tôi thường nóng lòng xin giáo sư cho trình bày trong lần GM trống gần nhất. Vì khi có ý tưởng mới là lúc chúng ta cảm thấy ‘excited’ nhất, muốn chia sẻ nhất để xem mọi người nhận xét thế nào.\nỞ lần trình bày thứ nhất, thường là đề xuất ý tưởng, chúng tôi sẽ nhận được phản hồi từ giáo sư về tính novelty và tính khả thi của ý tưởng. Nếu mọi việc thuận lợi, chúng tôi sẽ làm experiment và trình bày thêm khoảng 1-2 lần nữa. Sau khi có kết quả, chúng tôi sẽ quyết định nộp bài vào conference nào cho kịp thời gian. Đồng thời, cũng phải lựa xem phần nào nên viết trong conference, phần nào nên để lại cho journal. Journal paper, mặc dù được phát triển từ conference paper, cần có những điểm mới riêng biệt mà conference paper không có.\nNếu có dịp, ví dụ như các hội nghị sinh viên nghiên cứu khoa học ở trường, chúng tôi sẽ mang ý tưởng ra trình bày và nhận các phản hồi trong trường. Phần này thường không mang nhiều ý nghĩa vì trong trường thường ít người biết về nghiên cứu của chúng tôi.\n\nVới conference paper, vì là một bài ngắn nên paper chủ yếu là chia sẻ ý tưởng và một vài kết quả cơ bản. Sau khi nộp bài cho conference, chúng tôi phải bắt tay vào làm thêm experiment, phân tích thuật toán, cải thiện tốc độ và thêm một vài chứng minh toán cần thiết. Và hy vọng bài conference paper vừa nộp được Chấp nhận.\nThật may mắn cho tôi là các papers của tôi chưa bao giờ bị Từ chối.\nSau 3-4 tháng kể từ nộp, tới khi nhận được kết quả của bài conference, tôi sẽ nhận được các nhận xét của các reviewers. Dựa trên các nhận xét đó, tôi bắt tay vào lên dàn ý và bắt đầu viết journal paper. Lý tưởng nhất, tới khi conference diễn ra, thường là 3-4 tháng nữa sau đó, tôi phải hoàn thành bản nháp đầu tiên cho bài journal paper.\nTại conference, nội dung của poster hoặc slide sẽ dựa trên bản journal paper mà không phải conference paper nữa. Dựa trên phản hồi của khán giả, chúng tôi sẽ sửa đổi journal paper thêm một lần nữa trước khi nộp.\n\nCó một điểm tôi muốn đề cập là bản nộp lần đầu tiên thường không được vượt quá một số lượng trang nào đó. Ví dụ là 12 đối với bài IEEE Transactions on Image Processing (TIP) tôi nộp gần đây. Ở lần đầu, các reviewers không muốn tác giả viết quá nhiều. Làm sao gói gọn trong 12 trang là được. Sau lần đầu thì giới hạn là 16 trang.\nThêm một điểm nữa, các reviewers thường không bao giờ hài lòng ở lần review đầu tiên. Bao giờ họ cũng yêu cầu mình làm thêm experiment này nọ, giải thích rõ hơn về ý tưởng và thêm một vài chứng minh khác. Ở bản cuối cùng, nhà xuất bản cũng mong mình viết nhiều để họ còn thu thêm tiền quá trang, vì chỉ 10 trang đầu tiên là miễn phí. Mỗi trang sau trang thứ 10 sẽ bị tính thêm $200-$300 nữa.\nThế đấy, viết bài đã không được nhuận bút mà còn phải trả thêm để được xuất bản. Và nghèo thì không làm khoa học được.\nDựa trên quan sát này, ở lần nộp thứ nhất, chúng tôi thường để lại một vài thí nghiệm mà biết chắc reviewers sẽ hỏi. Sau vòng thứ nhất, hy vọng chưa bị reject, chúng tôi sẽ thêm những ý kia vào sau.\nCó một điều tôi hay thấy là có những reviewers không thực sự hiểu ý tưởng của mình vì có thể họ không quen với lĩnh vực đó. Họ hay có những nhận xét chung chung kiểu như: A, bài này không khác bài conference là mấy; Với tập training nhỏ hơn thì kết quả thế nào; khi tham số mô hình thay đổi thì kết quả có tốt không; độ phức tạp của thuật toán là ntn. Những bình luận như thế này thường rất dễ trả lời :).\nKhi phản hổi lại bình luận của reviewers, chúng tôi phải trả lời TỪNG Ý một. Phải thêm bớt vào bài báo sao cho mỗi reviewer đều cảm thấy các thắc mắc của mình đề đã được giải đáp triệt để. Nếu bạn làm họ hài lòng, thường ở lần thứ hai họ sẽ chấp nhận bài báo, vì cũng không muốn mất thêm thời gian vào việc review bài này nữa :).\nThi thoảng có những bình luận không được xác đáng, thầy tôi sẽ là người trực tiếp viết phản hồi. Tôi vẫn thường nhớ câu của thầy: We politely but strongly disagree with the reviewer that blah blah . Đọc câu này, các reviewer thường chột dạ, cũng sợ là mình nói gì đó sai sai, nên lần tới không dám nói bậy nữa. Tất nhiên, phải ở một trình độ rất cao mới dám viết một câu như thế này.\n\nỞ lần nộp đầu tiên, các reviewers thường được nhắc là có 6 tuần để gửi bình luận. Nhưng thường là các bác để lâu, có khi tới 5-6 tháng. Với reviewers, họ có quyền sinh sát nên chẳng quan tâm việc quá deadline. AE cũng phải ‘nhờ’ họ làm mà. Khi làm reviewer, tôi thường luôn làm đúng hẹn. Vì thường chỉ mất vài tiếng để hoàn thành, làm xong thì mình bớt đi 1 mục ở to-do list.\nNếu tới 5-6 tháng mà vẫn chưa có phản hồi, chúng tôi thường gửi một email ngắn nhắc nhở lịch sự tới AE. Thường thì sau khi nhắc, các AE sẽ thúc reviewers làm việc luôn và vài ngày sau sẽ có kết quả.\nSau khi có kết quả vòng 1 mà vẫn chưa bị Reject, chúng tôi có 6 tuần để trả lời tất cả các thắc mắc và nộp lại. Chúng tôi phải nộp 2 bản: 1 bản là bản sửa của bài báo, 1 bản là bản phản hồi tới các reviewers. Tốt nhất là làm xong trong 6 tuần, đừng có để lâu như các reviewers, chúng ta không có quyền đó. Nếu cảm thấy làm không kịp thì xin AE thêm extension. Tôi chưa xin bao giờ.\nChú ý rằng phải viết thế nào để không làm phật lòng các reviewer và cho họ thấy rằng mình đã rất nỗ lực sửa bài báo theo ý của họ. Chú ý highlight những phần thay đổi so với vòng một để reviewers không mất thời gian đọc lại những phần cũ nữa. Hai bài journal papers tôi từng viết đều được chấp nhận ở vòng thứ hai này.\nỞ lần review thứ hai, các reviewers có 3 tuần để phản hồi vì họ đã quen với nội dung rồi. Và họ đôi khi cũng hay trì hoãn để tới vài tháng. May mắn cho tôi là bài đầu tiên tôi nhận kết quả Chấp nhận sau 3 tuần; bài thứ hai là sau 2 tháng, không tệ lắm.\n\nTôi có vài nguyên tắc khi trình bày bài viết:\nLời lẽ trong các bài phản hồi phải thật lịch sự. Phải luôn tránh làm reviewer bực bội vì họ nắm trong tay vận mệnh bài báo của mình :D. Một điểm lưu ý nữa là hình thức của bài phản hồi cũng cần được chau chuốt.\nCác tài liệu nên được viết bằng LaTex vì nó hỗ trợ các công thức cũng như việc trích dẫn chéo rất tốt, và rất khoa học. Đã lâu rồi tôi không dùng các sản phẩm Microsoft Office để soạn thảo, chỉ dùng để đọc các tài liệu khác. (Tôi hơi bị định kiến với các sản phẩm của Microsoft, thường nặng và đắt).\nCố gắng publish mã nguồn nếu có thể. Việc có mã nguồn sẽ khiến các reviewers ‘tin tưởng’ vào bài của mình hơn.\nLàm Literature review thật kỹ trước khi viết bài. Tránh trường hợp có một bài báo khác có ý tưởng gần giống với bài của mình và đã được xuất bản từ trước.\nViệc nộp bài vào một tạp chí và nhận phản hồi là miễn phí cho tới khi bài báo được Chấp nhận. Lợi dụng việc này, nhiều tác giả bắt đầu bằng việc nộp bài vào các tạp chí có thứ hạng cao hơn chất lượng của bài để nhận phản hồi; sau đó nếu bị Từ chối thì họ cũng đã có một bản tốt hơn với rất nhiều góp ý miễn phí và chất lượng. Sau đó đem bản này nộp tới tạp chí có thứ hạng thấp hơn.\nTôi thực sự phản đối cách làm này. Tôi cho rằng các tác giả làm như thế là thiếu tôn trọng các reviewers và thiếu tôn trọng chính mình. Một mặt, nó lấy đi thời gian của rất nhiều người, bao gồm AE, các reviewers, các nhân viên trong tạp chí, và cũng trì hoãn việc được Chấp nhận của chính bài báo đó. Một mặt khác, khi nộp một bài chất lượng thấp vào một tạp chí lớn, giáo sư đứng kèm tên cho bài báo đó sẽ bị đồng nghiệp (AR và các reviewers) đánh giá thấp hơn. Thi thoảng tôi có gặp một vài bài ở các nhóm nghiên cứu có giáo sư nổi tiếng nhưng chất lượng rất tệ, có thể vì giáo sư đó bận nên không đọc kỹ bài. Giáo sư của tôi rất cẩn thận, ông đọc và trực tiếp sửa trên Latex cho tất cả các bài. Vì dù sao ông cũng là người đứng tên và tài trợ trung gian cho dự án.\nMột bài viết chưa thể nói hết ý về những công việc chúng tôi phải làm thường xuyên. Tôi cũng không gọi đây là bài chia sẻ kinh nghiệm mà chỉ là kể lại những gì chúng tôi gặp phải trong quá trình viết bài báo khoa học.\nHy vọng rằng bài viết có ích cho các bạn.\nThân mến,\nTiệp Vũ"
    },
    {
        "ID": 15,
        "URL": "https://machinelearningcoban.com/2017/07/17/mlemap/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\nNhững sự kiện có xác suất cao là những sự kiện có khả năng xảy ra hơn.\nCâu nói nói cũng như không này là khơi nguồn cho rất nhiều các thuật toán Machine Learning có liên quan đến xác suất.\nCách giải quyết bài toán Machine Learning có thể viết gọn lại thành 3 bước chính: Modeling, Learning và Inference. (Xem Computer Vision: Models, Learning, and Inference)\nModeling là việc đi tìm môt mô hình thích hợp cho bài toán cần giải quyết. Với bài toán Linear Regression, modeling chính là việc mô hình dữ liệu đầu ra (output) như là tổ hợp tuyến tính của dữ liệu đầu vào (input). Với bài toán k-means clustering, modeling chính là việc quan sát ra rằng các clusters thường được mô tả bởi các centroids (hoặc centers) và mỗi điểm được xếp vào cluster tương ứng với centroid gần nó nhất. Trong bài toán Support Vector Machine cho dữ liệu linearly separable, modeling chính là bước quan sát thấy rằng đường thẳng phân chia hai classes phải là đường làm cho margin đạt giá trị lớn nhất. Việc đi tìm ra mô hình nào phù hợp cho bài toán chính là bước Modeling.\nLearning là bước tiến hành tối ưu các tham số của mô hình. Mỗi model được mô hình bởi một bộ các tham số (parameters). Với Linear Regression, tham số mô hình là bộ vector hệ số và bias \\((\\mathbf{w}, b)\\). Với K-means clustering, tham số mô hình có thể được coi là các clusters. Với Support Vector Machine, tham số mô hình có thể là vector hệ số và bias mô tả đường thằng \\((\\mathbf{w}, b)\\). Việc đi tìm các tham số cho mô hình thường được thực hiện bằng việc giải một bài toán tối ưu. Quá trình giải bài toán tối ưu, hay chính là quá trình đi tìm tham số của mô hình, chính là quá trình Learning. Sau bước Learning này, chúng ta thu được các trained parameters.\nInference là bước dự đoán ouput của mô hình dựa trên các trained parameters. Với Linear Regression, Inference chính là việc tính \\(y = \\mathbf{w}^T\\mathbf{x} + b\\) dựa trên bộ các tham số đã được huấn luyện \\((\\mathbf{w}, b)\\). Với K-means clustering, việc Inference chính là việc đi tìm centroid gần nhất. Với Support Vector Machine, Inference chính là việc xác định class của một dữ liệu mới dựa vào công thức \\(y = \\text{sgn}(\\mathbf{w}^T\\mathbf{x} + b)\\). So với hai bước Modeling và Learning, Inference thường đơn giản hơn.\nNhư đã đề cập, ở nửa sau của blog, tôi sẽ giới thiệu rất nhiều các mô hình thống kê. Trong các mô hình này, việc Modeling là việc đi tìm một mô hình thống kê (statistical model) phù hợp với từng loại dữ liệu và bài toán. Việc Learning là việc đi tìm các tham số cho mô hình thống kê đó. Việc Inference có thể coi là việc tính xác suất để xảy ra mỗi giá trị ở đầu ra khi biết các giá trị ở đầu vào và model được mô tả bởi các trained parameters.\nCác Mô Hình Thống Kê (Statistical Models) thường là sự kết hợp của các phân phối xác suất đơn giản. Với Bernoulli distribution, tham số là biến \\(\\lambda\\). Với Multivariate Normal Distribution, tham số là mean vector \\(\\mu\\) và ma trận hiệp phương sai \\(\\Sigma\\). Với một mô hình thông kê bất kỳ, ký hiệu \\(\\theta\\) là tập hợp tất cả các tham số của mô hình đó. Learning chính là quá trình đánh giá (estimate) bộ tham số \\(\\theta\\) sao cho dữ liệu sẵn có và mô hình khớp với nhau nhất. Quá trình đó còn được gọi là parameter estimation.\nCó hai cách đánh giá tham số thường được dùng trong Statistical Machine Learning. Cách thứ nhất chỉ dựa trên dữ liệu đã biết trong tập traing (training data), được gọi là Maximum Likelihood Estimation hay ML Estimation hoặc MLE. Cách thứ hai không những dựa trên training data mà còn dựa trên những thông tin đã biết của các tham số. Những thông tin này có thể có được bằng cảm quan của người xây dựng mô hình. Cảm quan càng rõ ràng, càng hợp lý thì khả năng thu được bộ tham số tốt là càng cao. Chẳng hạn, thông tin biết trước của \\(\\lambda\\) trong Bernoulli distribution là việc nó là một số trong đoạn \\([0, 1]\\). Với bài toán tung đồng xu, với \\(\\lambda\\) là xác suất có được mặt head, ta dự đoán được rằng giá trị này nên là một số gần với \\(0.5\\). Cách đánh giá tham số thứ hai này được gọi là Maximum A Posteriori Estimation hay MAP Estimation.\nTrong bài viết này, tôi sẽ trình bày về ý tưởng và cách giải quyết bài toán đánh giá tham số mô hình theo MLE hoặc MAP Estimation. Và như thường lệ, chúng ta sẽ cùng thực hiện mộ vài ví dụ đơn giản.\n\n\nGiả sử có các điểm dữ liệu \\(\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N\\). Giả sử thêm rằng ta đã biết các điểm dữ liệu này tuân theo một phân phối nào đó được mô tả bởi bộ tham số \\(\\theta\\).\n\nMaximum Likelihood Estimation là việc đi tìm bộ tham số \\(\\theta\\) sao cho xác suất sau đây đạt giá trị lớn nhất:\n\\[\n\\theta = \\max_{\\theta} p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N | \\theta) ~~~~ (1)\n\\]\nBiểu thức \\((1)\\) có ý nghĩa như thế nào và vì sao việc này có lý?\nGiả sử rằng ta đã biết mô hình rồi, và mô hình này được mô tả bởi bộ tham số \\(\\theta\\). Thế thì, \\(p(\\mathbf{x}_1 | \\theta)\\) chính là xác suất xảy ra sự kiện \\(\\mathbf{x}_1\\) biết rằng mô hình là (được mô tả bởi) \\(\\theta\\) (đây là một conditional probability). Và \\(p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N | \\theta)\\) chính là xác suất để toàn bộ các sự kiện \\(\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N\\) xảy ra đồng thời (nó là một joint probability), xác suất đồng thời này còn được gọi là likelihood. Ở đây, likelihood chính là hàm mục tiêu.\nBởi vì sự đã rồi, tức dữ liệu training bản thân nó đã là như thế rồi, xác suất đồng thời này cần phải càng cao càng tốt. Việc này cũng giống như việc đã biết kết quả, và ta cần đi tìm nguyên nhân sao cho xác suất xảy ra kết quả này càng cao càng tốt.\nMaximum Likelihood chính là việc đi tìm bộ tham số \\(\\theta\\) sao cho Likelihood là lớn nhất.\n\nViệc giải trực tiếp bài toán \\((1)\\) thường là phức tạp vì việc đi tìm mô hình xác suất đồng thời cho toàn bộ dữ liệu là ít khi khả thi. Một cách tiếp cận phổ biến là giả sử đơn giản rằng các điểm dữ liệu \\(\\mathbf{x}_n\\) là độc lập với nhau, nếu biết tham số mô hình \\(\\theta\\) (độc lập có điều kiện). Nói cách khác, ta xấp xỉ likelihood trong \\((1)\\) bởi:\n\\[\np(\\mathbf{x}_1, \\dots, \\mathbf{x}_N | \\theta) \\approx \\prod_{n = 1}^N p(\\mathbf{x}_n |\\theta) ~~~~ (2)\n\\]\n(Nhắc lại rằng hai sự kiện \\(x, y\\) là độc lập nếu xác suất đồng thời của chúng bằng tích xác suất của từng sự kiện: \\(p(x, y) = p(x)p(y)\\). Và khi là xác suất có điều kiện: \\(p(x, y | z) = p(x|z)p(y|z)\\))\nLúc đó, bài toán \\((1)\\) có thể được giải quyết bằng cách giải bài toán tối ưu sau:\n\\[\n\\theta = \\max_{\\theta} \\prod_{n=1}^N p(\\mathbf{x}_n| \\theta) ~~~~ (3)\n\\]\nViệc tối ưu hoá một tích thường phức tạp hơn việc tối ưu một tổng, vì vậy việc tối đa hàm mục tiêu thường được chuyển về việc tối đa \\(\\log\\) của hàm mục tiêu. Ôn lại một chút:\n\\(\\log\\) của một tích bằng tổng của các \\(\\log\\).\nvì rằng \\(\\log\\) là một hàm đồng biến, một biểu thức sẽ là lớn nhất nếu \\(\\log\\) của nó là lớn nhất, và ngược lại.\nBài toán Maximum Likelihood được đưa về bài toán Maximum Log-likelihood:\n\\[\n\\theta = \\max_{\\theta} \\sum_{n = 1}^N \\log\\left(p(\\mathbf{x}_n | \\theta)\\right) ~~~~ (4)\n\\]\nBạn vẫn chưa hiểu? Không lo, bây giờ chúng ta sẽ làm một vài ví dụ.\n\n\nBài toán: giả sử tung một đồng xu \\(N\\) lần và nhận được \\(n\\) mặt head. Tính xác suất có một mặt head khi tung đồng xu đó ở lần tiếp theo.\nLời giải:\nMột cách trực quan nhất, ta có thể dự đoán được rằng xác suất đó chính là \\(\\lambda = \\frac{n}{N}\\). Tuy nhiên, là một người muốn biết ngọn ngành vấn đề, bạn có thể chưa cảm thấy thuyết phục, và muốn biết liệu có cơ sở toán học vững chắc hơn chứng minh việc đó không.\nViệc này có thể thực hiện bằng Maximum Likelihood.\nThật vậy, giả sử \\(\\lambda\\) là xác suất để nhận được một mặt head. Đặt \\(x_1, x_2, \\dots, x_N\\) là các đầu ra nhận được, trong đó có \\(n\\) giá trị bằng 1 tương ứng với mặt head và \\(m = N - n\\) giá trị bằng 0 tương ứng với mặt tail. Ta có thể suy ra ngay:\n\\[\n  \\sum_{i=1}^N x_i = n, ~~N - \\sum_{i=1}^N x_i = N - n = m\n\\]\nCó thể nhận thấy việc nhận được mặt head hay tail khi tung đồng xu tuân theo Bernoulli distribution:\n\\[\np(x_i | \\lambda) = \\lambda^{x_i} ( 1- \\lambda)^{1 - x_i}\n\\]\nKhi đó tham số mô hình \\(\\lambda\\) có thể được đánh giá bằng việc giải bài toán tối ưu:\n\\[\n\\begin{eqnarray}\n  \\lambda & = & \\arg\\max_{\\lambda}\\left[ p(x_1, x_2, \\dots, x_N | \\lambda)\\right] \\\n  & = & \\arg\\max_{\\lambda} \\left[\\prod_{i = 1}^N p(x_i | \\lambda)\\right] & (5) \\\n  & = & \\arg\\max_{\\lambda} \\left[\\prod_{i=1}^N  \\lambda^{x_i} ( 1- \\lambda)^{1 - x_i}\\right] & (6)\\\n  & = & \\arg\\max_{\\lambda} \\left[\\lambda^{\\sum_{i=1}^N x_i} (1 - \\lambda)^{N - \\sum_{i=1}^N x_i}\\right] & (7) \\\n  & = & \\arg\\max_{\\lambda} \\left[\\lambda^{n} (1 - \\lambda)^{m}\\right] & (8)\\\n  & = & \\arg\\max_{\\lambda} \\left[ n\\log(\\lambda) + m\\log(1 - \\lambda) \\right] & (9)\n\\end{eqnarray}\n\\]\nở trên, tôi đã giả sử rằng kết quả của mỗi lần tung đồng xu là độc lập với nhau. Từ \\((8)\\) sang \\((9)\\) ta đã lấy \\(\\log\\) của hàm mục tiêu.\nTới đây, bài toán tối ưu \\((9)\\) có thể được giải bằng cách lấy đạo hàm của hàm mục tiêu bằng 0. Tức \\(\\lambda\\) là nghiệm của phương trình:\n\\[\n\\begin{eqnarray}\n  \\frac{n}{\\lambda} - \\frac{m}{1 - \\lambda} & = & 0 \\\n  \\Leftrightarrow \\frac{n}{\\lambda} & = & \\frac{m}{1 - \\lambda} \\\n  \\Leftrightarrow \\lambda & = & \\frac{n}{n + m} = \\frac{n}{N}\n\\end{eqnarray}\n\\]\nVậy kết quả ta khẳng định ở trên là có cơ sở.\n\nMột ví dụ khác khó hơn một chút.\nBài toán: giả sử tung một viên xúc xắc 6 mặt có xác suất rơi vào các mặt có thể không đều nhau. Giả sử trong \\(N\\) lần tung, số lượng xuất hiện các mặt thứ nhất, thứ hai,…, thứ sáu lần lượt là \\(n_1, n_2, \\dots, n_6\\) lần với \\(\\sum_{i=1}^6 n_i = N\\). Tính xác suất rơi vào mỗi mặt ở lần tung tiếp theo.\nLời giải:\nBài toán này có vẻ phức tạp hơn bài toán trên một chút, nhưng ta cũng có thể dự đoán được đánh giá tốt nhất của xác suất rơi vào mặt thứ \\(i\\) là \\(\\lambda_i = \\frac{n_i}{N}\\).\nMã hoá mỗi quan sát đầu ra thứ \\(i\\) bởi một vector 6 chiều \\(\\mathbf{x}_i \\in \\{0, 1\\}^6\\) trong đó các phần tử của nó bằng 0 trừ phần tử tương ứng với mặt quan sát được là bằng 1. (Cách làm này giống với one-hot encoding). Ta cũng có thể suy ra:\n\\[\n\\begin{eqnarray}\n  \\sum_{i=1}^N x^j_i = n_j, ~ \\forall j = 1, 2, \\dots, 6\n\\end{eqnarray}\n\\]\ntrong đó \\(x^j_i\\) là thành phần thứ \\(j\\) của vector \\(\\mathbf{x}_i\\).\nCó thể thấy rằng xác suất rơi vào mỗi mặt tuân theo Categorical distribution với các tham số \\(\\lambda_j > 0, j = 1, 2, \\dots, 6\\) (ta bỏ qua trường hợp tầm thường khi có một \\(\\lambda_j = 0\\)). Ta dùng \\(\\lambda\\) để thể hiện cho cả 6 tham số này. Với các tham số này, xác suất để sự kiện \\(\\mathbf{x}_i\\) xảy ra là:\n\\[\n\\begin{eqnarray}\n  p(\\mathbf{x}_i | \\lambda) = \\prod_{j = 1}^6 \\lambda_j^{x_i^j}\n\\end{eqnarray}\n\\]\nKhi đó, vẫn với giả sử về sự độc lập giữa các lần tung xúc xắc, đánh giá bộ tham số \\(\\lambda\\) dựa trên Maximum log-likelihood ta có:\n\\[\n\\begin{eqnarray}\n  \\lambda & = & \\arg\\max_{\\lambda} \\left[ p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N  | \\lambda) \\right]\\\n  & = & \\arg\\max_{\\lambda} \\left[ \\prod_{i=1}^N p(\\mathbf{x}_i | \\lambda)  \\right] & (10) \\\n  & = & \\arg\\max_{\\lambda} \\left[ \\prod_{i=1}^N  \\prod_{j = 1}^6 \\lambda_j^{x_i^j} \\right] & (11) \\\n  & = & \\arg\\max_{\\lambda} \\left[  \\prod_{j = 1}^6 \\lambda_j^{\\sum_{i=1}^N x_i^j} \\right] & (12) \\\n  & = & \\arg\\max_{\\lambda} \\left[  \\prod_{j = 1}^6 \\lambda_j^{n_j} \\right] & (13) \\\n  & = & \\arg\\max_{\\lambda} \\left[  \\sum_{j=1}^6 n_j\\log(\\lambda_j) \\right] & (14) \\\n\\end{eqnarray}\n\\]\nKhác với bài toán \\((9)\\) một chút, chúng ta không được quên điều kiện \\(\\sum_{j=1}^6 \\lambda_j = 1\\). Vậy ta có bài toán tối ưu có ràng buộc:\n\\[\n\\begin{eqnarray}\n  \\max_{\\lambda} & \\sum_{j=1}^6 n_j\\log(\\lambda_j) \\\n  \\text{subject to:} & \\sum_{j=1}^6 \\lambda_j = 1~~~~~~~~ (15)\n\\end{eqnarray}\n\\]\nBài toán tối ưu này có thể được giải bằng phương pháp nhân tử Lagrange.\nLagrangian của bài toán này là:\n\\[\n  \\mathcal{L}(\\lambda, \\mu) = \\sum_{j=1}^6 n_j\\log(\\lambda_j) + \\mu (1- \\sum_{j=1}^6 \\lambda_j)\n\\]\nNghiệm của bài toán là nghiệm của hệ đạo hàm của \\(\\mathcal{L}(.)\\) theo từng biến bằng 0:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial \\mathcal{L}(\\lambda, \\mu)}{\\partial \\lambda_j} & = &  \\frac{n_j}{\\lambda_j} - \\mu & = & 0, ~~ \\forall j = 1, 2, \\dots, 6 ~~~~ (16) \\\n\\frac{\\partial \\mathcal{L}(\\lambda, \\mu)}{\\partial \\mu} & = & 1-\\sum_{j=1}^6 \\lambda_j & = & 0 ~~~~ (17)\n\\end{eqnarray}\n\\]\nTừ \\((16)\\) ta có \\(\\lambda_j = \\frac{n_j}{\\mu}\\). Thay vào \\((17)\\):\n\\[\n  \\sum_{j=1}^6 \\frac{n_j}{\\mu} = 1 \\Rightarrow \\mu = \\sum_{j=1}^6 n_j = N\n\\]\nTừ đó ta có đánh giá:\n\\[\n  \\lambda_j = \\frac{n_j}{N}, ~~\\forall j = 1, 2, \\dots, 6\n\\]\nQua hai ví dụ trên ta thấy Maximum Likelihood cho kết quả hợp lý.\n\nBài toán: Khi thực hiện một phép đo, giả sử rằng rất khó để có thể đo chính xác độ dài của một vật. Thay vào đó, người ta thường đo vật đó nhiều lần rồi suy ra kết quả, với giả thiết rằng các phép đo là độc lập với nhau và kết quả mỗi phép đo là một phân phối chuẩn. Đánh giá chiều dài của vật đó.\nLời giải:\nVì ta biết rằng kết quả phép đo tuân theo phân phối chuẩn nên ta sẽ cố gắng đi xây dựng phân phối chuẩn đó. Chiều dài của vật có thể được coi là giá trị mà hàm mật độ xác suất đạt giá trị cao nhất. Trong phân phối chuẩn, ta biết rằng đó chính là kỳ vọng của phân phối đó. Chú ý rằng kỳ vọng của phân phối và kỳ vọng của dữ liệu quan sát được có thể không bằng nhau, chúng chỉ xấp xỉ bằng nhau khi mà số lượng phép đó là một số rất lớn.\nTuy nhiên, nếu đánh giá kỳ vọng của phân phối như cách làm dưới đây sử dụng Maximum Likelihood, ta sẽ thấy rằng kỳ vọng của dữ liệu chính là đánh giá tốt nhất cho kỳ vọng của phân phối.\nThật vậy, giả sử các kích thước quan sát được là \\(x_1, x_2, \\dots, x_N\\). Ta cần đi tìm một phân phối chuẩn, tức một giá trị kỳ vọng \\(\\mu\\) và phương sai \\(\\sigma^2\\), sao cho các giá trị \\(x_1, x_2, \\dots, x_N\\) là likely nhất.\nTa đã biết rằng, hàm mật độ xác suất tại \\(x_i\\) của một phân phối chuẩn có kỳ vọng \\(\\mu\\) và phương sai \\(\\sigma^2\\) là:\n\\[\n  p(x_i | \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left(-\\frac{(x_i - \\mu)^2}{2\\sigma^2}\\right)\n\\]\nVậy, để đánh giá \\(\\mu\\) và \\(\\sigma\\), ta sử dụng Maximum likelihood với giả thiết rằng kết quả các phép đo là độc lập:\n\\[\n\\begin{eqnarray}\n  \\mu, \\sigma & = & \\arg\\max_{\\mu, \\sigma} \\left[ \\prod_{i=1}^N p(x_i | \\mu, \\sigma^2)\\right] & (18)\\\n  & = & \\arg\\max_{\\mu, \\sigma} \\left[ \\frac{1}{(2\\pi \\sigma^2)^{N/2}} \\exp\\left(-\\frac{\\sum_{i=1}^N (x_i - \\mu)^2}{2\\sigma^2} \\right) \\right] & (19)\\\n  & = & \\arg\\max_{\\mu, \\sigma}\\left[ -N\\log(\\sigma) - \\frac{\\sum_{i=1}^N (x_i - \\mu)^2}{2\\sigma^2}\\right] \\triangleq \\arg\\max_{\\mu, \\sigma} J(\\mu, \\sigma)(20)\n\\end{eqnarray}\n\\]\nTa đã lấy \\(\\log\\) của hàm bên trong dấu ngoặc vuông của \\((19)\\) để được \\((20)\\), phần hằng số có chứa \\(2\\pi\\) cũng được bỏ đi vì nó không ảnh hưởng tới kết quả.\nMột lần nữa, để tìm \\(\\mu\\) và \\(\\sigma\\), ta giải hệ phương trình đạo hàm của \\(J(\\mu, \\sigma)\\) theo mỗi biến bằng 0:\n\\[\n\\begin{eqnarray}\n  \\frac{\\partial J}{\\partial \\mu} & = & \\frac{1}{\\sigma^2}\\sum_{i=1}^N(x_i - \\mu) = 0 & (21) \\\n  \\frac{\\partial J}{\\partial \\sigma} & = & -\\frac{N}{\\sigma} + \\frac{1}{\\sigma^3} \\sum_{i=1}^N (x_i - \\mu)^2  & (22)\n\\end{eqnarray}\n\\]\nTừ đó ta có:\n\\[\n\\begin{eqnarray}\n  \\mu & = & \\frac{\\sum_{i=1}^N x_i}{N} & (23)\\\n  \\sigma^2 & = & \\frac{\\sum_{i=1}^N (x_i - \\mu)^2}{N} & (24)\n\\end{eqnarray}\n\\]\nĐây chính là công thức đánh giá hai giá trị kỳ vọng và phương sai của dữ liệu mà chúng ta quen dùng.\n\nBài toán: Giả sử tập dữ liệu ta thu được là các giá trị nhiều chiều \\(\\mathbf{x}_1, \\dots, \\mathbf{x}_N\\). Giả sử thêm rằng dữ liệu này tuân theo phân phối chuẩn nhiều chiều. Hãy đánh giá các tham số, vector kỳ vọng \\(\\mu\\) và ma trận hiệp phương sai \\(\\Sigma\\), của phân phối này dựa trên Maximum Likelihood, giả sử rằng các \\(\\mathbf{x}_1, \\dots, \\mathbf{x}_N\\) là độc lập.\nLời giải:\nViệc chứng minh các công thức:\n\\[\n\\begin{eqnarray}\n  \\mu & = & \\frac{\\sum_{i=1}^N \\mathbf{x}_i}{N} \\\n  \\Sigma & = & \\frac{1}{N}\\sum_{i=1}^N (\\mathbf{x} - \\mu)(\\mathbf{x} - \\mu)^T\n\\end{eqnarray}\n\\]\nxin được dành lại cho bạn đọc như một bài tập nhỏ. Dưới đây là một vài gợi ý:\n\\[\n  \\nabla_{\\Sigma} (\\mathbf{x}_i - \\mu)^T \\Sigma^{-1} (\\mathbf{x}_i-\\mu) = -\\Sigma^{-T}(\\mathbf{x}_i - \\mu)(\\mathbf{x}_i - \\mu)^T\\Sigma^{-T}\n\\]\n(Xem thêm Matrix Calculus, mục D.2.1 và D.2.4.)\n\n\nQuay lại với ví dụ 1 về tung đồng xu. Nếu tung 5 lần và chỉ nhận được 1 mặt head, theo Maximum Likelihood, xác suất để có một mặt head được đánh giá là \\(1/5\\). Nếu tung đồng xu 5000 lần và nhận được 1000 lần head, ta có thể đánh giá xác suất của head là \\(1/5\\) và việc đánh giá này là đáng tin. Tuy nhiên, vì chỉ có 5 kết quả, thật khó để kết luận rằng kết quả là \\(1/5\\). Nếu kết luận ngay kết quả là \\(1/5\\), rất có thể chúng ta đã bị overfitting.\nKhi có quá ít dữ kiện, tương ứng với hiện tượng có quá ít dữ liệu trong training (low-training) chúng ta cần phải tự suy ra một vài giả thiết của các tham số. Chẳng hạn, với việc tung đồng xu, giả thiết của chúng ta là xác suất nhận được mặt head phải gần \\(1/2\\).\nMaximum A Posteriori (MAP) ra đời nhằm giải quyết vấn đề này. Trong MAP, chúng ta giới thiệu một giả thiết biết trước, được gọi là prior, của tham số \\(\\theta\\). Từ những kinh nghiệm trước đây, chúng ta có thể suy ra các khoảng giá trị và phân bố của tham số.\nNgược với MLE, trong MAP, chúng ta sẽ đánh giá tham số như là một conditional probability của dữ liệu:\n\\[\n  \\theta = \\arg\\max_{\\theta} \\underbrace{p(\\theta | \\mathbf{x}_1, \\dots, \\mathbf{x}_N)}_{\\text{posterior}} ~~~~~~~ (34)\n\\]\nBiểu thức \\(p(\\theta | \\mathbf{x}_1, \\dots, \\mathbf{x}_N) \\) còn được gọi là posterior probability của \\(\\theta\\). Chính vì vậy mà việc đánh giá \\(\\theta\\) theo \\((34)\\) được gọi là Maximum A Posteriori.\nThông thường, hàm tối ưu trong \\((34)\\) khó xác định dạng một cách trực tiếp. Chúng ta thường biết điều ngược lại, tức nếu biết tham số, ta có thể tính được hàm mật độ xác suất của dữ liệu. Vì vậy, để giải bải toán MAP, ta thường sử dụng Bayes’ rule. Bài toán MAP thường được biến đổi thành:\n\\[\n\\begin{eqnarray}\n  \\theta & = & \\arg\\max_{\\theta} p(\\theta | \\mathbf{x}_1, \\dots, \\mathbf{x}_N) \\\n  & = & \\arg\\max_{\\theta} \\left[ \\frac{\\overbrace{p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N | \\theta)}^{\\text{likelihood}} \\overbrace{p(\\theta)}^{\\text{prior}}}{\\underbrace{p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N)}_{\\text{evidence}}} \\right] & (35)\\\n  & = & \\arg\\max_{\\theta} \\left[ p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N | \\theta) p(\\theta) \\right] & (36) \\\n  & = & \\arg\\max_{\\theta} \\left[ \\prod_{i=1}^N p(\\mathbf{x}_i | \\theta) p(\\theta) \\right] & (37)\n\\end{eqnarray}\n\\]\nĐẳng thức \\((35)\\) xảy ra là do Bayes’ rule.\nĐẳng thức \\((36)\\) xảy ra vì mẫu số của \\((35)\\) không phụ thuộc vào tham số \\(\\theta\\).\nĐẳng thức \\((37)\\) xảy ra nếu chúng ta giả thiết về sự độc lập giữa các \\(\\mathbf{x}_i\\). Chú ý rằng giả thiết độc lập thường xuyên được sử dụng.\nNhư vậy, điểm khác biệt lớn nhất giữa hai bài toán tối ưu MLE và MAP là việc hàm mục tiêu của MAP có thêm \\(p(\\theta)\\), tức phân phối của \\(\\theta\\). Phân phối này chính là những thông tin ta biết trước về \\(\\theta\\) và được gọi là prior. Ta có kết luận: posteriori tỉ lệ thuận với tích của likelihood và prior.\nViệc lựa chọn các prior như thế nào, chúng ta cùng làm quen với khái niệm mới: Conjugate prior.\n\nKhi nhân một phân phối \\(p_1\\) một phân phối \\(p_2\\) khác, kết quả thu được tỉ lệ thuận với một phân phối có dạng giống như phân phối \\(p_2\\), ta nói \\(p_2\\) là conjugate distribution của \\(p_1\\). Nếu điều này xảy ra, việc tối ưu bài toán MAP sẽ trở nên tương tự như việc tôi ưu bài toán MLE vì nghiệm có cấu trúc giống nhau.\nNếu posterior distribution \\(p(\\theta | \\mathbf{X})\\) và likelihood \\(p(\\mathbf{X} |\\theta)\\) có cùng họ (family), thì prior distribution là conjugate distribution của likelihood distribution.\nTôi sẽ không đi sâu vào phần này, bạn đọc có thể đọc thêm Conjugate prior. Tôi sẽ nêu một vài cặp các conjugate distributions:\nNếu likelihood function là một Gaussian (phân phối chuẩn), và prior cho vector kỳ vọng cũng là một Gaussian, thế thì posterior distribution cũng là một Gaussian. Ta nói rằng Gaussian family conjugate với chính nó (hoặc còn gọi là self-conjugate).\nNếu likelihood function là một Gaussian (phân phối chuẩn), và prior cho phương sai là một gamma distribution, thì posterior distribution cũng là một Gaussian. Ta nói rằng gamma distribution là conjugate prior cho độ chính xác của Gaussian. Chú ý rằng phương sai có thể được coi là một biến giúp đo độ chính xác của mô hình. Phương sai càng nhỏ thì độ chính xác càng cao.\nBeta distribution là conjugate của Bernoulli distribution.\nDirichlet distribution là conjugate của Categorical distribution.\n\nChúng ta sẽ cùng xem xét một ví dụ nhỏ với Bernoulli distribution:\n\\[\n  p(x | \\lambda) = \\lambda^x ( 1 - \\lambda)^{1 - x}\n\\]\nVà conjugate của nó, Beta distribution, có hàm mật độ xác suất:\n\\[\n  p(\\lambda) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} \\lambda^{\\alpha - 1} ( 1 - \\lambda) ^{\\beta - 1}\n\\]\nBỏ qua thừa số hằng số chỉ mang mục đích chuẩn hoá cho tích phân của hàm mật độ xác suất bằng 1, ta có thể nhận thấy rằng phần còn lại của Beta distribution có cùng họ với Bernoulli distribution.\nCụ thể, nếu sử dụng Beta distribution làm prior cho tham số \\(\\lambda\\), và bỏ qua phần thừa số hằng số, posterior sẽ có dạng:\n\\[\n\\begin{eqnarray}\n  p(\\lambda | x) & \\propto & p(x | \\lambda) p(\\lambda) \\\n      & \\propto & \\lambda^{x + \\alpha - 1}(1 - \\lambda)^{1 - x + \\beta - 1} ~~~ (38)\n\\end{eqnarray}\n\\]\ntrong đó, \\(\\propto\\) là ký hiệu của tỉ lệ với.\nNhận thấy rằng \\((38)\\) vẫn có dạng của một Bernoulli distribution. Chính vì vậy mà Beta distribution được gọi là một conjugate prior cho Bernoulli distribution.\nTrong ví dụ này, tham số \\(\\lambda\\) phụ thuộc vào hai tham số khác là \\(\\alpha\\) và \\(\\beta\\). Để tránh nhầm lẫn, hai tham số \\((\\alpha, \\beta)\\) được gọi là siêu tham số (hyperparameters).\nQuay trở lại ví dụ về bài toán tung đồng xu \\(N\\) lần có \\(n\\) lần nhận được mặt head và \\(m = N - n\\) lần nhận được mặt tail. Nếu sử dụng MLE, ta nhận được đánh giá \\(\\lambda = n/M\\). Nếu sử dụng MAP với prior là một \\(\\text{Beta}[\\alpha, \\beta]\\) thì sao:\nBài toán tối ưu MAP:\n\\[\n\\begin{eqnarray}\n  \\lambda & = & \\arg\\max_{\\lambda} \\left[p(x_1, \\dots, x_N | \\lambda) p(\\lambda) \\right] \\\n  & = & \\arg\\max_{\\lambda} \\left[\\left(\\prod_{i=1}^N \\lambda^{x_i} ( 1- \\lambda)^{1 - x_i}\\right) \\lambda^{\\alpha - 1} ( 1 - \\lambda)^{\\beta - 1} \\right] \\\n  & = & \\arg\\max_{\\lambda} \\left[ \\lambda^{\\sum_{i = 1}^N x_i + \\alpha - 1} ( 1- \\lambda)^{N - \\sum_{i=1}^N x_i + \\beta - 1} \\right] \\\n  & = & \\arg\\max_{\\lambda} \\left[ \\lambda^{n + \\alpha - 1} ( 1- \\lambda)^{m + \\beta - 1} \\right] ~~~ (39)\n\\end{eqnarray}\n\\]\nBài toán tối ưu \\((39)\\) chính là bài toán tối ưu \\((8)\\) với tham số thay đổi một chút. Tương tự như \\((8)\\), nghiệm của \\((39)\\) có thể được suy ra là:\n\\[\n\\lambda = \\frac{n + \\alpha - 1}{N + \\alpha + \\beta - 2} ~~~ (40)\n\\]\nChính việc chọn prior phù hợp, ở đây là conjugate prior, mà posterior và likelihood có dạng giống nhau, khiến cho việc tối ưu bài toán MAP được thuận lợi.\nViệc còn lại là chọn cặp hyperparameters \\(\\alpha\\) và \\(\\beta\\).\nChúng ta cùng xem lại hình dạng của Beta distribution và nhận thấy rằng khi \\(\\alpha = \\beta > 1\\), ta có hàm mật độ xác suất của Beta distribution đối xứng qua điểm 0.5 và đạt giá trị cao nhất tại 0.5. Xét Hình 1, ta nhận thấy rằng khi \\(\\alpha = \\beta > 1\\) thì \\(\\lambda\\) có xu hướng đi về điểm 0.5, xu hướng này càng mạnh nên giá trị của chúng càng cao.\nNếu ta chọn \\(\\alpha = \\beta = 1\\), ta thấy đây là uniform distribution vì đồ thị hàm mật độ xác suất là 1 đường thẳng. Lúc này, xác suất của \\(\\lambda\\) tại mọi vị trí trong khoảng \\([0, 1]\\) là như nhau. Thực chất, nếu ta thay \\(\\alpha = \\beta = 1\\) vào \\((40)\\) ta sẽ thu được \\(\\lambda = n/N\\), chính là đánh giá thu được bằng MLE. MLE là một trường hợp đặc biệt của MAP khi prior là một uniform distribution.\nNếu ta chọn \\(\\alpha = \\beta = 2\\), ta sẽ thu được:\n\\[\n  \\lambda= \\frac{n + 1}{N + 2}\n\\]\nChẳng hạn khi \\(N = 5, n = 1\\) như trong ví dụ. MLE cho kết quả \\(\\lambda = 1/5\\), MAP sẽ cho kết quả \\(\\lambda = 2/6 = 1/3\\).\nNếu chọn \\(\\alpha = \\beta = 10\\) ta sẽ có \\(\\lambda = (1 + 9)/(5 + 18) = 10/23\\). Ta thấy rằng khi \\(\\alpha = \\beta\\) và càng lớn thì ta sẽ thu được \\(\\lambda\\) càng gần \\(1/2\\). Điều này có thể dễ nhận thấy vì prior nhận giá trị rất cao tại 0.5 khi các hyperparameters \\(\\alpha = \\beta\\) lớn.\n\nViệc chọn các hyperparameter thường được dựa trên thực nghiệm, bằng cross-validation chẳng hạn. Việc thử nhiều bộ tham số rồi chọn ra bộ tốt nhất là việc mà các kỹ sư machine learning thường xuyên phải đối mặt. Cũng giống như chọn regularization parameter để tránh overfitting vậy.\nRõ ràng MAP cho chúng ta các kết quả linh hoạt (flexible) với sự thay đổi của hyperparameters. Và là một cách để tránh overfitting.\nNếu viết lại bài toán MAP dưới dạng:\n\\[\n\\begin{eqnarray}\n  \\theta & = & \\arg\\max_{\\theta} p(\\mathbf{X}| \\theta) p(\\theta) \\\n  & = & \\arg\\max_{\\lambda} \\left[ \\log \\underbrace{p(\\mathbf{X}| \\theta)}_{\\text{likelihood}} + \\log \\underbrace{p(\\theta)}_{\\text{prior}} \\right]\n\\end{eqnarray}\n\\]\nta có thể thấy rằng đây giống như kỹ thuật regularization với \\(\\log\\) của likelihood được coi như phần loss chính, \\(\\log\\) của prior đóng vai trò như phần regularization. Nếu không có regularization, ta được bài toán Maximum (log-)likelihood.\n\nKhi sử dụng các mô hình thống kê Machine Learning, chúng ta thường xuyên phải đi đánh giá các tham số của mô hình, đại diện cho các tham số của các phân phối xác suất. Tập hợp tham số mô hình thường được ký hiệu là \\(\\theta\\). Có hai phương pháp phổ biến được sử dụng để đánh giá \\(\\theta\\) là Maximum Likelihood Estimation (MLE) và Maximum A Posteriori Estimation (MAP).\nVới MLE, việc xác định tham số \\(\\theta\\) được thực hiện bằng cách đi tìm các tham số sao cho xác suất của training data (sự thật), hay còn gọi là likelihood, là lớn nhất, :\n\\[\n\\theta = \\arg\\max_{\\theta} p(\\mathbf{x}_1, \\dots, \\mathbf{x}_N |\\theta)\n\\]\nĐể giải bài toán tối ưu này, giả thiết các dữ liệu \\(\\mathbf{x}_i\\) độc lập thường được sử dụng. Và bài toán MLE trở thành:\n\\[\n\\theta = \\arg\\max_{\\theta} \\prod_{i=1}^N p(\\mathbf{x}_i | \\theta)\n\\]\nĐể giải bài toán này, ta thường sử dụng Bayes’ rule và giả thiết độc lập của dữ liệu:\n\\[\n\\theta = \\arg\\max_{\\theta} \\left[\\prod_{i=1}^N p(\\mathbf{x}_i | \\theta) p(\\theta) \\right]\n\\]\nHàm mục tiêu chính là tích của likelihood và prior.\nPrior thường được chọn dựa trên các thông tin biết trước của tham số, và phân phối được chọn thường là các conjugate distribution với likelihood, tức các distribution khiến việc nhân thêm prior vẫn giữ được cấu trúc giống như likelihood.\nMAP có thể được coi là một phương pháp giúp tránh overfitting (hoặc overconfidence). MAP thường mang lại hiệu quả cao hơn MLE với trường hợp có ít dữ liệu training.\n\n[1] Chapter 4, 6 của Computer Vision:  Models, Learning, and Inference - Simon J.D. Prince\n[2] Conjugate prior"
    },
    {
        "ID": 16,
        "URL": "https://machinelearningcoban.com/lifesofar/",
        "Title": "Machine Learning cơ bản",
        "Content": "Gần đây có một độc giả nhận mình là loyal reader của blog, hỏi tôi về phương pháp tôi học đại số, giải tích, và tối ưu. Tôi không thực sự có thể trả lời câu hỏi này trong một vài câu trao đổi qua lại. Một phần vì tôi chưa tự tóm tắt lại ‘phương pháp’ của mình, một phần vì đó là cả một câu chuyện dài, bắt đầu từ hơn hai mươi năm trước.\nBài viết này không nhằm mục đích trả lời câu hỏi trên mà chủ yếu để chia sẻ với các bạn câu chuyện đi học của tôi. Trong quá trình hồi tưởng, tôi có thể xen thêm nhiều cảm xúc cá nhân và những người bạn tuổi thơ đã ảnh hưởng rất nhiều đến con người tôi bây giờ.\nNhìn chung, con đường đi học của tôi khá suôn sẻ và chủ yếu là niềm vui. Con đường đó có những chông gai, nhưng tôi luôn nhìn sự việc đơn giản bằng một đôi mắt lạc quan.\nNgày học mẫu giáo, tôi và đám bạn tự đi bộ đi học. Trường ngay trong làng, bố mẹ bận không đưa đón được.\nTrước khi học chữ quốc ngữ, tôi có thời gian một năm học chữ Nho ở nhà một ông đồ trong làng. Hàng tuần tôi đạp chiếc xe nhỏ xíu và mang theo một cuốn vở tới nhà ông. Mỗi tuần tôi được dạy khoảng mười chữ, không học viết mà chỉ học thuộc vẹt cặp song ngữ Nho-Việt. Tôi nhớ được khoảng mấy chữ đầu và hay đem khoe với các cô và bạn trong lớp mẫu giáo. Ai cũng trầm trồ khen, họ chẳng biết rằng tôi đôi khi cũng bịa ra mấy nét vẽ.\nNgày học tiểu học, tôi đi học ở một làng khác trong xã. Tôi và đám bạn vẫn tự đi bộ đi học.\nNgày được xếp vào lớp một, tôi được bầu làm lớp trưởng nhưng vẫn khóc như mưa vì không được học cùng các bạn hồi mẫu giáo. Tôi đòi mẹ đưa đến nhà thầy hiệu phó ăn vạ nhưng không thành. Buổi chiều tôi vẫn buồn một chút nhưng hôm sau quên ngay.\nCô giáo lớp một nói tôi nên dừng học chữ Nho để tập trung học chữ quốc ngữ. Tôi dừng, ông đồ tiếc mãi vì làng tôi vừa mất đi một thầy cúng tương lai.\nTôi có một con lợn nhựa, cứ một điểm mười thì bố tôi sẽ thưởng 1-2k cho vào lợn. Có ngày tôi được 23 điểm mười (à, tôi rất nhạy cảm với các con số, nhất là các số nguyên tố - mặc dù lớp một chưa biết số nguyên tố là gì), vậy mà bố tôi cũng chỉ cho 10k bỏ lợn :D.\nBố tôi dạy tôi chơi cờ vua. Một thời gian sau, tôi thường xuyên thắng bố.\nMột ngày năm lớp ba đi học ở lớp bồi dưỡng học sinh giỏi, tôi được 3 điểm môn toán trong khi cô bạn thân học cùng được 8 điểm. Tôi rất buồn và lo sợ, chưa bao giờ điểm toán của tôi tệ đến thế. Vậy nhưng nỗi buồn cũng chỉ kéo dài khoảng một ngày, tôi luôn biết cách làm cho mình vui vẻ trở lại.\nĐây là bước ngoặt quan trọng nhất trong cuộc đời tôi. Tôi sẽ nhớ mãi những người đã sống cùng tôi thời gian ấy\nTôi bắt đầu sống xa nhà khi mới chín tuổi. Tôi  lại khu nội trú của trường, một tuần chỉ về nhà một lần.\nTháng 09/1998, học sinh giỏi trong cả huyện Thái Thuỵ về thị trấn Diêm Điền dự thi để chọn ra một lớp đặc biệt. Tôi được trường tiểu học Thụy văn cử đi thi, tôi làm bài rất tệ! Tôi may mắn được nhận vào lớp với rất nhiều bạn giỏi, tôi đoán là các bạn thi đều được cả vì biết mình làm bài không tốt.\nVà tôi bắt đầu sống xa gia đình từ lúc mới chín tuổi. Tôi ở lại khu nội trú của trường cùng với rất nhiều bạn học. Bố mẹ một tuần đón tôi một lần. Vì bố mẹ làm việc cả tuần nên ít khi để ý thứ bảy chủ nhật, thi thoảng bố mẹ quên không đón thì tôi tự đi bộ về. Có lần đi bộ xa nhất là được nửa đường (khoảng 3km), may tôi gặp ông hàng xóm đi làm về nhìn thấy. May nữa là hồi đó xe cộ không nhiều và tôi không bị bắt cóc.\nTôi vẫn nhớ như in cô Diện dạy Toán tôi ngày lớp bốn. Ngày đó cô 27 tuổi,\nkém tôi bây giờ một tuổi. Bài học đầu tiên ở lớp mới là “cấu tạo số”. Bài tập mẫu đầu\ntiên là: tìm một số có hai chữ số sao cho khi thêm chữ số một vào trước thì được\nmột số mới gấp năm lần số ban đầu. Thật là kỳ diệu, một thế giới toán học sáng\nloà mở ra trước mắt tôi. Một bài học khác nữa tôi nhớ là: có bao nhiêu số có\nhai chữ số khác nhau được tạo bởi các chữ số 1, 2, 3. Tôi cực kỳ sung sướng vì\nthấy những lời giải thật đẹp mà cô Diện dạy chúng tôi. Tôi nghĩ cô quý tôi nhất lớp, vì tôi là học sinh duy nhất được cô tổ chức sinh nhật riêng ở lớp. Cô tặng tôi hai mươi cuốn vở ô li, các bạn trong lớp cũng tặng cho tôi rất nhiều quà. Cô là cô giáo dạy\ntoán mà tôi sẽ nhớ mãi suốt cuộc đời này, không phải là đầu tiên nhưng là người\nthực sự đưa tôi vào con đường học toán dài tới tận bây giờ. Vài năm sau đó, cô\nchuyển ra Hải Phòng và tôi không thể nào liên lạc lại với cô được nữa.\nSau khi viết bài này, tôi đã tìm được cô Diện. Cô cũng là giáo viên dạy Toán của một bạn đang theo dõi blog.\nLớp tôi có một cậu bạn tên Thịnh, nhà gần trường. Buổi chiều và tối Thịnh hay vào trong trường chơi với tôi. Tôi nhắc tới Thịnh vì con đường học Toán của tôi và Thịnh gắn với nhau khá nhiều về sau.\nTôi dạy Thịnh chơi cờ vua. Một thời gian sau, Thịnh thường xuyên thắng tôi.\nNăm ấy thi học sinh giỏi, tôi được giải Nhất tỉnh. Điểm đứng thứ hai ở huyện sau một cô bạn cùng lớp tên Trang (có nhiều giải Nhất). Hồi tiểu học thi học sinh giỏi có cả hai môn Toán và Tiếng Việt. Điểm Tiếng Việt của tôi khá cao. Thịnh không được giải cao, và cũng chưa nổi bật lắm trong lớp.\nNhững người bạn học rất giỏi và chơi rất vui đã giúp định hình con người tôi sau này rất nhiều. Đây là mốc thời gian mà tôi không thể không nhắc tới.\nNgày lớp năm, chúng tôi được học cô Thảo. Cô rất tốt, nhiệt tình và dạy rất giỏi. Thời gian gần lúc thi học sinh giỏi tỉnh, cô tổ chức dạy miễn phí cho các bạn dự thi vào buổi tối ở trường. Cả lớp tôi sau này vẫn thường gọi cô là “Mẹ Thảo”. Năm đó, lớp tôi có rất nhiều giải cao. Tôi một lần nữa được giải Nhất tỉnh Thái Bình, và điểm cao thứ hai trong huyện, sau một bạn nữ tên Trang. Một niềm vui nho nhỏ là điểm Tiếng Việt của tôi cao nhất huyện. Tôi còn nhớ bài Tập làm văn đề ra là “Hãy tưởng tượng em được giải nhất trong kỳ thi học sinh giỏi tỉnh. Ngay khi biết tin, cảm xúc của em như thế nào và em sẽ làm gì.” Cái đề gì kỳ quặc, chưa thi đã bắt tưởng tượng rồi. Cô Thảo có dặn tôi viết lại bài văn đó ngày sau khi biết kết quả. Tôi có viết lại, nhưng tôi biết chắc chắn không thể hay bằng lúc thi thật.\nSau khi thi học sinh giỏi vào khoảng tháng 03/2000. Các bạn trong khu nội trú của tôi về nhà hết, chỉ còn mình tôi ở lại vì bố mẹ tôi bận công việc không đưa đón hàng ngày được. Tôi vẫn nhớ buổi tối tôi ngủ cùng ông bảo vệ. Có một cô cấp dưỡng mỗi tối vào trường nấu cơm cho tôi, một mình tôi.\nCó những người tốt, việc tốt diễn ra rất bình thường ngày đó, bây giờ trở thành hiếm gặp.\nChúng tôi lên cấp hai, và gần như lớp cấp một vẫn được học chung một lớp. Nhưng lớp bây giờ chỉ như các lớp bình thường khác trong trường chứ không phải lớp đặc biệt như cấp một. Đội tuyển học sinh giỏi giờ cũng khác vì chúng tôi chỉ được chọn một trong ba đội tuyển: Toán, Văn, Anh. Cô giáo chủ nhiệm lớp sáu của tôi là cô Thoa. Cô dạy Văn, nghiêm khắc và rất quan tâm tới lớp. Tới ngày chọn đội tuyển, tôi lưỡng lự giữa Toán và Văn vì cả hai môn tôi đều học tốt :3. Cuối cùng tôi chọn Toán vì đám bạn thân, bao gồm Thịnh và Trang, cũng theo học Toán. Cô Thoa có lẽ hơi buồn vì lớp theo Toán gần hết.\nTrường cấp hai không có khu nội trú, tôi hàng ngày đạp xe đi học khoảng 7km một chiều. Học đội tuyển thường là 2-3 buổi sáng/tuần. Buổi chiều học ở lớp bình thường với các bạn. Buổi trưa tôi thường về nhà Đông, nhà bạn ấy bán cơm. Chúng tôi thường không ngủ trưa mà đọc Conan cả buổi trưa dưới phòng riêng của bạn ấy.\nKết thúc học kỳ I, tôi được điểm tổng kết 8.9, bằng với Hiệp lớp trưởng. Nhưng vì nhà tôi ở xa và hàng ngày đạp xe đi học nên được cô Thoa thưởng một quyển sổ dày, bìa cứng màu tím – quyển sổ đẹp nhất mà tôi từng sở hữu. Tôi dán ảnh Thuỷ thủ mặt trăng lên trang đầu tiên, ngay dưới lời khen và chữ ký của cô. Tôi dùng quyển sổ này để ghi chép bài tập ở lớp học đội tuyển Toán các năm sau đó. Quyển số này theo tôi đến tận năm thứ tư đại học, tôi vẫn thi thoảng mở ra đọc lại để nhớ về một thời học toán tươi đẹp. Rồi không hiểu vì sao mà tôi lại đem cho quyển sổ với rất nhiều kiến thức và kỷ niệm đó cho Tiến cùng phòng ký túc xá, Tiến xin cho đứa cháu đang học đội tuyển Toán. Bây giờ nghĩ lại tôi thấy rất tiếc, không biết cuốn đó giờ thế nào.\nNăm lớp sáu, tôi thi học sinh giỏi tỉnh chỉ được giải Khuyến Khích, tôi rất thất vọng. Thịnh bạn tôi xếp hạng khá cao trong đội và bắt đầu trở thành ngôi sao của huyện Thái Thụy. Điểm cao nhất thuộc về một bạn nữ tên Yến, một nhân vật mới xuất hiện trong lớp.\nLớp bảy, tôi được giải Ba, Thịnh hình như cũng thế, Yến vẫn giành điểm cao nhất đội.\nLớp tám, tôi được giải Nhất, điểm cao nhất đội (19.5/20) lần đầu tiên. Thịnh cũng đạt giải cao.\nTrong thời gian này, mỗi mùa hè tôi đều được bố đưa lên thị xã mua sách nâng cao môn Toán. Cuốn sách tôi thích nhất là cuốn “Những bài toán cổ” của NXB giáo dục, bìa màu vàng, tôi không nhớ tên tác giả. Tôi đọc và say mê các bài toán cũng như lịch sử của Toán học từ cuốn sách này. Các sách toán nâng cao khác của tác giả Vũ Hữu Bình (cùng họ Vũ Hữu với tôi) cũng là hành trang theo suốt tuổi thơ học Toán của tôi.\nNăm lớp chín, có một sự thay đổi lớn. Lớp học chính của chúng tôi ở thị trấn\nnhưng lớp học đội tuyển lại ở một trường khác cách thị trấn khoảng 6km về phía\nxa nhà tôi hơn. Tôi không thể đạp xe đi về được và phải tìm nhà trọ ở lại thị\ntrấn. Hiệp lớp trưởng đề nghị tôi về nhà bạn ấy ở cùng. Chúng tôi ở\ncùng phòng trong một năm và có rất nhiều kỷ niệm đẹp. Tôi vẫn thân với Hiệp và\ngia đình bạn ấy. Cả nhà đều rất thương tôi và coi tôi như người trong nhà.\nCô Diệp dạy Đại Số và thầy Quyết dạy hình học đã giúp chúng tôi học được rất\nnhiều điều mới vào năm đó. Chúng tôi bắt đầu làm quen với các bài toán bất đẳng\nthức từ lớp chín. Bất đẳng thức Cauchy và Bunhiacopxki cũng gắn với chúng tôi\ntừ những ngày đó. Ba tuần cuối trước khi thi học sinh giỏi tỉnh, chúng tôi được\nmiễn học trên lớp và chỉ tập trung học đội tuyển. Cả ngày chúng tôi học cùng\nnhau, buổi trưa ăn ở nhà một bạn bán cơm gần trường đó. Đội tuyển năm đó đạt\ngiải rất cao. Thịnh, Yến, Trang đều được giải Nhất.\nHiệp được giải Nhì, tôi được điểm cao nhất tỉnh năm đó (18.5/20).\nSau khi thi học sinh giỏi xong, bố mẹ tôi cảm ơn gia đình Hiệp và xin cho tôi về nhà vì chúng tôi không học đội tuyển nữa. Mẹ Hiệp giữ tôi ở lại vì tôi và Hiệp học và chơi cùng nhau rất tốt, muốn  hai đứa cùng nhau chuẩn bị cho kỳ thi vào cấp ba.\nMẹ Hiệp không biết rằng chúng tôi thường xuyên nhịn ăn sáng dành tiền đi chơi điện tử cùng nhau. Hồi đó chúng tôi thường chơi Bóng đá 99, chọn đội tuyển Brazil và thường xuyên vô địch.\nCũng trong năm đó, có chương trình đi học cấp ba ở Singapore; tỉnh tôi cử hai bạn điểm cao nhất môn Toán và tiếng Anh đi thi. Tôi rất dốt tiếng Anh nhưng vẫn qua được bài thi viết. Đến lúc phỏng vấn tại Đại sứ quán Singapore thì chịu luôn, không biết nói chữ nào. Có lẽ đó là một điều may mắn, không hiểu sao tôi luôn cho rằng như vậy.\nCuối năm lớp chín, tôi không hề biết gì về chuyên Sư Phạm và chuyên Tổng Hợp, tôi chỉ biết chuyên Thái Bình và đăng ký thi vào đó. Qua các bạn, tôi có kịp đăng ký thi chuyên Sư Phạm nhưng thi thiếu điểm rất nhiều. Thịnh và Đông đỗ và học Sư Phạm. Tôi đỗ chuyên Thái Bình, điểm đứng thứ tư trong kỳ thi đó, sau hai bạn nữ và một bạn nam khác. Chúng tôi có nhiều cuộc chia ly sau sáu năm học cùng nhau. Rất nhiều lưu luyến.\nCác bạn trong lớp cấp một và cấp hai vẫn chơi rất thân với nhau cho tới bây giờ. Lớp đó là lớp tôi nhớ nhất trong suốt thời gian đi học.\nTôi ở lại ký túc xá của trường Chuyên Thái Bình, một tuần đạp xe 32km về nhà vào sáng Thứ Bảy và lên lại vào chiều Chủ Nhật.\nTôi học lớp chuyên Toán, và thực sự được dạy rất sâu về Toán. Ký túc xá của tôi 19h30 đóng cửa, không TV, không internet, không nói chuyện to. Tôi thường thức đến 2-3 giờ sang đọc sách Toán và rất nhiều tiểu thuyết. Đơn giản vì tôi thích học và thích đọc. Cô giáo dạy Văn lớp 10 của chúng tôi cũng là quản lý thư viện trường nên lớp tôi được mượn rất nhiều sách từ thư viện.\nLớp 10 tỉnh Thái Bình không tổ chức thi học sinh giỏi tỉnh và tôi cũng chưa đủ điều kiện thi học sinh giỏi quốc gia. Tôi vẫn nhớ trường Chuyên Thái Bình tổ chức thi ba môn thi đại học sau mỗi nửa học kỳ. Lần đầu tiên điểm tôi khá cao trong trường. Điểm cao nhất là Nhung, cô bạn học rất giỏi ở lớp chuyên Lý.\nTôi và Thịnh vẫn thường xuyên liên lạc mặc dù Thịnh học ở Sư Phạm. Nhiều lần trên đường về\nquê, Thịnh dừng lại ở Tp Thái Bình một đêm và ở cùng tôi trong ký túc xá, hai thằng nằm chung một chiếc giường rộng 90cm. Thịnh\nthường mang theo rất nhiều tài liệu từ Sư Phạm về cho tôi. Tôi được tiếp cận nhiều bài toán\nhình học hay từ thầy Nguyễn Minh Hà và nhiều bài tổ hợp khó mới lạ, những\nthứ mà tôi không được học ở Thái Bình. Tôi và Thịnh thường thức đến 2-3 giờ đêm\nnói chuyện cùng nhau. Sáng năm giờ dậy đạp xe đưa Thịnh ra bến xe về quê. Những\ntài liệu quý giá Thịnh mang về đã giúp tôi rất nhiều trong việc học môn Toán.\nHè năm 2005, tôi xin bố lên Hà Nội mua sách Toán nâng cao. Tôi vẫn nhớ lần đầu tiên tiêu nhiều tiền thế để mua sách. Tôi tự đi Hà Nội lên nhà cậu; cậu đưa tôi đi nhà sách Giảng Võ và Nguyễn Thái Học. Tôi mua nhiều sách, hết tổng cộng 327k. Tôi thấy hơi tiếc tiền nhưng nhiều sách hay thế này chắc bố không mắng (một bữa cơm hồi đó tôi ăn chỉ ba nghìn đồng).\nNăm 2006, học lớp 11, tôi và bốn bạn khác trong lớp được chọn vào đội tuyển thi học sinh giỏi quốc gia của tỉnh Thái Bình. Tôi được giải Ba, hai bạn nữ trong lớp được giải Nhì. Điểm thi của tôi vẫn luôn kém các bạn nữ.\nNăm lớp 12, tôi vẫn trong đội tuyển toán của tỉnh. Năm này là năm Việt Nam tổ chức thi International Mathematical Olympiad (IMO). Tôi vẫn đón báo Toán học tuổi trẻ ngày 15 hàng tháng và thi thoảng nộp bài lên báo. Hàng tháng báo về tới bưu điện Thái Bình khoảng ngày 18-19 nhưng tôi đạp xe ra sạp báo mỗi ngày từ ngày 15 để đón mua. Năm đó báo có chương trình “Chào IMO”, tôi cũng nộp một số bài. Tôi nhớ mãi một lần được báo nêu tên, là một trong bốn học sinh cả nước giải được một bài tổ hợp và lời giải được lấy làm mẫu. Sau này một số bạn nghe tên tôi đều hỏi tôi từng được báo Toán học tuổi trẻ nêu tên đúng không. Tôi lấy làm vinh dự lắm.\nBài toán đó nằm trong tập tài liệu Thịnh mang về cho tôi, đã được dạy ở Sư Phạm.\nHồi đó internet mới bắt đầu nở rộ. Tôi tham gia Diễn Đàn Toán Học và có giải một số bài. Tôi cũng thường xuyên download các bài toán hay trong các kỳ thi toán trên khắp thế giới về học. Vẫn nhớ hồi đó in rất đắt. Có lần tôi in 46 trang tài liệu mất tới 23k. Đầu tư vào học tập tôi không bao giờ tiếc.\nNăm đó kỳ thi học sinh giỏi quốc gia có nhiều thay đổi. Không còn bảng A hay B như trước nữa mà cả nước thi chung một đề. Những năm trước các đội tuyển mỗi tỉnh được 8 thành viên, các đội của các trường đại học (Sư Phạm, Tổng Hợp, Vinh) được 10 hoặc 15. Năm này chỉ còn 6. Kỳ thi không còn là hai ngày, mỗi ngày ba bài như trước mà dồn lại một ngày, bảy bài trong 180 phút. Một điểm đặc biệt, từ năm này các học sinh được giải trong kỳ thi quốc gia không còn được tuyển thẳng đại học nữa nên Việt Nam bỏ lỡ khá nhiều nhân tài vào năm đó, tôi nghĩ thế.\nThịnh bất ngờ đạt điểm kém trong vòng thi cuối cùng ở Sư Phạm và không được tham dự kỳ thi Quốc gia mặc dù điểm các vòng trước rất cao. Đó là một điều đáng tiếc cho nhiều bên.\nThi xong, tôi nghĩ sẽ được giải Nhất vì làm được 6.5/7 bài. Thế nhưng niềm vui cứ giảm dần sau khi phát hiện ra các lỗi sai. Khi nhận giải, tôi là người duy nhất trong đội tuyển Thái Bình có giải. Được giải Ba, tôi khóc như mưa!!\nVì năm đó cả nước có ít giải, cả giải Khuyến khích mới là 41, nên tất cả học sinh đạt giải đều được vào vòng hai. Tôi cũng đi nhưng thầy và tôi đều không hy vọng vào được top sáu người cho đội Việt Nam năm đó. Tôi không buồn khi biết kết quả vì đó là điều được dự đoán từ trước. Trong kỳ thi này, tôi được gặp và làm quen với rất nhiều các bạn giỏi, nhiều trong số đó học cùng lớp đại học với tôi sau này và là bạn tốt tới bây giờ.\nSau khi thi vòng hai, tôi khá rảnh rang vì không phải thi Tốt nghiệp (tôi nhớ năm đó thi tốt nghiệp rất rất khó). Tôi cũng không phải thi đại học vì có giải Ba từ năm lớp 11, trước khi quy định có giải QG vẫn phải thi đại học. Tôi cũng được vào thẳng lớp Kỹ Sư Tài Năng (KSTN) của Bách Khoa nên chẳng phải lo nghĩ gì nữa. Kéo theo đó là thời gian xả hơi sau ba năm vất vả học tập. Tôi đi chơi cả mùa hè trong khi các bạn tập trung ôn thi. Việc không luyện tập thường xuyên mang lại nhiều hậu quả sau này.\nTrong 12 năm học Phổ Thông, tôi có vinh dự sáu lần được giải Nhất trong các kỳ thi học sinh giỏi cấp tỉnh, chia đều ra hai lần vào các năm cuối cấp.\nTôi vào lớp KSTN-ĐTVT-K52 của Bách Khoa Hà Nội. Lớp lớn (100 sinh viên) của tôi quy tụ rất nhiều nhân tài khắp miền Bắc và miền Trung. Rất nhiều trong đó có giải quốc gia, quốc tế. Lần đầu tiên tôi thấy mình nhỏ bé trong lớp! Rất nhiều bạn giỏi đang chuẩn bị làm hồ sơ du học. Kỳ I năm đó điểm GPA của tôi rất thấp, 2.9/4, Đại Số B, Giải tích C. Tại sao là toán mà điểm của tôi thấp vậy. Thời gian mùa hè bỏ bê quá nhiều khiến tôi không bao giờ tìm lại được cảm giác với toán như trước nữa. Cả thời gian đại học tôi ăn mày dĩ vãng thời đam mê sống và học tập hồi cấp ba mà không thể tìm lại được. Có lẽ vì có quá nhiều thú vui khiến tôi sao nhãng việc học hành, mặc dù tôi rất muốn tìm lại cảm xúc đam mê ngày nào.\nNăm thứ nhất tôi biết tin có kỳ thi Olympic toán sinh viên toàn quốc. Mặc dù biết mình khó cạnh tranh với toàn trường để vào đội tuyển năm người của Đại số hoặc Giải tích, tôi vẫn tham gia vì kỳ thi năm đó được tổ chức ở Nha Trang - wow. Kỳ lạ thay, tôi đứng thứ năm và được chọn vào đội tuyển Đại số của Bách Khoa năm đó. Tôi vẫn nhớ rằng thầy dạy đội tuyển năm đó không hy vọng nhiều vào tôi vì trong quá trình ôn thi tôi học tệ nhất đội.\nTôi vẫn nhớ kỳ thi năm đó. Có năm bài, tôi đánh vật với từng bài. Tới 2/3 thời gian thì thấy Thịnh, lúc đó ở đội của Sư Phạm Hà Nội, cười toe toét ở bên ngoài cửa sau khi xin ra sớm. Thật là ghen tị với bạn.\nTôi rất buồn sau khi thi xong, lại nghe tin trước lúc biết kết quả rằng BKHN có ba giải Nhất, một Nhì, một Ba. Chắc mình được giải Ba rồi, buồn quá. Thế mà tôi lại được giải Nhất, có lẽ do nhầm lẫn gì đó. Thịnh cũng được giải Nhất năm đó, như một điều hiển nhiên.\nNăm thứ hai. Các bạn đã đi du học rất nhiều. Tôi vẫn ở lại với Giải tích II B+, Giải tích III B+, Phương pháp tính B+, Xác suất thống kê B+. Không môn toán nào tôi được A! Tôi lại tham gia đội tuyển Đại số của BKHN đi thi ở Đồng Hới. Tôi nhớ như in tôi làm xong bài từ rất sớm, sau đó làm lại sạch đẹp không dập xoá tí nào. Tự tin giải Nhất, cuối cùng rất buồn vì được giải Nhì.\nNăm thứ ba, tôi một lần nữa vào đội Đại số. Kỳ thi năm đó ở Huế, tôi tham gia để đi du lịch là chính. Các thầy trong khoa toán nhìn tôi ngao ngán bảo sang năm nghỉ để nhường cho các em. Tôi lại được giải Nhất một lần nữa.\nSau năm thứ ba, tôi không học sâu Toán nữa vì các môn chuyên ngành yêu cầu thêm nhiều kiến thức khác. Tôi có tham gia một lab về phần cứng trong Viện Điện Tử Viễn Thông. Tôi cố gắng rất nhiều nhưng không bao giờ thấy lại đam mê như trước nữa. Phần cứng và tôi không có duyên với nhau. Tôi làm cháy khá nhiều mạch đắt tiền của thầy hướng dẫn!\nNăm cuối đại học, tôi được thầy hướng dẫn khuyến khích làm hồ sơ đi Mỹ học cao học. Tôi không tự tin với tiếng Anh của mình lắm. Cũng chỉ làm theo phong trào. May mắn thay, tôi được thầy hiện giờ ở Penn State nhận vào học, bắt đầu từ kỳ Fall 2013.\nThịnh hiện giờ đang làm nghiên cứu sinh ngành toán ở Singapore.\nĐây là một khoảng thời gian quan trọng với tôi. Tôi được học lại Đại số tuyến tính, Xác suất thông kê, Tối ưu rất kỹ, cả ở trong trường và cả tự học online. Tôi rất thích khoá Convex optimization của Stephen Boyd, khoá Probabilities and Random Processes, và khoá Pattern Regconition đều của thầy David Miller ở Penn State. Tôi thường xuyên phát biểu trong lớp và đạt điểm cao trong các môn học này. Cảm giác thích học toán và sự tự tin của tôi quay lại, và niềm đam mê học tập của tôi cũng tiệm cận với những gì tôi có hồi trước khi vào đại học.\nCàng học, tôi càng thấy mình nhỏ bé. Nhưng những điều đó không bao giờ làm tôi nản chí mà chỉ khiến tôi cố gắng tìm tòi hơn nữa. Tôi bắt đầu đọc và viết papers. Các papers của tôi đều có phần tăng tốc cho thuật toán, là một điều tôi rất thích. Có nhiều papers đề xuất các ý tưởng và bài toán tối ưu rất đẹp nhưng chưa thực sự giải quyết các bài toán đó một cách triệt để. Tôi rất thích tối ưu các thuật toán đó để có nghiệm tốt hơn và tốc độ chạy nhanh hơn, đó cũng là phần chính trong đề tài tốt nghiệp cao học của tôi. Tôi vừa mới biết chắc rằng mình sẽ tốt nghiệp vào mùa hè năm tới.\nNhư đã từng đề cập, tôi muốn ôn tập lại kiến thức Machine Learning, một lĩnh vực cần khá nhiều toán, nên tôi bắt đầu viết blog này từ đầu năm nay. Tôi được ôn lại toán rất nhiều, và hạnh phúc với những gì mình đang làm cho tới thời điểm này.\nCó thể các bạn thấy hụt hẫng vì tôi kết thúc ở đây, nhưng tôi xin phép được dừng lại. Có thể có nhiều câu chuyện thú vị khác nữa, tôi sẽ kể lại vào dịp khác, một dịp mà tôi lại có thời gian và cảm hứng. Thời đại học, tôi cũng có những kỷ niệm rất đẹp, những thầy cô tận tuỵ và những người bạn rất chân thành, nhưng những điều đó ảnh hưởng tới con người tôi hơn là con đường học Toán của tôi. Cảm xúc cũng không phải tự nhiên tuôn ra được, và không phải chuyện gì cũng đem ra kể được.\nCứ khoảng mỗi 5 năm, tôi lại xa nhà thêm một bậc. Từ làng, xã, thị trấn, thị xã, tới thủ đô. Và bây giờ tôi đang ở Mỹ.\nMỗi người có một con đường học tập khác nhau. Và tôi không nghĩ những gì trải qua trong cuộc đời tôi có thể đúc rút lại thành “kinh nghiệm học toán” cho bất kỳ ai. Chỉ có một điều tôi luôn ghi nhớ: đam mê là quan trọng nhất. Tôi tự nhận mình khá chăm chỉ, nhưng chăm chỉ thôi không đủ (như những năm cuối của đại học), quan trọng nhất là mình được làm những thứ mình đam mê.\nVới các bạn muốn học toán cho Machine Learning, đừng trách hay ỷ lại vào kiến thức ở trong trường đại học. Học đại học là phải tự tìm kiếm những gì cần thiết và đam mê. Tài liệu online rất nhiều, tốt và miễn phí. Và bạn có thể học bất cứ lúc nào, bắt đầu từ hôm nay.\nCảm ơn các bạn đã đọc đến những dòng cuối cùng này.\nTôi luôn ghi nhớ và trân trọng những con người đi cùng con đường học tập của tôi. Tôi biết rằng mình cần phải cố gắng nhiều nhiều hơn nữa.\nHoa Kỳ, tháng 7 năm 2017."
    },
    {
        "ID": 17,
        "URL": "https://machinelearningcoban.com/2017/07/09/prob/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\n\nCho tới thời điểm này, kế hoạch viết về phần Machine Learning cơ bản của tôi đã thực hiện được 1 nửa. Trong nửa đầu của blog, các bạn đã làm quen (lại) rất nhiều với Đại số tuyến tính và Tối ưu.\nNhìn chung, tôi đều viết các thuật toán Machine Learning dưới dạng các bài toán tối ưu và cách giải mỗi bài toán đó.\nCác bài viết trong nửa đầu có thể chia thành các Phần:\nBài 1-6: Làm quen với Machine Learning. Một vài thuật toán Machine Learning cơ bản chưa cần nhiều tới tối ưu.\nBài 7-8: Gradient Descent. Thuật toán tối ưu đơn giản mà hiệu quả cho các bài toán tối ưu không ràng buộc.\nBài 9-15: Neural Networks. Phần này giúp các bạn nắm được các thành phần cơ bản của một Neural Network và các Networks cơ bản nhất, chủ yếu cho các bài toán classification. Các bài toán tối ưu đều là không ràng buộc, các hàm mất mát hầu hết là không lồi, nghiệm tìm được là các local optimal.\nBài 16-18: Convex Optimization. Phần này bắt đầu sâu hơn một chút về Tối ưu. Định nghĩa về tập lồi, hàm lồi, bài toán tối ưu lồi và bài toán đối ngẫu. Đây là nền tảng cho rất nhiều thuật toán cơ bản Machine Learning sau này.\nBài 19-22: Support Vector Machine. Đây là một trong những thuật toán đẹp nhất và ‘intuitive’ nhất trong Machine Learning. Nếu bạn vào wiki tìm ‘Machine Learning’ thì sẽ thấy hình đại diện chính là SVM và Kernel SVM. Một trong những điều lý thú của SVM là bài toán tối ưu là lồi và nghiệm tìm được là duy nhất, cũng là global optimal.\nBài 23-25: Recommendation Systems. Đây là một lớp các bài toán thực tế và quan trọng của Machine Learning. Tôi chủ động thêm phần này vào vì làm giảm lượng toán đã đề cập quá nhiều trong Phần 4 và 5. Các thuật toán và bài toán trong phần này khá đơn giản nhưng kết quả khá tốt.\nBài 26-29: Dimensionality Reduction. Phần này cũng rất quan trọng trong Machine Learning. PCA gần như được dùng trong hầu hết các bài toán ML, trong khi LDA hiệu quả trong các bài toán classification. SVD, sau này các bạn sẽ thấy, được dùng rất nhiều vì những tính chất đẹp của nó.\nTrong nửa còn lại, tôi sẽ đi vào một mảng lớn khác của ML trong đó các kiến thức về xác suất thống kê được áp dụng rất nhiều, tôi tạm gọi phần này là Bayesian Machine Learning. Các bạn sẽ từ từ được ôn lại kiến thức về Xác Suất Thống Kê và làm quen với các thuật toán Machine Learning cơ bản khác.\nTrong bài viết này, tôi sẽ ôn tập lại những kiến thức về Xác Suất thường được sử dụng trong Machine Learning. Mục 2 sẽ nhắc lại về biến ngẫu nhiên, xác suất đồng thời, xác suất biên, xác suất có điều kiện, và quy tắc Bayes. Mục 3 sẽ nhác lại một vài phân bố xác suất thường dùng.\nPhần này được viết dựa trên Chương 2 và 3 của cuốn Computer Vision:  Models, Learning, and Inference - Simon J.D. Prince.\n\n\n\n\nMột biến ngẫu nhiên (random variable) \\(x\\) là một đại lượng dùng để đo những đại lượng không xác định. Biến này có thể ký hiệu kết quả/đầu ra (outcome) của một thí nghiệm (ví dụ như tung đồng xu) hoặc một đại lượng biến đổi trong tự nhiên (ví dụ như nhiệt độ trong ngày). Nếu chúng ta quan sát rất nhiều đầu ra \\( \\{x_i\\}_{i=1}^I\\) của các thí nghiệm này, ta có thể nhận được những giá trị khác nhau ở mỗi thí nghiệm. Tuy nhiên, sẽ có những giá trị xảy ra nhiều lần hơn những giá trị khác. Thông tin về đầu ra được đo bởi phân phối xác suất (probability distribution) \\(p(x)\\) của biến ngẫu nhiên.\nMột biến ngẫu nhiên có thể là rời rạc (discrete) hoặc liên tục (continuous). Một biến ngẫu nhiên rời rạc sẽ lấy giá trị trong một tập hợp cho trước. Ví dụ tung đồng xu thì có hai khả năng là head và tail (tên gọi này bắt nguồn từ đồng xu Mỹ, một mặt có hình mặt người, được gọi là head, trái ngược với mặt này được gọi là mặt tail, cách gọi này hay hơn cách gọi xấp ngửa vì ta không có quy định rõ ràng thế nào là xấp ngay ngửa).Tập các giá trị này có thể là có thứ tự (khi tung xúc xắc) hoặc không có thứ tự (unorderd), ví dụ khi đầu ra là các giá trị nắng, mưa, bão, etc. Mỗi đầu ra có một giá trị xác suất tương ứng với nó. Các giá trị xác suất này không âm và có tổng bằng một:\n\\[\n\\text{if}~ x ~\\text{is discrete:}\\quad \\sum_{x} p(x) = 1 ~~~~ (1)\n\\]\nBiến ngẫu nhiên liên tục lấy các giá trị là tập con của các số thực. Những giá trị này có thể là hữu hạn, ví dụ thời gian làm bài của mỗi thí sinh trong một bài thi 180 phút, hoặc vô hạn, ví dụ thời gian để chiếc xe bus tiếp theo tới. Không như biến ngẫu nhiên rời rạc, xác suất để đầu ra bằng chính xác một giá trị nào đó, theo lý thuyết, là bằng 0. Thay vào đó, ta có thể hình dung xác suất để đầu ra nằm trong một khoảng giá trị nào đó; và việc này được mô tả bởi hàm mật đô xác suất (probability density function - pdf). Hàm mật độ xác suất luôn cho giá trị dương, và tích phân của nó trên toàn miền possible outcome phải bằng 1.\n\\[\n\\text{if}~ x ~\\text{is continuous:}\\quad \\int p(x)dx = 1 ~~~~ (2)\n\\]\nĐể giảm thiểu ký hiệu, hàm mật độ xác suất của một biến ngẫu nhiên liên tục \\(x\\) cũng được ký hiệu là \\(p(x)\\).\nChú ý: Nếu \\(x\\) là biến ngẫu nhiên rời rạc, \\(p(x)\\) luôn luôn nhỏ hơn hoặc bằng 1. Trong khi đó, nếu \\(x\\) là biến ngẫu nhiên liên tục, \\(p(x)\\) có thể nhận giá trị dương bất kỳ, điều này vẫn đảm bảo là tích phân của hàm mật độ xác suất theo toàn bộ giá trị có thể có của \\(x\\) bằng 1. Với biến ngẫu nhiên rời rạc, \\(p(x)\\) được hiểu là mật độ xác suất tại \\(x\\).\n\n\nXét hai biến ngẫu nhiên \\(x\\) và \\(y\\). Nếu ta quan sát rất nhiều cặp đầu ra của \\(x\\) và \\(y\\), thì có những tổ hợp hai đầu ra xảy ra thường xuyên hơn những tổ hợp khác. Thông tin này được biểu diễn bằng một phân phối được gọi là joint probability của \\(x\\) và \\(y\\), và được viết là \\(p(x, y)\\). Dấu phẩy trong \\(p(x, y)\\) có thể đọc là và, vậy \\(p(x, y)\\) là xác suất của \\(x\\) và \\(y\\). \\(x\\) và \\(y\\) có thể là hai biến ngẫu nhiên rời rạc, liên tục, hoặc một rời rạc, một liên tục. Luôn nhớ rằng tổng các xác suất trên mọi cặp giá trị có thể xảy ra \\((x, y)\\) bằng 1.\n\\[\n\\begin{eqnarray}\n\\text{both are discrete} \\quad \\quad & \\sum_{x, y} p(x, y) &=& 1 \\newline\n\\text{both are continuous} & \\int p(x, y) dx dy &=& 1\\newline\nx ~\\text{is discrete}, ~ y ~\\text{is continuous} & \\sum_{x} \\int p(x, y) dy = \\int \\left(\\sum_{x} p(x, y) \\right)dy &=& 1\n\\end{eqnarray}\n\\]\nXét ví dụ trong Hình 1, phần có nền màu lục nhạt. \\(x\\) là biến ngẫu nhiên chỉ điểm thi môn Toán của học sinh trong một trường trong kỳ thi Quốc gia, \\(y\\) là biến ngẫu nhiên chỉ điểm thi môn Vật Lý cũng trong kỳ thi đó. \\(p(x = x^*, y = y^*)\\) là tỉ lệ giữa tần suất số học sinh được \\(x^*\\) điểm trong môn Toán và \\(y^*\\) điểm trong môn Vật Lý và toàn bộ số học sinh. Tỉ lệ này có thể coi là xác suất khi số học sinh trong trường là lớn. Ở đây \\(x^*\\) và \\(y^*\\) là các số xác định. Thông thường, xác suất này được viết gọn lại thành \\(p(x^*, y^*)\\), và \\(p(x, y)\\) được dùng như một hàm tổng quát để mô tả các xác suất. Giả sử thêm rằng điểm các môn là các số tự nhiên từ 1 đến 10.\nCác ô vuông màu lam thể hiện xác suất \\(p(x, y)\\) với diện tích ô vuông càng to thể hiện xác suất đó càng lớn. Chú ý rằng tổng các xác suất này bằng 1.\nCác bạn có thể thấy rằng xác suất để một học sinh được 10 điểm một Toán và 1 điểm môn Lý rất thấp, điều tương tự xảy ra với 10 điểm môn Lý và 1 điểm môn Toán. Ngược lại, xác suất để một học sinh được khoảng 7 điểm cả hai môn là cao nhất.\n\nThông thường, chúng ta sẽ làm việc với các bài toán ở đó joint probability xác định trên nhiều hơn 2 biến ngẫu nhiên. Chẳng hạn, \\(p(x, y, z)\\) thể hiện joint probability của 3 biến ngẫu nhiên \\(x,y\\) và \\(z\\). Khi có nhiều biến ngẫu nhiên, ta có thể viết chúng dưới dạng vector. Ta có thể viết \\(p(\\mathbf{x})\\) để thể hiện joint probability của biến ngẫu nhiên nhiều chiều \\(\\mathbf{x} = [x_1, x_2, \\dots, x_n]^T\\). Khi có nhiều tập các biến ngẫu nhiên, ví dụ \\(\\mathbf{x}\\) và \\(\\mathbf{y}\\), ta có thể biết \\(p(\\mathbf{x}, \\mathbf{y})\\) để thể hiện joint probability của tất cả các thành phần trong hai biến ngẫu nhiên nhiều chiều này.\n\n\nNếu biết joint probability của nhiều biến ngẫu nhiên, ta cũng có thể xác định được phân bố xác suất của từng biến bằng cách lấy tổng (với biến ngẫu nhiên rời rạc) hoặc tích phân (với biến ngẫu nhiên liên tục) theo tất cả các biến còn lại:\n\\[\n\\begin{eqnarray}\n  p(x) &=& \\sum_{y}p(x, y) \\quad & (3) \\newline\n  p(y) &=& \\sum_{x}p(x, y) & (4)\n\\end{eqnarray}\n\\]\nVà với biến liên tục:\n\\[\n\\begin{eqnarray}\n  p(x) &=& \\int p(x, y)dy \\quad & (5)\\newline\n  p(y) &=& \\int p(x, y)dx & (6)\n\\end{eqnarray}\n\\]\nVới nhiều biến hơn, chẳng hạn 4 biến rời rạc \\(x, y, z, w\\):\n\\[\n\\begin{eqnarray}\n  p(x) &=& \\sum_{ y, z, w}p(x, y, z, w) \\quad & (7) \\newline\n  p(x, y) &=& \\sum_{z, w}p(x, y, z, w) & (8)\n\\end{eqnarray}\n\\]\nCách xác định xác suất của một biến dựa trên joint probability được gọi là marginalization. Và phân phối đó được gọi là marginal probability.\nTừ đây trở đi, nếu không nói gì thêm, tôi sẽ dùng ký hiệu \\(\\sum\\) để chỉ chung cho cả hai loại biến. Nếu biến ngẫu nhiên là liên tục, bạn đọc ngầm hiểu rằng dấu \\(\\sum\\) cần được thay bằng dấu tích phân \\(\\int\\), biến lấy vi phân chính là biến được viết dưới dấu \\(\\sum\\). Chẳng hạn, trong \\((8)\\), nếu \\(z\\) là liên tục, \\(w\\) là rời rạc, công thức đúng sẽ là:\n\\[\n  p(x, y) = \\sum_{w}\\left( \\int p(x, y, z, w)dz \\right) = \\int \\left( \\sum_{w} p(x, y, z, w)\\right) dz\n\\]\nQuay lại ví dụ trong Hình 1 với hai biến ngẫu nhiên rời rạc \\(x, y\\). Lúc này, \\(p(x)\\) được hiểu là xác suất để một học sinh đạt được \\(x\\) điểm môn toán. Xác suất này được thể hiện ở khu vực có nền màu tím nhạt, phía trên. Có hai cách tính xác suất này, nhắc lại rằng xác suất ở đây thực ra là tỉ lệ giữa số học sinh đạt \\(x\\) điểm môn toán và toàn bộ số học sinh. Cách thứ nhất, dựa trên cách vừa định nghĩa, là đếm số học sinh được \\(x\\) điểm môn toán và tổng số học sinh. Cách tính thứ hai là dựa trên Joint probability đã biết về xác suất để một học sinh được \\(x\\) điểm môn Toán và \\(y\\) điểm môn Lý. Số lượng học sinh đạt \\(x = x^*\\) điểm môn Toán sẽ bằng tổng số lượng học sinh đạt \\(x = x^*\\) điểm môn Toán và \\(y\\) điểm môn Lý, với \\(y\\) là một giá trị bất kỳ từ 1 đến 10. Vậy nên để tính xác suất \\(p(x)\\), ta chỉ cần tính tổng của toàn bộ \\(p(x, y)\\) với \\(y\\) chạy từ 1 đến 10. Điều tương tự xảy ra nếu ta muốn tính \\(p(y)\\) (xem phần bên trái của khu vực nền tím nhạt).\nDựa trên nhận xét này, mỗi giá trị của \\(p(x)\\) chính bằng tổng các giá trị\ntrong cột thứ \\(x\\) của Hình vuông trung tâm. Mỗi giá trị của \\(p(y)\\) sẽ\nbằng tổng các giá trị trong hàng thứ \\(y\\) tính từ đưới lên của Hình vuông\ntrung tâm. Chú ý rằng tổng các xác suất luôn bằng 1. Từ hình ta cũng có thể\nthấy điểm môn Lý tuân theo phân phối chuẩn, đề khá tốt; còn đề thi môn Toán có\nvẻ hơi dễ vì phổ điểm bị lệch sang phải. Số liệu này chỉ là ví dụ nên các\nbạn có thể thấy một vài điểm bất thường.\n\n\nXác suất có điều kiện.\nDựa vào phổ điểm của các học sinh, liệu ta có thể tính được xác suất để một học sinh được điểm 10 môn Lý, biết rằng học sinh đó được điểm 1 môn Toán (ai cũng có quyền hy vọng). Hoặc biết rằng bây giờ đang là tháng 7, tính xác suất để nhiệt độ hôm nay cao hơn 30 độ C.\nXác suất có điều kiện (conditional probability) của một biến ngẫu nhiên \\(x\\) biết rằng biến ngẫu nhiên \\(y\\) có giá trị \\(y^*\\) được ký hiệu là \\(p(x| y = y^*)\\) (đọc là probability of \\(x\\) given that \\(y\\) takes value \\(y^*\\)).\nConditional probability \\(p(x | y = y^*)\\) có thể được tính dựa trên joint probobability \\(p(x, y)\\). Quay lại Hình 1 với vùng có nền màu nâu nhạt. Nếu biết rằng \\(y = 9\\), xác suất \\(p(x | y = 9)\\) có thể tính được dựa trên hàng thứ 9 của hình vuông trung tâm, tức hàng \\(p(x, y = 9)\\). Trong hàng này, những ô vuông lớn hơn thể hiện xác suất lớn hơn. Tương ứng như thế, \\(p(x | y = 9) \\) cũng lớn nếu \\(p(x, y= 9)\\) lớn. Chú ý rằng tổng các xác suất \\(\\sum_{x} p(x, y = 9)\\) nhỏ hơn 1 và bằng tổng các xác suất trên hàng thứ 9 này. Để có đúng xác suất, tức tổng các xác suất có điều kiện bằng 1, ta cần chia mỗi đại lượng \\(p(x, y = 9)\\) cho tổng của toàn hàng này. Tức là:\n\\[\n\\displaystyle\n  p(x | y = 9) = \\frac{p(x, y = 9)}{\\sum_x p(x, y = 9)} = \\frac{p(x, y = 9)}{p(y = 9)}\n\\]\nTổng quát:\n\\[\n\\displaystyle\n  p(x|y = y^*) = \\frac{p(x, y = y^*)}{\\sum_{x} p(x, y = y^*)} = \\frac{p(x, y = y^*)}{p(y = y^*)}  ~~~~ (9)\n\\]\nở đây ta đã sử dụng công thức marginal probability ở \\((4)\\) cho mẫu số. Thông thường, ta có thể viết xác suất có điều kiện mà không cần chỉ rõ giá trị \\(y = y^*\\) và có công thức gọn hơn:\n\\[\n  p(x |y) = \\frac{p(x, y)}{p(y)}~~~ (10)\n\\]\nTương tự:\n\\[\n  p(y | x) = \\frac{p(y, x)}{p(x)}\n\\]\nvà ta sẽ có quan hệ:\n\\[\n  p(x, y) = p(x|y)p(y) = p(y | x) p(x) ~~~ (11)\n\\]\nKhi có nhiều hơn hai biến ngẫu nhiên, ta có các công thức:\n\\[\n\\begin{eqnarray}\n  p(x, y, z, w)\n  & = & p(x, y, z | w) p(w) & (12)\\newline\n  & = & p(x, y | z, w)p(z, w) = p(x, y | z, w) p(z | w) p(w) \\quad & (13) \\newline\n  & = & p(x | y, z, w)p(y | z, w) p(z | w) p(w) & (14)\n\\end{eqnarray}\n\\]\nCông thức \\((14)\\) có dạng chuỗi (chain) và được sử dụng nhiều sau này.\n\n\nCông thức \\((11)\\) biểu diễn joint probability theo hai cách. Từ đây ta có thể suy ra quan hệ giữa hai conditional probabilities \\(p(x |y)\\) và \\(p(y | x)\\):\n\\[\n  p(y |x) p(x) = p(x | y) p(y)\n\\]\nBiến đối một chút:\n\\[\n\\displaystyle\n\\begin{eqnarray}\n  p(y | x)\n  & = & \\frac{p(x |y) p(y)}{p(x)}  & (15)\\newline\n  & = & \\frac{p(x |y) p(y)}{\\sum_{y} p(x, y)} & (16)\\newline\n  & = & \\frac{p(x |y) p(y)}{\\sum_{y} p(x | y) p(y)} \\quad & (17)\n\\end{eqnarray}\n\\]\nở đây, mẫu số của \\((16)\\) và \\((17)\\) đã lần lượt sử dụng các công thức về marginal \\((3)\\) và conditional probability \\((11)\\). Từ \\((17)\\) ta có thể thấy rằng \\(p(y | x)\\) hoàn toàn có thể tính được nếu ta biết mọi \\(p(x | y)\\) và \\(p(y)\\). Tuy nhiên, việc tính trực tiếp xác suất này thường là phức tạp. Thay vào đó, ta có thể đi tìm mô hình phù hợp của \\(p(\\mathbf{x} | y)\\) trên training data sao cho những gì đã thực sự xảy ra có xác suất cao nhất có thể (Chỗ này có thể hơi khó hình dung, tôi sẽ nói cụ thể về việc này trong bài tiếp theo). Dựa trên training data, các tham số của mô hình này có thể tìm được qua một bài toán tối ưu.\nBa công thức \\((15) - (17)\\) thường được gọi là Quy tắc Bayes (Bayes’ rule). Quy tắc này rất quan trọng trong Machine Learning!\nTrong Machine Learning, chúng ta thường mô tả quan hệ giữa hai biến \\(x\\) và \\(y\\) dưới dạng xác suất có điều kiện \\(p(x|y)\\). Ví dụ, biết rằng đầu vào là một bức ảnh ở dạng vector \\(\\mathbf{x}\\), xác suất để bức ảnh chứa một chiếc xe là bao nhiêu. Khi đó, ta phải tính \\(p(y | \\mathbf{x})\\).\n\n\nNếu biết giá trị của một biến ngẫu nhiên \\(x\\) không mang lại thông tin về việc suy ra giá trị của biến ngẫu nhiên \\(y\\) (và ngược lại), thì ta nói rằng hai biến ngẫu nhiên là độc lập (independence). Chẳng hạn, chiều cao của một học sinh và điểm thi môn Toán của học sinh đó có thể coi là hai biến ngẫu nhiên độc lập.\nKhi hai biến ngẫu nhiên \\(x\\) và \\(y\\) là độc lập, ta sẽ có:\n\\[\n\\begin{eqnarray}\n  p(x | y) &=& p(x) \\quad & (18) \\newline\n  p(y | x) &=& p(y) & (19)\n\\end{eqnarray}\n\\]\nThay vào biểu thức Conditional Probability trong \\((11)\\), ta có:\n\\[\n  p(x, y) = p(x | y) p(y) = p(x) p(y) ~~~ (20)\n\\]\n\n\nKỳ vọng (expectation) của một biến ngẫu nhiên được định nghĩa là:\n\\[\n\\begin{eqnarray}\n  \\text{E}[x] = \\sum_x x p(x) \\quad & \\text{if}~ x ~ \\text{is discrete} \\quad & (21)\\newline\n  \\text{E}[x] = \\int x p(x) dx \\quad & \\text{if}~ x ~ \\text{is continuous} & (22)\n\\end{eqnarray}\n\\]\nGiả sử \\(f(.)\\) là một hàm số trả về một giá trị với mỗi giá trị \\(x^*\\) của biến ngẫu nhiên \\(x\\). Khi đó, nếu \\(x\\) là biến ngẫu nhiên rời rạc, ta sẽ có:\n\\[\n  \\text{E}[f(x)] = \\sum_x f(x) p(x) ~~~ (23)\n\\]\nCông thức cho biến ngẫu nhiên liên tục cũng được viết tương tự.\nVới joint probability:\n\\[\n  \\text{E}[f(x, y)] = \\sum_{x,y} f(x, y) p(x, y) dx dy  ~~~ (24)\n\\]\nCó 3 quy tắc cần nhớ về kỳ vọng:\nKỳ vọng của một hằng số theo một biến ngẫu nhiên \\(x\\) bất kỳ bằng chính hằng số đó:\n\\[\n  \\text{E}[\\alpha] = \\alpha ~~~ (25)\n\\]\nKỳ vọng có tính chất tuyến tính:\n\\[\n\\begin{eqnarray}\n  \\text{E}[\\alpha x] & = & \\alpha \\text{E}[x] \\quad & (26)\\newline\n  \\text{E}[f(x) + g(x)] & = & \\text{E}[f(x)] + \\text{E}[g(x)] & (27)\n\\end{eqnarray}\n\\]\nKỳ vọng của tích hai biến ngẫu nhiên bằng tích kỳ vọng của hai biến đó nếu hai biến ngẫu nhiên đó là độc lập. Điều ngược lại không đúng, tôi sẽ bàn nếu có dịp:\n\\[\n  \\text{E}[f(x) g(y)] = \\text{E}[f(x)] \\text{E}[g(y)] ~~~ (28)\n\\]\n\n\n\n\nBernoulli distribution là một phân bố rời rạc mô tả biến ngẫu nhiên nhị phân: nó mô tả trường hợp khi đầu ra chỉ nhận một trong hai giá trị \\(x \\in \\{0, 1\\}\\). Hai giá trị này có thể là head và tail khi tung đồng xu; có thể là fraud transaction và normal transaction trong bài toán xác định giao dịch lừa đảo trong tín dụng; có thể là người và không phải người trong bài toán tìm xem trong một bức ảnh có người hay không.\nBernoulli distribution được mô tả bằng một tham số \\(\\lambda \\in [0, 1]\\) và là xác suất để \\(x = 1\\). Phân bố của mỗi đầu ra sẽ là:\n\\[\n  p(x = 1) = \\lambda, ~~~~ p(x = 0) = 1 - p(x = 1) = 1 - \\lambda ~~~ (29)\n\\]\nHai đẳng thức này thường được viết gọn lại:\n\\[\n  p(x) = \\lambda^x (1 - \\lambda)^{1 - x} ~~~~ (29)\n\\]\nvới giả định rằng \\(0 ^0 = 1\\).\nCó thể bạn chưa quen với cách viết này, hồi đầu tôi cũng hơi ngạc nhiên. Nhưng bạn cứ thử thay \\(x\\) bằng 0 và 1 vào là sẽ hiểu.\nBernoulli distribution được ký hiệu ngắn gọn dưới dạng:\n\\[\n  p(x) = \\text{Bern}_x [\\lambda] ~~~~~ (30)\n\\]\n\n\nCũng là biến ngẫu nhiên rời rạc, nhưng trong hầu hết các trường hợp, đầu ra có thể là một trong nhiều hơn hai giá trị khác nhau. Ví dụ, một bức ảnh có thể chứa một chiếc xe, một người, hoặc một con mèo. Khi đó, ta dùng phân bố tổng quát của Bernoulli distribution và được gọi là Categorical distribution. Các đầu ra được mô tả bởi 1 phần tử trong tập \\(\\{1, 2, \\dots, K\\}\\).\nNếu có \\(K\\) đầu ra có thể đạt được, Categorical distribution sẽ được mô tả bởi \\(K\\) tham số, viết dưới dạng vector: \\(\\lambda = [\\lambda_1, \\lambda_2, \\dots, \\lambda_K]\\) với các \\(\\lambda_k\\) không âm và có tổng bằng 1. Mỗi giá trị \\(\\lambda_k\\) thể hiện xác suất để đầu ra nhận giá trị \\(k\\):\n\\[\n  p(x = k) = \\lambda_k\n\\]\nViết gọn lại:\n\\[\n  p(x) = \\text{Cat}_x [\\lambda]\n\\]\nBiểu diễn theo cách khác, ta có thể coi như đầu ra là một vector ở dạng one-hot vector, tức \\(\\mathbf{x} \\in \\{\\mathbf{e}_1, \\mathbf{e}_2, \\dots, \\mathbf{e}_K\\}\\) với \\(\\mathbf{e}_k\\) là vector đơn vị thứ \\(k\\), tức tất cả các phần tử bằng 0, trừ phần tử thứ \\(k\\) bằng 1. Khi đó, ta sẽ có:\n\\[\np(\\mathbf{x} = \\mathbf{e}_k) = \\prod_{j=1}^K \\lambda_j^{x_j} = \\lambda_k ~~~~ (31)\n\\]\nCách viết này được sử dụng rất nhiều trong Machine Learning.\n\n\nPhân phối chuẩn 1 biến (univariate normal hoặc Gaussian distribution) được định nghĩa trên các biến liên tục nhận giá trị \\(x \\in (-\\infty, \\infty)\\).\nPhân phối này được mô tả bởi hai tham số: mean \\(\\mu\\) và variance \\(\\sigma^2\\). Giá trị \\(\\mu\\) có thể là bất kỳ số thực nào, thể hiện vị trí của peak, tức tại đó mà hàm mật độ xác suất đạt giá trị cao nhất. Giá trị \\(\\sigma^2\\) là một giá trị dương, với \\(\\sigma\\) thể hiện độ rộng của phân bố này. \\(\\sigma\\) lớn chứng tỏ khoảng giá trị đầu ra biến đổi mạnh, và ngược lại.\nHàm mật độ xác suất của phân phối này được định nghĩa là:\n\\[\n  p(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}}\\exp \\left( -\\frac{(x - \\mu)^2}{2\\sigma^2}\\right)~~~~ (32)\n\\]\nDạng gọn hơn:\n\\[\n  p(x) = \\text{Norm}_x [\\mu, \\sigma^2]\n\\]\nVí dụ về đồ thị hàm mật độ xác suất của univariate normal distribution được cho trên Hình 2a).\n\n\nĐây là trường hợp tổng quát của normal distribution khi biến là nhiều chiều, giả sử là \\(D\\) chiều. Có hai tham số mô tả phân phối này: mean vector \\(\\mu \\in \\mathbb{R}^D\\) và covariance matrix \\(\\Sigma \\in \\mathbb{S}_{++}^D \\) là một ma trận đối xứng xác định dương.\nHàm mật độ xác suất có dạng:\n\\[\n  p(\\mathbf{x}) = \\frac{1}{(2\\pi)^{D/2} |\\Sigma|^{1/2}} \\exp \\left(\\frac{1}{2} (\\mathbf{x} - \\mu)^T \\Sigma^{-1} (\\mathbf{x} - \\mu)\\right) ~~~ (33)\n\\]\nvới \\(|\\Sigma|\\) là định thức của ma trận hiệp phương sai \\(\\Sigma\\).\nHoặc viết gọn:\n\\[\n  p(\\mathbf{x}) = \\text{Norm}_{\\mathbf{x}}[\\mu, \\Sigma]\n\\]\nVí dụ về hàm mật độ xác suất của một bivariate normal distribution (2 biến) được cho trên Hình 2b). Các level-sets của mặt này đều là các hình Ellipse đồng tâm. \n\n\nBeta distribution là một phân phối liên tục được định nghĩa trên một biến ngẫu nhiên \\(\\lambda \\in [0, 1]\\). Phân phối này phù hợp với miệc mô tả sự biến động (uncertainty) của tham số \\(\\lambda\\) trong Bernoulli distribution. Nhắc lại, Beta distribution được dùng để mô tả tham số cho một distribution khác. Các bạn sẽ thấy rõ hơn trong một ví dụ ở bài tiếp theo.\nBeta distribution được mô tả bởi hai tham số dương \\(\\alpha, \\beta \\in (0, \\infty)\\). Hàm mật độ xác suất của nó là:\n\\[\n  p(\\lambda) = \\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} \\lambda^{\\alpha - 1} ( 1 - \\lambda) ^{\\beta - 1} ~~~ (34)\n\\]\nvới \\(\\Gamma(.)\\) là gamma function:\n\\[\n  \\Gamma(z) = \\int_0^{\\infty} t^{z-1}\\exp(-t) dt\n\\]\nvà có liên quan tới giai thừa khi \\(z\\) là số tự nhiên:\n\\[\n  \\Gamma[z] = (z-1)!\n\\]\nTôi giới thiệu gamma function để bạn đọc tham khảo. Trên thực tế, việc tính giá trị của gamma function không thực sự quan trọng vì nó chỉ mang tính chuẩn hoá để tổng xác suất bằng 1.\nDạng gọn của Beta distribution:\n\\[\n  p(\\lambda) = \\text{Beta}_{\\lambda}[\\alpha, \\beta]\n\\]\nHình 3 minh hoạ các hàm mật độ xác suất của Beta distribution với các cặp giá trị \\((\\alpha, \\beta)\\) khác nhau.\n\nTrong Hình 3a), \\(\\alpha =\\beta\\). Đồ thị là đối xứng qua đường thẳng \\(\\lambda = 0.5\\). Khi \\(\\alpha = \\beta = 1\\), thay vào \\((34)\\) ta thấy \\(p(\\lambda) = 1\\) với mọi \\(\\lambda\\). Trong trường hợp này, Beta distribution trở thành uniform distribution (phân phối đều). Khi \\(\\alpha = \\beta > 1\\), các hàm số đạt giá trị cao tại gần trung tâm, tức là khả năng cao là \\(\\lambda\\) sẽ nhận giá trị xung quanh điểm 0.5. Khi \\(\\alpha = \\beta < 1\\), hàm số đạt giá trị cao tại các điểm gần 0 và 1. Điều này chứng tỏ Bernoulli distribution tương ứng với các \\(\\lambda\\) này bị thiên lệch nhiều.\nTrong hình 3b), khi \\(\\alpha < \\beta\\), ta thấy rằng đồ thị có xu hướng lệch trái. Các giá trị \\((\\alpha, \\beta)\\) này nên được sử dụng nếu ta dự đoán rằng \\(\\lambda\\) là một số nhỏ hơn \\(0.5\\).\nTrong Hình 3c), khi \\(\\alpha > \\beta\\), điều ngược lại xảy ra.\n\n\nDirichlet distribution chính là trưởng hợp tổng quát của Beta distribution khi được dùng để mô tả tham số của Categorical distribution (nhắc lại rằng Categorical distribution là trường hợp tổng quát của Bernoulli distribution).\nDirichlet distribution được định nghĩa trên \\(K\\) biến liên tục \\(\\lambda_1, \\dots, \\lambda_K\\) trong đó các \\(\\lambda_k\\) không âm và có tổng bằng 1. Bởi vậy, nó phù hợp để mô tả tham số của Categorical distribution.\nCó \\(K\\) tham số dương để mô tả một Dirichlet distribution: \\(\\alpha_1, \\dots, \\alpha_K\\).\n\nHàm mật độ xác suất:\n\\[\n  p(\\lambda_1, \\dots, \\lambda_K) = \\frac{\\Gamma(\\sum_{k=1}^K \\alpha_k)}{\\prod_{k=1}^K\\Gamma(\\alpha_k)} \\prod_{k=1}^K \\lambda_k^{\\alpha_k - 1}~~~ (35)\n\\]\nViết gọn:\n\\[\n  p(\\lambda_1, \\dots, \\lambda_K) = \\text{Dir}_{\\lambda_1, \\dots, \\lambda_K}[\\alpha_1, \\dots, \\alpha_K]\n\\]\n\n\nVề Xác suất thống kê, còn rất nhiều điều chúng ta cần lưu ý. Tạm thời, tôi ôn tập lại những kiến thức này để phục vụ cho một số bài viết tiếp theo. Khi nào có phần nào cần nhắc lại, tôi sẽ ôn tập thêm cho các bạn.\n\n\n[1] Chapter 2, 3 của Computer Vision:  Models, Learning, and Inference - Simon J.D. Prince"
    },
    {
        "ID": 18,
        "URL": "https://machinelearningcoban.com/2017/07/02/tl/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trước Deep Learning, bài toán phân loại ảnh (các loại dữ liệu khác cũng tương tự) thường được chia thành 2 bước: Feature Engineering và Train a Classifier. Hai bước này thường được tách rời nhau. Với Feature Engineering, các phương pháp thường được sử dụng cho ảnh là SIFT (Scale Invariant Feature Transform), SURF (Speeded-Up Robust Features), HOG (Histogram of Oriented Gradients), LBP (Local Binary Pattern), etc. Các Classifier thường được sử dụng là multi-class SVM, Softmax Regression, Discriminative Dictionary Learning, Random Forest, etc.\nCác phương pháp Feature Engineering nêu trên thường được gọi là các hand-crafted features (feature được tạo thủ công) vì nó chủ yếu dựa trên các quan sát về đặc tính riêng của ảnh. Các phương pháp này cho kết quả khá ấn tượng trong một số trường hợp. Tuy nhiên, chúng vẫn còn nhiều hạn chế vì quá trình tìm ra các features và các classifier phù hợp vẫn là riêng biệt.\n(Tôi đã từng đề cập tới vấn đề này trong các mô hình end-to-end)\nNhững năm gần đây, Deep Learning phát triển cực nhanh dựa trên lượng dữ liệu training khổng lồ và khả năng tính toán ngày càng được cải tiến của các máy tính. Các kết quả cho bài toán phân loại ảnh ngày càng được nâng cao. Bộ cơ sở dữ liệu thường được dùng nhất là ImageNet với 1.2M ảnh cho 1000 classes khác nhau. Rất nhiều các mô hình Deep Learning đã giành chiến thắng trong các cuộc thi ILSVRC (ImageNet Large Scale Visual Recognition Challenge). Có thể kể ra một vài: AlexNet, ZFNet, GoogLeNet, ResNet, VGG.\nNhìn chung, các mô hình này đều bao gồm rất nhiều layers. Các layers phía trước thường là các Convolutional layers kết hợp với các nonlinear activation functions và pooling layers (và được gọi chung là ConvNet). Layer cuối cùng là một Fully Connected Layer và thường là một Softmax Regression (Xem Hình 1). Số lượng units ở layer cuối cùng bằng với số lượng classes (với ImageNet là 1000). Vì vậy output ở layer gần cuối cùng (second to last layer) có thể được coi là feature vectors và Softmax Regression chính là Classifier được sử dụng.\nChính nhờ việc features và classifier được trained cùng nhau qua deep networks khiến cho các mô hình này đạt kết quả tốt. Tuy nhiên, những mô hình này đều là các Deep Networks với rất nhiều layers. Việc training dựa trên 1.2M bức ảnh của ImageNet cũng tốn rất nhiều thời gian (2-3 tuần).\nVới các bài toàn dựa trên tập dữ liệu khác, rất ít khi người ta xây dựng và train lại toàn bộ Network từ đầu, bởi vì có rất ít các cơ sở dữ liệu có kích thước lớn. Thay vào đó, phương pháp thường được dùng là sử dụng các mô hình (nêu phía trên) đã được trained từ trước, và sử dụng một vài kỹ thuật khác để giải quyết bài toán. Phương pháp sử dụng các mô hình có sẵn như thế này được gọi là Transfer Learning.\nNhư đã đề cập, toàn bộ các layer trừ output layer có thể được coi là một bộ Feature Extractor. Dựa trên nhận xét rằng các bức ảnh đều có những đặc tính giống nhau nào đó, với cơ sở dữ liệu khác, ta cũng có thể sử dụng phần Feature Extractor này để tạo ra các feature vectors. Sau đó, ta thay output layer cũng bằng một Softmax Regression (hoặc multi-class SVM) nhưng với số lượng units bằng với số lượng class ở bộ cơ sở dữ liệu mới. Ta chỉ cần train layer cuối cùng này. Kinh nghiệm thực tế của tôi cho thấy, việc làm này đã tăng kết quả phân lớp lên rất nhiều so với việc sử dụng các hand-crafted features.\nCách làm như trên được gọi là ConvNet as fixed feature extractor, tức ta sử dụng trực tiếp vector ở second to last layer làm feature vector. Nếu tiếp tục tinh chỉnh (Fine-tuning) một chút nữa, kết quả sẽ có thể tốt hơn.\nFine-tuning the ConvNet. Hướng tiếp cận thứ hai là sử dụng các weights đã được trained từ một trong các mô hình ConvNet như là khởi tạo cho mô hình mới với dữ liệu mới và sử dụng Back Propagation để train lại toàn bộ mô hình mới hoặc train lại một số layer cuối (cũng là để tránh overfitting khi mà mô hình quá phức tạp khi dữ liệu không đủ lớn). Việc này được dựa trên quan sát rằng những layers đầu trong ConvNet thường giúp extract những đặc tính chung của ảnh (các cạnh - edges, còn được gọi là low-level features), các layers cuối thường mang những đặc trưng riêng của cơ sở dữ liệu (CSDL) (và được gọi là high-level features). Vì vậy, việc train các layer cuối mang nhiều giá trị hơn.\nDựa trên kích thước và độ tương quan giữa CSDL mới và CSDL gốc (chủ yếu là ImageNet) để train các mô hình có sẵn, CS231n đưa ra một vài lời khuyên:\nCSDL mới là nhỏ và tương tự như CSDL gốc. Vì CSDL mới nhỏ, việc tiếp tục train model dễ dẫn đến hiện tượng overfitting. Cũng vì hai CSDL là tương tự nhau, ta dự đoán rằng các high-level features là tương tự nhau. Vậy nên ta không cần train lại model mà chỉ cần train một classifer dựa trên feature vectors ở đầu ra ở layer gần cuối.\nCSDL mới là lớn và tương tự như CSDL gốc. Vì CSDL này lớn, overfitting ít có khả năng xảy ra hơn, ta có thể train mô hình thêm một chút nữa (toàn bộ hoặc chỉ một vài layers cuối).\nCSDL mới là nhỏ và rất khác với CSDL gốc. Vì CSDL này nhỏ, tốt hơn hết là dùng các classifier đơn giản (các linear classifiers) để tránh overfitting). Nếu muốn train thêm, ta cũng chỉ nên train các layer cuối. Hoặc có một kỹ thuật khác là coi đầu ra của một layer xa layer cuối hơn làm các feature vectors.\nCSDL mới là lớn và rất khác CSDL gốc. Trong trường hợp này, ta vẫn có thể sử dụng mô hình đã train như là điểm khởi tạo cho mô hình mới, không nên train lại từ đầu.\nCó một điểm đáng chú ý nữa là khi tiếp tục train các mô hình này, ta chỉ nên chọn learning rate nhỏ để các weights mới không đi quá xa so với các weights đã được trained ở các mô hình trước.\n\n[1] Introduction to SIFT (Scale-Invariant Feature Transform) - OpenCV\n[2] Introduction to SURF (Speeded-Up Robust Features) - OpenCV\n[3] Histogram of Oriented Gradients - OpenCV\n[4] Transfer Learning\n[5] Transfer Learning - Machine Learning’s Next Frontier\n[6] Transfer learning & The art of using Pre-trained Models in Deep Learning"
    },
    {
        "ID": 19,
        "URL": "https://machinelearningcoban.com/2017/06/30/lda/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\nTrong hai bài viết trước, tôi đã giới thiệu về thuật toán giảm chiều dữ liệu được sử dụng rộng rãi nhất - Principle Component Analysis (PCA). Như đã đề cập, PCA là một phương pháp thuộc loại unsupervised learning, tức là nó chỉ sử dụng các vector mô tả dữ liệu mà không dùng tới labels, nếu có, của dữ liệu. Trong bài toán classification, dạng điển hình nhất của supervised learning, việc sử dụng labels sẽ mang lại kết quả phân loại tốt hơn.\nNhắc lại một lần nữa, PCA là phương pháp giảm chiều dữ liệu sao cho lượng thông tin về dữ liệu, thể hiện ở tổng phương sai, được giữ lại là nhiều nhất. Tuy nhiên, trong nhiều trường hợp, ta không cần giữ lại lượng thông tin lớn nhất mà chỉ cần giữ lại thông tin cần thiết cho riêng bài toán. Xét ví dụ về bài toán phân lớp với 2 classes được mô tả trong Hình 1.\nTrong Hình 1, ta giả sử rằng dữ liệu được chiếu lên 1 đường thẳng và mỗi điểm được đại diện bởi hình chiếu của nó lên đường thẳng kia. Như vậy, từ dữ liệu nhiều chiều, ta đã giảm nó về 1 chiều. Câu hỏi đặt ra là, đường thẳng cần có phương như thế nào để hình chiếu của dữ liệu trên đường thẳng này giúp ích cho việc classification nhất? Việc classification đơn giản nhất có thể được hiểu là việc tìm ra một ngưỡng giúp phân tách hai class một cách đơn giản và đạt kết quả tốt nhất.\nXét hai đường thằng \\(d_1\\) và \\(d_2\\). Trong đó phương của \\(d_1\\) gần với phương của thành phần chính nếu làm PCA, phương của \\(d_2\\) gần với phương của thành phần phụ tìm được bằng PCA. Nếu ra làm giảm chiều dữ liệu bằng PCA, ta sẽ thu được dữ liệu gần với các điểm được chiếu lên \\(d_1\\). Lúc này việc phân tách hai class trở nên phức tạp vì các điểm đại diện cho hai classes chồng lấn lên nhau. Ngược lại, nếu ta chiếu dữ liệu lên đường thẳng gần với thành phần phụ tìm được bởi PCA, tức \\(d_2\\), các điểm hình chiếu nằm hoàn toàn về hai phía khác nhau của điểm màu lục trên đường thẳng này. Với bài toán classification, việc chiếu dữ liệu lên \\(d_2\\) vì vậy sẽ mang lại hiệu quả hơn. Việc phân loại một điểm dữ liệu mới sẽ được xác định nhanh chóng bằng cách so sánh hình chiếu của nó lên \\(d_2\\) với điểm màu xanh lục này.\nQua ví dụ trên ta thấy, không phải việc giữ lại thông tin nhiều nhất sẽ luôn mang lại kết quả tốt nhất. Chú ý rằng kết quả của phân tích trên đây không có nghĩa là thành phần phụ mang lại hiệu quả tốt hơn thành phần chính, nó chỉ là một trường hợp đặc biệt. Việc chiếu dữ liệu lên đường thẳng nào cần nhiều phân tích cụ thể hơn nữa. Cũng xin nói thêm, hai đường thằng \\(d_1\\) và \\(d_2\\) trên đây không vuông góc với nhau, tôi chỉ chọn ra hai hướng gần với các thành phần chính và phụ của dữ liệu để minh hoạ. Nếu bạn cần đọc thêm về thành phần chính/phụ, bạn sẽ thấy Bài 27 và Bài 28 về Principal Component Analysis (Phân tích thành phần chính) có ích.\nLinear Discriminant Analysis (LDA) được ra đời nhằm giải quyết vấn đề này. LDA là một phương pháp giảm chiều dữ liệu cho bài toán classification. LDA có thể được coi là một phương pháp giảm chiều dữ liệu (dimensionality reduction), và cũng có thể được coi là một phương pháp phân lớp (classification), và cũng có thể được áp dụng đồng thời cho cả hai, tức giảm chiều dữ liệu sao cho việc phân lớp hiệu quả nhất. Số chiều của dữ liệu mới là nhỏ hơn hoặc bằng \\(C-1\\) trong đó \\(C\\) là số lượng classes. Từ ‘Discriminant’ được hiểu là những thông tin đặc trưng cho mỗi class, khiến nó không bị lẫn với các classes khác. Từ ‘Linear’ được dùng vì cách giảm chiều dữ liệu được thực hiện bởi một ma trận chiếu (projection matrix), là một phép biến đổi tuyến tính (linear transform).\nTrong Mục 2 dưới đây, tôi sẽ trình bày về trường hợp binary classification, tức có 2 classes. Mục 3 sẽ tổng quát lên cho trường hợp với nhiều classes hơn 2. Mục 4 sẽ có các ví dụ và code Python cho LDA.\n\n\nMọi phương pháp classification đều được bắt đầu với bài toán binary classification, và LDA cũng không phải ngoại lệ.\nQuay lại với Hinh 1, các đường hình chuông thể hiện đồ thị của các hàm mật độ xác suất (probability density function - pdf) của dữ liệu được chiếu xuống theo từng class. Phân phối chuẩn ở đây được sử dụng như là một đại diện, dữ liệu không nhất thiết luôn phải tuân theo phân phối chuẩn.\nĐộ rộng của mỗi đường hình chuông thể hiện độ lệch chuẩn của dữ liệu. Dữ liệu càng tập trung thì độ lệch chuẩn càng nhỏ, càng phân tán thì độ lệch chuẩn càng cao. Khi được chiếu lên \\(d_1\\), dữ liệu của hai classes bị phân tán quá nhiều, khiến cho chúng bị trộn lẫn vào nhau. Khi được chiếu lên \\(d_2\\), mỗi classes đều có độ lệch chuẩn nhỏ, khiến cho dữ liệu trong từng class tập trung hơn, dẫn đến kết quả tốt hơn.\nTuy nhiên, việc độ lệch chuẩn nhỏ trong mỗi class chưa đủ để đảm bảo độ Discriminant của dữ liệu. Xét các ví dụ trong Hình 2.\nHình 2a) giống với dữ liệu khi chiếu lên \\(d_1\\) ở Hình 1. Cả hai class đều quá phân tán khiến cho tỉ lệ chồng lấn (phần diện tích màu xám) là lớn, tức dữ liệu chưa thực sự discriminative.\nHình 2b) là trường hợp khi độ lệch chuẩn của hai class đều nhỏ, tức dữ liệu tập trung hơn. Tuy nhiên, vấn đề với trường hợp này là khoảng cách giữa hai class, được đo bằng khoảng cách giữa hai kỳ vọng \\(m_1\\) và \\(m_2\\), là quá nhỏ, khiến cho phần chồng lấn cũng chiếm môt tỉ lệ lớn, và tất nhiên, cũng không tốt cho classification.\nHình 2c) là trường hợp khi hai độ lệch chuẩn là nhỏ và khoảng cách giữa hai kỳ vọng là lớn, phần chống lấn nhỏ không đáng kể.\nCó thể bạn đang tự hỏi, độ lệch chuẩn và khoảng cách giữa hai kỳ vọng đại diện cho các tiêu chí gì:\nNhư đã nói, độ lệch chuẩn nhỏ thể hiện việc dữ liệu ít phân tán. Điều này có nghĩa là dữ liệu trong mỗi class có xu hướng giống nhau. Hai phương sai \\(s_1^2, s_2^2\\) còn được gọi là các within-class variances.\nKhoảng cách giữa các kỳ vọng là lớn chứng tỏ rằng hai classes nằm xa nhau, tức dữ liệu giữa các classes là khác nhau nhiều. Bình phương khoảng cách giữa hai kỳ vọng \\((m_1 - m_2)^2\\) còn được gọi là between-class variance.\nHai classes được gọi là discriminative nếu hai class đó cách xa nhau (between-class variance lớn) và dữ liệu trong mỗi class có xu hướng giống nhau (within-class variance nhỏ). Linear Discriminant Analysis là thuật toán đi tìm một phép chiếu sao cho tỉ lệ giữa between-class variance và within-class variance lớn nhất có thể.\n\nGiả sử rằng có \\(N\\) điểm dữ liệu \\(\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N\\) trong đó \\(N_1 < N\\) điểm đầu tiên thuộc class thứ nhất, \\(N_2 = N - N_1\\) điểm cuối cùng thuộc class thứ hai. Ký hiệu \\(\\mathcal{C}_1 = \\{n | 1 \\leq n \\leq N_1\\}\\) là tập hợp các chỉ số của các điểm thuộc class 1 và \\(\\mathcal{C}_2 = \\{m| N_1 + 1 \\leq m \\leq N\\})\\) là tập hợp các chỉ số của các điểm thuộc class 2. Phép chiếu dữ liệu xuống 1 đường thẳng có thể được mô tả bằng một vector hệ số \\(\\mathbf{w}\\), giá trị tương ứng của mỗi điểm dữ liệu mới được cho bởi:\n\\[\ny_n = \\mathbf{w}^T\\mathbf{x}_n, 1 \\leq n \\leq N\n\\]\nVector kỳ vọng của mỗi class:\n\\[\n\\mathbf{m}_k = \\frac{1}{N_k}\\sum_{n \\in \\mathcal{C}_k}\\mathbf{x}_n,~~~ k = 1, 2 ~~~~ (1)\n\\]\nKhi đó:\n\\[\nm_1 - m_2 = \\frac{1}{N_1}\\sum_{i \\in \\mathcal{C}_1}y_i - \\frac{1}{N_2}\\sum_{j \\in \\mathcal{C}_2}y_j =  \\mathbf{w}^T(\\mathbf{m}_1 - \\mathbf{m}_2) ~~~~ (2)\n\\]\nCác within-class variances được định nghĩa là:\n\\[\ns_k^2 = \\sum_{n \\in \\mathcal{C}_k} (y_n - m_k)^2, ~~ k = 1, 2 ~~~~ (3)\n\\]\nChú ý rằng các within-class variances ở đây không được lấy trung bình như variance thông thường. Điều này được lý giải là tầm quan trọng của mỗi within-class variance nên tỉ lệ thuận với số lượng điểm dữ liệu trong class đó, tức within-class variance bằng variance nhân với số điểm trong class đó. Thế nên ta không chia trung bình nữa.\nLDA là thuật toán đi tìm giá trị lớn nhất của hàm mục tiêu:\n\\[\nJ(\\mathbf{w}) = \\frac{(m_1 - m_2)^2}{s_1^2 + s_2^2} ~~~~~~~~~ (4)\n\\]\nTiếp theo, chúng ta sẽ đi tìm biểu thức phụ thuộc giữa tử số và mẫu số trong vế phải của \\((4)\\) vào \\(\\mathbf{w}\\).\nVới tử số:\n\\[\n\\begin{eqnarray}\n(m_1 - m_2)^2 = \\mathbf{w}^T \\underbrace{(\\mathbf{m}_1 - \\mathbf{m}_2)(\\mathbf{m}_1 - \\mathbf{m}_2)^T}_{\\mathbf{S}_B} \\mathbf{w} = \\mathbf{w}^T\\mathbf{S}_B \\mathbf{w} ~~~~ (5)\n\\end{eqnarray}\n\\]\n\\(\\mathbf{S}_B\\) còn được gọi là between-class covariance matrix. Đây là một ma trận đối xứng nửa xác định dương.\nVới mẫu số:\n\\[\n\\begin{eqnarray}\ns_1^2 + s_2^2 &=& \\sum_{k=1}^2 \\sum_{n \\in \\mathcal{C}_k} \\left(\\mathbf{w}^T(\\mathbf{x}_n - \\mathbf{m}_k)\\right)^2 \\newline\n&=&\\mathbf{w}^T \\underbrace{\\sum_{k=1}^2 \\sum_{n \\in \\mathcal{C}_k} (\\mathbf{x}_n - \\mathbf{m}_k)(\\mathbf{x}_n - \\mathbf{m}_k)^T}_{\\mathbf{S}_W} \\mathbf{w} = \\mathbf{w}^T\\mathbf{S}_W \\mathbf{w}~~~~~(6)\n\\end{eqnarray}\n\\]\n\\(\\mathbf{S}_W\\) còn được gọi là within-class covariance matrix. Đây cũng là một ma trận đối xứng nửa xác định dương vì nó là tổng của hai ma trận đối xứng nửa xác định dương.\nTrong \\((5)\\) và \\((6)\\), ta đã sử dụng đẳng thức:\n\\[\n(\\mathbf{a}^T\\mathbf{b})^2 = (\\mathbf{a}^T\\mathbf{b})(\\mathbf{a}^T\\mathbf{b}) = \\mathbf{a}^T\\mathbf{b}\\mathbf{b}^T\\mathbf{a}\n\\]\nvới \\(\\mathbf{a}, \\mathbf{b}\\) là hai vectors cùng chiều bất kỳ.\nNhư vậy, bài toán tối ưu cho LDA trở thành:\n\\[\n\\mathbf{w}  = \\arg\\max_{\\mathbf{w}}\\frac{\\mathbf{w}^T\\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T\\mathbf{S}_W\\mathbf{w}} ~~~~~~~~ (7)\n\\]\n\nNghiệm \\(\\mathbf{w}\\) của \\((7)\\) sẽ là nghiệm của phương trình đạo hàm hàm mục tiêu bằng 0. Sử dụng chain rule cho đạo hàm hàm nhiều biến và công thức \\(\\nabla_{\\mathbf{w}}\\mathbf{w} \\mathbf{A}\\mathbf{w} = 2\\mathbf{Aw}\\) nếu \\(\\mathbf{A}\\) là một ma trận đối xứng, ta có:\n\\[\n\\begin{eqnarray}\n\\nabla_{\\mathbf{w}} J(\\mathbf{w}) &=& \\frac{1}{(\\mathbf{w}^T\\mathbf{S}_{W}\\mathbf{w})^2} \\left(\n2\\mathbf{S}_B \\mathbf{w} (\\mathbf{w}^T\\mathbf{S}_{W}\\mathbf{w}) - 2\\mathbf{w}^T\\mathbf{S}_{B}\\mathbf{w}^T\\mathbf{S}_W \\mathbf{w}\n\\right) = \\mathbf{0}& (8)\\newline\n\\Leftrightarrow \\mathbf{S}_B\\mathbf{w} &=& \\frac{\\mathbf{w}^T\\mathbf{S}_B \\mathbf{w}}{\\mathbf{w}^T\\mathbf{S}_W\\mathbf{w}}\\mathbf{S}_W\\mathbf{w}& (9) \\newline\n\\mathbf{S}_W^{-1}\\mathbf{S}_B \\mathbf{w} &=& J(\\mathbf{w})\\mathbf{w} & (10)\n\\end{eqnarray}\n\\]\nLưu ý: Trong \\((10)\\), ta đã giả sử rằng ma trận \\(\\mathbf{S}_W\\) là khả nghịch. Điều này không luôn luôn đúng, nhưng có một trick nhỏ là ta có thể xấp xỉ \\(\\mathbf{S}_W\\) bởi \\( \\bar{\\mathbf{S}}_W \\approx \\mathbf{S}_W + \\lambda\\mathbf{I}\\) với \\(\\lambda\\) là một số thực dương nhỏ. Ma trận mới này là khả nghịch vì trị riêng nhỏ nhất của nó bằng với trị riêng nhỏ nhất của \\(\\mathbf{S}_W\\) cộng với \\(\\lambda\\) tức không nhỏ hơn \\(\\lambda > 0\\). Điều này được suy ra từ việc \\(\\mathbf{S}_W\\) là một ma trận nửa xác định dương. Từ đó suy ra \\(\\bar{\\mathbf{S}}_W\\) là một ma trận xác định dương vì mọi trị riêng của nó là thực dương, và vì thế, nó khả nghịch. Khi tính toán, ta có thể sử dụng nghịch đảo của \\(\\bar{\\mathbf{S}}_W\\).\nKỹ thuật này được sử dụng rất nhiều khi ta cần sử dụng nghịch đảo của một ma trận nửa xác định dương và chưa biết nó có thực sự là xác định dương hay không.\nQuay trở lại với \\((10)\\), vì \\(J(\\mathbf{w})\\) là một số vô hướng, ta suy ra \\(\\mathbf{w}\\) phải là một vector riêng của \\(\\mathbf{S}_W^{-1}\\mathbf{S}_B\\) ứng với một trị riêng nào đó. Hơn nữa, giá trị của trị riêng này bằng với \\(J(\\mathbf{w})\\). Vậy, để hàm mục tiêu là lớn nhất thì \\(J(\\mathbf{w})\\) chính là trị riêng lớn nhất của \\(\\mathbf{S}_W^{-1}\\mathbf{S}_B\\). Dấu bằng xảy ra khi \\(\\mathbf{w}\\) là vector riêng ứng với trị riêng lớn nhất đó. Bạn đọc có thể hiểu phần này hơn khi xem cách lập trình trên Python ở Mục 4.\nTừ có thể thấy ngay rằng nếu \\(\\mathbf{w}\\) là nghiệm của \\((7)\\) thì \\(k\\mathbf{w}\\) cũng là nghiệm với \\(k\\) là số thực khác không bất kỳ. Vậy ta có thể chọn \\(\\mathbf{w}\\) sao cho \\((\\mathbf{m}_1 - \\mathbf{m}_2)^T\\mathbf{w} = J(\\mathbf{w}) = L =\\) trị riêng lớn nhất của \\(\\mathbf{S}_W^{-1}\\mathbf{S}_B\\) . Khi đó, thay định nghĩa của \\(\\mathbf{S}_B\\) ở \\((5)\\) vào \\((10)\\) ta có:\n\\[\nL \\mathbf{w} = \\mathbf{S}_{W}^{-1}(\\mathbf{m}_1 - \\mathbf{m}_2)\\underbrace{(\\mathbf{m}_1 - \\mathbf{m}_2)^T\\mathbf{w}}_L =  L\\mathbf{S}_{W}^{-1}(\\mathbf{m}_1 - \\mathbf{m}_2)\n\\]\nĐiều này có nghĩa là ta có thể chọn:\n\\[\n\\mathbf{w} = \\alpha\\mathbf{S}_{W}^{-1}(\\mathbf{m}_1 - \\mathbf{m}_2) ~~~~ (11)\n\\]\nvới \\(\\alpha \\neq 0\\) bất kỳ.\nBiểu thức \\((11)\\) còn được biết như là Fisher’s linear discriminant, được đặt theo tên nhà khoa học Ronald  Fisher.\n\n\nTrong mục này, chúng ta sẽ xem xét trường hợp tổng quát khi có nhiều hơn 2 classes. Giả sử rằng chiều của dữ liệu \\(D\\) lớn hơn số lượng classes \\(C\\).\nGiả sử rằng chiều mà chúng ta muốn giảm về là \\(D’ < D\\) và dữ liệu mới ứng với mỗi điểm dữ liệu \\(\\mathbf{x}\\) là:\n\\[\n\\mathbf{y} = \\mathbf{W}^T\\mathbf{x}\n\\]\nvới \\(\\mathbf{W} \\in \\mathbb{R}^{D\\times D’}\\).\nChú ý rằng LDA ở đây không sử dụng bias.\nMột vài ký hiệu:\n\\(\\mathbf{X}_k, \\mathbf{Y}_k = \\mathbf{W}^T\\mathbf{X}_k\\) lần lượt là ma trận dữ liệu của class \\(k\\) trong không gian ban đầu và không gian mới với số chiều nhỏ hơn.\n\\(\\mathbf{m}_k = \\frac{1}{N_k}\\sum_{n \\in \\mathcal{C}_k}\\mathbf{x}_k \\in \\mathbb{R}^{D}\\) là vector kỳ vọng của class \\(k\\) trong không gian ban đầu.\n\\(\\mathbf{e}_k = \\frac{1}{N_k}\\sum_{n \\in \\mathcal{C}_k} \\mathbf{y}_n = \\mathbf{W}^T\\mathbf{m}_k \\in \\mathbb{R}^{D’}\\) là vector kỳ vọng của class \\(k\\) trong không gian mới.\n\\(\\mathbf{m}\\) là vector kỳ vọng của toàn bộ dữ liệu trong không gian ban đầu và \\(\\mathbf{e}\\) là vector kỳ vọng trong không gian mới.\nMột trong những cách xây dựng hàm mục tiêu cho multi-class LDA được minh họa trong Hình 3.\nĐộ phân tán của một tập hợp dữ liệu có thể được coi như tổng bình phương khoảng cách từ mỗi điểm tới vector kỳ vọng của chúng. Nếu tất cả các điểm đều gần vector kỳ vọng của chúng thì độ phân tán của tập dữ liệu đó được coi là nhỏ. Ngược lại, nếu tổng này là lớn, tức trung bình các điểm đều xa trung tâm, tập hợp này có thể được coi là có độ phân tán cao.\nDựa vào nhận xét này, ta có thể xây dựng các đại lượng:\n\nWithin-class variance của class \\(k\\) có thể được tính như sau:\n\\[\n\\begin{eqnarray}\n\\sigma_k^2 &=& \\sum_{n \\in \\mathcal{C}_k} ||\\mathbf{y}_n -\\mathbf{e}_k||_F^2 = ||\\mathbf{Y}_k - \\mathbf{E}_k||_2^2 & (15) \\newline\n&=& ||\\mathbf{W}^T (\\mathbf{X}_k - \\mathbf{M}_k) ||_F^2 & (16)\\newline\n&=& \\text{trace}\\left(\\mathbf{W}^T (\\mathbf{X}_k - \\mathbf{M}_k)(\\mathbf{X}_k - \\mathbf{M}_k)^T \\mathbf{W}\\right)\n\\end{eqnarray}\n\\]\nVới \\(\\mathbf{E}_k\\) một ma trận có các cột giống hệt nhau và bằng với vector kỳ vọng \\(\\mathbf{e}_k\\). Có thể nhận thấy \\( \\mathbf{E}_k = \\mathbf{W}^T\\mathbf{M}_k\\) với \\(\\mathbf{M}_k\\) là ma trận có các cột giống hệt nhau và bằng với vector kỳ vọng \\(\\mathbf{m}_k\\) trong không gian ban đầu.\nVậy đại lượng đo within-class trong multi-class LDA có thể được đo bằng:\n\\[\n\\begin{eqnarray}\ns_W = \\sum_{k = 1}^C \\sigma_k^2 &=& \\sum_{k=1}^C \\text{trace}\\left(\\mathbf{W}^T (\\mathbf{X}_k - \\mathbf{M}_k)(\\mathbf{X}_k - \\mathbf{M}_k)^T \\mathbf{W}\\right)& (17)\\newline\n&=& \\text{trace}\\left( \\mathbf{W}^T\\mathbf{S}_W \\mathbf{W}\\right) & (18)\n\\end{eqnarray}\n\\]\nvới:\n\\[\n\\mathbf{S}_W = \\sum_{k=1}^C ||\\mathbf{X}_k- \\mathbf{M}_k ||_F^2 = \\sum_{k=1}^C \\sum_{n \\in \\mathcal{C}_k} (\\mathbf{x}_n - \\mathbf{m}_k)(\\mathbf{x}_n - \\mathbf{m}_k)^T ~~~~~(19)\n\\]\nvà nó có thể được coi là within-class covariance matrix của multi-class LDA. Ma trận \\(\\mathbf{S}_B\\) này là một ma trận nửa xác định dương theo định nghĩa.\n\nViệc betwwen-class lớn, như đã đề cập, có thể đạt được nếu tất cả các điểm trong không gian mới đều xa vector kỳ vọng chung \\(\\mathbf{e}\\). Việc này cũng có thể đạt được nếu các vector kỳ vọng của mỗi class xa các vector kỳ vọng chung (trong không gian mới). Vậy ta có thể định nghĩa đại lượng between-class như sau:\n\\[\ns_B = \\sum_{k=1}^C N_k ||\\mathbf{e}_k - \\mathbf{e} ||_F^2 = \\sum_{k=1}^C ||\\mathbf{E}_k - \\mathbf{E} ||_F^2~~~~~ (20)\n\\]\nTa lấy \\(N_k\\) làm trọng số vì có thể có những class có nhiều phần tử so với các classes còn lại.\nChú ý rằng ma trận \\(\\mathbf{E}\\) có thể có số cột linh động, phụ thuộc vào số cột của ma trận \\(\\mathbf{E}_k\\) mà nó đi cùng (và bằng \\(N_k\\)).\nLập luận tương tự như \\((17), (18)\\), bạn đọc có thể chứng minh được:\n\\[\ns_B = \\text{trace} \\left(\\mathbf{W}^T \\mathbf{S}_B \\mathbf{W} \\right) ~~~ (21)\n\\]\nvới:\n\\[\n\\mathbf{S}_B = \\sum_{k = 1}^C (\\mathbf{M}_k - \\mathbf{M})(\\mathbf{M}_k - \\mathbf{M})^T = \\sum_{k=1}^C N_k (\\mathbf{m}_k - \\mathbf{m})(\\mathbf{m}_k - \\mathbf{m})^T ~~~~~ (22)\n\\]\nvà số cột của ma trận \\(\\mathbf{M}\\) cũng linh động theo số cột của \\(\\mathbf{M}_k\\). Ma trận này là tổng của các ma trận đối xứng nửa xác định dương, nên nó là một ma trận đối xứng nửa xác định dương.\n\nVới cách định nghĩa và ý tưởng về within-class nhỏ và between-class lớn như trên, ta có thể xây dựng bài toán tối ưu:\n\\[\n  \\mathbf{W} = \\arg\\max_{\\mathbf{W}}J(\\mathbf{W}) =  \\arg\\max_{\\mathbf{W}} \\frac{\\text{trace}(\\mathbf{W}^T\\mathbf{S}_B\\mathbf{W})}{\\text{trace}(\\mathbf{W}^T\\mathbf{S}_W\\mathbf{W})}\n\\]\nNghiệm cũng được tìm bằng cách giải phương trình đạo hàm hàm mục tiêu bằng 0. Nhắc lại về đạo hàm của hàm \\(\\text{trace}\\) theo ma trận:\n\\[\n  \\nabla_{\\mathbf{W}} \\text{trace}(\\mathbf{W}^T\\mathbf{A} \\mathbf{W}) = 2\\mathbf{A}\\mathbf{W}\n\\]\nvới \\(\\mathbf{A} \\in \\mathbb{R}^{D \\times D}\\) là một ma trận đối xứng. (Xem trang 597 của tài liệu này).\nVới cách tính tương tự như \\((8) - (10)\\), ta có:\n\\[\n\\begin{eqnarray}\n  \\nabla_{\\mathbf{W}} J(\\mathbf{W}) &=& \\frac{2 \\left( \\mathbf{S}_B\\mathbf{W} \\text{trace}(\\mathbf{W}^T\\mathbf{S}_W\\mathbf{W}) - \\text{trace}(\\mathbf{W}^T\\mathbf{S}_B\\mathbf{W})\\mathbf{S}_W \\mathbf{W} \\right)}{\\left(\\text{trace}(\\mathbf{W}^T\\mathbf{S}_W\\mathbf{W})\\right)^2}  = \\mathbf{0} & (23)\\newline\n  \\Leftrightarrow \\mathbf{S}_W^{-1}\\mathbf{S}_B\\mathbf{W}&=& J \\mathbf{W} & (24)\n\\end{eqnarray}\n\\]\nTừ đó suy ra mỗi cột của \\(\\mathbf{W}\\) là một vector riêng của \\(\\mathbf{S}_W^{-1} \\mathbf{S}_B\\) ứng với trị riêng lớn nhất của ma trận này.\nNhận thấy rằng các cột của \\(\\mathbf{W}\\) cần phải độc lập tuyến tính. Vì nếu không, dữ liệu trong không gian mới \\(\\mathbf{y} = \\mathbf{W}^T\\mathbf{x}\\) sẽ phụ thuộc tuyến tính và có thể tiếp tục được giảm số chiều mà không ảnh hưởng gì.\nVậy các cột của \\(\\mathbf{W}\\) là các vector độc lập tuyến tính ứng với trị riêng cao nhất của \\(\\mathbf{S}_W^{-1} \\mathbf{S}_B\\). Câu hỏi đặt ra là: Có nhiều nhất bao nhiêu vector riêng độc lập tuyến tính ứng với trị riêng lớn nhất của \\(\\mathbf{S}_W^{-1} \\mathbf{S}_B\\)?\nSố lượng lớn nhất các vector riêng độc lập tuyến tính ứng với 1 trị riêng chính là rank của không gian riêng ứng với trị riêng đó, và không thể lớn hơn rank của ma trận.\nTa có một bổ đề quan trọng:\nBổ đề:\n\\[\n\\text{rank}(\\mathbf{S}_B) \\leq C - 1 ~~~~~~ (23)\n\\]\nChứng minh: (Tuy nhiên, việc chứng minh này không thực sự quan trọng, chỉ phù hợp với những bạn muốn hiểu sâu)\nViết lại \\((22)\\) dưới dạng:\n\\[\n\\mathbf{S}_B = \\mathbf{P}\\mathbf{P}^T\n\\]\nvới \\(\\mathbf{P} \\in {R}^{D \\times C}\\) mà cột thứ \\(k\\) cuả nó là:\n\\[\n\\mathbf{p}_k = \\sqrt{N_k} (\\mathbf{m}_k - \\mathbf{m})\n\\]\nThêm nữa, cột cuối cùng là một tổ hợp tuyến tính của các cột còn lại. Lý do là:\n\\[\n\\mathbf{m}_C - \\mathbf{m} = \\mathbf{m}_C - \\frac{\\sum_{k=1}^C N_k \\mathbf{m}_k}{N} = \\sum_{k=1}^{C-1} \\frac{N_k}{N} (\\mathbf{m}_k - \\mathbf{m})\n\\]\nNhư vậy ma trận \\(\\mathbf{P}\\) có nhiều nhất \\(C-1\\) cột độc lập tuyến tính, vậy nên rank của nó không vượt quá \\(C -1\\).\nCuối cùng, \\(\\mathbf{S}_B\\) là tích của hai ma trận với rank không quá \\(C-1\\), nên \\(\\text{rank}(\\mathbf{S}_B)\\) không vượt quá \\(C-1\\). \\(~~~~~~\\square\\).\nNếu bạn cần ôn lại vài kiến thức về rank:\nHạng (rank) của một ma trận, không nhất thiết vuông, là số lượng lớn nhất các cột độc lập tuyến tính của ma trận đó. Vậy nên rank của một ma trận không thể lớn hơn số cột của ma trận đó.\n\\(\\text{rank}(\\mathbf{A}) = \\text{rank}(\\mathbf{A}^T)\\). Vậy nên số lượng lớn nhất các cột độc lập tuyến tính cũng chính bằng số lượng lớn nhất các hàng độc lập tuyến tính.\n\\(\\text{rank}(\\mathbf{AB}) \\leq \\min \\left\\{\\text{rank}(\\mathbf{A}), \\text{rank}(\\mathbf{B}) \\right\\}\\) với \\(\\mathbf{A}, \\mathbf{B}\\) là hai ma trận bất kỳ có thể nhân với nhau được.\n\\(\\text{rank}(\\mathbf{A} + \\mathbf{B}) \\leq \\text{rank}(\\mathbf{A}) + \\text{rank}(\\mathbf{B})\\) với \\(\\mathbf{A}, \\mathbf{B}\\) là hai ma trận cùng chiều bất kỳ.\nTừ đó ra có \\(\\text{rank}\\left(\\mathbf{S}_W^{-1} \\mathbf{S}_B\\right) \\leq \\text{rank}\\mathbf{S}_B \\leq C - 1\\).\nVậy số chiều của không gian mới là một số không lớn hơn \\(C-1\\). Xem ra số chiều theo multi-class LDA đã được giảm đi rất nhiều. Nhưng chất lượng của dữ liệu mới như thế nào, chúng ta cần làm một vài thí nghiệm.\nTóm lại, nghiệm của bài toán multi-class LDA là các vector riêng độc lập tuyến tính ứng với trị riêng cao nhất của \\(\\mathbf{S}_W^{-1} \\mathbf{S}_B\\).\nLưu ý: Có nhiều cách khác nhau để xây dựng hàm mục tiêu cho multi-class LDA dựa trên việc định nghĩa within-class variance nhỏ và between-class variance lớn. Chúng ta đang sử dụng hàm \\(\\text{trace}\\) để đong đếm hai đại lượng này. Có nhiều cách khác nữa, ví dụ như sử dụng định thức. Tuy nhiên, có một điểm chung giữa các cách tiếp cận này là chiều của không gian mới sẽ không vượt quá \\(C-1\\).\n\n\nTạo dữ liệu giả:\nCác điểm cho 2 classes này được minh hoạ bởi các điểm màu lam và đỏ trên Hình 4.\nTiếp theo, chúng ta đi tính các within-class và between-class covariance matrices:\nNghiệm của bài toán là vector riêng ứng với trị riêng lớn nhất của np.linalg.inv(S_W).dot(S_B)\nĐường thẳng có phương w được minh hoạ bởi đường màu lục trên Hình 4. Ta thấy rằng nghiệm này hợp lý với dữ liệu có được.\nĐể kiểm chứng độ chính xác của nghiệm tìm được, ta cùng so sánh nó với nghiệm tìm được bởi thư viện sklearn.\nTa thấy rằng nghiệm tìm theo công thức và nghiệm tìm theo thư viện là như nhau. Như vậy việc phân tích ở Mục 2 là hoàn toàn chính xác.\nMột ví dụ khác so sánh PCA và LDA có thể được tìm thấy tại đây: Comparison of LDA and PCA 2D projection of Iris dataset.\n\nLDA là một phương pháp giảm chiều dữ liệu có sử dụng thông tin về label của dữ liệu. LDA là một thuật toán supervised.\nÝ tưởng cơ bản của LDA là tìm một không gian mới với số chiều nhỏ hơn không gian ban đầu sao cho hình chiếu của các điểm trong cùng 1 class lên không gian mới này là gần nhau trong khi hình chiếu của các điểm của các classes khác nhau là khác nhau.\nTrong PCA, số chiều của không gian mới có thể là bất kỳ số nào không lớn hơn số chiều và số điểm của dữ liệu. Trong LDA, với bài toán có \\(C\\) classes, số chiều của không gian mới chỉ có thể không vượt quá \\(C-1\\).\nLDA có giả sử ngầm rằng dữ liệu của các classes đều tuân theo phân phối chuẩn và các ma trận hiệp phương sai của các classes là gần nhau.\nVới bài toán có 2 classes, từ Hình 1 ta có thể thấy rằng hai classes là linearly separable nếu và chỉ nếu tồn tại một đường thẳng và 1 điểm trên đường thẳng đó (điểm mùa lục) sao cho: dữ liệu hình chiếu trên đường thẳng của hai classes nằm về hai phía khác nhau của điểm đó.\nLDA hoạt động rất tốt nếu các classes là linearly separable, tuy nhiên, chất lượng mô hình giảm đi rõ rệt nếu các classes là không linearly separable. Điều này dễ hiểu vì khi đó, chiếu dữ liệu lên phương nào thì cũng bị chồng lần, và việc tách biệt không thể thực hiện được như ở không gian ban đầu.\nMặc dù có hạn chế, ý tưởng về small within-class và large between-class được sử dụng rất nhiều trong các mô hình classification khác. Ví dụ Fisher discrimination dictionary learning for sparse representation - ICCV 2011.\n\n[1] Linear discriminant analysis.\n[2] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer (2006). Chapter 4. (book)\n[3] Comparison of LDA and PCA 2D projection of Iris dataset"
    },
    {
        "ID": 20,
        "URL": "https://machinelearningcoban.com/2017/06/22/qns1/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\nPost ngắn tổng hợp các ‘ghi chú nhanh’ nhận được nhiều quan tâm trên Facebook page Machine Learning cơ bản.\nLưu ý: các phần ghi chú nhanh này không có toán và hình, chỉ gồm ngôn ngữ thông thường để các bạn có một cái nhìn nhanh về các vấn đề.\n\nLink gốc.\nTrong bài toán Classification, phải làm như thế nào khi dữ liệu giữa các class quá chênh lệch?\nĐường link dưới đây có thể mang lại nhiều thông tin có ích cho bạn:\nIn depth skewed data classification - Kaggle Kernel\nTôi xin được tóm tắt vài điểm như sau.\nTrong nhiều bài toán thực tế, việc dữ liệu chênh lệch (imbalanced data) xảy ra rất thường xuyên. Bài toán trong link phía trên là bài toán ‘Credit Card Fraud Detection’, tức xác định các giao dịch lừa đảo trong credit card. Dữ liệu training bao gồm rất nhiều các giao dịch trong lịch sử và nhãn của chúng: ‘Normal’ hoặc ‘Fraud’. Tỉ lệ ‘Fraud’ thường là rất nhỏ so với ‘Normal’, giả sử là 1%. Như vậy hai class này là cực kỳ chênh lệch.\nVậy có điểm gì đáng chú ý trong bài toán này:\nTrước tiên, chúng ta cần đi xác định một Phương pháp đánh giá hiệu quả cho mô hình. Khi đánh giá các thuật toán Classification thông thường, ta thường sử dụng ‘độ chính xác’ như là tỉ lệ giữa các dữ liệu được phân loại đúng trên toàn bộ dữ liệu. Cách làm này không phù hợp trong bài toán của chúng ta vì nếu mô hình dự đoán toàn bộ các giao dịch là ‘Normal’ thì độ chính xác cũng đã là 99%?? Như vậy ta cần phải tìm một phép đo khác. Các phép đo thường được sử dụng với dữ liệu chênh lệch là: Precision, Recall, F1 score, ROC curves, etc. Trong đó, theo kinh nghiệm của tôi, Precision và Recall được sử dụng nhiều, bạn đọc có thể theo link dưới đây để hiểu thế nào là Precision và Recall - Wiki.\nĐiều thứ hai cần lưu ý là các thuật toán Classification thông thường thường hoạt động tốt nếu các class có lượng dữ liệu training tương đối như nhau. Nếu không, hiện tượng overfitting rất dễ xảy ra vì mô hình cố gắng ‘fit’ dữ liệu ở class trội hơn. Về Overfitting, bạn có thể đọc Bài 15: Overfitting.\nCó một hướng tiếp cận được gọi là ‘Resampling’ để hai classes có lượng dữ liệu tương đối như nhau. Cách thứ nhất là UNDER-sampling, tức chỉ chọn ra vài phần tử của class trội hơn và kết hợp với class còn lại để làm dữ liệu training. Cách thứ hai là OVER-sampling, tức có thể lặp lại dữ liệu, hoặc tìm cách kết hợp để tạo ra dữ liệu mới, của class ít hơn, và kết hợp với class còn lại để làm dữ liệu training. Như trong bài viết, cách UNDER-sampling khá hiệu quả.\nĐây là một bài toán binary classification, hướng tiếp cận đầu tiên bạn có thể nghĩ đến là dùng Logistic Regression. Trong Logistic Regression, dữ liệu đầu ra sẽ là một số dương nằm trong khoảng (0, 1) thể hiện xác suất để đầu ra bằng 1. Khi đó, ta có thể coi ‘1’ là ‘Fraud’, ‘0’ là ‘Normal’. Việc xác định ‘Fraud’ hay ‘Normal’ được xác định dựa trên một ngưỡng nào đó, ví dụ 0.5; các giá trị lớn hơn 0.5 được coi là 1 và ngược lại. Tuy nhiên, ta có thể thay đổi ngưỡng này cho phù hợp với bài toán. Chẳng hạn, nếu việc ‘miss’ các giao dịch ‘Fraud’ là nghiêm trọng thì ta cần hạ thấp ngưỡng xuống mức thấp hơn, ví dụ 0.3 để tỉ lệ ‘miss’ thấp xuống. Tuy nhiên, lúc này ta cần lưu ý về việc rất nhiều giao dịch ‘Normal’ bị biến thành ‘Fraud’.\nVới bài toán này, tác giả đã chỉ ra rằng Logistic Regression hoạt động rất hiệu quả.\nBạn có thể muốn đọc lại Logistic Regression.\nVới bài toán có nhiều classes, bạn có thể đọc thuật toán mở rộng của Logistic Regression, có tên là Softmax Regression.\nCảm ơn và chúc các bạn buổi tối vui vẻ,\nTiệp Vũ\n\nLink gốc.\nSimilarity Search là một chủ đề đang được quan tâm nhiều gần đây. Chủ đề này khá gần với Information Retrieval. Tôi cũng đã có một bài viết ngắn nói về vấn đề Information Retrieval, đặc biệt là Image Retrieval trong link dưới đây:\nChia sẻ về bài toán Image Retrieval\nỞ link trên, tôi đã đề cập đến những khó khăn của việc tìm kiếm khi mà lượng ảnh trong cơ sở dữ liệu ngày một lớn trong khi việc tìm kiếm yêu cầu trả về kết quả gần như tức thì. Các phương pháp tôi đề cập trong đó dựa trên Binary Hashing, tức tìm một mô hình tạo ra một binary vector ngắn cho mỗi bức ảnh để thuận tiện lưu trữ và tính toán.\nTrong post này, tôi xin giới thiệu một kỹ thuật khác mà tôi tìm thấy trong bài viết thú vị về cách thức tìm kiếm các ảnh giống nhau của Flickr - Một trang chia sẻ ảnh và video:\nIntroducing Similarity Search at Flickr\nTrong Flickr, việc tìm kiếm các ảnh giống với một ảnh cho trước là một việc mấu chốt được thực hiện nhiều lần và kết quả tìm kiếm cho thấy thuật toán hoạt động rất hiệu quả.\nÝ tưởng rất cơ bản xuất phát từ k-means clustering. Việc tìm kiếm dựa trên rất nhiều, giả sử 1 tỉ, bức ảnh tốn khá nhiều thời gian. Thay vào đó, ta có thể cluster các bức ảnh thành khoảng 1 triệu clusters, mỗi clusters được biểu diễn bởi một centroid. Khi tìm kiếm các ảnh gần giống với một bức ảnh (gọi là query), ta thực hiện 2 bước. Ở bước thứ nhất, centroid gần nhất với query sẽ được chọn. Ở bước thứ hai, các bức ảnh trong cluster ứng với centroid đó sẽ được chọn để so sánh với ảnh query. Đây chính là kỹ thuật xấp xỉ mỗi vector bằng 1 vector khác, trong trường hợp này là centroid, tên tiếng Anh là Vector Quantization (VQ).\n(Tôi xin bỏ qua phần feature engineering cho mỗi bức ảnh mà coi như các feature vectors đã được cho trước.)\nTuy nhiên, việc clustering từ 1 tỉ bức ảnh ra 1 triệu clusters (training process) và so sánh 1 query với từng cluster (test process) vẫn tốn rất nhiều thời gian. Một kỹ thuật đơn giản nhưng hiệu quả giúp vẫn tạo ra 1 triệu clusters nhưng cả training và test được thực hiện rất nhanh được gọi là Product Quantization (PQ).\nTrong PQ, mỗi vector được chia đôi thành 2 vectors con. Như vậy ta sẽ có 2 nhóm, mỗi nhóm có 1 tỉ vectors con. Ta thực hiện k-means clustering trên mỗi nhóm này với k = 1000. Như vậy, với mỗi nhóm, ta có 1000 centroids, tổng cộng là 2000 centroids, tạm gọi là các sub-centroids. Với mỗi sub-centroid thuộc nhóm 1 và 1 sub-centroid thuộc nhóm 2, ta sẽ có 1 full-centroid. Vậy tổng cộng ta vẫn có 1000x1000 = 1 triệu cluster nhưng việc training đã giảm đi rất nhiều. Khi test, ta cũng chia query vector thành 2 phần và tìm centroid gần nhất ứng với mỗi phần. Vector ghép bởi 2 sub-centroids này chính là full-centroid gần nhất ứng với query đó. Vì có tổng cộng chỉ 2000 sub-centroids nên việc tính toán đã nhanh hơn rất nhiều.\nPQ chỉ là ý tưởng ban đầu, nó có nhiều hạn chế. Và Flickr dùng một kỹ thuật khác dựa trên PQ, được gọi là LOPQ, bạn đọc có thể đọc thêm trong bài.\nBạn đọc có thể thấy bài viết về K-means clustering có ích.\nChúc các bạn một buổi tối vui vẻ.\nTiệp Vũ\n\nLink gốc.\nChia sẻ về Information Retrieval.\nInformation Retrieval hiểu một cách cơ bản là tìm những items trong cơ sở dữ liệu có liên quan đến query, thường là chưa có trong cơ sở dữ liệu. Ví dụ như Google Search và Google Search Image.\nBài toán đặt ra là cho một query, bạn phải sắp xếp, hoặc ít nhất là tìm kiếm, những items có liên quan trong cơ sở dữ liệu. Khi cơ sở dữ liệu là các hình ảnh thì nhánh này được gọi là Image Retrieval. Phần sau của post này sẽ chủ yếu nói về Image Retrieval.\nCó hai hướng tiếp cận trong Image Retrieval : Concept-based và Content-based Image Retrieval.\nConcept-based IR là việc tìm kiếm dựa trên các thông tin liên quan đến một bức ảnh như caption, labels, tag và phần text xung quanh. Khi bạn search Google hình ảnh bằng 1 text query thì, theo tôi hiểu, chính là Concept-based IR. Cách này phụ thuộc nhiều vào phần thông tin text liên quan đến ảnh mà không phụ thuộc trực tiếp vào nội dung ảnh.\nContent-based IR là việc tìm kiếm dựa trên nội dung của ảnh (giá trị các pixel trong ảnh). Ví dụ của việc này chính là Google Hình ảnh nhưng query là 1 bức ảnh. Bạn có thể upload bức ảnh hoặc link tới 1 bức ảnh trên internet, Google sẽ trả về các bức ảnh có nội dung tương tự.\nImage Retrieval khác với Image Classification ở điểm nào? Trong các bài toán Image classification, mỗi bức ảnh sẽ được phân loại vào 1 hoặc một vài class. Ví dụ, bức ảnh có một chú chó thì có thể được phân loại vào ‘dog’, ‘pet’, hay ‘animal’. Việc xác định một bức ảnh thuộc nhóm nào thường trả về các class mà bức ảnh đó có thể thuộc về, tức kết quả là một vài words. Image Retrieval thì khác, kết quả trả về là các bức ảnh, và khi query là 1 bức ảnh thì kết quả trả về có thể là các bức ảnh thuộc class khác. Ví dụ, nếu bức ảnh là 1 con chó cưng thì các ảnh trả về sẽ là các con chó cưng hoặc thậm chí là mèo cưng. Nhưng nếu bức ảnh là 1 con chó chăn cừu thì kết quả trả về có thể là các bức ảnh có cừu và thảo nguyên. Đây là một thách thức (challenge) của Image Retrieval so với Image Classification.\nPhương pháp phổ biến nhất trong Image Retrieval là dùng Similarity Search. Tức là đi tìm độ giống nhau giữa bức ảnh query và các bức ảnh khác trong dataset, sau đó trả về kết quả dựa trên sự giống nhau từ cao đến thấp. Khó khăn thứ nhất là phải tìm được một cách ‘biểu diễn’ (representation) ảnh tốt dưới dạng các vector để có thể ‘đong đếm’ được sự giống nhau giữa các bức ảnh. Phần này được gọi là Feature Extraction. Nhưng khó khăn lớn hơn là với cả triệu bức ảnh trong dataset, việc tính toán độ giống nhau giữa bức ảnh query và toàn bộ các bức ảnh khác là rất mất thời gian.\nVề khó khắn thứ nhất, hướng tiếp cận phổ biến nhất hiện nay là dùng Deep Learning. Cụ thể là sử dụng các mô hình Convolutional Neural Networks cho Image Classification nổi tiếng, tức đã được trained với các cơ sở dữ liệu lớn và đạt kết quả cao, để tạo ra các feature vector có độ dài như nhau cho mỗi bức ảnh. Cụ thể hơn, đầu ra của layer gần cuối cùng (trước softmax hoặc svm layer) được dùng như là 1 feature tốt (bạn nào quan tâm có thể đọc thêm về Transfer Learning). Những feature này thường có độ dài khoảng vài nghìn, nếu lưu trữ và tính toán trực tiếp trên feature này thì có thể là bất khả thi, đây là khó khăn thứ hai tôi nêu ở trên.\nVề khó khăn thứ hai, hướng tiếp cận tôi thấy được sử dụng nhiều là Binary Hashing, tức tiếp tục ‘map’ các feature trên thành 1 vector nhị phân có độ dài nhỏ (32, 64, 128, …). Vector này được gọi là ‘hash code’. Chú ý rằng 2^64 đã là 1 số rất lớn, có thể nhiều hơn toàn bộ số bức ảnh mà con người đã tạo ra. Vì vậy, trong trường hợp lý tưởng, sẽ không có hai bức ảnh khác nhau nào có hash code là như nhau. Sau khi có một mô hình giúp tìm hash code cho từng bức ảnh, việc tính toán similarity trở nên đơn giản hơn vì số chiều thấp hơn và chỉ phải làm việc với các toán tử logic nhị phân đơn giản.\nĐể đọc tài liệu về những gì tôi đã đề cập, chúng ta có thể bắt đầu tìm kiếm “Deep Binary Hashing for Image Retrieval”.\n\nLink gốc\nVề việc có cần học cơ bản Machine Learning (hay bất cứ lĩnh vực nào khác) hay không, nếu có thì sâu đến mức nào, có cần bằng cấp để học Machine Learning hay không, tôi xin đưa ra quan điểm cá nhân như sau:\nThật khó để biết mức độ hiểu sâu về một vấn đề nào đó. Cũng không có công thức cụ thể là với background như thế này, mục đích như thế này thì cần hiểu sâu đến đâu. (Trừ khi bạn tìm ra được một mô hình regression cho bạn tính toán được việc này :D).\nVới tôi thì làm gì cũng vậy, bắt đầu từ việc hiểu bài toán, tìm một mô hình đơn giản nhất giúp giải quyết bài toán, mô hình đó không nhất thiệt phải hiệu quả, cứ chạy là được. Sau đó sẽ hiểu dần dần rồi đào sâu vào các hướng cái thiện. Khi làm càng sâu thì sẽ càng cần đọc lại kiến thức cơ bản.\nKiến thức cơ bản không phải chỉ để đọc 1 lần rồi hiểu luôn. Bạn chỉ cần đọc và biết rằng nó ở đó, khi nào gặp khúc mắc thì sẽ biết tìm lại nó ở đâu. Có khi phải đọc lại vài lần rồi mới hiểu, hoặc làm vài project rồi mới hiểu.\nNghiên cứu của tôi ở một nhánh khác, không phải Neural Networks, cũng không phải SVMs. Nhưng đây vẫn là những thứ đầu tiên tôi học khi bắt đầu làm Machine Learning. Đến một mức độ nào đó chúng ta sẽ thấy các mô hình Machine Learning đều có những điểm cốt lõi chung, cần phải nắm rõ cái cốt lõi đó. Đây cũng là mục đích chính của tôi trước khi tạo dựng blog này - hệ thống lại kiến thức. Sự thật là khi viết lại những thứ cơ bản này tôi mới thực sự hiểu hơn về Machine Learning và học thêm được nhiều thứ.\nCũng chính vì xác định rằng đây sẽ là một nguồn tham khảo quan trọng và lâu dài cho chính bản thân mình nếu muốn gắn bó với Machine Learning, tôi quyết định viết càng cơ bản càng tốt, các hình vẽ càng chi tiết càng tốt, các công thức càng thống nhất (consistent) càng tốt. Tốt cho tôi và tốt cho cả bạn đọc của tôi. Nếu bạn đọc của tôi thấy hứng thú, tôi cũng có hứng thú để duy trì việc viết. Win-win.\nMột lần nữa, với các bạn muốn làm Machine Learning, việc đầu tiên là chọn cho mình một bài toán mà mình thấy hứng thú (cái này thì chính các bạn phải trả lời được). Rồi học dần dần để hiểu thêm. Qua thời gian nó sẽ ngấm dần. Cũng đừng quan tâm đến việc mình phải hiểu đến đâu trước khi bắt đầu làm. Không bắt tay vào làm thì bạn không hiểu được đâu. Mỗi người có một background khác nhau, có mục tiêu khác nhau, phải bắt tay vào làm thì mới biết mình hiểu gì và mình cần làm gì, và cũng để hiểu mình đam mê gì.\nVới những bạn không muốn đi sâu vào cơ bản mà muốn bắt đầu từ các mô hình hiệu quả có sẵn. Hãy cứ làm thế, không có gì sai cả. Quan trọng là sau khi sử dụng các mô hình có sẵn đó, bạn muốn làm gì tiếp. Lúc đó bạn tự đặt ra câu hỏi cho mình rồi google dần dần. Rồi cũng sẽ đến lúc bạn nhận ra là mình cần đọc lại kiến thức cơ bản về phần đó. Chỉ là thứ tự học của mỗi người là khác nhau thôi.\nCó cần có Master degree hay PhD degree để làm Machine Learning không? Tôi xin trả lời là không. Bằng cấp chỉ là một tờ giấy. Học cao học không phải là một điều đảm bảo cho việc bạn có hợp với Machine Learning hay không. Sự khác nhau chính có lẽ nằm ở việc bạn có bị ngừời khác thúc ép bạn làm hay không mà thôi. Ngoài ra, những kiến thức quan trọng cho Machine Learning đều có sẵn online với lượng tutorial vô cùng dồi dào - và tốt hơn những gì tôi được dạy ở chương trình cao học. Điều quan trọng là bạn có đủ đam mê để duy trì việc tự học tập (có thể là suốt đời) hay không. Ngày càng nhiều người làm Machine Learning, nhưng điều đó không có nghĩa là ai cũng có thể học và làm Machine Learning. Niềm đam mê, sự kiên trì, không phải bằng cấp, là những nhân tố quan trọng khi bạn muốn theo đuổi một mục tiêu. Ở bất cứ lĩnh vực nào cũng thế thôi.\nLời kết:\nMỗi ngừời có một background khác nhau và có một mục tiêu khác nhau. Cách tốt nhất là đặt ra mục tiêu, bắt tay vào làm rồi bạn sẽ biết cần phải học thêm những gì. Khi đã bắt tay vào làm rồi, bạn sẽ hiểu thêm và có thể điều chỉnh lại mục tiêu ban đầu của mình cho phù hợp. Một khi làm đã đủ nhiều, bạn sẽ nhận ra là những kiến thức cơ bản là quan trọng, dù mức độ quan trọng với từng ngừời là khác nhau. Bản thân từ ‘cơ bản’ cũng tự nó mang thông tin là ‘cần thiết’ rồi.\nThế giới thay đổi rất nhanh, chỉ có liên tục học tập và làm việc mới giúp mình không bị bỏ lại phía sau.\nVà đừng bao giờ nói rằng toán là không quan trọng khi làm Machine Learning.\n\nLink gốc.\nCAPTCHA - công cụ tránh spam và cũng là công cụ thu thập nhãn cho dữ liệu.\nHẳn các bạn đều đã trải qua những bài test nhỏ tương tự như các hình dưới đây. Mục đích chính của nó là để phân biệt ‘human’ và ‘bot’ (tức người và máy), để tránh hiện tượng spam trong các website. Lý dó đơn giản là có những việc con người làm được nhưng ‘bot’ vẫn chưa thể làm được. Ví dụ: Gõ lại các từ trong một bức ảnh mà chữ đã bị làm méo mó; đọc số nhà trong một bức ảnh thật; tìm các ảnh tương ứng trong rất nhiều ảnh; hoặc xác định những ô vuông nhỏ trong một ảnh lớn có chứa một vật thể nào đó.\nNhững bức ảnh này sẽ ngày một khó hơn, tương ứng với các bài toán thực tế khó hơn, vì các con ‘bot’ ngày một thông minh hơn nhờ vào Machine Learning.\nKhông chỉ giúp phân biệt người/máy, CAPTCHA còn được sử dụng với một mục đích rất thú vị khác: thu thập nhãn cho dữ liệu chưa có nhãn.\nChúng ta biết rằng có hàng tỉ bức ảnh trên internet nhưng phần lớn không có “nhãn”, tức chưa được máy tính nhận ra nội dung trong đó là gì. Các thuật toán nhận dạng, muốn đạt kết quả cao, cần rất nhiều dữ liệu cho tập huấn luyện (training). Và đây chính là một lợi ích khác của CAPTCHA. Chính người dùng đã giúp các công ty tương tự như CAPTCHA thu thập nhãn cho dữ liệu!\nCâu hỏi đặt ra là: Nếu chưa biết nhãn của dữ liệu, làm thế nào để biết một kết quả nhập vào là chính xác? Có một cách đơn giản là cho người dùng làm nhiều bài test khác nhau, trong đó có những bài đã có đáp án (nhãn). Sau đó, nếu những kết quả nhận được ở những bài đã có đáp án là chính xác thì khả năng cao đó chính là con người. Vậy thì các kết quả còn lại cũng có độ tin cậy cao. Và để cho độ chính xác cao hơn, một bức ảnh sẽ được dùng cho nhiều bài test. Nếu nó nhận được kết quả giống nhau ở những trường hợp có khả năng cao là con người thì kết quả đó được cho là nhãn của bức ảnh đó.\nQuick thought: sử dụng phương pháp tương tự cho việc thu thập nhãn cho các loại dữ liệu không-phải-là-ảnh, ví dụ như tiếng Việt.\nNhững trang web tiếng Việt, thay vì sử dụng CAPTCHA, có thể sử dụng một đoạn văn ngắn và trắc nghiệm ngừời dùng về sắc thái/nội dung của đoạn đó. Đoạn văn này có thể là các posts/comments trên mạng xã hội. Qua đó, các công ty có thể thu được một lượng dữ liệu lớn về hành vi người dùng với nhãn cụ thể. Hoặc là dùng chính người dùng làm “classifier” luôn. Khá là tin cậy.\nBài viết được soạn nhanh, chủ yếu dựa trên suy luận cá nhân. Mong bạn đọc cùng thảo luận.\n\n[Natural Language Processing - NLP]\nTrong Xử lý ngôn ngữ tự nhiên, việc biểu diễn một từ (word) dưới dạng 1 vector đóng vai trò cực kỳ quan trọng. Nó giúp ích rất nhiều trong việc tìm từ gần nghĩa, trái nghĩa, mô phỏng câu, thâm chí là tìm các câu có nghĩa tương đồng. Trong các thuật toán biến một từ thành một vector của các số thực, word2vec là một trong các phương pháp đơn giản và quan trọng để hiểu nhất. Đây cũng là nội dung chính trong bài thứ hai của loạt bài giảng về NLP của Stanford mà tôi chia sẻ ngày hôm qua.\nMột cách đơn giản nhất để biểu diễn 1 từ bằng 1 vector là dùng one-hot vector. Trong đó, mỗi vector sẽ có độ dài bằng với số từ trong từ điển, và mỗi vector chỉ có 1 phần tử khác không, và bằng 1, tại vị trí tương ứng với vị trí của từ đó trong từ điển. Mô hình này có rất nhiều nhược điểm: i) độ dài của một vector là quá lớn (bằng độ dài của từ điển, có thể lên đến cả triêu ), ii), không xác định được sự tương quan giữa các từ vì tích vô hướng của hai từ nào cũng bằng 0. word2vec giúp biến 1 từ ở dạng one-hot vector thành một vector có số chiều nhỏ hơn rất nhiều (300 đến 1000), và có thể tính được sự tương quan giữa hai từ dựa vào tích vô hướng giữa hai vector biểu diễn hai từ đó.\nTôi mới tìm được một post giải thích cực kỳ dễ hiểu về thuật toán này. Về cơ bản, đó là một mạng neural với 1 hidden layer, không có activation function, và layer cuối là một softmax regression.\nWord2Vec Tutorial - The Skip-Gram Model\nNếu bạn chưa rõ về softmax regression và mạng neural nhiều lớp, bạn có thể tìm được những điều lý thú trong hai bài viết này:\nBài 13: Softmax Regression\nBài 14: Multi-layer Perceptron và Backpropagation"
    },
    {
        "ID": 21,
        "URL": "https://machinelearningcoban.com/2017/06/21/pca2/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\nTrong phần 1 của Principal Component Analysis (PCA), một phương pháp giảm chiều dữ liệu rất quan trọng, chúng ta đã cùng ôn lại một vài kiến thức về Đại số tuyến tính và Thống kê, đồng thời, ý nghĩa toán học và các bước thực hiện PCA cũng đã được trình bày. Trong phần 2 này, chúng ta cùng tìm hiểu thêm một vài tính chất quan trọng của PCA cũng như các ứng dụng nổi bật của PCA trong các bài toán Machine Learning.\nCác bạn được khuyến khích đọc Bài 26 và Bài 27 trước khi đọc bài này.\n\nGiữa PCA và SVD có mỗi quan hệ đặc biệt với nhau. Để nhận ra điều này, tôi xin được nhắc lại hai điểm đã trình bày sau đây:\n\nNghiệm \\(\\mathbf{A}\\) của bài toán xấp xỉ một ma trận bởi một ma trận khác có rank không vượt quá \\(k\\):\n\\[\n\\begin{eqnarray}\n\\min_{\\mathbf{A}} &&||\\mathbf{X} - \\mathbf{A}||_F ~~~~~~~~~~~~~~ (1)\\newline\n\\text{s.t.} && \\text{rank}(\\mathbf{A}) = K\n\\end{eqnarray}\n\\]\nchính là Truncated SVD của \\(\\mathbf{A}\\). Cụ thể, nếu SVD của \\(\\mathbf{X} \\in\\mathbb{R}^{D\\times N}\\) là:\n\\[\n  \\mathbf{X} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^T\n\\]\nvới \\(\\mathbf{U} \\in \\mathbb{R}^{D \\times D}\\) và \\(\\mathbf{V}\\in \\mathbb{R}^{N\\times N}\\) là các ma trận trực giao, và \\(\\mathbf{\\Sigma} \\in \\mathbb{R}^{D \\times N}\\) là ma trận đường chéo (không nhất thiết vuông) với các phần tử trên đường chéo không âm giảm dần, thì nghiệm của bài toán \\((1)\\) chính là:\n\\[\n  \\mathbf{A} = \\mathbf{U}_K \\mathbf{\\Sigma}_K \\mathbf{V}_K^T ~~~ (2)\n\\]\nvới \\(\\mathbf{U} \\in \\mathbb{R}^{D \\times K}\\) và \\(\\mathbf{V}\\in \\mathbb{R}^{N\\times K}\\) là các ma trận tạo bởi \\(K\\) cột đầu tiên của \\(\\mathbf{U}\\) và \\(\\mathbf{V}\\), và \\(\\mathbf{\\Sigma}_K \\in \\mathbb{R}^{K \\times K}\\) là ma trận đường chéo con ứng với \\(K\\) hàng đầu tiên và \\(K\\) cột đầu tiên của \\(\\mathbf{\\Sigma}\\).\n\nTrong PCA, như đã chứng minh ở biểu thức \\((10)\\) trong Bài 27, PCA là bài toán đi tìm ma trận trực giao \\(\\mathbf{U}\\) và ma trận mô tả dữ liệu ở không gian thấp chiều \\(\\mathbf{Z}\\) sao cho việc xấp xỉ sau đây là tốt nhất:\n\\[\n\\mathbf{X} \\approx \\tilde{\\mathbf{X}} = \\mathbf{U}_K \\mathbf{Z} + \\bar{\\mathbf{U}}_K \\bar{\\mathbf{U}}_K^T\\bar{\\mathbf{x}}\\mathbf{1}^T ~~~ (3)\n\\]\nvới \\(\\mathbf{U}_K, \\bar{\\mathbf{U}}_K\\) lần lượt là các ma trận được tạo bởi \\(K\\) cột đầu tiên và \\(D-K\\) cột cuối cùng của ma trận trực giao \\(\\mathbf{U}\\), và \\(\\bar{\\mathbf{x}}\\) là vector kỳ vọng của dữ liệu.\nGiả sử rằng vector kỳ vọng \\(\\bar{\\mathbf{x}} = \\mathbf{0}\\). Khi đó, \\((3)\\) tương đương với:\n\\[\n\\mathbf{X} \\approx \\tilde{\\mathbf{X}} = \\mathbf{U}_K \\mathbf{Z}~~~ (4)\n\\]\nBài toán tối ưu của PCA sẽ trở thành:\n\\[\n\\begin{eqnarray}\n  \\mathbf{U}_K, \\mathbf{Z} &=& \\min_{\\mathbf{U}_K, \\mathbf{Z} } ||\\mathbf{X} - \\mathbf{U}_K \\mathbf{Z}||_F& (5)\\newline\n  \\text{s.t.:}&& \\mathbf{U}_K^T \\mathbf{U}_K = \\mathbf{I}_K &\n\\end{eqnarray}\n\\]\nvới \\(\\mathbf{I}_K \\in \\mathbb{R}^{K\\times K}\\) là ma trận đơn vị trong không gian \\(K\\) chiều, và điều kiện ràng buộc là để đảm bảo các cột của \\(\\mathbf{U}_K\\) tạo thành một hệ trực chuẩn.\n\nBạn có nhận ra điểm tương đồng giữa hai bài toán tối ưu \\((1)\\) và \\((5)\\) với nghiệm của bài toán đầu tiên được cho trong \\((2)\\)? Bạn có thể nhận ra ngay nghiệm của bài toán \\((5)\\) chính là:\n\\[\n\\begin{eqnarray}\n  \\mathbf{U}_K \\quad \\text{in}\\quad (5) &=& \\mathbf{U}_K\\quad \\text{in} \\quad(2) \\newline\n  \\mathbf{Z} \\quad\\text{in}\\quad (5) &=& \\mathbf{\\Sigma}_K \\mathbf{V}_K^T \\quad \\text{in} \\quad (2)\n\\end{eqnarray}\n\\]\nNhư vậy, nếu các điểm dữ liệu được biễu diễn bởi các cột của một ma trận, và trung bình cộng của mỗi hàng của ma trận đó bằng 0 (để cho vector kỳ vọng bằng 0), thì nghiệm của bài toán PCA được rút ra trực tiếp từ Truncated SVD của ma trận đó. Nói cách khác, nghiệm của PCA chính là một trường hợp đặc biệt của bài toán Matrix Factorization giải bằng SVD.\n\nMột câu hỏi được đặt ra là, làm thế nào để chọn ra giá trị \\(K\\) - chiều của dữ liệu mới - với từng loại dữ liệu khác nhau?\nCó một cách xác định \\(K\\) là dựa trên việc lượng thông tin muốn giữ lại. Như đã trình bày, PCA còn được gọi là phương pháp tối đa tổng phương sai được giữ lại. Vậy ta có thể coi tổng các phương sai được giữ lại là lượng thông tin được giữ lại. Với phương sai càng lớn, tức dữ liệu có độ phân tán cao, thể hiện lượng thông tin càng lớn.\nNhắc lại rằng trong mọi hệ trục toạ độ, tổng phương sai của dữ liệu là như nhau và bằng tổng các trị riêng của ma trận hiệp phương sai \\(\\sum_{i=1}^D \\lambda_i\\). Thêm nữa, PCA giúp giữ lại lượng thông tin (tổng các phương sai) là: \\(\\sum_{i=1}^K \\lambda_i\\). Vậy ta có thể coi biểu thức:\n \\[\n   r_K = \\frac{\\sum_{i=1}^K \\lambda_i}{\\sum_{j=1}^D \\lambda_j} \\quad \\quad (6)\n \\]\nlà lượng thông tin được giữ lại khi số chiều dữ liệu mới sau PCA là \\(K\\).\nNhư vậy, giả sử ta muốn giữ lại 99% dữ liệu, ta chỉ cần chọn \\(K\\) là số tự nhiên nhỏ nhất sao cho \\(r_K \\geq 0.99\\).\nKhi dữ liệu phân bố quanh một không gian con, các giá trị phương sai lớn nhất ứng với các \\(\\lambda_i\\) đầu tiên lớn hơn nhiều so với các phương sai còn lại. Khi đó, ta có thể chọn được \\(K\\) khá nhỏ để đạt được \\(r_K \\geq 0.99\\).\n\nCó hai trường hợp trong thực tế mà chúng ta cần lưu ý về PCA. Trường hợp thứ nhất là lượng dữ liệu có được nhỏ hơn rất nhiều so với số chiều dữ liệu. Trường hợp thứ hai là khi lượng dữ liệu trong tập training là rất lớn, có thể lên tới cả triệu. Việc tính toán ma trận hiệp phương sai và trị riêng đôi khi trở nên bất khả thi. Có những hướng giải quyết hiệu quả cho các trường hợp này.\nTrong mục này, ta sẽ coi như dữ liệu đã được chuẩn hoá, tức đã được trừ đi vector kỳ vọng. Khi đó, ma trận hiệp phương sai sẽ là \\(\\mathbf{S} = \\frac{1}{N}\\mathbf{X}\\mathbf{X}^T\\).\n\nĐó là trường hợp \\(D > N\\), tức ma trận dữ liệu \\(\\mathbf{X}\\) là một ‘ma trận cao’. Khi đó, số trị riêng khác không của ma trận hiệp phương sai \\(\\mathbf{S}\\) sẽ không vượt quá rank của nó, tức không vượt quá \\(N\\). Vậy ta cần chọn \\(K \\leq N\\) vì không thể chọn ra được \\(K > N\\) trị riêng khác 0 của một ma trận có rank bằng \\(N\\).\nViệc tính toán các trị riêng và vector riêng cũng có thể được thực hiện một cách hiệu quả dựa trên các tính chất sau đây:\nTính chất 1: Trị riêng của \\(\\mathbf{A}\\) cũng là trị riêng của \\(k\\mathbf{A}\\) với \\(k \\neq 0\\) bất kỳ. Điều này có thể được suy ra trực tiếp từ định nghĩa của trị riêng và vector riêng.\nTính chât 2: Trị riêng của \\(\\mathbf{AB}\\) cũng là trị riêng của \\(\\mathbf{BA}\\) với \\(\\mathbf{A} \\in \\mathbb{R}^{d_1 \\times d_2}, \\mathbf{B} \\in \\mathbb{R} ^{d_2 \\times d_1}\\) là các ma trận bất kỳ và \\(d_1, d_2\\) là các số tự nhiên khác không bất kỳ. Tôi xin không chứng minh quan sát này.\nNhư vậy, thay vì tìm trị riêng của ma trận hiệp phương sai \\(\\mathbf{S} \\in \\mathbb{R}^{D\\times D}\\), ta đi tìm trị riêng của ma trận \\(\\mathbf{T} = \\mathbf{X}^T \\mathbf{X} \\in \\mathbb{R}^{N \\times N}\\) có số chiều nhỏ hơn (vì \\(N < D\\)).\nTính chất 3: Giả sử \\((\\lambda, \\mathbf{u})\\) là một cặp trị riêng - vector riêng của \\(\\mathbf{T}\\), thế thì \\((\\lambda, \\mathbf{Xu})\\) là một cặp trị riêng - vector riêng của \\(\\mathbf{S}\\).\nThật vậy:\n\\[\n\\begin{eqnarray}\n  \\mathbf{X}^T \\mathbf{Xu} &=& \\lambda \\mathbf{u}& \\quad (7) \\newline\n  \\Rightarrow (\\mathbf{X}\\mathbf{X}^T)(\\mathbf{Xu}) &=& \\lambda \\mathbf{Xu} & \\quad (8)\n\\end{eqnarray}\n\\]\nBiểu thức \\((7)\\) là theo định nghĩa của trị riêng và vector riêng. Biểu thức \\((8)\\) thu được từ \\((7)\\) bằng cách nhân bên trái cả hai vế với ma trận \\(\\mathbf{X}\\). Từ \\((8)\\) ta suy ra Quan sát 3.\nNhư vậy, ta có thể hoàn toàn tính được trị riêng và vector riêng của ma trận hiệp phương sai dựa trên một ma trận nhỏ hơn.\n\nNhắc lại định nghĩa không gian riêng: Không gian riêng ứng với trị riêng của một ma trận là không gian sinh (span subspace) tạo bởi toàn bộ các vector riêng ứng với trị riêng đó.\nViệc cuối cùng phải làm là chuẩn hoá các vector riêng tìm được sao cho chúng tạo thành một hệ trực chuẩn. Việc này có thể dựa trên hai điểm sau đây:\nThứ nhất, nếu \\(\\mathbf{A}\\) là một ma trận đối xứng, \\((\\lambda_1, \\mathbf{x}_1), (\\lambda_2, \\mathbf{x}_2)\\) là các căp trị riêng - vector riêng của \\(\\mathbf{A}\\) với \\(\\lambda_1 \\neq \\lambda_2\\), thế thì \\(\\mathbf{x}_1^T\\mathbf{x}_2 = 0\\). Nói cách khác, hai vector bất kỳ trong hai không gian riêng khác nhau của một ma trận đối xứng thì trực giao với nhau. Chứng minh cho tính chất này có thể được thấy trong một dòng dưới đây:\n\\[\n\\begin{eqnarray}\n  \\mathbf{x}_2^T \\mathbf{Ax}_1 = \\mathbf{x}_1^T \\mathbf{Ax}_2 = \\lambda_1 \\mathbf{x}_2^T \\mathbf{x}_1 = \\lambda_2 \\mathbf{x}_1^T \\mathbf{x}_2 \\Rightarrow \\mathbf{x}_1^T \\mathbf{x}_2 = 0\n\\end{eqnarray}\n\\]\nDấu bằng cuối cùng xảy ra vì \\(\\lambda_1 \\neq \\lambda_2\\).\nThứ hai, với các trị riêng độc lập tìm được trong một không gian riêng, ta có thể dùng Gram-Schmit process để chuẩn hoá chúng về một hệ trực chuẩn.\nKết hợp hai điểm trên, ta có thể thu được các vector riêng tạo thành một hệ trực chuẩn, chính là ma trận \\(\\mathbf{U}_K\\) trong PCA.\n\nTrong rất nhiều bài toán, cả \\(D\\) và \\(N\\) đều là các số rất lớn, đồng nghĩa với việc ta phải tìm trị riêng cho một ma trận rất lớn. Ví dụ, có 1 triệu bức ảnh 1000 \\(\\times\\) 1000 pixel, như vậy \\(D = N = 10^6\\) là một số rất lớn, việc trực tiếp tính toán trị riêng và vector riêng cho ma trận hiệp phương sai là không khả thi. Tuy nhiên, có một phương pháp cho phép tính xấp xỉ các giá trị này một cách nhanh hơn. Phương pháp đó có tên là Power Method.\nPhương pháp này nói rằng, nếu thực hiện quy trình sau, ta sẽ tìm được cặp trị riêng và vector đầu tiên của một ma trận nửa xác định dương:\nPhương pháp Power tìm trị riêng và vector riêng của một ma trận nửa xác định dương \\(\\mathbf{A} \\in \\mathbb{R}^{n \\times n}\\):\nQuy trình này hội tụ khá nhanh và đã được chứng minh tại đây. Phần chứng minh tương đối đơn giản và không mang lại nhiều thông tin hữu ích, tôi xin được bỏ qua.\nĐể tìm vector riêng và trị riêng thứ hai của ma trận \\(\\mathbf{A}\\), chúng ta dựa trên định lý sau:\nĐịnh lý: Nếu ma trận nửa xác định dương \\(\\mathbf{A}\\) có các trị riêng \\(\\lambda_1 \\geq \\lambda_2 \\geq \\dots \\geq \\lambda_n ( \\geq 0)\\) và các vector riêng tương ứng \\(\\mathbf{v}_1, \\dots, \\mathbf{v}_n\\), hơn nữa các vector riêng này tạo thành 1 hệ trực chuẩn, thì ma trận:\n\\[\n  \\mathbf{B} = \\mathbf{A} - \\lambda_1 \\mathbf{v}_1 \\mathbf{v}_1^T\n\\]\ncó các trị riêng \\(\\lambda_2 \\geq \\lambda_3 \\geq \\dots \\geq \\lambda_n \\geq 0\\) và các vector riêng tương ứng là \\(\\mathbf{v}_2, \\mathbf{v}_3, \\dots, \\mathbf{v}_n, \\mathbf{v}_1\\).\nChứng minh:\nVới \\(i = 1\\):\n\\[\n\\begin{eqnarray}\n  \\mathbf{Bv}_1 &=& (\\mathbf{A} - \\lambda_1 \\mathbf{v}_1 \\mathbf{v}_1^T) \\mathbf{v}\n  &= & \\mathbf{Av}_1 - \\lambda_1 \\mathbf{v}_1 = \\mathbf{0} \\newline\n\\end{eqnarray}\n\\]\nVới \\(i > 1\\):\n\\[\n\\begin{eqnarray}\n  \\mathbf{Bv}_i &=& (\\mathbf{A} - \\lambda_1 \\mathbf{v}_1 \\mathbf{v}_1^T)\\mathbf{v}_i \\newline\n  &=& \\mathbf{Av}_i - \\lambda_1 \\mathbf{v}_1 (\\mathbf{v}_1^T \\mathbf{v}_i) \\newline\n  &=& \\mathbf{Av}_i = \\lambda_i \\mathbf{v}_i\n\\end{eqnarray}\n\\]\nNhư vậy định lý đã được chứng minh.\nLúc này, \\((\\lambda_2, \\mathbf{v}_2)\\) lại trở thành cặp trị riêng-vector riêng lớn nhất của \\(\\mathbf{B}\\). Cách tìm hai biến số này một lần nữa được thực hiện bằng Phương pháp Power.\nTiếp tục quy trình này, ta sẽ tìm được (xấp xỉ) tất cả các trị riêng và vector riêng tương ứng của ma trận hiệp phương sai. Cũng xin lưu ý rằng ta chỉ cần tìm tới trị riêng thứ \\(K\\) của ma trận hiệp phương sai. Cách làm này trên thực tế được sử dụng rất nhiều.\nPhương pháp Power còn là thuật toán cơ bản trong Google PageRank giúp sắp xếp các website theo mức độ phổ biến giảm dần. PageRank chính là nền móng của Google; ngày nay, việc tìm kiếm trong Google sử dụng nhiều thuật toán nâng cao hơn PageRank. Tôi sẽ có một bài riêng về Google PageRank sau khi nói về Chuỗi Markov và Mô hình Markov ẩn.\n\n\nEigenface là một trong các phương pháp phổ biến nhất trong bài toán nhận dạng khuôn mặt. Ý tưởng của Eigenface là đi tìm một không gian có số chiều nhỏ hơn để mô tả mỗi khuôn mặt, từ đó sử dụng vector trong không gian thấp này như là feature vector cho việc thực hiện classification. Điều đáng nói là một bức ảnh khuôn mặt có kích thước khoảng 200 \\(\\times\\) 200 sẽ có số chiều là 40k - là một số cực lớn, trong khi đó, feature vector thường chỉ có số chiều bằng vài trăm.\nEigenface thực ra chính là PCA. Các Eigenfaces chính là các eigenvectors ứng với các trị riêng lớn nhất của ma trận hiệp phương sai.\nTrong phần này, chúng ta cùng làm một thí nghiệm nhỏ trên cơ sở dữ liệu Yale face database. Các bức ảnh trong thí nghiệm này đã được căn chỉnh cho cùng với kích thước và khuôn mặt nằm trọn vẹn trong một hình chữ nhật có kích thước \\(116 \\times  98\\) pixel. Có tất cả 15 người khác nhau, mỗi người có 11 bức ảnh được chụp ở các điều kiện ánh sáng và cảm xúc khác nhau, bao gồm: ‘centerlight’, ‘glasses’, ‘happy’, ‘leftlight’, ‘noglasses’, ‘normal’, ‘rightlight’,’sad’, ‘sleepy’, ‘surprised’, và ‘wink’.\nHình 1 dưới đây là ví dụ về các bức ảnh của người có id là 10.\nTa có thể thấy rằng số chiều dữ liệu là \\(116 \\times 98 = 11368\\) là một số khá lớn. Tuy nhiên, vì chỉ có tổng cộng \\(15 \\times 11 = 165\\) bức ảnh nên ta có thể nén các bức ảnh này về dữ liệu mới có chiều nhỏ hơn 165. Trong ví dụ này, tôi chọn \\(K = 100\\).\nDưới đây là đoạn code thực hiện PCA cho toàn bộ dữ liệu. Chú ý rằng tôi sử dụng thư viện sklearn.\nChú ý rằng các hàm của sklearn đều chọn dữ liệu ở dạng hàng. Còn tôi thường chọn dữ liệu ở dạng cột cho thuận tiện trong biểu diễn toán học. Trước khi sử dụng sklearn, bạn đọc chú ý chuyển vị ma trận dữ liệu.\nTrong dòng pca = PCA(n_components=K), nếu n_components là một số thực trong khoảng \\((0, 1)\\), PCA sẽ thực hiện việc tìm \\(K\\) dựa trên biểu thức \\((6)\\).\nHình 2 dưới đây biểu diễn 18 vector riêng đầu tiên tìm được bằng PCA. Các vector tìm được ở dạng vector cột, ta cần phải reshape chúng để có thể minh hoạ như các bức ảnh.\nCó một điều dễ nhận ra là các ảnh minh hoạ các vector thu được ít nhiều mang thông tin của mặt người. Thực tế, một khuôn mặt gốc sẽ được xấp xỉ như tổng có trọng số của các khuôn mặt này. Vì các vector riêng này đóng vai trò như cơ sở của không gian mới với ít chiều hơn, chúng còn được gọi là khuôn mặt riêng, tức eigenfaces.\nĐể xem mức độ hiệu quả của Eigenfaces như thế nào, chúng ta thử minh hoạ các bức ảnh gốc và các bức ảnh được xấp xỉ bằng PCA, kết quả được cho như Hình 3 dưới đây:\n\nNhư vậy, vector với số chiều \\(K = 100\\) trong không gian mới mang khá đầy đủ thông tin của vector có số chiều \\(D = 11368\\) trong không gian ban đầu.\nPhần còn lại của source code có thể được tìm thấy tại đây.\n\nNgoài các ứng dụng về nén và classification, PCA còn được sử dụng trong nhiều lĩnh vực khác nhau. Abnormal Detection (dò tìm các hiện tượng không bình thường) là một trong số đó. Thêm nữa, giả sử chúng ta không biết nhãn của các sự kiện này, tức ta đang làm việc với một bài toán Unsupervised.\nÝ tưởng cơ bản là các sự kiện ‘normal’ thường nằm gần một không gian con nào đó, trong khi các sự kiện ‘abnormal’ thường khác biệt với các sự kiện ‘normal’, tức nằm xa không gian con đó. Hơn nữa, vì là ‘abnormal’ nên số lượng các sự kiện thuộc loại này là rất nhỏ so với ‘normal’.\nNhư vậy, chúng ta có thể làm PCA trên toàn bộ dữ liệu để tìm ra các thành phần chính của dữ liệu, từ đó suy ra không gian con mà các điểm ‘normal’ nằm gần. Việc xác định một điểm là ‘normal’ hay ‘abnoral’ được xác định bằng cách đo khoảng cách từ điểm đó tới không gian con tìm được.\nHình 4 dưới đây minh hoạ cho việc xác định các sự kiện không bình thường.\nMột ứng dụng của việc này có thể được tìm thấy trong bài báo: Diagnosing Network-Wide Traffic Anomalies.\n\nPCA là một phương pháp Unsupervised. Việc thực hiện PCA trên toàn bộ dữ liệu không phụ thuộc vào class(nếu có) của mỗi dữ liệu. Việc này đôi khi khiến cho PCA không mang lại hiệu quả cho các bài toán classification. Thật vậy, giả sử trong không gian hai chiều, 2 classes phân bố dọc hai bên của 1 đường thẳng. Như vậy, PCA nhiều khả năng sẽ cho chúng ta giữ lại thành phần chính chính là đường thẳng đó. Khi chiếu dữ liệu lên đường thẳng này, cả hai classes bị trộn lẫn vào nhau, khiến cho việc classification đạt kết quả thấp. Có một phương pháp tương tự như PCA giúp tận dụng thông tin về các class để xác định chiếu theo chiều nào, phương pháp đó có tên là Linear Discriminant Analysis, sẽ được thảo luận trong bài tiếp theo.\nVới các bài toán Large-scale, đôi khi việc tính toán trên toàn bộ dữ liệu là không khả thi vì còn có vấn đề về bộ nhớ. Giải pháp là thực hiện PCA lần đầu trên một tập con dữ liệu vừa với bộ nhớ, sau đó lấy một tập con khác để (incrementally) cập nhật nghiệm của PCA tới khi nào hội tụ. Ý tưởng này khá giống với Mini-batch Gradient Descent, và được gọi là Incremental PCA.\nNgoài ra, còn rất nhiều hướng mở rộng của PCA, bạn đọc có thể tìm kiếm theo từ khoá: Sparse PCA, Kernel PCA, Robust PCA. Tôi sẽ đề cập tới các phương pháp này khi có dịp.\n\n[1] PCA, SVD\n[2] Eigenface\n[3] The Fast Convergence of Incremental PCA\n[4] Diagnosing Network-Wide Traffic  Anomalies"
    },
    {
        "ID": 22,
        "URL": "https://machinelearningcoban.com/2017/06/15/pca/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\nDimensionality Reduction (giảm chiều dữ liệu), như đã được đề cập một vài lần trong blog, là một trong những kỹ thuật quan trọng trong Machine Learning. Các feature vectors trong các bài toán thực tế có thể có số chiều rất lớn, tới vài nghìn. Ngoài ra, số lượng các điểm dữ liệu cũng thường rất lớn. Nếu thực hiện lưu trữ và tính toán trực tiếp trên dữ liệu có số chiều cao này thì sẽ gặp khó khăn cả về việc lưu trữ và tốc độ tính toán. Vì vậy, giảm số chiều dữ liệu là một bước quan trọng trong nhiều bài toán. Đây cũng được coi là một phương pháp nén dữ liệu.\nDimensionality Reduction, nói một cách đơn giản, là việc đi tìm một hàm số, hàm số này lấy đầu vào là một điểm dữ liệu ban đầu \\(\\mathbf{x} \\in \\mathbb{R}^D\\) với \\(D\\) rất lớn, và tạo ra một điểm dữ liệu mới \\(\\mathbf{z} \\in \\mathbb{R}^K\\) có số chiều \\(K < D\\).\nVà như thường lệ, tôi sẽ trình bày một phương pháp đơn giản nhất trong các thuật toán Dimensionality Reduction dựa trên một mô hình tuyến tính. Phương pháp này có tên là Principal Component Analysis (PCA), tức Phân tích thành phần chính. Phương pháp này dựa trên quan sát rằng dữ liệu thường không phân bố ngẫu nhiên trong không gian mà thường phân bố gần các đường/mặt đặc biệt nào đó. PCA xem xét một trường hợp đặc biệt khi các mặt đặc biệt đó có dạng tuyến tính là các không gian con (subspace).\nBài viết này dành cho nhiều đối tượng độc giả khác nhau:\nNếu bạn cần ôn tập lại các kiến thức về hệ độc lập tuyến tính, kỳ vọng, phương sai, ma trận hiệp phương sai, bạn có thể đọc Mục 2.\nNếu bạn muốn hiểu nguồn gốc, ý tưởng đứng sau PCA, tại sao PCA lại được thực hiện như vậy, bạn có thể tìm được ở Mục 3.\nNếu bạn không muốn đi sâu vào toán mà chỉ cần hiểu các bước thực hiện PCA, bạn có thể tới ngay Mục 4.\nNếu bạn không muốn hiểu các bước thực hiện mà chỉ muốn biết hàm số thực hiện PCA, một vài ứng dụng của PCA, và có thể thêm các phần mở rộng của PCA, bạn có thể thấy PCA phần 2 có ích, dự tính được ra mắt sau đây một tuần.\nNếu tôi là các bạn, tôi sẽ đọc hết cả bài.\nTrước khi đi vào chi tiết của PCA, chúng ta cùng điểm lại một chút về Đại số tuyến tính và Thống kê.\n\n\nChúng ta vẫn thường nhắc nhiều đến norm cho vector nhưng chưa thực sự làm việc nhiều với norm của ma trận (ngoài Frobenius norm). Trong mục này, chúng ta sẽ làm quen với 1 lớp các norm cho ma trận được định nghĩa dựa trên norm của vector. Lớp các norms này còn được gọi là Induced Norms.\nGiả sử hàm số \\(||\\mathbf{x}||_{\\alpha}\\) là một norm bất kỳ của vector \\(\\mathbf{x}\\). Ứng với norm này, định nghĩa norm tương ứng cho ma trận \\(\\mathbf{A}\\):\n\\[\n||\\mathbf{A}||_{\\alpha} = \\max_{\\mathbf{x}} \\frac{||\\mathbf{Ax}||_{\\alpha}}{||\\mathbf{x}||_{\\alpha}}\n\\]\nchú ý rằng ma trận \\(\\mathbf{A}\\) có thể không vuông và số cột của nó bằng với số chiều của \\(\\mathbf{x}\\). Như vậy, bản thân việc tính toán norm của ma trận là việc giải một bài toán tối ưu. Chú ý rằng hàm tối ưu có cả tử số và mẫu số là các norm trên vectors.\nChúng ta sẽ quan tâm nhiều hơn tới norm 2. Norm 2 của ma trận được định nghĩa là:\n\\[\n||\\mathbf{A}||_2 = \\max_{\\mathbf{x}} \\frac{||\\mathbf{Ax}||_2}{||\\mathbf{x}||_2} ~~~ (1)\n\\]\nNhận thấy rằng nếu \\(\\mathbf{x}\\) là nghiệm của bài toán tối ưu \\((1)\\) thì \\(k\\mathbf{x}\\) cũng là nghiệm với \\(k\\) là một số thực khác không bất kỳ. Không mất tính tổng quát, ta có thể giả sử mẫu số bằng 1. Khi đó, bài toán tối ưu \\((1)\\) có thể được viết dưới dạng:\n\\[\n||\\mathbf{A}||_2 = \\max_{||\\mathbf{x}||_2 = 1} ||\\mathbf{Ax}||_2 ~~~ (2)\n\\]\nNói cách khác, ta cần đi tìm \\(\\mathbf{x}\\) sao cho:\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\text{argmax}_{\\mathbf{x}} ||\\mathbf{Ax}||_2^2 & \\newline\n\\text{s.t.: } && ||\\mathbf{x}||_2^2 = 1 & (3)\n\\end{eqnarray}\n\\]\nỞ đây, các norm 2 đã được bình phương lên để tránh dấu căn bậc hai. Bài toán \\((3)\\) có thể được giải bằng Phương pháp nhân tử Lagrange vì ràng buộc là một phương trình.\nLagrangian của Bài toán \\((3)\\) là:\n\\[\n\\mathcal{L}(\\mathbf{x}, \\lambda) = ||\\mathbf{Ax}||_2^2 + \\lambda (1 - ||\\mathbf{x}||_2^2)\n\\]\nNghiệm của bài toán \\((3)\\) sẽ thoả mãn hệ phương trình:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{x}} &=& 2\\mathbf{A}^T\\mathbf{Ax} - 2\\lambda \\mathbf{x} = \\mathbf{0} & (4)\\newline\n\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} &=& 1 - ||\\mathbf{x}||_2^2 = 0 & (5)\n\\end{eqnarray}\n\\]\nTừ \\((4)\\) ta có:\n\\[\n\\mathbf{A}^T\\mathbf{Ax} = \\lambda\\mathbf{x} ~~~~ (6)\n\\]\nĐiều này suy ra rằng \\(\\lambda\\) là một trị riêng của \\(\\mathbf{A}^T\\mathbf{A}\\) và \\(\\mathbf{x}\\) là 1 vector riêng ứng với trị riêng đó. Tiếp tục nhân hai vế của \\((6)\\) với \\(\\mathbf{x}^T\\) vào bên trái, ta có:\n\\[\n\\mathbf{x}^T\\mathbf{A}^T\\mathbf{Ax} = \\lambda \\mathbf{x}^T\\mathbf{x} = \\lambda\n\\]\nNhận thấy rằng vế trái chính là \\(||\\mathbf{Ax}||_2^2\\) chính là hàm mục tiêu trong \\((3)\\). Vậy hàm mục tiêu đạt giá trị lớn nhất khi \\(\\lambda\\) đạt giá trị lớn nhất. Nói cách khác, \\(\\lambda\\) chính là trị riêng lớn nhất của \\(\\mathbf{A}^T\\mathbf{A}\\) hay chính là singular value lớn nhất của ma trận \\(\\mathbf{A}\\).\nNhư vậy, norm 2 của một ma trận chính là singular value lớn nhất của ma trận đó. Và nghiệm của bài toán \\((3)\\) chính một là right-singular vector ứng với singular value đó.\nVới lý luận tương tự, chúng ta có thể suy ra rằng bài toán:\n\\[\n\\min_{||\\mathbf{x}||_2 =1} \\mathbf{x}^T\\mathbf{A}^T\\mathbf{A}\\mathbf{x}\n\\]\ncó nghiệm là vector riêng ứng với trị riêng nhỏ nhất của \\(\\mathbf{A}^T\\mathbf{A}\\). Khi đó, hàm số đạt giá trị nhỏ nhất bằng chính trị riêng nhỏ nhất này.\n\n\nTrong không gian \\(D\\) chiều , toạ độ của mỗi điểm được xác định dựa trên một hệ toạ độ nào đó. Ở các hệ toạ độ khác nhau, hiển nhiên là toạ độ của mỗi điểm cũng khác nhau.\nTập hợp các vector \\(\\mathbf{e}_1, \\dots, \\mathbf{e}_D\\) mà mỗi vector \\(\\mathbf{e}_d\\) có đúng 1 phần tử khác 0 ở thành phần thứ \\(d\\) và phần tử đó bằng 1, được gọi là hệ cơ sở đơn vị (hoặc hệ đơn vị) trong không gian \\(D\\) chiều. Nếu xếp các vector \\(\\mathbf{e}_d, d = 1, 2, \\dots, D\\) theo đúng thứ tự đó, ta sẽ được ma trận đơn vị \\(D\\) chiều.\nMỗi vector cột \\(\\mathbf{x} = [x_1, x_2, \\dots, x_D] \\in \\mathbb{R}^D\\), biểu diễn của nó trong hệ đơn vị là:\n\\[\n\\mathbf{x} = x_1 \\mathbf{e}_1 + x_2 \\mathbf{e}_2 + \\dots + x_D\\mathbf{e}_D\n\\]\nGiả sử có một hệ cơ sở khác \\(\\mathbf{u}_1, \\mathbf{u}_2, \\dots, \\mathbf{u}_D\\) (các vector này độc lập tuyến tính), vậy thì biểu diễn của vector \\(\\mathbf{x}\\) trong hệ cơ sở mới này có dạng:\n\\[\n\\mathbf{x} = y_1 \\mathbf{u}_1 + y_2 \\mathbf{u}_2 + \\dots + y_D\\mathbf{u}_D  = \\mathbf{U}\\mathbf{y}\n\\]\n\\(\\mathbf{U}\\) là ma trận mà cột thứ \\(d\\) của nó chính là vector \\(\\mathbf{u}_d\\). Lúc này, vector \\(\\mathbf{y}\\) chính là biểu diễn của \\(\\mathbf{x}\\) trong hệ cơ sở mới. Bộ các số \\(y_d, d = 1, 2, \\dots, D\\) là duy nhất vì \\(\\mathbf{y}\\) có thể tính được bằng:\n\\[\n\\mathbf{y} = \\mathbf{U}^{-1} \\mathbf{x} ~~~ (7)\n\\]\nvới chú ý rằng \\(\\mathbf{U}\\) là ma trận khả nghịch vì các cột của nó độc lập tuyến tính.\nTrong các ma trận đóng vai trò như hệ cơ sở \\(\\mathbf{U}\\), các ma trận trực giao, tức \\(\\mathbf{U}^T\\mathbf{U} = \\mathbf{I}\\), được quan tâm nhiều hơn vì nghịch đảo của chúng chính là chuyển vị của chúng:\n\\[\n\\mathbf{U}^{-1} = \\mathbf{U}^T\n\\]\nKhi đó, \\(\\mathbf{y}\\) trong \\((7)\\) có thể được tính một cách nhanh chóng:\n\\[\n\\mathbf{y} = \\mathbf{U}^{T} \\mathbf{x}\n\\]\ntừ đó suy ra: \\(y_i = \\mathbf{x}^T \\mathbf{u}_i = \\mathbf{u}_i^T\\mathbf{x}, i= 1, 2, \\dots, D\\).\nCó thể nhận thấy rằng vector \\(\\mathbf{0}\\) được biểu diễn như nhau trong mọi hệ cơ sở.\nHình 1 dưới đây là 1 ví dụ về việc chuyển hệ cơ sở:\nViệc chuyển đổi hệ cơ sở sử dụng ma trận trực giao có thể được coi như một phép xoay trục toạ độ. Nhìn theo một cách khác, đây cũng chính là một phép xoay vector dữ liệu theo chiều ngược lại.\n\nHàm số trace xác định trên tập các ma trận vuông được sử dụng rất nhiều trong tối ưu vì những tính chất đẹp của nó. Hàm trace trả về tổng các phần tử trên đường chéo của một ma trận vuông.\nCác tính chất quan trọng của hàm trace, với giả sử rằng các ma trận trong hàm trace là vuông và các phép nhân ma trận thực hiện được:\n\\(\\text{trace}(\\mathbf{A}) = \\text{trace}(\\mathbf{A}^T)\\)\n\\(\\text{trace}(k\\mathbf{A}) = k\\text{trace}(\\mathbf{A})\\) với \\(k\\) là một số bất kỳ.\n\\(\\text{trace}(\\mathbf{AB}) = \\text{trace}(\\mathbf{BA})\\)\n\\(||\\mathbf{A}||_F^2 = \\text{trace}(\\mathbf{A}^T\\mathbf{A}) = \\text{trace}(\\mathbf{A}\\mathbf{A}^T)\\) với \\(\\mathbf{A}\\) là ma trận bất kỳ, có thể không vuông.\n\\(\\text{trace}(\\mathbf{A}) = \\sum_{i = 1}^D \\lambda_i \\) với \\(\\mathbf{A}\\) là một ma trận vuông và \\(\\lambda_i, i = 1, 2, \\dots, N\\) là toàn bộ các trị riêng của nó, có thể phức hoặc lặp. Việc chứng minh tính chất này có thể được dựa trên ma trận đặc trưng của \\(\\mathbf{A}\\) và định lý Viète. Tôi xin được bỏ qua.\n\n\nCho \\(N\\) giá trị \\(x_1, x_2, \\dots, x_N\\). Kỳ vọng và phương sai của bộ dữ liệu này được định nghĩa là:\n\\[\n\\begin{eqnarray}\n\\bar{x} &=& \\frac{1}{N}\\sum_{n=1}^N x_n = \\frac{1}{N}\\mathbf{X1}\\newline\n\\sigma^2 &=& \\frac{1}{N} \\sum_{n=1}^N (x_n - \\bar{x})^2\n\\end{eqnarray}\n\\]\nvới \\(\\mathbf{1} \\in \\mathbb{R}^N\\) là vector cột chứa toàn phần tử 1.\nKỳ vọng đơn giản là trung bình cộng của toàn bộ các giá trị. Phương sai là trung bình cộng của bình phương khoảng cách từ mỗi điểm tới kỳ vọng. Phương sai càng nhỏ thì các điểm dữ liệu càng gần với kỳ vọng, tức các điểm dữ liệu càng giống nhau. Phương sai càng lớn thì ta nói dữ liệu càng có tính phân tán. Ví dụ về kỳ vọng và phương sai của dữ liệu một chiều có thể được thấy trong Hình 2a).\nCăn bậc hai của phương sai, \\(\\sigma\\) còn được gọi là độ lệch chuẩn (standard deviation) của dữ liệu.\n\nCho \\(N\\) điểm dữ liệu được biểu diễn bởi các vector cột \\(\\mathbf{x}_1, \\dots, \\mathbf{x}_N\\), khi đó, vector kỳ vọng và ma trận hiệp phương sai của toàn bộ dữ liệu được định nghĩa là:\n\\[\n\\begin{eqnarray}\n\\bar{\\mathbf{x}} &=& \\frac{1}{N} \\sum_{n=1}^N \\mathbf{x}_n \\newline\n\\mathbf{S} &=&  \\frac{1}{N}\\sum_{n=1}^N (\\mathbf{x}_n - \\bar{\\mathbf{x}})(\\mathbf{x}_n - \\bar{\\mathbf{x}})^T = \\frac{1}{N}\\hat{\\mathbf{X}}\\hat{\\mathbf{X}}^T\n\\end{eqnarray}\n\\]\nTrong đó \\(\\hat{\\mathbf{X}}\\) được tạo bằng cách trừ mỗi cột của \\(\\mathbf{X}\\) đi \\(\\bar{\\mathbf{x}}\\):\n\\[\n\\hat{\\mathbf{x}}_n = \\mathbf{x}_n - \\bar{\\mathbf{x}}\n\\]\nCác công thức này khá tương đồng với các công thức cho dữ liệu 1 chiều phía trên. Có một vài điểm lưu ý:\nMa trận hiệp phương sai là một ma trận đối xứng, hơn nữa, nó là một ma trận nửa xác định dương.\nMọi phần tử trên đường chéo của ma trận hiệp phương sai là các số không âm. Chúng cũng chính là phương sai của từng chiều của dữ liệu.\nCác phần tử ngoài đường chéo \\(s_{ij}, i \\neq j\\) thể hiện sự tương quan giữa thành phần thứ \\(i\\) và thứ \\(j\\) của dữ liệu, còn được gọi là hiệp phương sai. Giá trị này có thể dương, âm hoặc bằng 0. Khi nó bằng 0, ta nói rằng hai thành phần \\(i, j\\) trong dữ liệu là không tương quan (uncorrelated).\nNếu ma trận hiệp phương sai là ma trận đường chéo, ta có dữ liệu hoàn toàn không tương quan giữa các chiều.\nVí dụ về dữ liệu không tương quan và tương quan được cho trong Hình 2bc).\n\nCách đơn giản nhất để giảm chiều dữ liệu từ \\(D\\) về \\(K < D\\) là chỉ giữ lại \\(K\\) phần tử quan trọng nhất. Tuy nhiên, việc làm này chắc chắn chưa phải tốt nhất vì chúng ta chưa biết xác định thành phần nào là quan trọng hơn. Hoặc trong trường hợp xấu nhất, lượng thông tin mà mỗi thành phần mang là như nhau, bỏ đi thành phần nào cũng dẫn đến việc mất một lượng thông tin lớn.\nTuy nhiên, nếu chúng ta có thể biểu diễn các vector dữ liệu ban đầu trong một hệ cơ sở mới mà trong hệ cơ sở mới đó, tầm quan trọng giữa các thành phần là khác nhau rõ rệt, thì chúng ta có thể bỏ qua những thành phần ít quan trọng nhất.\nLấy một ví dụ về việc có hai camera đặt dùng để chụp một con người, một camera đặt phía trước người và một camera đặt trên đầu. Rõ ràng là hình ảnh thu được từ camera đặt phía trước người mang nhiều thông tin hơn so với hình ảnh nhìn từ phía trên đầu. Vì vậy, bức ảnh chụp từ phía trên đầu có thể được bỏ qua mà không có quá nhiều thông tin về hình dáng của người đó bị mất.\nPCA chính là phương pháp đi tìm một hệ cơ sở mới sao cho thông tin của dữ liệu chủ yếu tập trung ở một vài toạ độ, phần còn lại chỉ mang một lượng nhỏ thông tin. Và để cho đơn giản trong tính toán, PCA sẽ tìm một hệ trực chuẩn để làm cơ sở mới.\nGiả sử hệ cơ sở trực chuẩn mới là \\(\\mathbf{U}\\) và chúng ta muốn giữ lại \\(K\\) toạ độ trong hệ cơ sở mới này. Không mất tính tổng quát, giả sử đó là \\(K\\) thành phần đầu tiên. Quan sát Hình 3 dưới đây:\nQuan sát hình vẽ trên với cơ sở mới \\(\\mathbf{U} = [\\mathbf{U}_K, \\bar{\\mathbf{U}}_K]\\) là một hệ trực chuẩn với \\(\\mathbf{U}_K\\) là ma trận con tạo bởi \\(K\\) cột đầu tiên của \\(\\mathbf{U}\\). Với cơ sở mới này, ma trận dữ liệu có thể được viết thành:\n\\[\n\\mathbf{X} = \\mathbf{U}_K \\mathbf{Z} + \\bar{\\mathbf{U}}_K \\mathbf{Y} ~~~~ (8)\n\\]\nTừ đây ta cũng suy ra:\n\\[\n\\begin{eqnarray}\n\\left[\n\\begin{matrix}\n\\mathbf{Z} \\newline \\mathbf{Y}\n\\end{matrix}\n\\right] =\n\\left[\n\\begin{matrix}\n\\mathbf{U}_K^T \\newline \\bar{\\mathbf{U}}_K^T\n\\end{matrix}\n\\right]\\mathbf{X}\n\\Rightarrow\n\\begin{matrix}\n\\mathbf{Z} = \\mathbf{U}_K^T \\mathbf{X} \\newline\n\\mathbf{Y} = \\bar{\\mathbf{U}}_K^T\\mathbf{X}\n\\end{matrix}\n\\end{eqnarray} ~~~~ (9)\n\\]\nMục đích của PCA là đi tìm ma trận trực giao \\(\\mathbf{U}\\) sao cho phần lớn thông tin được giữ lại ở phần màu xanh \\(\\mathbf{U}_K \\mathbf{Z}\\) và phần màu đỏ \\(\\bar{\\mathbf{U}}_K\\mathbf{Y}\\) sẽ được lược bỏ và thay bằng một ma trận không phụ thuộc vào từng điểm dữ liệu. Nói cách khác, ta sẽ xấp xỉ \\(\\mathbf{Y}\\) bởi một ma trận có toàn bộ các cột là như nhau. Chú ý rằng các cột này có thể phụ thuộc vào dữ liệu training nhưng không phụ thuộc vào dữ liệu test, các bạn sẽ thấy rõ hơn khi lập trình mà tôi sẽ trình bày trong bài tiếp theo. Gọi mỗi cột đó là \\(\\mathbf{b}\\) và có thể coi nó là bias, khi đó, ta sẽ xấp xỉ:\n\\[\n\\mathbf{Y} \\approx \\mathbf{b1}^T\n\\]\nTrong đó \\(\\mathbf{1}^T\\in \\mathbb{R}^{1 \\times N}\\) là vector hàng có toàn bộ các phần tử bằng 1. Giả sử đã tìm được \\(\\mathbf{U}\\), ta cần tìm \\(\\mathbf{b}\\) thoả mãn:\n\\[\n\\mathbf{b} = \\text{argmin}_{\\mathbf{b}} ||\\mathbf{Y} - \\mathbf{b1}^T||_F^2 = \\text{argmin}_{\\mathbf{b}} ||\\bar{\\mathbf{U}}_K^T\\mathbf{X} - \\mathbf{b1}^T||_F^2\n\\]\nGiải phương trình đạo hàm theo \\(\\mathbf{b}\\) của hàm mục tiêu bằng 0:\n\\[\n(\\mathbf{b1}^T - \\bar{\\mathbf{U}}_K^T\\mathbf{X})\\mathbf{1} = 0 \\Rightarrow N\\mathbf{b} = \\bar{\\mathbf{U}}_K^T \\mathbf{X1} \\Rightarrow \\mathbf{b} = \\bar{\\mathbf{U}}_K^T \\bar{\\mathbf{x}}\n\\]\nNhư vậy, việc tính toán sẽ thuận tiện hơn nhiều nếu vector kỳ vọng \\(\\bar{\\mathbf{x}} = \\mathbf{0}\\). Việc này có thể đạt được nếu ngay từ đầu, chúng ta trừ mỗi vector dữ liệu đi vector kỳ vọng của toàn bộ dữ liệu. Đây chính là các bước đầu tiên của PCA.\n\nVới giá trị \\(\\mathbf{b}\\) tìm được này, dữ liệu ban đầu sẽ được xấp xỉ với:\n\\[\n\\mathbf{X} \\approx \\tilde{\\mathbf{X}} = \\mathbf{U}_K \\mathbf{Z} + \\bar{\\mathbf{U}}_K \\bar{\\mathbf{U}}_K^T\\bar{\\mathbf{x}}\\mathbf{1}^T ~~~ (10)\n\\]\nKết hợp \\((8), (9), (10)\\) ta định nghĩa hàm mất mát chính như sau:\n\\[\nJ = \\frac{1}{N} || \\mathbf{X} - \\tilde{\\mathbf{X}}||_F^2 = \\frac{1}{N} ||\\bar{\\mathbf{U}}_K \\bar{\\mathbf{U}}_K^T \\mathbf{X} -  \\bar{\\mathbf{U}}_K \\bar{\\mathbf{U}}_K^T \\bar{\\mathbf{x}}\\mathbf{1}^T||_F^2 ~~~~ (11)\n\\]\nChú ý rằng, nếu các cột của một ma trận \\(\\mathbf{V}\\) tạo thành một hệ trực chuẩn thì với một ma trận \\(\\mathbf{W}\\) bất kỳ, ta luôn có:\n\\[\n||\\mathbf{VW}||_F^2 = \\text{trace} (\\mathbf{W}^T\\mathbf{V}^T\\mathbf{V} \\mathbf{W}) = \\text{trace}(\\mathbf{W}^T\\mathbf{W}) = ||\\mathbf{W}||_F^2\n\\]\nVì vậy hàm mất mát trong \\((11)\\) có thể viết lại thành:\n\\[\n\\begin{eqnarray}\nJ &=& \\frac{1}{N} || \\bar{\\mathbf{U}}_K^T (\\mathbf{X} -   \\bar{\\mathbf{x}}\\mathbf{1})^T||_F^2 = \\frac{1}{N} ||\\bar{\\mathbf{U}}_K^T\\hat{\\mathbf{X}} ||_F^2& \\newline\n&=& \\frac{1}{N} ||\\hat{\\mathbf{X}}^T \\bar{\\mathbf{U}}_K ||_F^2 =\n\\frac{1}{N}\\sum_{i = K+1}^D ||\\hat{\\mathbf{X}}^T\\mathbf{u}_i ||_2^2& \\newline\n&=& \\frac{1}{N} \\sum_{i=K+1}^D \\mathbf{u}_i^T\\hat{\\mathbf{X}}\\hat{\\mathbf{X}}^T \\mathbf{u}_i& \\newline\n&=& \\sum_{i=K+1}^D \\mathbf{u}_i^T\\mathbf{S} \\mathbf{u}_i & (12)\n\\end{eqnarray}\n\\]\nVới \\(\\hat{\\mathbf{X}} = \\mathbf{X} - \\bar{\\mathbf{x}}\\mathbf{1}^T\\) là dữ liệu đã chuẩn hoá và với \\(\\mathbf{S}\\) là ma trận hiệp phương sai của dữ liệu.  Ta gọi ma trận này \\(\\hat{\\mathbf{X}}\\) là zero-corrected data hoặc dữ liệu đã được chuẩn hoá. Có thể nhận thấy \\(\\hat{\\mathbf{x}}_n = \\mathbf{x}_n - \\bar{\\mathbf{x}}\\).\nCông việc còn lại là tìm các \\(\\mathbf{u}_i\\) để mất mát là nhỏ nhất. Trước hết, chúng ta có một nhận xét thú vị. Nhắc lại định nghĩa ma trận hiệp phương sai \\(\\mathbf{S} = \\frac{1}{N} \\hat{\\mathbf{X}}^T\\hat{\\mathbf{X}}\\). Với ma trận \\(\\mathbf{U}\\) trực giao bất kỳ, thay \\(K = 0\\) vào \\((12)\\) ta có:\n\\[\n\\begin{eqnarray}\nL &=& \\sum_{i=1}^D \\mathbf{u}_i^T\\mathbf{Su}_i = \\frac{1}{N} ||\\hat{\\mathbf{X}}^T\\mathbf{U}||_F^2 \\newline\n&=& \\frac{1}{N} \\text{trace}(\\hat{\\mathbf{X}}^T\\mathbf{U} \\mathbf{U}^T \\hat{\\mathbf{X}}) & (12) \\newline\n&=& \\frac{1}{N} \\text{trace} (\\hat{\\mathbf{X}}^T \\hat{\\mathbf{X}}) & (13) \\newline\n&=& \\frac{1}{N} \\text{trace} (\\hat{\\mathbf{X}} \\hat{\\mathbf{X}}^T) & (14) \\newline\n&=& \\text{trace} (\\mathbf{S}) = \\sum_{i=1}^D \\lambda_i & (16)\n\\end{eqnarray}\n\\]\nVới \\(\\lambda_1 \\geq \\lambda_2 \\geq \\dots \\geq \\lambda_D \\geq 0\\) là các trị riêng của ma trận nửa xác định dương \\(\\mathbf{S}\\). Chú ý rằng các trị riêng này là thực và không âm.\nNhư vậy \\(L\\) không phụ thuộc vào cách chọn ma trận trực giao \\(\\mathbf{U}\\) và bằng tổng các phần tử trên đường chéo của \\(\\mathbf{S}\\). Nói cách khác, \\(L\\) chính là tổng của các phương sai theo từng thành phần của dữ liệu ban đầu.\nVì vậy, việc tối thiểu hàm mất mát \\(J\\) được cho bởi \\((13)\\) tương đương với việc tối đa:\n\\[\nF  = L - J = \\sum_{i=1}^K \\mathbf{u}_i \\mathbf{S} \\mathbf{u}_i^T\n\\]\nĐịnh lý 1: \\(F\\) đạt giá trị lớn nhất bằng \\(\\sum_{i=1}^K \\lambda_i\\) khi \\(\\mathbf{u}_i\\) là các vector riêng có norm 2 bằng 1 ứng với các trị riêng này. Tất nhiên, chúng ta không quên điều kiện trực giao giữa các \\(\\mathbf{u}_i\\).\nChú ý rằng \\(\\lambda_i, i = 1, \\dots, K\\) chính là \\(K\\) trị riêng lớn nhất của ma trận hiệp phương sai \\(\\mathbf{S}\\). Trị riêng lớn nhất \\(\\lambda_1\\) của ma trận này còn được gọi là Thành phần chính thứ nhất (First Principal Component), trị riêng thứ hai \\(\\lambda_2\\) còn được gọi là Thành phần chính thứ hai, etc. Chính vì vậy, phương pháp này có tên gọi là Phân tích thành phần chính - Principal Component Analysis. Ta chỉ giữ lại \\(K\\) thành phần chính của dữ liệu khi muốn giảm số chiều dữ liệu. Để có cái nhìn trực quan hơn, chúng ta cùng theo dõi Hình dưới đây:\nTrong không gian ban đầu với các vector cơ sở màu đen \\(\\mathbf{e}_1, \\mathbf{e}_2\\), phương sai theo mỗi chiều dữ liệu đều lớn. Trong không gian mới với các vector cơ sở màu đỏ \\(\\mathbf{u}_1, \\mathbf{u}_2\\), phương sai theo chiều thứ hai \\(\\hat{\\sigma}_2\\) rất nhỏ so với \\(\\hat{\\sigma}_1\\). Điều này nghĩa là khi chiếu dữ liệu lên \\(\\mathbf{u}_2\\) ta được các điểm rất gần nhau và gần với kỳ vọng theo chiều đó. Trong trường hợp này, kỳ vọng theo mọi chiều bằng 0 nên ta có thể thay thế toạ độ theo chiều \\(\\mathbf{u}_2\\) bằng 0. Rõ ràng là  nếu dữ liệu có phương sai càng nhỏ theo một chiều nào đó thì khi xấp xỉ chiều đó bằng một hằng số, sai số xảy ra càng nhỏ. PCA thực chất là đi tìm một phép xoay tương ứng với một ma trận trực giao sao cho trong hệ toạ độ mới, tồn tại các chiều có phương sai nhỏ mà ta có thể bỏ qua; ta chỉ cần giữ lại các chiều/thành phần khác quan trọng hơn. Như đã chứng minh ở trên, tổng phương sai theo mọi chiều trong hệ cơ sở nào cũng là như nhau và bằng tổng các trị riêng của ma trận hiệp phương sai. Vì vậy, PCA còn được coi là phương pháp giảm số chiều dữ liệu mà giữ được tổng phương sai còn lại là lớn nhất.\nTôi sẽ bỏ qua phần chứng minh của Định lý 1. Tuy nhiên, cũng nêu một vài ý để bạn đọc có thể hình dung:\nKhi \\(K = 1\\). Ta cần giải bài toán:\n\\[\n\\begin{eqnarray}\n\\max_{\\mathbf{u}_1} &\\mathbf{u}_1^T\\mathbf{S} \\mathbf{u}_1 \\newline\n\\text{s.t.:} &||\\mathbf{u}_1||_2 = 1\n\\end{eqnarray}\n\\]\nNhư đã đề cập ở phía trên, hàm mục tiêu đạt giá trị lớn nhất bằng \\(\\lambda_1\\) khi \\(\\mathbf{u}_1\\) là một vector riêng của ma trận hiệp phương sai \\(\\mathbf{S}\\) tương ứng với trị riêng \\(\\lambda_1\\). Vậy định lý đúng với \\(K = 1\\)\nGiả sử \\(\\mathbf{u}_1\\) đã là vector riêng ứng với trị riêng lớn nhất của \\(\\mathbf{S}\\) thế thì nghiệm \\(\\mathbf{u}_2\\) của bài toán tối ưu:\n\\[\n\\begin{eqnarray}\n\\max_{\\mathbf{u}_2} &\\mathbf{u}_2^T\\mathbf{S} \\mathbf{u}_2 &\\newline\n\\text{s.t.} &||\\mathbf{u}_2||_2 = 1 & (21)\\newline\n& \\mathbf{u}_2^T \\mathbf{u}_1 = 0 &\n\\end{eqnarray}\n\\]\nlà một vector riêng của \\(\\mathbf{S}\\) ứng với trị riêng lớn thứ hai \\(\\lambda_2\\) của nó. Chú ý rằng \\(\\lambda_2\\) có thể bằng \\(\\lambda_1\\) nếu không gian riêng ứng với \\(\\lambda_1\\) có số rank lớn hơn 1.\nNhận định này có thể được chứng minh bằng phương pháp nhân tử Lagrange. Thật vậy, Lagrangian của bài toán \\((21)\\) là:\n\\[\n\\mathcal{L}( \\mathbf{u}_2, \\nu_1, \\nu_2) = \\mathbf{u}_2^T\\mathbf{S} \\mathbf{u}_2 + \\nu_1\\mathbf{u}_1^T\\mathbf{u}_2 + \\nu_2(1 - \\mathbf{u}_2^T\\mathbf{u}_2)\n\\]\nTa cần giải hệ phương trình đạo hàm của \\(\\mathcal{L}\\) theo từng biến bằng 0:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{u}_2} &=& 2 \\mathbf{Su}_2 + \\nu_1 \\mathbf{u}_1 - 2\\nu_2\\mathbf{u}_2 = 0 & (22)\\newline\n\\frac{\\partial \\mathcal{L}}{\\partial \\nu_1} &=& \\mathbf{u}_1^T \\mathbf{u}_2 = 0 & (23)\\newline\n\\frac{\\partial \\mathcal{L}}{\\partial \\nu_2} &=& 1 - \\mathbf{u}_2^T \\mathbf{u}_2 = 0 &(24)\\newline\n\\end{eqnarray}\n\\]\nNhân cả hai vế của \\((22)\\) với \\(\\mathbf{u}_1^T\\) vào bên trái ta có:\n\\[\n2\\mathbf{u}_1^T\\mathbf{Su}_2 + \\nu_1 = 0\n\\]\nVì \\(\\mathbf{Su}_1 = \\lambda_1 \\mathbf{u}_1 \\Rightarrow \\mathbf{u}_1^T\\mathbf{Su}_2 = \\lambda_1 \\mathbf{u}_1^T\\mathbf{u}_2 = 0\\). Từ đó suy ra \\(\\nu_1 = 0\\) và \\((22)\\) lúc này tương đương với:\n\\[\n\\mathbf{Su}_2 = \\nu_2\\mathbf{u}_2 \\Rightarrow \\mathbf{u}_2^T\\mathbf{S} \\mathbf{u}_2 = \\nu_2\n\\]\nVậy \\(\\mathbf{u}_2\\) là một vector riêng của \\(\\mathbf{S}\\) ứng với \\(\\nu_2\\). Và để hàm mục tiêu đạt giá trị lớn nhất, \\(\\nu_2\\) cần càng lớn càng tốt. Điều này dẫn đến \\(\\nu_2\\) phải là trị riêng thứ hai của \\(\\mathbf{S}\\).\nLập luận tương tự, ta có thể chứng minh được: Nếu \\(\\mathbf{u}_i, i = 1, 2, \\dots, k-1\\) là các vector riêng ứng với trị riêng lớn thứ \\(i\\) của ma trận nửa xác định dương \\(\\mathbf{S}\\), hơn nữa, \\(k-1\\) vector riêng này tạo thành một hệ trực chuẩn, thế thì:\n\\[\n\\begin{eqnarray}\n\\max_{\\mathbf{u}_k} & \\mathbf{u}_k^T\\mathbf{Su}_k \\newline\n\\text{s.t.} & \\mathbf{u}_k^T\\mathbf{u}_k = 1; \\newline\n& \\mathbf{u}_k^T\\mathbf{u}_i = 1, i = 1,\\dots, k -1\n\\end{eqnarray}\n\\]\nbằng đúng với trị riêng tiếp theo \\(\\lambda_k\\) tại \\(\\mathbf{u}_k\\) là vector riêng ứng với trị riêng này.\n\nTừ các suy luận phía trên, ta có thể tóm tắt lại các bước trong PCA như sau:\nDữ liệu ban đầu có thể tính được xấp xỉ theo dữ liệu mới như sau:\n\\[\n\\mathbf{x} \\approx \\mathbf{U}_K\\mathbf{Z} + \\bar{\\mathbf{x}}\n\\]\nCác bước thực hiện PCA có thể được xem trong Hình dưới đây:\n\nVì bài viết đã khá dài, tôi xin giữ phần còn lại của PCA cho bài viết tiếp theo. Trong bài tới, chúng ta cùng thảo luận về mối quan hệ giữa PCA và SVD, lập trình PCA, một vài ứng dụng và mở rộng của SVD. Mời các bạn đón đọc.\n\n[1] Principal component analysis - Wikipedia\n[2] A tutorial on Principal Components Analysis\n[3] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer (2006). Chapter 12. (book)"
    },
    {
        "ID": 23,
        "URL": "https://machinelearningcoban.com/2017/06/07/svd/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\nHẳn các bạn vẫn nhớ một loại bài toán được làm rất nhiều khi học Đại số tuyến tính: Bài toán chéo hoá ma trận. Bài toán đó nói rằng: Một ma trận vuông \\(\\mathbf{A} \\in \\mathbb{R}^{n\\times n}\\) được gọi là chéo hoá được (diagonalizable) nếu tồn tại ma trận đường chéo \\(\\mathbf{D}\\) và ma trận khả nghịch \\(\\mathbf{P}\\) sao cho:\n\\[\n\\mathbf{A} = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}~~~~(1)\n\\]\nSố lượng phần tử khác 0 của ma trận đường chéo \\(\\mathbf{D}\\) chính là rank của ma trận \\(\\mathbf{A}\\).\nNhân cả hai vế của \\((1)\\) với \\(\\mathbf{P}\\) ta có:\n\\[\n\\mathbf{AP} = \\mathbf{PD}~~~~(2)\n\\]\nGọi \\(\\mathbf{p}_i, \\mathbf{d}_i\\) lần lượt là cột thứ \\(i\\) của ma trận \\(\\mathbf{P}\\) và \\(\\mathbf{D}\\). Vì mỗi một cột của vế trái và vế phải của \\((2)\\) phải bằng nhau, ta sẽ có:\n\\[\n\\mathbf{Ap}_i = \\mathbf{Pd}_i = d_{ii}\\mathbf{p}_i ~~~~ (3)\n\\]\nvới \\(d_{ii}\\) là phần tử thứ \\(i\\) của \\(\\mathbf{p}_i\\).\nDấu bằng thứ hai xảy ra vì \\(\\mathbf{D}\\) là ma trận đường chéo, tức \\(\\mathbf{d}_i\\) chỉ có thành phần \\(d_{ii}\\) là khác 0. Và nếu bạn vẫn nhớ, biểu thức \\((3)\\) chỉ ra rằng mỗi phần tử \\(d_{ii}\\) phải là một trị riêng (eigenvalue) của \\(\\mathbf{A}\\) và mỗi vector cột \\(\\mathbf{p}_i\\) phải là một vector riêng (eigenvector) của \\(\\mathbf{A}\\) ứng với trị riêng \\(d_{ii}\\).\nCách phân tích một ma trận vuông thành nhân tử như \\((1)\\) còn được gọi là Eigen Decomposition.\nMột điểm quan trọng là cách phân tích như \\((1)\\) chỉ được áp dụng với ma trận vuông và không phải lúc nào cũng tồn tại. Nó chỉ tồn tại nếu ma trận \\(\\mathbf{A}\\) có \\(n\\) vector riêng độc lập tuyến tính, vì nếu không thì không tồn tại ma trận \\(\\mathbf{P}\\) khả nghịch. Thêm nữa, cách phân tích này cũng không phải là duy nhất vì nếu \\(\\mathbf{P}, \\mathbf{D}\\) thoả mãn \\((1)\\) thì \\(k\\mathbf{P}, \\mathbf{D}\\) cũng thoả mãn với \\(k\\) là một số thực khác 0 bất kỳ.\nViệc phân tích một ma trận ra thành tích của nhiều ma trận đặc biệt khác (Matrix Factorization hoặc Matrix Decomposition) mang lại nhiều ích lợi quan trọng mà các bạn sẽ thấy: giảm số chiều dữ liệu, nén dữ liệu, tìm hiểu các đặc tính của dữ liệu, giải các hệ phương trình tuyến tính, clustering, và nhiều ứng dụng khác. Recommendation System cũng là một trong rất nhiều ứng dụng của Matrix Factorization.\nTrong bài viết này, tôi sẽ giới thiệu với các bạn một trong những phương pháp Matrix Factorization rất đẹp của Đại số tuyến tính. Phương pháp đó có tên là Singular Value Decomposition (SVD). Các bạn sẽ thấy, mọi ma trận, không nhất thiết là vuông, đều có thể được phân tích thành tích của ba ma trận đặc biệt.\nDưới đây, tôi sẽ phát biểu SVD cũng như các tính chất và ứng dụng điển hình của nó.\nTrước hết, chúng ta cần ôn tập lại một chút về Đại số tuyến tính. Chú ý rằng các ma trận trong bài viết này đều được ngầm giả sử là ma trận thực.\n\n\nCho một ma trận vuông \\(\\mathbf{A} \\in \\mathbb{R}^{n\\times n}\\), nếu số vô hướng \\(\\lambda\\) và vector \\(\\mathbf{x} \\neq \\mathbf{0} \\in \\mathbb{R}^n\\) thoả mãn:\n\\[\n\\mathbf{Ax} = \\lambda \\mathbf{x}\n\\]\nthì \\(\\lambda\\) được gọi là một trị riêng của \\(\\mathbf{A}\\) và \\(\\mathbf{x}\\) được gọi là vector riêng tương ứng với trị riêng đó.\nMột vài tính chất:\nNếu \\(\\mathbf{x}\\) là một vector riêng của \\(\\mathbf{A}\\) ứng với \\(\\lambda\\) thì \\(k\\mathbf{x}, k \\neq 0\\) cũng là vector riêng ứng với trị riêng đó.\nMọi ma trận vuông bậc \\(n\\) đều có \\(n\\) trị riêng (kể cả lặp) và có thể là các số phức.\nVới ma trận đối xứng, tất cả các trị riêng đều là các số thực.\nVới ma trận xác định dương, tất cả các trị riêng của nó đều là các số thực dương. Với ma trận nửa xác định dương, tất cả các trị riêng của nó đều là các số thực không âm.\nTính chất cuối cùng có thể được suy ra từ định nghĩa của ma trận (nửa) xác định dương. Thật vậy, gọi \\(\\mathbf{u} \\neq \\mathbf{0}\\) là vector riêng ứng với một trị riêng \\(\\lambda\\) của ma trận \\(\\mathbf{A}\\) xác định dương, ta có:\n\\[\n\\mathbf{Au} = \\lambda \\mathbf{u} \\Rightarrow \\mathbf{u}^T\\mathbf{Au} = \\lambda \\mathbf{u}^T\\mathbf{u} = \\lambda ||\\mathbf{u}||_2^2\n\\]\nVì \\(\\mathbf{A}\\) là nửa xác định dương nên với mọi \\(\\mathbf{u} \\neq \\mathbf{0}\\): \\(\\mathbf{u}^T\\mathbf{Au} \\geq 0\\); \\(\\mathbf{u} \\neq 0\\) nên \\(||\\mathbf{u}||_2^2 > 0\\). Từ đó suy ra \\(\\lambda\\) là một số không âm.\n\nMột hệ cơ sở \\({\\mathbf{u}_1, \\mathbf{u}_2,\\dots, \\mathbf{u}_m \\in \\mathbb{R}^m}\\) được gọi là trực giao (orthogonal) nếu mỗi vector là khác 0 và tích của hai vector khác nhau bất kỳ bằng 0:\n\\[\n\\mathbf{u}_i \\neq \\mathbf{0}; ~~ \\mathbf{u}_i^T \\mathbf{u}_j = 0 ~ \\forall ~1 \\leq i \\neq j \\leq m\n\\]\nMột hệ cơ sở \\({\\mathbf{u}_1, \\mathbf{u}_2,\\dots, \\mathbf{u}_m \\in \\mathbb{R}^m}\\) được gọi là trực chuẩn (orthonormal) nếu nó là một hệ trực giao và độ dài Euclidean (norm 2) của mỗi vector bằng 1:\n\\[\n\\begin{eqnarray}\n\\mathbf{u}_i^T \\mathbf{u}_j = \\left\\{\n\\begin{matrix}\n    1 & \\text{if} &i = j \\newline\n    0 & \\text{otherwise}\n\\end{matrix}\n\\right. ~~~~ (4)\n\\end{eqnarray}\n\\]\nGọi \\(\\mathbf{U} = [\\mathbf{u}_1, \\mathbf{u}_2,\\dots, \\mathbf{u}_m]\\) với \\({\\mathbf{u}_1, \\mathbf{u}_2,\\dots, \\mathbf{u}_m \\in \\mathbb{R}^m}\\) là trực chuẩn, thế thì từ \\((4)\\) có thể suy ra ngay:\n\\[\n\\mathbf{UU}^T = \\mathbf{U}^T\\mathbf{U} = \\mathbf{I}\n\\]\ntrong đó \\(\\mathbf{I}\\) là ma trận đơn vị bậc \\(m\\). Ta gọi \\(\\mathbf{U}\\) là ma trận trực giao (orthogonal matrix). Ma trận loại này không được gọi là ma trận trực chuẩn, không có định nghĩa cho ma trận trực chuẩn.\nMột vài tính chất:\n\\(\\mathbf{U}^{-1} = \\mathbf{U}^T\\): nghịch đảo của một ma trận trực giao chính là chuyển vị của nó.\nNếu \\(\\mathbf{U}\\) là ma trận trực giao thì chuyển vị của nó \\(\\mathbf{U}^T\\) cũng là một ma trận trực giao.\nĐịnh thức (determinant) của ma trận trực giao bằng \\(1\\) hoặc \\(-1\\). Điều này có thể suy ra từ việc \\(\\det(\\mathbf{U}) = \\det(\\mathbf{U}^T)\\) và \\(\\det(\\mathbf{U}) \\det(\\mathbf{U}^T) = \\det(\\mathbf{I}) = 1\\).\nMa trận trực giao thể hiện cho phép xoay (rotate) một vector. Giả sử có hai vector \\(\\mathbf{x,y} \\in \\mathbb{R}^m\\) và ma trận trực giao \\(\\mathbf{U} \\in \\mathbb{R}^{m \\times m}\\). Dùng ma trận này để xoay hai vector trên ta được \\(\\mathbf{Ux}, \\mathbf{Uy}\\). Tích vô hướng của hai vector mới là:\n\\[\n(\\mathbf{Ux})^T (\\mathbf{Uy}) = \\mathbf{x}^T \\mathbf{U}^T \\mathbf{Uy} = \\mathbf{x}^T\\mathbf{y}\n\\]\nnhư vậy phép xoay không làm thay đổi tích vô hướng giữa hai vector.\nGiả sử \\(\\hat{\\mathbf{U}} \\in \\mathbb{R}^{m \\times r}, r < m\\) là môt ma trận con của ma trận trực giao \\(\\mathbf{U}\\) được tạo bởi \\(r\\) cột của \\(\\mathbf{U}\\), ta sẽ có \\(\\hat{\\mathbf{U}}^T\\hat{\\mathbf{U}} = \\mathbf{I}_{r}\\). Việc này có thể được suy ra từ \\((4)\\).\n\nVì trong mục này cần nắm vững chiều của mỗi ma trận nên tôi sẽ thay đổi ký hiệu một chút để chúng ta dễ hình dung. Ta sẽ ký hiệu một ma trận cùng với số chiều của nó, ví dụ \\(\\mathbf{A}_{m \\times n}\\) nghĩa là ma trận \\(\\mathbf{A} \\in \\mathbb{R}^{m \\times n}\\).\n\nMột ma trận \\(\\mathbf{A}_{m \\times n}\\) bất kỳ đều có thể phân tích thành dạng:\n\\[\n\\mathbf{A}_{m \\times n} = \\mathbf{U}_{m \\times m}\\mathbf{\\Sigma}_{m \\times n} (\\mathbf{V}_{n \\times n})^T ~~~~ (5)\n\\]\nTrong đó, \\(\\mathbf{U}, \\mathbf{V}\\) là các ma trận trực giao, \\(\\mathbf{\\Sigma}\\) là ma trận đường chéo không vuông với các phần tử trên đường chéo \\(\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq\\sigma_r \\geq 0 = 0 = \\dots = 0\\) và \\(r\\) là rank của ma trận \\(\\mathbf{A}\\). Lưu ý rằng mặc dù \\(\\Sigma\\) không phải ma trận vuông, ta vẫn có thể coi nó là ma trận chéo nếu các thành phần khác không của nó chỉ nằm ở vị trí đường chéo, tức tại các vị trí có chỉ số hàng và chỉ số cột là như nhau.\nSố lượng các phần tử khác 0 trong \\(\\Sigma\\) chính là rank của ma trận \\(\\mathbf{A}\\).\nNếu bạn muốn xem chứng minh về sự tồn tại của SVD, bạn có thể xem tại đây.\nChú ý rằng cách biểu diễn \\((5)\\) không là duy nhất vì ta chỉ cần đổi dấu của cả \\(\\mathbf{U}\\) và \\(\\mathbf{V}\\) thì \\((5)\\) vẫn thoả mãn. Tuy vậy, người ta vẫn thường dùng ‘the SVD’ thay vì ‘a SVD’.\nHình 1 mô tả SVD của ma trận \\(\\mathbf{A}_{m \\times n}\\) trong hai trường hợp: \\(m < n\\) và \\(m > n\\). Trường hợp \\(m =n\\) có thể xếp vào một trong hai trường hợp trên.\n\nTạm bỏ qua chiều của mỗi ma trận, từ \\((5)\\) ta có:\n\\[\n\\begin{eqnarray}\n\\mathbf{AA}^T &=& \\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V}^T (\\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V}^T)^T \\newline\n&=& \\mathbf{U}\\mathbf{\\Sigma} \\mathbf{V}^T \\mathbf{V}\\mathbf{\\Sigma}^T\\mathbf{U}^T \\newline\n&=& \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{\\Sigma}^T\\mathbf{U}^T =  \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{\\Sigma}^T\\mathbf{U}^{-1} ~~~~~ (6)\n\\end{eqnarray}\n\\]\nDấu bằng cuối cùng xảy ra vì \\(\\mathbf{V}^T\\mathbf{V} = \\mathbf{I}\\) do \\(\\mathbf{V}\\) là một ma trận trực giao.\nQuan sát thấy rằng \\(\\Sigma\\Sigma^T\\) là một ma trận đường chéo với các phần tử trên đường chéo là \\(\\sigma_1^2, \\sigma_2^2, \\dots\\). Vậy \\((6)\\) chính là Eigen Decomposition của \\(\\mathbf{A}\\mathbf{A}^T\\). Thêm nữa, \\(\\sigma_1^2, \\sigma_2^2, \\dots\\) chính là các trị riêng của \\(\\mathbf{A}\\mathbf{A}^T\\).\nMa trận \\(\\mathbf{A}\\mathbf{A}^T\\) luôn là ma trận nửa xác định dương nên các trị riêng của nó là không âm. Các \\(\\sigma_i\\) là căn bậc hai của các trị riêng của \\(\\mathbf{A}\\mathbf{A}^T\\) còn được gọi là singular values của \\(\\mathbf{A}\\). Cái tên Singular Value Decomposition xuất phát từ đây.\nCũng theo đó, mỗi cột của \\(\\mathbf{U}\\) chính là một vector riêng của \\(\\mathbf{A}\\mathbf{A}^T\\). Ta gọi mỗi cột này là left-singular vectors của \\(\\mathbf{A}\\). Tương tự như thế, \\(\\mathbf{A}^T\\mathbf{A} = \\mathbf{V}\\Sigma^T\\Sigma \\mathbf{V}^T\\) và các cột của \\(\\mathbf{V}\\) còn được gọi là các right-singular vectors của \\(\\mathbf{A}\\).\nTrong Python, để tính SVD của một ma trận, chúng ta sử dụng module linalg của numpy như sau:\nLưu ý rằng biến S được trả về chỉ bao gồm các phần tử trên đường chéo của \\(\\Sigma\\). Biến V trả về là \\(\\mathbf{V}^T\\) trong \\((5)\\).\n\nViết lại biểu thức \\((5)\\) dưới dạng tổng của các ma trận rank 1:\n\\[\n\\mathbf{A} = \\sigma_1 \\mathbf{u}_1 \\mathbf{v}^T_1 + \\sigma_2\\mathbf{u}_2\\mathbf{v}_2^2 + \\dots + \\sigma_r\\mathbf{u}_r\\mathbf{v}_r^T\n\\]\nvới chú ý rằng mỗi \\(\\mathbf{u}_1 \\mathbf{v}^T_i, 1 \\leq i \\leq r\\) là một ma trận có rank bằng 1.\nRõ ràng trong cách biểu diễn này, ma trận \\(\\mathbf{A}\\) chỉ phụ thuộc vào \\(r\\) cột đầu tiên của \\(\\mathbf{U, V}\\) và \\(r\\) giá trị khác 0 trên đường chéo của ma trận \\(\\Sigma\\). Vì vậy ta có một cách phân tích gọn hơn và gọi là compact SVD:\n\\[\n\\mathbf{A} = {\\mathbf{U}}_r{\\Sigma}_r({\\mathbf{V}}_r)^T\n\\]\nVới \\(\\mathbf{U}_r, \\mathbf{V}_r \\) lần lượt là ma trận được tạo bởi \\(r\\) cột đầu tiên của \\(\\mathbf{U}\\) và \\(\\mathbf{V}\\). \\(\\Sigma_r\\) là ma trận con được tạo bởi \\(r\\) hàng đầu tiên và \\(r\\) cột đầu tiên của \\(\\Sigma\\). Nếu ma trận \\(\\mathbf{A}\\) có rank nhỏ hơn rất nhiều so với số hàng và số cột \\(r \\ll m, n\\), ta sẽ được lợi nhiều về việc lưu trữ.\nDưới đây là ví dụ minh hoạ với \\(m = 4, n = 6, r = 2\\).\n\nChú ý rằng trong ma trận \\(\\Sigma\\), các giá trị trên đường chéo là không âm và giảm dần \\(\\sigma_1 \\geq \\sigma_2 \\geq \\dots, \\geq \\sigma_r \\geq 0 = 0 = \\dots = 0\\). Thông thường, chỉ một lượng nhỏ các \\(\\sigma_i\\) mang giá trị lớn, các giá trị còn lại thường nhỏ và gần 0. Khi đó ta có thể xấp xỉ ma trận \\(\\mathbf{A}\\) bằng tổng của \\(k < r\\) ma trận có rank 1:\n\\[\n\\mathbf{A} \\approx \\mathbf{A}_k = \\mathbf{U}_k \\Sigma_k (\\mathbf{V}_k)^T = \\sigma_1 \\mathbf{u}_1 \\mathbf{v}^T_1 + \\sigma_2\\mathbf{u}_2\\mathbf{v}_2^2 + \\dots + \\sigma_k\\mathbf{u}_k\\mathbf{v}k^T ~~~~ (7)\n\\]\nDưới đây là một định lý thú vị. Định lý này nói rằng sai số do cách xấp xỉ trên chính là căn bậc hai của tổng bình phương của các singular values mà ta đã bỏ qua ở phần cuối của \\(\\Sigma\\). Ở đây sai số được định nghĩa là Frobineous norm của hiệu hai ma trận:\nĐịnh lý:\n\\[\n||\\mathbf{A} - \\mathbf{A}_k||_F^2 = \\sum_{i = k + 1}^r \\sigma_i^2 ~~~ (8)\n\\]\nChứng minh:\nSử dụng tính chất \\(||\\mathbf{X}||_F^2 = \\text{trace}(\\mathbf{X}\\mathbf{X}^T)\\) và \\(\\text{trace}(\\mathbf{XY}) = \\text{trace}(\\mathbf{YX})\\) với mọi ma trận \\(\\mathbf{X, Y}\\) ta có:\n\\[\n\\begin{eqnarray}\n    ||\\mathbf{A} - \\mathbf{A}_k||_F^2 & = & ||\\sum_{i = k + 1}^r \\sigma_i \\mathbf{u}_i\\mathbf{v}_i^T ||_F^2    & (9)\\newline\n    & = & \\text{trace}\\left\\{ \\left(\\sum_{i = k + 1}^r \\sigma_i \\mathbf{u}_i\\mathbf{v}_i^T\\right)\n    \\left(\\sum_{j = k + 1}^r \\sigma_j \\mathbf{u}_j\\mathbf{v}_j^T\\right)^T\n    \\right\\} & (10) \\newline\n    &=& \\text{trace}\\left\\{ \\sum_{i = k + 1}^r \\sum_{j = k + 1}^r \\sigma_i\\sigma_j \\mathbf{u}_i\\mathbf{v}_i^T \\mathbf{v}_j \\mathbf{u}_j^T\n    \\right\\} & (11) \\newline\n    &=& \\text{trace}\\left\\{ \\sum_{i = k + 1}^r  \\sigma_i^2\\mathbf{u}_i\\mathbf{u}_i^T\n    \\right\\} & (12) \\newline\n    &=& \\text{trace}\\left\\{ \\sum_{i = k + 1}^r  \\sigma_i^2\\mathbf{u}_i^T\\mathbf{u}_i\n    \\right\\} & (13) \\newline\n    &=& \\text{trace}\\left\\{ \\sum_{i = k + 1}^r  \\sigma_i^2\n    \\right\\} & (14) \\newline\n    & = & \\sum_{i = k + 1}^r \\sigma_i^2 & (15)\n\\end{eqnarray}\n\\]\nDấu bằng ở \\((12)\\) là vì \\(\\mathbf{V}\\) là ma trận trực giao (xem \\((4)\\)).\nDấu bằng ở \\((13)\\) là vì hàm \\(\\text{trace}\\) có tính chất giao hoán.\nDấu bằng ở \\((15)\\) là vì biểu thức trong dấu ngoặc của \\((14)\\) là một số vô hướng.\nThay \\(k = 0\\) ta sẽ có:\n\\[||\\mathbf{A}||_F^2 = \\sum_{i = 1}^r \\sigma_i^2~~~~ (16) \\]\nTừ đó:\n\\[\n\\frac{||\\mathbf{A} - \\mathbf{A}_k||_F^2}{||\\mathbf{A}||_F^2} = {\\frac{\\sum_{i = k + 1}^r \\sigma_i^2}{\\sum_{j = 1}^r \\sigma_j^2}} ~~~~ (17)\n\\]\nNhư vậy, sai số do xấp xỉ càng nhỏ nếu phần singular values bị truncated có giá trị càng nhỏ so với phần singular values được giữ lại. Đây là một định lý quan trọng giúp xác định việc xấp xỉ ma trận dựa trên lượng thông tin muốn giữ lại.\nVí dụ, nếu ta muốn giữ lại ít nhất 90% lương thông tin trong \\(\\mathbf{A}\\), trước hết ta tính \\(\\sum_{j = 1}^r \\sigma_j^2\\), sau đó chọn \\(k\\) là số nhỏ nhất sao cho:\n\\[\n\\frac{\\sum_{i = 1}^k \\sigma_i^2}{\\sum_{j = 1}^r \\sigma_j^2} \\geq 0.9\n\\]\nKhi \\(k\\) nhỏ, ma trận \\(\\mathbf{A}_k\\) có rank là \\(k\\), là một ma trận có rank nhỏ. Vì vậy, Truncated SVD còn được coi là một phương pháp Low-rank approximation.\n\nNgười ta chứng minh được rằng (Singular Value Decomposition - Princeton) \\(\\mathbf{A}_k\\) chính là nghiệm của bài toán tối ưu:\n\\[\n\\begin{eqnarray}\n\\min_{\\mathbf{B}} &&||\\mathbf{A} - \\mathbf{B}||_F \\newline\n\\text{s.t.} && \\text{rank}(\\mathbf{B}) = k ~~~~~~~~~~~~~~ (17)\n\\end{eqnarray}\n\\]\nvà như đã chứng minh ở trên \\(||\\mathbf{A} - \\mathbf{A}_k||_F^2 = \\sum_{i = k + 1}^r \\sigma_i^2\\).\nNếu sử dụng norm 2 của ma trận thay vì Frobenius norm để đo sai số, \\(\\mathbf{A}_k\\) cũng là nghiệm của bài toán tối ưu:\n\\[\n\\begin{eqnarray}\n\\min_{\\mathbf{B}} &&||\\mathbf{A} - \\mathbf{B}||_2 \\newline\n\\text{s.t.} && \\text{rank}(\\mathbf{B}) = k ~~~~~~~~~~~~~~ (18)\n\\end{eqnarray}\n\\]\nvà sai số: \\(||\\mathbf{A} - \\mathbf{A}_k||_2^2 = \\sigma_{k+1}^2\\).\nĐịnh nghĩa của norm 2 của một ma trận là:\n\\[\n||\\mathbf{A}||_2 = \\max_{||\\mathbf{x}||_2 = 1} ||\\mathbf{Ax}||_2\n\\]\nĐây là lý do căn bậc hai của tổng bình phương của các phần tử của một ma trận không được gọi là norm 2 như đối với vector.\nNếu bạn muốn biết thêm:\n\\[\n||\\mathbf{A}||_2 = \\sigma_1\n\\]\ntức norm 2 của một ma trận chính là singular value lớn nhất của ma trận đó.\nFrobenius norm và norm 2 là hai norms được sử dụng nhiều nhất trong ma trận. Như vậy, xét trên cả hai norm này, Truncated SVD đều cho xấp xỉ tốt nhất. Vì vậy Truncated SVD còn được gọi là Best low-rank Approximation.\n\n\nXét ví dụ trong Hình 3 dưới đây:\nHình 3 mô tả chất lượng ảnh khi chọn các giá trị \\(k\\) khác nhau. Khi \\(k\\) gần 100, lượng thông tin mất đi rơi vào khoảng nhỏ hơn 2%, ảnh thu được có chất lượng gần như ảnh gốc.\nĐể lưu ảnh với Truncated SVD, ta sẽ lưu các ma trận \\(\\mathbf{U}_k \\in \\mathbb{R}^{m \\times k}, \\Sigma_k \\in \\mathbb{R}^{k \\times k}, \\mathbf{V}_k \\in \\mathbb{R}^{n \\times k}\\). Tổng số phần tử phải lưu là \\(k(m + n + 1)\\) với chú ý rằng ta chỉ cần lưu các giá trị trên đường chéo của \\(\\Sigma_k\\). Giả sử mỗi phần tử được lưu bởi một số thực 4 byte, thế thì số byte cần lưu trữ là \\(4k(m + n + 1)\\). Nếu so giá trị này với ảnh gốc có kích thước \\(mn\\), mỗi giá trị là 1 số nguyên 1 byte, tỉ lệ nén là:\n\\[\n\\frac{4k(m + n + 1)}{mn}\n\\]\nKhi \\(k \\ll m, n\\), ta được một tỉ lệ nhỏ hơn 1. Trong ví dụ của chúng ta \\(m = 960, n = 1440, k = 100\\), ta có tỉ lệ nén xấp xỉ 0.69, tức đã tiết kiệm được khoảng 30% bộ nhớ.\n\nNhư đã nhắc ở Mục 1, SVD là một phương pháp Matrix Factorization, vì vậy, nó cũng hoàn toàn có thể được áp dụng vào bài toán Recommendation Systems như trong Bài 25.\nÝ tưởng hoàn toàn tương tự, ta sẽ xấp xỉ Utility Matrix đã được chuẩn hoá (theo user-based hoặc item-based). Giá trị của ma trận xấp xỉ có rank nhỏ hơn chính là giá trị được dự đoán.\nKết quả (RMSE) với cơ sở dữ liệu tương tự như Bài 25 là:\nMovieLens 100k, user-based: 1.018 (tốt hơn so với 1.06 của Matrix Factorization).\nMovieLens 100k, item-based: 1.014 (tốt hơn so với 1.05)\nMovieLens 1M, item-based: 0.95 (tốt hơn so với 0.98)\nNhư vậy, Truncated SVD cho kết quả tốt hơn so với Matrix Factorization giải bằng Gradient Descent một chút.\nMột cách giải thích thú vị về mối liên quan giữa SVD và Utility Matrix với user-\n\nNgoài hai ứng dụng nêu trên, SVD còn có mối liên quan chặt chẽ đến giả nghịch đảo Moore Penrose. (Xem thêm The Moore-Penrose Pseudoinverse (Math 33A - UCLA)). Giả nghịch đảo đóng một vài trò quan trọng trong giải hệ phương trình tuyến tính. Một ví dụ của nó đã được đề cập trong Bài 3: Linear Regression.\nCòn nhiều tính chất và ứng dụng thú vị khác của SVD, chúng ta sẽ dần tìm hiểu. Trước tiên là trong Dimensionality Reduction với Principle Component Analysis. Chúng ta sẽ cùng trao đổi tới vấn đề này trong bài tiếp theo.\nKhi ma trận \\(\\mathbf{A}\\) lớn, việc tính toán SVD của nó tốn nhiều thời gian. Cách tính Truncated SVD với \\(k\\) nhỏ bằng cách tính SVD như tôi sử dụng trong bài trở nên không khả thi. Thay vào đó, có một phương pháp lặp giúp tính các trị riêng và vector riêng của một ma trận lớn một cách hiệu quả, và ta chỉ cần tìm \\(k\\) trị riêng lớn nhất của \\(\\mathbf{AA}^T\\) và các vector riêng tương ứng, việc này sẽ tiết kiệm được khá nhiều thời gian. Bạn đọc có thể tìm đọc thêm Power method for approximating eigenvalues. Phương pháp này cũng là phần chính của thuật toán nổi tiếng Google PageRank, tôi sẽ có một bài về vấn đề này khi thấy phù hợp.\nSource code\n\n[1] Singular Value Decomposition - Stanford University\n[2] Singular Value Decomposition - Princeton\n[3] CS168: The Modern Algorithmic Toolbox Lecture #9: The Singular Value Decomposition (SVD) and Low-Rank Matrix Approximations - Stanford\n[4] The Moore-Penrose Pseudoinverse (Math 33A - UCLA)"
    },
    {
        "ID": 24,
        "URL": "https://machinelearningcoban.com/2017/05/31/matrixfactorization/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\nTrong Bài 24, chúng ta đã làm quen với một hướng tiếp cận trong Collaborative Filtering dựa trên hành vi của các users hoặc items lân cận có tên là Neighborhood-based Collaborative Filtering. Trong bài viết này, chúng ta sẽ làm quen với một hướng tiếp cận khác cho Collaborative Filtering dựa trên Matrix Factorization (hoặc Matrix Decomposition), tức Phân tích ma trận thành nhân tử.\nNhắc lại rằng trong Content-based Recommendation Systems, mỗi item được mô tả bằng một vector \\(\\mathbf{x}\\) được gọi là item profile. Trong phương pháp này, ta cần tìm một vector hệ số \\(\\mathbf{w}\\) tương ứng với mỗi user sao cho rating đã biết mà user đó cho item xấp xỉ với: \n\\[\ny \\approx \\mathbf{xw}\n\\]\nVới cách làm trên, Utility Matrix \\(\\mathbf{Y}\\), giả sử đã được điền hết, sẽ xấp xỉ với:\n\\[\n\\mathbf{Y} \\approx \\left[ \\begin{matrix}\n\\mathbf{x}_1\\mathbf{w}_1 & \\mathbf{x}_1\\mathbf{w}_2 & \\dots & \\mathbf{x}_1 \\mathbf{w}_N \\newline\n\\mathbf{x}_2\\mathbf{w}_1 & \\mathbf{x}_2\\mathbf{w}_2 & \\dots & \\mathbf{x}_2 \\mathbf{w}_N \\newline\n\\dots & \\dots & \\ddots & \\dots \\newline\n\\mathbf{x}_M\\mathbf{w}_1 & \\mathbf{x}_M\\mathbf{w}_2 & \\dots & \\mathbf{x}_M \\mathbf{w}_N \\newline\n\\end{matrix} \\right]\n = \\left[ \\begin{matrix}\n\\mathbf{x}_1 \\newline\n\\mathbf{x}_2 \\newline\n\\dots \\newline\n\\mathbf{x}_M \\newline\n\\end{matrix} \\right]\n\\left[ \\begin{matrix}\n\\mathbf{w}_1 & \\mathbf{w}_2 & \\dots & \\mathbf{w}_N\n\\end{matrix} \\right] = \\mathbf{XW}\n\\]\nvới \\(M, N\\) lần lượt l\nà số items và số users.\nChú ý rằng, \\(\\mathbf{x}\\) được xây dựng dựa trên thông tin mô tả của item và quá trình xây dựng này độc lập với quá trịnh đi tìm hệ số phù hợp cho mỗi user. Như vậy, việc xây dựng item profile đóng vai trò rất quan trọng và có ảnh hưởng trực tiếp lên hiệu năng của mô hình. Thêm nữa, việc xây dựng từng mô hình riêng lẻ cho mỗi user dẫn đến kết quả chưa thực sự tốt vì không khai thác được đặc điểm của những users gần giống nhau.\nBây giờ, giả sử rằng ta không cần xây dựng từ trước các item profile \\(\\mathbf{x}\\) mà vector đặc trưng cho mỗi item này có thể được huấn luyện đồng thời với mô hình của mỗi user (ở đây là 1 vector hệ số). Điều này nghĩa là, biến số trong bài toán tối ưu là cả \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\); trong đó, \\(\\mathbf{X}\\) là ma trận của toàn bộ item profiles, mỗi hàng tương ứng với 1 item, \\(\\mathbf{W}\\) là ma trận của toàn bộ user models, mỗi cột tương ứng với 1 user.\nVới cách làm này, chúng ta đang cố gắng xấp xỉ Utility Matrix \\(\\mathbf{Y} \\in \\mathbb{R}^{M \\times N}\\) bằng tích của hai ma trận \\(\\mathbf{X}\\in \\mathbb{R}^{M\\times K}\\) và \\(\\mathbf{W} \\in \\mathbb{R}^{K \\times N}\\).\nThông thường, \\(K\\) được chọn là một số nhỏ hơn rất nhiều so với \\(M, N\\). Khi đó, cả hai ma trận \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\) đều có rank không vượt quá \\(K\\). Chính vì vậy, phương pháp này còn được gọi là Low-Rank Matrix Factorization (xem Hình 1).\nCó một vài điểm lưu ý ở đây:\nÝ tưởng chính đằng sau Matrix Factorization cho Recommendation Systems là tồn tại các latent features (tính chất ẩn) mô tả sự liên quan giữa các items và users. Ví dụ với hệ thống gợi ý các bộ phim, tính chất ẩn có thể là hình sự, chính trị, hành động, hài, …; cũng có thể là một sự kết hợp nào đó của các thể loại này; hoặc cũng có thể là bất cứ điều gì mà chúng ta không thực sự cần đặt tên. Mỗi item sẽ mang tính chất ẩn ở một mức độ nào đó tương ứng với các hệ số trong vector \\(\\mathbf{x}\\) của nó, hệ số càng cao tương ứng với việc mang tính chất đó càng cao. Tương tự, mỗi user cũng sẽ có xu hướng thích những tính chất ẩn nào đó và được mô tả bởi các hệ số trong vector \\(\\mathbf{w}\\) của nó. Hệ số cao tương ứng với việc user thích các bộ phim có tính chất ẩn đó. Giá trị của biểu thức \\(\\mathbf{xw}\\) sẽ cao nếu các thành phần tương ứng của \\(\\mathbf{x}\\) và \\(\\mathbf{w}\\) đều cao. Điều này nghĩa là item mang các tính chất ẩn mà user thích, vậy thì nên gợi ý item này cho user đó.\nVậy tại sao Matrix Factorization lại được xếp vào Collaborative Filtering? Câu trả lời đến từ việc đi tối ưu hàm mất mát mà chúng ta sẽ thảo luận ở Mục 2. Về cơ bản, để tìm nghiệm của bài toán tối ưu, ta phải lần lượt đi tìm \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\) khi thành phần còn lại được cố định. Như vậy, mỗi hàng của \\(\\mathbf{X}\\) sẽ phụ thuộc vào toàn bộ các cột của \\(\\mathbf{W}\\). Ngược lại, mỗi cột của \\(\\mathbf{W}\\) lại phục thuộc vào toàn bộ các hàng của \\(\\mathbf{X}\\). Như vậy, có những mỗi quan hệ ràng buộc chằng chịt giữa các thành phần của hai ma trận trên. Tức chúng ta cần sử dụng thông tin của tất cả để suy ra tất cả. Vậy nên phương pháp này cũng được xếp vào Collaborative Filtering.\nTrong các bài toán thực tế, số lượng items \\(M\\) và số lượng users \\(N\\) thường rất lớn. Việc tìm ra các mô hình đơn giản giúp dự đoán ratings cần được thực hiện một cách nhanh nhất có thể. Neighborhood-based Collaborative Filtering không yêu cầu việc learning quá nhiều, nhưng trong quá trình dự đoán (inference), ta cần đi tìm độ similarity của user đang xét với toàn bộ các users còn lại rồi suy ra kết quả. Ngược lại, với Matrix Factorization, việc learning có thể hơi phức tạp một chút vì phải lặp đi lặp lại việc tối ưu một ma trận khi cố định ma trận còn lại, nhưng việc inference đơn giản hơn vì ta chỉ cần lấy tích của hai vector \\(\\mathbf{xw}\\), mỗi vector có độ dài \\(K\\) là một số nhỏ hơn nhiều so với \\(M, N\\). Vậy nên quá trình inference không yêu cầu khả năng tính toán cao. Việc này khiến nó phù hợp với các mô hình có tập dữ liệu lớn.\nThêm nữa, việc lưu trữ hai ma trận \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\) yêu cầu lượng bộ nhớ nhỏ khi so với việc lưu toàn bộ Similarity matrix trong Neighborhood-based Collaborative Filtering. Cụ thể, ta cần bộ nhớ để chứa \\(K(M+N)\\) phần tử thay vì lưu \\(M^2\\) hoặc \\(N^2\\) của Similarity matrix.\nTiếp theo, chúng ta cùng đi xây dựng hàm mất mát và cách tối ưu nó.\n\n\nTương tự như trong Content-based Recommendation Systems, việc xây dựng hàm mất mát cũng được dựa trên các thành phần đã được điền của Utility Matrix \\(\\mathbf{Y}\\), có khác một chút là không có thành phần bias và biến tối ưu là cả \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\). Việc thêm bias vào sẽ được thảo luận ở Mục 4. Việc xây dựng hàm mất mát cho Matrix Factorization là tương đối dễ hiểu:\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{W}) = \\frac{1}{2s} \\sum_{n=1}^N \\sum_{m:r_{mn} = 1} (y_{mn} - \\mathbf{x}_m\\mathbf{w}_n)^2 + \\frac{\\lambda}{2} (||\\mathbf{X}||_F^2 + ||\\mathbf{W}||_F^2) ~~~~~ (1)\n\\]\ntrong đó \\(r_{mn} = 1\\) nếu item thứ \\(m\\) đã được đánh giá bởi user thứ \\(n\\), \\(||\\bullet||_F^2\\) là Frobineous norm, tức căn bậc hai của tổng bình phương tất cả các phần tử của ma trận (giống với norm 2 trong vector), \\(s\\) là toàn bộ số ratings đã có. Thành phần thứ nhất chính là trung bình sai số của mô hình. Thành phần thứ hai trong hàm mất mát phía trên là \\(l_2\\) regularization, giúp tránh overfitting.\nLưu ý: Giá trị ratings thường là các giá trị đã được chuẩn hoá, bằng cách trừ mỗi hàng của Utility Matrix đi trung bình cộng của các giá trị đã biết của hàng đó (item-based) hoặc trừ mỗi cột đi trung bình cộng của các giá trị đã biết trong cột đó (user_based). Trong một số trường hợp nhất định, ta không cần chuẩn hoá ma trận này, nhưng kèm theo đó phải có thêm các kỹ thuật khác để giải quyết vấn đề thiên lệch trong khi rating.\nViệc tối ưu đồng thời \\(\\mathbf{X}, \\mathbf{W}\\) là tương đối phức tạp, thay vào đó, phương pháp được sử dụng là lần lượt tối ưu một ma trận trong khi cố định ma trận kia, tới khi hội tụ.\n\nKhi cố định \\(\\mathbf{X}\\), việc tối ưu \\(\\mathbf{W}\\) chính là bài toán tối ưu trong Content-based Recommendation Systems:\n\\[\n\\mathcal{L}(\\mathbf{W}) = \\frac{1}{2s} \\sum_{n=1}^N \\sum_{m:r_{mn} = 1} (y_{mn} - \\mathbf{x}_m\\mathbf{w}_n)^2 + \\frac{\\lambda}{2} ||\\mathbf{W}||_F^2 ~~~~~ (2)\n\\]\nKhi cố định \\(\\mathbf{W}\\), việc tối ưu \\(\\mathbf{X}\\) được đưa về tối ưu hàm:\n\\[\n\\mathcal{L}(\\mathbf{X}) = \\frac{1}{2s} \\sum_{n=1}^N \\sum_{m:r_{mn} = 1} (y_{mn} - \\mathbf{x}_m\\mathbf{w}_n)^2 + \\frac{\\lambda}{2} ||\\mathbf{X}||_F^2 ~~~~~ (3)\n\\]\nHai bài toán này sẽ được tối ưu bằng Gradient Descent.\nChúng ta có thể thấy rằng bài toán \\((2)\\) có thể được tách thành \\(N\\) bài toán nhỏ, mỗi bài toán ứng với việc đi tối ưu một cột của ma trận \\(\\mathbf{W}\\): \n\\[\n\\mathcal{L}(\\mathbf{w}_n) = \\frac{1}{2s} \\sum_{m:r_{mn} = 1} (y_{mn} - \\mathbf{x}_m\\mathbf{w}_n)^2 + \\frac{\\lambda}{2}||\\mathbf{w}_n||_2^2 ~~~~ (4)\n\\]\nVì biểu thức trong dấu \\(\\sum\\) chỉ phụ thuộc vào các items đã được rated bởi user đang xét, ta có thể đơn giản nó bằng cách đặt \\(\\hat{\\mathbf{X}}_n\\) là ma trận được tạo bởi các hàng tương ứng với các items đã được rated đó, và \\(\\hat{\\mathbf{y}}_n\\) là các ratings tương ứng. Khi đó: \n\\[\n\\mathcal{L}(\\mathbf{w}_n) = \\frac{1}{2s} ||\\hat{\\mathbf{y}}_n - \\hat{\\mathbf{X}}_n\\mathbf{w}_n||^2 + \\frac{\\lambda}{2}||\\mathbf{w}_n||_2^2 ~~~~~(5)\n\\]\nvà đạo hàm của nó: \n\\[\n\\frac{\\partial \\mathcal{L}(\\mathbf{w}_n)}{\\partial \\mathbf{w}_n} = -\\frac{1}{s}\\hat{\\mathbf{X}}_n^T(\\hat{\\mathbf{y}}_n - \\hat{\\mathbf{X}}_n\\mathbf{w}_n) + \\lambda \\mathbf{w}_n ~~~~~ (6)\n\\]\nVậy công thức cập nhật cho mỗi cột của \\(\\mathbf{W}\\) là: \n\\[\n\\mathbf{w}_n = \\mathbf{w}_n - \\eta \\left(-\\frac{1}{s}\\hat{\\mathbf{X}}_n^T (\\hat{\\mathbf{y}}_n - \\hat{\\mathbf{X}}_n\\mathbf{w}_n) + \\lambda \\mathbf{w}_n\\right) ~~~~~(7)\n\\]\nTương tự như thế, mỗi cột của \\(\\mathbf{X}\\), tức vector cho mỗi item, sẽ được tìm bằng cách tối ưu: \n\\[\n\\begin{eqnarray}\n\\mathcal{L}(\\mathbf{x}_m) &=& \\frac{1}{2s}\\sum_{n:r_{mn} = 1} (y_{mn} - \\mathbf{x}_m\\mathbf{w}_n)^2 + \\frac{\\lambda}{2}||\\mathbf{x}_m||_2^2 ~~~~ (8)\n\\end{eqnarray}\n\\]\nĐặt \\(\\hat{\\mathbf{W}}_m\\) là ma trận được tạo bằng các cột của \\(\\mathbf{W}\\) ứng với các users đã đánh giá item đó và \\(\\hat{\\mathbf{y}}^m\\) là vector ratings tương ứng. \\((8)\\) trở thành:\n\\[\n\\mathcal{L}(\\mathbf{x}_m)\n = \\frac{1}{2s}||\\hat{\\mathbf{y}}^m - {\\mathbf{x}}_m\\hat{\\mathbf{W}}_m||_2^2 + \\frac{\\lambda}{2} ||\\mathbf{x}_m||_2^2 ~~~~~ (9)\n\\]\nTương tự như trên, công thức cập nhật cho mồi hàng của \\(\\mathbf{X}\\) sẽ có dạng:\n\\[\n\\mathbf{x}_m = \\mathbf{x}_m - \\eta\\left(-\\frac{1}{s}(\\hat{\\mathbf{y}}^m - \\mathbf{x}_m\\hat{\\mathbf{W}}_m)\\hat{\\mathbf{W}}_m^T + \\lambda \\mathbf{x}_m\\right) ~~~~~ (10)\n\\]\nBạn đọc có thể muốn xem thêm Đạo hàm của hàm nhiều biến\n\nTiếp theo, chúng ta sẽ đi sâu vào phần lập trình.\n\nKhởi tạo và chuẩn hoá:\nTính giá trị hàm mất mát:\nXác định các items được đánh giá bởi 1 user, và users đã đánh giá 1 item và các ratings tương ứng:\nCập nhật \\(\\mathbf{X}, \\mathbf{W}\\):\nPhần thuật toán chính:\nDự đoán:\nĐánh giá kết quả bằng cách đo Root Mean Square Error:\n\nChúng ta cùng quay lại với cơ sở dữ liệu MovieLens 100k\nKết quả nếu sư dụng cách chuẩn hoá dựa trên user:\nTa nhận thấy rằng giá trị loss giảm dần và RMSE train cũng giảm dần khi số vòng lặp tăng lên. RMSE có cao hơn so với Neighborhood-based Collaborative Filtering (~0.99) một chút nhưng vẫn tốt hơn kết quả của Content-based Recommendation Systems rất nhiều (~1.2).\nNếu chuẩn hoá dựa trên item:\nKết quả có tốt hơn một chút.\nChúng ta cùng làm thêm một thí nghiệm nữa khi không sử dụng regularization, tức lam = 0:\nNếu các bạn chạy đoạn code trên, các bạn sẽ thấy chất lượng của mô hình giảm đi rõ rệt (RMSE cao).\n\nTiếp theo, chúng ta cùng đến với một bộ cơ sở dữ liệu lớn hơn là MovieLens 1M bao gồm xấp xỉ 1 triệu ratings của 6000 người dùng lên 4000 bộ phim. Đây là một bộ cơ sở dữ liệu lớn, thời gian training cũng sẽ tăng theo. Bạn đọc cũng có thể thử áp dụng mô hình Neighborhood-based Collaborative Filtering lên cơ sở dữ liệu này để so sánh kết quả. Tôi dự đoán là thời gian training sẽ nhanh nhưng thời gian inference sẽ rất lâu.\nLoad dữ liệu:\nTách tập training và test, sử dụng 1/3 dữ liệu cho test\nÁp dụng Matrix Factorization:\nKết quả khá ấn tượng sau 10 vòng lặp. Kết quả khi áp dụng Neighborhood-based Collaborative Filtering là khoảng 0.92 nhưng thời gian inference khá lớn.\n\n\nMột lợi thế của hướng tiếp cận Matrix Factorization cho Collaborative Filtering là khả năng linh hoạt của nó khi có thêm các điều kiện ràng buộc khác, các điều kiện này có thể liên quan đến quá trình xử lý dữ liệu hoặc đến từng ứng dụng cụ thể.\nGiả sử ta chưa chuẩn hoá các giá trị ratings mà sử dụng trực tiếp giá trị ban đầu của chúng trong đẳng thức \\((1)\\). Việc chuẩn hoá cũng có thể được tích hợp trực tiếp vào trong hàm mất mát. Như tôi đã đề cập, các ratings thực tế đều có những thiên lệch về users hoặc/và items. Có user dễ và khó tính, cũng có những item được rated cao hơn những items khác chỉ vì user thấy các users khác đã đánh giá item đó cao rồi. Vấn đề thiên lệch có thể được giải quyết bằng các biến gọi là biases, phụ thuộc vào mỗi user và item và có thể được tối ưu cùng với \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\). Khi đó, ratings của user \\(n\\) lên item \\(m\\) không chỉ được xấp xỉ bằng \\(\\mathbf{x}_m\\mathbf{w}_n\\) mà còn phụ thuộc vào các biases của item \\(m\\) và user \\(n\\) nữa. Ngoài ra, giá trị này cũng có thể phụ thuộc vào giá trị trung bình của toàn bộ ratings nữa:\n\\[\ny_{mn} \\approx \\mathbf{x}_m \\mathbf{w}_n + b_m + d_n + \\mu\n\\]\nvới \\(b_m, d_n, \\mu\\) lần lượt là bias của item \\(m\\), user \\(n\\), và giá trị trung bình của toàn bộ các ratings (là hằng số).\nLúc này, hàm mất mát có thể được thay đổi thành: \n\\[\n\\begin{eqnarray}\n\\mathcal{L}(\\mathbf{X}, \\mathbf{W}, \\mathbf{b}, \\mathbf{d}) &=& \\frac{1}{2s} \\sum_{n=1}^N \\sum_{m:r_{mn} = 1} (\\mathbf{x}_m\\mathbf{w}_n + b_m + d_n +\\mu - y_{mn})^2 + \\newline \n&& + \\frac{\\lambda}{2} (||\\mathbf{X}||_F^2 + ||\\mathbf{W}||_F^2 + ||\\mathbf{b}||_2^2  + ||\\mathbf{d}||_2^2)\n\\end{eqnarray}\n\\]\nViệc tính toán đạo hàm cho từng biến không quá phức tạp, tôi sẽ không bàn tiếp ở đây. Tuy nhiên, nếu bạn quan tâm, bạn có thể tham khảo source code mà tôi viết tại đây. Link này cũng kèm theo các ví dụ nêu trong Mục 3 và dữ liệu liên quan.\n\nKhi dữ liệu chưa được chuẩn hoá, chúng đều mang các giá trị không âm. Nếu dải giá trị của ratings có chứa giá trị âm, ta chỉ cần cộng thêm vào Utility Matrix một giá trị hợp lý để có được các ratings là các số không âm. Khi đó, một phương pháp Matrix Factorization khác cũng được sử dụng rất nhiều và mang lại hiệu quả cao trong Recommendation Systems là Nonnegative Matrix Factorization, tức phân tích ma trận thành tích các ma trận có các phần tử không âm.\nBằng Matrix Factorization, các users và items được liên kết với nhau bởi các latent features (tính chất ẩn). Độ liên kết của mỗi user và item tới mỗi latent feature được đo bằng thành phần tương ứng trong feature vector hệ số của chúng, giá trị càng lớn thể hiện việc user hoặc item có liên quan đến latent feature đó càng lớn. Bằng trực giác, sự liên quan của một user hoặc item đến một latent feature nên là một số không âm với giá trị 0 thể hiện việc không liên quan. Hơn nữa, mỗi user và item chỉ liên quan đến một vài latent feature nhất định. Vậy nên feature vectors cho users và items nên là các vectors không âm và có rất nhiều giá trị bằng 0. Những nghiệm này có thể đạt được bằng cách cho thêm ràng buộc không âm vào các thành phần của \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\).\nBạn đọc muốn tìm hiểu thêm về Nonnegative Matrix Factorization có thể tham khảo các tài liệu ở Mục 6.\n\nNhư đã đề cập, thời gian inference của Recommendation Systems sử dụng Matrix Factorization là rất nhanh nhưng thời gian training là khá lâu với các tập dữ liệu lớn. Thực tế cho thấy, Utility Matrix thay đổi liên tục vì có thêm users, items cũng như các ratings mới hoặc user muốn thay đổi ratings của họ, vì vậy hai ma trận \\(\\mathbf{X}\\) và \\(\\mathbf{W}\\) phải thường xuyên được cập nhật. Điều này đồng nghĩa với việc ta phải tiếp tục thực hiện quá trình training vốn tốn khá nhiều thời gian.\nViệc này được giải quyết phần nào bằng Incremental Matrix Factorization. Bạn đọc quan tâm có thể đọc Fast incremental matrix factorization for recommendation with positive-only feedback.\n\nBài toán Matrix Factorization có nhiều hướng giải quyết khác ngoài Gradient Descent. Bạn đọc có thể xem thêm Alternating Least Square (ALS), Generalized Low Rank Models. Trong bài tiếp theo, tôi sẽ viết về Singular Value Decomposition (SVD), một phương pháp phổ biến trong Matrix Factorization,  được sử dụng không những trong (Recommendation) Systems mà còn trong nhiều hệ thống khác. Mời các bạn đón đọc.\nSource code\n\n[1] Recommendation Systems - Stanford InfoLab\n[2] Collaborative Filtering - Stanford University\n[3] Recommendation systems - Machine Learning - Andrew Ng\n[4] Ekstrand, Michael D., John T. Riedl, and Joseph A. Konstan. “Collaborative filtering recommender systems.” Foundations and Trends® in Human–Computer Interaction 4.2 (2011): 81-173.\n[5] Matrix factorization techniques for recommender systems\n[6] Matrix Factorization For Recommender Systems\n[7] Learning from Incomplete Ratings Using Non-negative Matrix Factorization\n[8] Fast Incremental Matrix Factorization for Recommendation with Positive-Only Feedback"
    },
    {
        "ID": 25,
        "URL": "https://machinelearningcoban.com/2017/05/24/collaborativefiltering/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\nTrong Content-based Recommendation Systems, chúng ta đã làm quen với một Hệ thống gợi ý sản phẩm đơn giản dựa trên đặc trưng của mỗi item. Đặc điểm của Content-based Recommendation Systems là việc xây dựng mô hình cho mỗi user không phụ thuộc vào các users khác mà phụ thuộc vào profile của mỗi items. Việc làm này có lợi thế là tiết kiệm bộ nhớ và thời gian tính toán. Đồng thời, hệ thống có khả năng tận dụng các thông tin đặc trưng của mỗi item như được mô tả trong bản mô tả (description) của mỗi item. Bản mô tả này có thể được xây dựng bởi nhà cung cấp hoặc được thu thập bằng cách yêu cầu users gắn tags cho items. Việc xây dựng feature vector cho mỗi item thường bao gồm các kỹ thuật Xử lý ngôn ngữ tự nhiên (Natural Language Processing - NLP).\nCách làm trên có hai nhược điểm cơ bản. Thứ nhất, khi xây dựng mô hình cho một user, các hệ thống Content-based không tận dụng được thông tin từ các users khác. Những thông tin này thường rất hữu ích vì hành vi mua hàng của các users thường được nhóm thành một vài nhóm đơn giản; nếu biết hành vi mua hàng của một vài users trong nhóm, hệ thống nên suy luận ra hành vi của những users còn lại. Thứ hai, không phải lúc nào chúng ta cũng có bản mô tả cho mỗi item. Việc yêu cầu users gắn tags còn khó khăn hơn vì không phải ai cũng sẵn sàng làm việc đó; hoặc có làm nhưng sẽ mang xu hướng cá nhân. Các thuật toán NLP cũng phức tạp hơn ở việc phải xử lý các từ gần nghĩa, viết tắt, sai chính tả, hoặc được viết ở các ngôn ngữ khác nhau.\nNhững nhược điểm phía trên có thể được giải quyết bằng Collaborative Filtering (CF). Trong bài viết này, tôi sẽ trình bày tới các bạn một phương pháp CF có tên là Neighborhood-based Collaborative Filtering (NBCF). Bài tiếp theo sẽ trình bày về một phương pháp CF khác có tên Matrix Factorization Collaborative Filtering. Khi chỉ nói Collaborative Filtering, chúng ta sẽ ngầm hiểu rằng phương pháp được sử dụng là Neighborhood-based.\nÝ tưởng cơ bản của NBCF là xác định mức độ quan tâm của một user tới một item dựa trên các users khác gần giống với user này. Việc gần giống nhau giữa các users có thể được xác định thông qua mức độ quan tâm của các users này tới các items khác mà hệ thống đã biết.  Ví dụ, A, B đều thích phim Cảnh sát hình sự, tức đều rate bộ phim này 5 sao. Ta đã biết A cũng thích Người phán xử, vậy nhiều khả năng B cũng thích bộ phim này.\nCác bạn có thể đã hình dung ra, hai câu hỏi quan trọng nhất trong một hệ thống Neighborhood-based Collaborative Filtering là:\nViệc xác định mức độ quan tâm của mỗi user tới một item dựa trên mức độ quan tâm của similar users tới item đó còn được gọi là User-user collaborative filtering. Có một hướng tiếp cận khác được cho là làm việc hiệu quả hơn là Item-item collaborative filtering. Trong hướng tiếp cận này, thay vì xác định user similarities, hệ thống sẽ xác định item similarities. Từ đó, hệ thống gợi ý những items gần giống với những items mà user có mức độ quan tâm cao.\nCấu trúc của bài viết như sau: Mục 2 sẽ trình bày User-user Collaborative Filtering. Mục 3 sẽ nêu một số hạn chế của  User-user Collaborative Filtering và cách khắc phục bằng Item-item Collaborative Filtering. Kết quả của hai phương pháp này sẽ được trình bày qua ví dụ trên cơ sở dữ liệu MovieLens 100k trong Mục 4. Một vài thảo luận và Tài liệu tham khảo được cho trong Mục 5 và 6.\n\n\nCông việc quan trọng nhất phải làm trước tiên trong User-user Collaborative Filtering là phải xác định được sự giống nhau (similarity) giữa hai users. Dữ liệu duy nhất chúng ta có là Utility matrix \\(\\mathbf{Y}\\), vậy nên sự giống nhau này phải được xác định dựa trên các cột tương ứng với hai users trong ma trận này. Xét ví dụ trong Hình 1.\nGiả sử có các users từ \\(u_0\\) đến \\(u_6\\) và các items từ \\(i_0\\) đến \\(i_4\\) trong đó các số trong mỗi ô vuông thể hiện số sao mà mỗi user đã rated cho item với giá trị cao hơn thể hiện mức độ quan tâm cao hơn. Các dấu hỏi chấm là các giá trị mà hệ thống cần phải đi tìm. Đặt mức độ giống nhau của hai users \\(u_i, u_j\\) là \\(\\text{sim}(u_i, u_j)\\).\nQuan sát đầu tiên chúng ta có thể nhận thấy là các \\(u_0, u_1\\) thích \\(i_0, i_1, i_2\\) và không thích \\(i_3, i_4\\) cho lắm. Điều ngược lại xảy ra ở các users còn lại. Vì vậy, một similiarity function tốt cần đảm bảo:\n\\[\\text{sim}(u_0, u_1) > \\text{sim}(u_0, u_i), ~\\forall i > 1.\\]\nTừ đó, để xác định mức độ quan tâm của \\(u_0\\) lên \\(i_2\\), chúng ta nên dựa trên hành vi của \\(u_1\\) lên sản phẩm này. Rất may rằng \\(u_1\\) đã thích \\(i_2\\) nên hệ thống cần recommend \\(i_2\\) cho \\(u_0\\).\nCâu hỏi đặt ra là: hàm số similarity nào là tốt? Để đo similarity giữa hai users, cách thường làm là xây dựng feature vector cho mỗi user rồi áp dụng một hàm có khả năng đo similarity giữa hai vectors đó. Chú ý rằng việc xây dựng feature vector này khác với việc xây dựng item profiles như trong Content-based Recommendation Systems. Các vectors này được xây dựng trực tiếp dựa trên Utility matrix chứ không dùng dữ liệu ngoài như item profiles. Với mỗi user, thông tin duy nhất chúng ta biết là các ratings mà user đó đã thực hiện, tức cột tương ứng với user đó trong Utility matrix. Tuy nhiên, khó khăn là các cột này thường có rất nhiều mising ratings vì mỗi user thường chỉ rated một số lượng rất nhỏ các items. Cách khắc phục là bằng cách nào đó, ta giúp hệ thống điền các giá trị này sao cho việc điền không làm ảnh hưởng nhiều tới sự giống nhau giữa hai vector. Việc điền này chỉ phục vụ cho việc tính similarity chứ không phải là suy luận ra giá trị cuối cùng.\nVậy mỗi dấu ‘?’ nên được thay bởi giá trị nào để hạn chế việc sai lệch quá nhiều? Một lựa chọn bạn có thể nghĩ tới là thay các dấu ‘?’ bằng giá trị ‘0’. Điều này không thực sự tốt vì giá trị ‘0’ tương ứng với mức độ quan tâm thấp nhất. Một giá trị an toàn hơn là 2.5 vì nó là trung bình cộng của 0, mức thấp nhất, và 5, mức cao nhất. Tuy nhiên, giá trị này có hạn chế đối với những users dễ tính hoặc khó tính. Với các users dễ tính, thích tương ứng với 5 sao, không thích có thể ít sao hơn 1 chút, 3 sao chẳng hạn. Việc chọn giá trị 2.5 sẽ khiến cho các items còn lại là quá negative đối với user đó. Điều ngược lại xảy ra với những user khó tính hơn khi chỉ cho 3 sao cho các items họ thích và ít sao hơn cho những items họ không thích.\nMột giá trị khả dĩ hơn cho việc này là trung bình cộng của các ratings mà user tương ứng đã thực hiện. Việc này sẽ tránh được việc users quá khó tính hoặc dễ tính, tức lúc nào cũng có những items mà một user thích hơn so với những items khác.\nHãy cùng xem ví dụ trong Hình 2a) và 2b).\nChuẩn hoá dữ liệu:\nHàng cuối cùng trong Hình 2a) là giá trị trung bình của ratings cho mỗi user. Giá trị cao tương ứng với các user dễ tính và ngược lại. Khi đó, nếu tiếp tục trừ từ mỗi rating đi giá trị này và thay các giá trị chưa biết bằng 0, ta sẽ được normalized utility matrix như trong Hình 2b). Bạn có thể thắc mắc tại sao bước chuẩn hoá này lại quan trọng, câu trả lời ở ngay đây:\nSau khi đã chuẩn hoá dữ liệu như trên, một vài similiraty function thường được sử dụng là:\nCosine Similarity:\nĐây là hàm được sử dụng nhiều nhất, và cũng quen thuộc với các bạn nhất. Nếu các bạn không nhớ công thức tính \\(\\text{cos}\\) của góc giữa hai vector \\(\\mathbf{u}_1, \\mathbf{u}_2\\) trong chương trình phổ thông, thì dưới đây là công thức:\n\\[\n\\text{cosine_similarity}(\\mathbf{u}_1, \\mathbf{u}_2) =\\text{cos}(\\mathbf{u}_1, \\mathbf{u}_2) \n=  \\frac{\\mathbf{u}_1^T\\mathbf{u}_2}{ ||\\mathbf{u}_1||_2.||\\mathbf{u}_2||_2}~~~~ (1)\n\\]\nTrong đó \\(\\mathbf{u}_{1, 2}\\) là vectors tương ứng với users 1, 2 đã được chuẩn hoá như ở trên.\nCó một tin vui là python có hàm hỗ trợ tính toán hàm số này một cách hiệu quả.\nĐộ similarity của hai vector là 1 số trong đoạn [-1, 1]. Giá trị bằng 1 thể hiện hai vector hoàn toàn similar nhau. Hàm số \\(\\text{cos}\\) của một góc bằng 1 nghĩa là góc giữa hai vector bằng 0, tức một vector bằng tích của một số dương với vector còn lại. Giá trị \\(\\text{cos}\\) bằng -1 thể hiện hai vector này hoàn toàn trái ngược nhau. Điều này cũng hợp lý , tức khi hành vi của hai users là hoàn toàn ngược nhau thi similarity giữa hai vector đó là thấp nhất.\nVí dụ về cosine_similarity của các users trong Hình 2b) được cho trong Hình 2c). Similarity matrix \\(\\mathbf{S}\\) là một ma trận đối xứng vì \\(\\text{cos}\\) là một hàm chẵn, và nếu user A giống user B thì điều ngược lại cũng đúng. Các ô màu xanh trên đường chéo đều bằng 1 vì đó là \\(\\text{cos}\\) của góc giữa 1 vector và chính nó, tức \\(\\text{cos}(0) = 1\\). Khi tính toán ở các bước sau, chúng ta không cần quan tâm tới các giá trị 1 này. Tiếp tục quan sát các vector hàng tương ứng với \\(u_0, u_1, u_2\\), chúng ta sẽ thấy một vài điều thú vị:\n\\(u_0\\) gần với \\(u_1\\) và \\(u_5\\) (độ giống nhau là dương) hơn các users còn lại. Việc similarity cao giữa \\(u_0\\) và \\(u_1\\) là dễ hiểu vì cả hai đều có xu hướng quan tâm tới \\(i_0, i_1, i_2\\) hơn các items còn lại. Việc \\(u_0\\) gần với \\(u_5\\) thoạt đầu có vẻ vô lý vì \\(u_5\\) đánh giá thấp các items mà \\(u_0\\) đánh giá cao (Hình 2a)); tuy nhiên khi nhìn vào ma trận utility đã chuẩn hoá ở Hình 2b), ta thấy rằng điều này là hợp lý. Vì item duy nhất mà cả hai users này đã cung cấp thông tin là \\(i_1\\) với các giá trị tương ứng đều là tích cực.\n\\(u_1\\) gần với \\(u_0\\) và xa các users còn lại.\n\\(u_2\\) gần với \\(u_3, u_4, u_5, u_6\\) và xa các users còn lại.\nTừ similarity matrix này, chúng ta có thể phân nhóm các users ra làm hai nhóm \\((u_0, u_1)\\) và \\((u_2, u_3, u_4, u_5, u_6)\\). Vì ma trận \\(\\mathbf{S}\\) này nhỏ nên chúng ta có thể dễ dàng quan sát thấy điều này; khi số users lớn hơn, việc xác định bằng mắt thường là không khả thi. Việc xây dựng thuật toán phân nhóm các users (users clustering) rất có thể sẽ được trình bày ở một trong các bài viết tiếp theo.\nCó một chú ý quan trọng ở đây là khi số lượng users lớn, ma trận \\(\\mathbf{S}\\) cũng rất lớn và nhiều khả năng là không có đủ bộ nhớ để lưu trữ, ngay cả khi chỉ lưu hơn một nửa số các phần tử của ma trận đối xứng này. Với các trường hợp đó, mới mỗi user, chúng ta chỉ cần tính và lưu kết quả của một hàng của similarity matrix, tương ứng với việc độ giống nhau giữa user đó và các users còn lại.\nTrong bài viết này, tôi sẽ sử dụng similarity function này.\nPerson corelation:\nTôi xin không đi chi tiết về phần này, bạn đọc quan tâm có thể đọc thêm Pearson correlation coefficient - Wikipedia\n\nViệc xác định mức độ quan tâm của một user lên một item dựa trên các users gần nhất (neighbor users) này rất giống với những gì chúng ta thấy trong Bài 6: K-nearest neighbors. Khi làm việc với large-scale problems, chúng ta sẽ thấy thêm rằng phương pháp lười học K-nearest neighbors (KNN) được sử dụng rất nhiều vì tính đơn giản của nó. Tất nhiên, chúng ta không thể trực tiếp sử dụng KNN mà còn cần phải làm thêm nhiều bước trung gian nữa.\nTương tự như KNN, trong Collaborative Filtering, missing rating cũng được xác định dựa trên thông tin về \\(k\\) neighbor users. Tất nhiên, chúng ta chỉ quan tâm tới các users đã rated item đang xét. Predicted rating thường được xác định là trung bình có trọng số của các ratings đã chuẩn hoá. Có một điểm cần lưu ý, trong KNN, các trọng số được xác định dựa trên distance giữa 2 điểm, và các distance này là các số không âm. Trong khi đó, trong CF, các trọng số được xác định dựa trên similarity giữa hai users, những trọng số này có thể nhỏ hơn 0 như trong Hình 2c).\nCông thức phổ biến được sử dụng để dự đoán rating của \\(u\\) cho \\(i\\) là:\n\\[\n\\hat{y}_{i, u} = \\frac{\\sum_{u_j \\in \\mathcal{N}(u, i)} \\bar{y}_{i, u_j} \\text{sim}(u, u_j)}{\\sum_{u_j \\in \\mathcal{N}(u, i)} |\\text{sim}(u, u_j)|} ~~~~ (2)\n\\]\n(sự khác biết so với trung bình có trọng số là mẫu số có sử dụng trị tuyệt đối để xử lý các số âm).\ntrong đó \\(\\mathcal{N}(u, i)\\) là tập hợp \\(k\\) users trong neighborhood  (tức có similarity cao nhất) của \\(u\\) mà đã rated \\(i\\).\nHình 2d) thể hiện việc điền các giá trị còn thiếu trong normalized utility matrix. Các ô màu nền đỏ thể hiện các giá trị dương, tức các items mà có thể users đó quan tâm. Ở đây, tôi đã lấy ngưỡng bằng 0, chúng ta hoàn toàn có thể chọn các ngưỡng khác 0.\nMột ví dụ về việc tính normalized rating của \\(u_1\\) cho \\(i_1\\) được cho trong Hình 2e) với số nearest neighbors là \\(k = 2\\). Các bước thực hiện là:\nXác định các users đã rated \\(i_1\\), đó là \\(u_0, u_3, u_5\\).\nXác định similarities của \\(u_1\\) với các users này ta nhận được \\({0.83, -0.40, -0.23}\\). Hai (\\(k = 2\\)) giá trị lớn nhất là \\(0.83\\) và \\(-0.23\\) tương ứng với \\(u_0\\) và \\(u_5\\).\nXác định các normalized ratings của \\(u_0, u_5\\) cho \\(i_1\\), ta thu được hai giá trị lần lượt là \\(0.75\\) và \\(0.5\\).\nDự đoán kết quả:\n\\[\n\\hat{y}_{i_1, u_1} = \\frac{0.83\\times 0.75 + (-0.23)\\times 0.5}{0.83 + |-0.23|} \\approx 0.48\n\\]\nViệc quy đổi các giá trị ratings đã chuẩn hoá về thang 5 có thể được thực hiện bằng cách cộng các cột của ma trận \\(\\hat{\\mathbf{Y}}\\) với giá trị rating trung bình của mỗi user như đã tính trong Hình 2a).\nViệc hệ thống quyết định recommend items nào cho mỗi user có thể được xác định bằng nhiều cách khác nhau. Có thể sắp xếp unrated items theo thứ tự tự lớn đến bé của các predicted ratings, hoặc chỉ chọn các items có normalized predicted ratings dương - tương ứng với việc user này có nhiều khả năng thích hơn.\nTrước khi vào phần lập trình cho User-user CF, chúng ta cùng xem xét Item-item CF.\n\nMột số hạn chês của User-user CF:\nTrên thực tế, số lượng users luôn lớn hơn số lượng items rất nhiều. Kéo theo đó là Similarity matrix là rất lớn với số phần tử phải lưu giữ là hơn 1 nửa của bình phương số lượng users (chú ý rằng ma trận này là đối xứng). Việc này, như đã đề cập ở trên, khiến cho việc lưu trữ ma trận này trong nhiều trường hợp là không khả thi.\nMa trận Utility \\(\\mathbf{Y}\\) thường là rất sparse. Với số lượng users rất lớn so với số lượng items, rất nhiều cột của ma trận này sẽ rất sparse, tức chỉ có một vài phần tử khác 0. Lý do là users thường lười rating. Cũng chính vì việc này, một khi user đó thay đổi rating hoặc rate thêm items, trung bình cộng các ratings cũng như vector chuẩn hoá tương ứng với user này thay đổi nhiều. Kéo theo đó, việc tính toán ma trận Similarity, vốn tốn nhiều bộ nhớ và thời gian, cũng cần được thực hiện lại.\nNgược lại, nếu chúng ta tính toán similarity giữa các items rồi recommend những items gần giống với item yêu thích của một user thì sẽ có những lợi ích sau:\nVì số lượng items thường nhỏ hơn số lượng users, Similarity matrix trong trường hợp này cũng nhỏ hơn nhiều, thuận lợi cho việc lưu trữ và tính toán ở các bước sau.\nVì số lượng phần tử đã biết trong Utility matrix là như nhau nhưng số hàng (items) ít hơn số cột (users), nên trung bình, mỗi hàng của ma trận này sẽ có nhiều phần tử đã biết hơn số phần tử đã biết trong mỗi cột. Việc này cũng dễ hiểu vì mỗi item có thể được rated bởi nhiều users. Kéo theo đó, giá trị trung bình của mỗi hàng ít bị thay đổi hơn khi có thêm một vài ratings. Như vậy, việc cập nhật ma trận Similarity Matrix có thể được thực hiện ít thường xuyên hơn.\nCách tiếp cận thứ hai này được gọi là Item-item Collaborative Filtering. Hướng tiếp cận này được sử dụng nhiều trong thực tế hơn.\nQuy trình dự đoán missing ratings cũng tương tự như trong User-user CF. Hình 3 mô tả quy trình này với ví dụ nêu ở phần trên.\nCó một điểm thú vị trong Similarity matrix ở Hình 3c) là có các phần tử trong hai hình vuông xanh và đỏ đều là các số không âm, các phần tử bên ngoài là các số âm. Việc này thể hiện rằng các items có thể được chia thành 2 nhóm rõ rệt với những items có similarity không âm vào 1 nhóm. Như vậy, một cách vô tình, chúng ta đã thực hiện việc item clustering. Việc này sẽ giúp ích rất nhiều trong việc dự đoán ở phần sau.\nKết quả về việc chọn items nào để recommend cho mỗi user được thể hiện bởi các ô màu đỏ trong Hình 3d). Kết quả này có khác một chút so với kết quả tìm được bởi User-user CF ở 2 cột cuối cùng tương ứng với \\(u_5, u_6\\). Dường như kết quả này hợp lý hơn vì từ Utility Matrix, có hai nhóm users thích hai nhóm items khác nhau. (Bạn có nhận ra không?)\nVề mặt tính toán, Item-item CF có thể nhận được từ User-user CF bằng cách chuyển vị (transpose) ma trận utility, và coi như items đang rate users. Sau khi tính ra kết quả cuối cùng, ta lại chuyển vị một lần nữa để thu được kết quả.\nPhần 3 dưới đây sẽ mô tả cách lập trình cho Collaborative Filtering trên python. Chú ý rằng thư viện sklearn tôi vẫn dùng không có các modules cho Recommendation Systems.\n\nTrong bày này, tôi lập trình theo hướng Hướng Đối Tượng cho class CF. Class này được sử dụng chung cho cả User-user và Item-item CF. Trước hết, chúng ta sẽ thử nghiệm với ví dụ nhỏ trong bài, sau đó sẽ áp dụng vào bài toán với cơ sở dữ liệu MovieLens.\nDưới đây là file ex.dat mô tả dữ liệu đã biết cho ví dụ. Thứ tự của ba cột là user_id, item_id, và rating. Ví dụ, hàng đầu tiên nghĩa là u_0 rates i_0 số sao là 5.\nKhi làm việc với Item-item CF, chúng ta chỉ cần đổi vị trí của hai cột đầu tiên để nhận được ma trận chuyển vị.\n\nKhởi tạo class CF\nDữ liệu đầu vào của hàm khởi tạo class CF là ma trận Utility Y_data được lưu dưới dạng một ma trận với 3 cột, k là số lượng các điểm lân cận được sử dụng để dự đoán kết quả. dist_func là hàm đó similarity giữa hai vectors, mặc định là cosine_similarity được lấy từ sklearn.metrics.pairwise. Bạn đọc cũng có thể thử với các giá trị k và hàm dist_func khác nhau. Biến uuCF thể hiện việc đang sử dụng User-user CF (1) hay Item-item CF(0).\nKhi có dữ liệu mới, cập nhận Utility matrix bằng cách thêm các hàng này vào cuối Utility Matrix. Để cho đơn giản, giả sử rằng không có users hay items mới, cũng không có ratings nào bị thay đổi.\nTính toán normalized utility matrix và Similarity matrix\nThực hiện lại 2 hàm phía trên khi có thêm dữ liệu.\nDự đoán kết quả:\nHàm __pred là hàm dự đoán rating mà user u cho item i cho trường hợp User-user CF. Vì trong trường hợp Item-item CF, chúng ta cần hiểu ngược lại nên hàm pred sẽ thực hiện đổi vị trí hai biến của __pred. Để cho API được đơn giản, tôi cho __pred là một phương thức private, chỉ được gọi trong class CF; pred là một phương thức public, thứ tự của biến đầu vào luôn là (user, item), bất kể phương pháp sử dụng là User-user CF hay Item-item CF.\nTìm tất cả các items nên được gợi ý cho user u trong trường hợp User-user CF, hoặc tìm tất cả các users có khả năng thích item u trong trường hợp Item-item CF\nIn toàn bộ kết quả:\nSource code cho class này có thể được tìm thấy ở đây.\n\nChúng ta sẽ thử với User-user CF trước:\nKết quả:\nVới Item-item Collaborative Filtering:\nKết quả:\n\nChúng ta cùng quay lại làm với cơ sở dữ liệu MoiveLens 100k như trong Content-based Recommendation Systems. Nhắc lại rằng kết quả của phương pháp này có trung bình lỗi là 1.2 sao với mỗi rating.\nChúng ta cùng xem kết quả với User-user CF và Item-item CF.\nTrước hết, ta cần load dữ liệu.\nKết quả với User-user CF:\nKết quả với Item-item CF:\nTừ đó ta nhận thấy Item-item CF cho lỗi nhỏ hơn (0.987) so với User-user CF (0.995) và tốt hơn so với Content-based Recommendation Systems ở bài trước (1.2).\nCác bạn cũng có thể thay _neighborhood size k bằng các giá trị khác và so sánh kết quả._\n\nCollaborative Filtering là một phương pháp gợi ý sản phẩm với ý tưởng chính dựa trên các hành vi của các users khác (collaborative) cùng trên một item để suy ra mức độ quan tâm (filtering) của một user lên sản phẩm. Việc suy ra này được thực hiện dựa trên Similarity matrix đo độ giống nhau giữa các users.\nĐể tính được Similarity matrix, trước tiên ta cần chuẩn hoá dữ liệu. Phương pháp phổ biến là mean offset, tức trừ các ratings đi giá trị trung bình mà một user đưa ra cho các _items.\nSimilarity function thường được dụng là Cosine similarity hoặc Pearson correlation.\nUser-user CF có một vài hạn chế khi lượng users là lớn. Trong các trường hợp đó, Item-item thường được sử dụng và cho kết quả tốt hơn.\nSource code\n\n[1] Recommendation Systems - Stanford InfoLab\n[2] Collaborative Filtering - Stanford University\n[3] Recommendation systems - Machine Learning - Andrew Ng\n[4] Ekstrand, Michael D., John T. Riedl, and Joseph A. Konstan. “Collaborative filtering recommender systems.” Foundations and Trends® in Human–Computer Interaction 4.2 (2011): 81-173."
    },
    {
        "ID": 26,
        "URL": "https://machinelearningcoban.com/2017/05/17/contentbasedrecommendersys/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\n\nCác bạn có lẽ đã gặp những hiện tượng này nhiều lần:\nYoutube tự động chuyển các clip liên quan đến clip bạn đang xem. Youtube cũng tự gợi ý những clip mà có thể bạn sẽ thích.\nKhi bạn mua một món hàng trên Amazon, hệ thống sẽ tự động gợi ý “Frequently bought together”, hoặc nó biết bạn có thể thích món hàng nào dựa trên lịch sử mua hàng của bạn.\nFacebook hiển thị quảng cáo những sản phẩm có liên quan đến từ khoá bạn vừa tìm kiếm.\nFacebook gợi ý kết bạn.\nNetflix tự động gợi ý phim cho người dùng.\nVà rất nhiều ví dụ khác mà hệ thống có khả năng tự động gợi ý cho ngừời dùng những sản phẩm họ có thể thích. Bằng cách quảng cáo hướng đúng đội tượng như thế này, hiệu quả của việc marketing cũng sẽ tăng lên. Những thuật toán đằng sau những ứng dụng này là những thuật toán Machine Learning có tên gọi chung là Recommender Systems hoặc Recommendation Systems, tức Hệ thống gợi ý.\nRecommendation Systems là một mảng khá rộng của Machine Learning và có tuổi đời ít hơn so với Classification vì internet mới chỉ thực sự bùng nổ khoảng 10-15 năm đổ lại đây. Có hai thực thể chính trong Recommendation Systems là users và items. Users là người dùng. Items là sản phẩm, ví dụ như các bộ phim, bài hát, cuốn sách, clip, hoặc cũng có thể là các users khác trong bài toán gợi ý kết bạn. Mục đích chính của các Recommender Systems là dự đoán mức độ quan tâm của một user tới một item nào đó, qua đó có chiến lược recommend phù hợp.\n\n\nChúng ta cùng đi vào việc so sánh điểm khác nhau căn bản giữa các cửa hàng thực và cửa hàng điện tử, xét trên khía cạnh lựa chọn sản phẩm để quảng bá.\nCó thể các bạn đã biết tới Nguyên lý Pareto (hay quy tắc 20/80): phần lớn kết quả được gây ra bởi phẩn nhỏ nguyên nhân. Phần lớn số từ sử dụng hàng ngày chỉ là một phần nhỏ số từ trong bộ từ điển. Phần lớn của cải được sở hữu bởi phần nhỏ số người. Khi làm thương mại cũng vậy, những sản phẩm bán chạy nhất chỉ chiếm phần nhỏ tổng số sản phẩm.\nCác cửa hàng thực thường có hai khu vực, một là khu trưng bày, hai là kho. Nguyên tắc dễ thấy để đạt doanh thu cao là trưng ra các sản phẩm phổ biến nhất ở những nơi dễ nhìn thấy và những sản phẩm ít phổ biến hơn được cất trong kho. Cách làm này có một hạn chế rõ rệt: những sản phẩm được trưng ra mang tính phổ biến chứ chưa chắc đã phù hợp với một khách hàng cụ thể. Một cửa hàng có thể có món hàng một khách hàng tìm kiếm nhưng có thể không bán được vì khách hàng không nhìn thấy sản phẩm đó trên giá; việc này dẫn đến việc khách hàng không tiếp cận được sản phẩm ngay cả khi chúng đã được trưng ra. Ngoài ra, vì không gian có hạn, cửa hàng không thể trưng ra tất cả các sản phẩm mà mỗi loại chỉ đưa ra một số lượng nhỏ. Ở đây, phần lớn doanh thu (80%) đến từ phần nhỏ số sản phẩm phổ biến nhất (20%). Nếu sắp xếp các sản phẩm của cửa hàng theo doanh số từ cao đến thấp, ta sẽ nhận thấy có thể phần nhỏ các sản phẩm tạo ra phần lớn doanh số; và một danh sách dài phía sau chỉ tạo ra một lượng nhỏ đóng góp. Hiện tượng này còn được gọi là long tail phenomenon, tức phần đuôi dài của những sản phẩm ít phổ biến.\nVới các cửa hàng online, nhược điểm trên hoàn toàn có thể tránh được. Vì gian trưng bày của các cửa hàng online gần như là vô tận, mọi sản phẩm đều có thể được trưng ra. Hơn nữa, việc sắp xếp online là linh hoạt, tiện lợi với chi phí chuyển đổi gần như bằng 0 khiến việc mang đúng sản phẩm tới khách hàng trở nên thuận tiện hơn. Doanh thu, vì thế có thể được tăng lên.\n(Ở đây, chúng ta tạm quên đi khía cạnh có cảm giác thật chạm vào sản phẩm của các cửa hàng thực. Hãy cùng tập trung vào phần làm thế nào để quảng bá đúng sản phẩm tới đúng khách hàng)\n\n\nCác Recommendation Systems thường được chia thành hai nhóm lớn:\nContent-based systems: đánh giá đặc tính của items được recommended. Ví dụ: một user xem rất nhiều các bộ phim về cảnh sát hình sự, vậy thì gơi ý một bộ phim trong cơ sở dữ liệu có chung đặc tính hình sự tới user này, ví dụ phim Người phán xử. Cách tiếp cận này yêu cầu việc sắp xếp các items vào từng nhóm hoặc đi tìm các đặc trưng của từng item. Tuy nhiên, có những items không có nhóm cụ thể và việc xác định nhóm hoặc đặc trưng của từng item đôi khi là bất khả thi.\nCollaborative filtering: hệ thống gợi ý items dựa trên sự tương quan (similarity) giữa các users và/hoặc items. Có thể hiểu rằng ở nhóm này một item được recommended tới một user dựa trên những users có hành vi tương tự. Ví dụ: users A, B, C đều thích các bài hát của Noo Phước Thịnh. Ngoài ra, hệ thống biết rằng users B, C cũng thích các bài hát của  Bích Phương nhưng chưa có thông tin về việc liệu user A có thích Bích Phương hay không. Dựa trên thông tin của những users tương tự là B và C, hệ thống có thể dự đoán rằng A cũng thích Bích Phương và gợi ý các bài hát của ca sĩ này tới A.\nTrong bài viết này, chúng ta sẽ làm quen với nhóm thứ nhất: Content-based systems. Tôi sẽ nói về Collaborative filtering trong bài viết tiếp theo.\n\n\n\n\nNhư đã đề cập, có hai thực thể chính trong các Recommendation Systems là users và items. Mỗi user sẽ có mức độ quan tâm (degree of preference) tới từng item khác nhau. Mức độ quan tâm này, nếu đã biết trước, được gán cho một giá trị ứng với mỗi cặp user-item. Giả sử rằng mức độ quan tâm được đo bằng giá trị user rate cho item, ta tạm gọi giá trị này là rating. Tập hợp tất cả các ratings, bao gồm cả những giá trị chưa biết cần được dự đoán, tạo nên một ma trận gọi là utility matrix. Xét ví dụ sau:\nTrong ví dụ này, có 6 users A, B, C, D, E, F và 5 bài hát. Các ô màu xanh thể hiện việc một user đã đánh giá một bài hát với ratings từ 0 (không thích) đến 5 (rất thích). Các ô có dấu ‘?’ màu xám tương ứng với các ô chưa có dữ liệu. Công việc của một Recommendation Systems là dự đoán giá trị tại các ô màu xám này, từ đó đưa ra gợi ý cho người dùng. Recommendation Systems, vì vậy, đôi khi cũng được coi là bài toán Matrix Completion (Hoàn thiện ma trận).\nTrong ví dụ đơn giản này, dễ thấy có 2 thể loại nhạc khác nhau: 3 bài đầu là nhạc Bolero và 2 bài sau là nhạc Thiếu nhi. Từ dữ liệu này, ta cũng có thể đoán được rằng A, B thích thể loại Bolero; C, D, E, F thích thể loại Thiếu nhi. Từ đó, một hệ thống tốt nên gợi ý Cỏ úa cho B; Vùng lá me bay cho A,; Em yêu trường em cho D, E, F. Giả sử chỉ có hai thể loại nhạc này, khi có một bài hát mới, ta chỉ cần phân lớp nó vào thể loại nào, từ đó đưa ra gợi ý với từng người dùng.\nThông thường, có rất nhiều users và items trong hệ thống, và mỗi user thường chỉ rate một số lượng rất nhỏ các item, thậm chí có những user không rate item nào (với những users này thì cách tốt nhất là gợi ý các items phổ biến nhất). Vì vậy, lượng ô màu xám của utility matrix trong các bài toán đó thường là rất lớn, và lượng các ô đã được điền là một số rất nhỏ.\nRõ ràng rằng càng nhiều ô được điền thì độ chính xác của hệ thống sẽ càng được cải thiện. Vì vậy, các hệ thống luôn luôn hỏi người dùng về sự quan tâm của họ tới sản phẩm, và muốn người dùng đánh giá càng nhiều sản phẩm càng tốt. Việc đánh giá các sản phẩm, vì thế, không những giúp các người dùng khác biết được chất lượng sản phẩm mà còn giúp hệ thống biết được sở thích của người dùng, qua đó có chính sách quảng cáo hợp lý.\n\n\nKhông có Utility matrix, gần như không thể gợi ý được sản phẩm tới ngừời dùng, ngoài cách luôn luôn gợi ý các sản phẩm phổ biến nhất. Vì vậy, trong các Recommender Systems, việc xây dựng Utility Matrix là tối quan trọng. Tuy nhiên, việc xây dựng ma trận này thường có gặp nhiều khó khăn. Có hai hướng tiếp cận phổ biến để xác định giá trị rating cho mỗi cặp user-item trong Utility Matrix:\nNhờ người dùng rate sản phẩm. Amazon luôn nhờ người dùng rate các sản phẩm của họ bằng cách gửi các email nhắc nhở nhiều lần. Rất nhiều hệ thống khác cũng làm việc tương tự. Tuy nhiên, cách tiếp cận này có một vài hạn chế, vì thường thì người dùng ít khi rate sản phẩm. Và nếu có, đó có thể là những đánh giá thiên lệch bởi những người sẵn sàng rate.\nHướng tiếp cận thứ hai là dựa trên hành vi của users. Rõ ràng, nếu một người dùng mua một sản phẩm trên Amazon, xem một clip trên Youtube (có thể là nhiều lần), hay đọc một bài báo, thì có thể khẳng định rằng ngừời dùng đó thích sản phẩm đó. Facebook cũng dựa trên việc bạn like những nội dung nào để hiển thị newsfeed của bạn những nội dung liên quan. Bạn càng đam mê facebook, facebook càng được hưởng lợi, thế nên nó luôn mang tới bạn những thông tin mà khả năng cao là bạn muốn đọc. (Đừng đánh giá xã hội qua facebook). Thường thì với cách này, ta chỉ xây dựng được một ma trận với các thành phần là 1 và 0, với 1 thể hiện người dùng thích sản phẩm, 0 thể hiện chưa có thông tin. Trong trường hợp này, 0 không có nghĩa là thấp hơn 1, nó chỉ có nghĩa là ngừời dùng chưa cung cấp thông tin. Chúng ta cũng có thể xây dựng ma trận với các giá trị cao hơn 1 thông qua thời gian hoặc số lượt mà người dùng xem một sản phẩm nào đó. Đôi khi, nút dislike cũng mang lại những lợi ích nhất định cho hệ thống, lúc này có thể gán giá trị tương ứng bằng -1 chẳng hạn.\n\n\n\n\nTrong các hệ thống content-based, tức dựa trên nội dung của mỗi item, chúng ta cần xây dựng một bộ hộ sơ (profile) cho mỗi item. Profile này được biểu diễn dưới dạng toán học là một feature vector. Trong những trường hợp đơn giản, feature vector được trực tiếp trích xuất từ item. Ví dụ, xem xét các features của một bài hát mà có thể được sử dụng trong các Recommendation Systems:\nCó rất nhiều yếu tố khác của một bài hát có thể được sử dụng. Ngoại trừ Thể loại khó định nghĩa, các yếu tố khác đều được xác định rõ ràng.\nTrong ví dụ ở Hình 1 phía trên, chúng ta đơn giản hoá bài toán bằng việc xây dựng một feature vector hai chiều cho mỗi bài hát: chiều thứ nhất là mức độ Bolero, chiều thứ hai là mức độ Thiếu nhi của bài đó. Đặt các feature vector cho mỗi bài hát là \\(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3, \\mathbf{x}_4, \\mathbf{x}_5\\). Giả sử các feature vector (ở dạng hàng) cho mỗi bài hát được cho trong Hình 2 dưới đây:\nBài toán đi tìm mô hình \\(\\theta_i\\) cho mỗi user có thể được coi là một bài toán Regression trong trường hợp ratings là một dải giá trị, hoặc bài toán Classification trong trường hợp ratings là một vài trường hợp cụ thể, như like/dislike chẳng hạn. Dữ liệu training để xây dựng mỗi mô hình \\(\\theta_i\\) là các cặp (item profile, ratings) tương ứng với các items mà user đó đã rated. Việc điền các giá trị còn thiếu trong ma trận Utility chính là việc dự đoán đầu ra cho các unrated items khi áp dụng mô hình \\(\\theta_i\\) lên chúng.\nViệc lựa chọn mô hình Regression/Classification nào tuỳ thuộc vào ứng dụng. Tôi sẽ lấy ví dụ về một mô hình đơn giản nhất: mô hình tuyến tính, mà cụ thể là Linear Regression với regularization, tức Ridge Regression.\n\n\nGiả sử rằng số users là \\(N\\), số items là \\(M\\), utility maxtrix được mô tả bởi ma trận \\(\\mathbf{Y}\\). Thành phần ở hàng thứ \\(m\\), cột thứ \\(n\\) của \\(\\mathbf{Y}\\) là mức độ quan tâm (ở đây là số sao đã rate) của user thứ \\(n\\) lên sản phẩm thứ \\(m\\) mà hệ thống đã thu thập được. Ma trận \\(\\mathbf{Y}\\) bị khuyết rất nhiều thành phần tương ứng với các giá trị mà hệ thống cần dự đoán. Thêm nữa, gọi \\(\\mathbf{R}\\) là ma trận rated or not thể hiện việc một user đã rated một item hay chưa. Cụ thể, \\(r_{ij}\\) bằng 1 nếu item thứ \\(i\\) đã được rated bởi user thứ \\(j\\), bằng 0 trong trường hợp ngược lại.\nMô hình tuyến tính:\nGiả sử rằng ta có thể tìm được một mô hình cho mỗi user, minh hoạ bởi vector cột hệ số \\(\\mathbf{w}_i\\) và bias \\(b_n\\) sao cho mức độ quan tâm của một user tới một item có thể tính được bằng một hàm tuyến tính:\n\\[\ny_{mn} = \\mathbf{x}_m \\mathbf{w}_n + b_n ~~~~(1)\n\\]\n(Chú ý rằng \\(\\mathbf{x}_m\\) là một vector hàng, \\(\\mathbf{w}_n\\) là một vector cột.)\nXét một user thứ \\(n\\) bất kỳ, nếu ta coi training set là tập hợp các thành phần đã được điền của \\(\\mathbf{y}_n\\), ta có thể xây dựng hàm mất mát tương tự như Ridge Regression như sau:\n\\[\n\\mathcal{L}_n = \\frac{1}{2} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x}_m \\mathbf{w}_n + b_n - y_{mn})^2 + \\frac{\\lambda}{2} ||\\mathbf{w}_n||_2^2 \n\\]\nTrong đó, thành phần thứ hai là regularization term và \\(\\lambda\\) là một tham số dương. Chú ý rằng regularization thường không được áp dụng lên bias \\(b_n\\). Trong thực hành, trung bình cộng của lỗi thường được dùng, và mất mát \\(\\mathcal{L}_n\\) được viết lại thành:\n\\[\n\\mathcal{L}_n = \\frac{1}{2s_n} \\sum_{m~:~ r_{mn} = 1}(\\mathbf{x}_m \\mathbf{w}_n + b_n - y_{mn})^2 + \\frac{\\lambda}{2s_n} ||\\mathbf{w}_n||_2^2 \n\\]\nTrong đó \\(s_n\\) là số lượng các items mà user thứ \\(n\\) đã rated. Nói cách khác: \n\\[\ns_n = \\sum_{m=1}^M r_{mn},\n\\]\nlà tổng các phần tử trên cột thứ \\(n\\) của ma trận rated or not \\(\\mathbf{R}\\).\nCác bạn đã thấy loss function này quen chưa?\nVì biểu thức loss function chỉ phụ thuộc vào các items đã được rated, ta có thể rút gọn nó bằng cách đặt \\(\\hat{\\mathbf{y}}_n\\) là sub vector của \\(\\mathbf{y}\\) được xây dựng bằng cách trích các thành phần khác dấu ? ở cột thứ \\(n\\), tức đã được rated bởi user thứ \\(n\\) trong Utility Matrix \\(\\mathbf{Y}\\). Đồng thời, đặt \\(\\hat{\\mathbf{X}}_n\\) là sub matrix của ma trận feature \\(\\mathbf{X}\\), được tạo bằng cách trích các hàng tương ứng với các items đã được rated bởi user thứ \\(n\\). (Xem ví dụ phía dưới để hiểu rõ hơn). Khi đó, biểu thức hàm mất mát của mô hình cho user thứ \\(n\\) được viết gọn thành:\n\\[\n\\mathcal{L}_n = \\frac{1}{2s_n} ||\\hat{\\mathbf{X}}_n\\mathbf{w}_n + b_n \\mathbf{e}_n- \\hat{\\mathbf{y}}_n||_2^2 + \\frac{\\lambda}{2s_n} ||\\mathbf{w}_n||_2^2\n\\]\ntrong đó, \\(\\mathbf{e}_n\\) là vector cột chứa \\(s_n\\) phần tử 1.\nĐây chính xác là hàm mất mát của Ridge Regression. Cặp nghiệm \\(\\mathbf{w}_n, b_n\\) có thể được tìm qua Stochastic Gradient Descent (SGD), hoặc Mini-batch GD. Tôi không đi sâu vào việc tính đạo hàm theo \\(\\mathbf{w}_n\\) và \\(b_n\\) của \\(\\mathcal{L}_n\\) nữa. Việc này đã được đề cập nhiều trong các bài trước. Trong bài này, tôi sẽ sử dụng class Ridge trong sklearn.linear_model.\nNếu vẫn có điểm chưa hiểu, bạn đọc có thể xem ví dụ nhỏ dưới đây:\n\n\nQuay trở lại với ví dụ trong hình 2, feature matrix cho các items (mỗi hàng tương ứng với một item) là: \n\\[\n\\mathbf{X} = \n\\left[\n\\begin{matrix}\n0.99 & 0.02 \\newline\n0.91 & 0.11 \\newline\n0.95 & 0.05 \\newline\n0.01 & 0.99 \\newline\n0.03 & 0.98\n\\end{matrix}\n\\right]\n\\]\nXét trường hợp của user E với \\(n = 5\\), \\(\\mathbf{y}_5 = [1, ?, ?, 4, ?]^T \\Rightarrow \\mathbf{r}_5 = [1, 0, 0, 1, 0]^T\\). Vì E mới chỉ rated cho items thứ nhất và thứ tư nên \\(s_5 = 2\\). Hơn nữa:\n\\[\n\\hat{\\mathbf{X}}_5 = \n\\left[\n\\begin{matrix}\n0.99 & 0.02 \\newline\n0.01 & 0.99\n\\end{matrix}\n\\right],\n\\hat{\\mathbf{y}}_5 = \\left[\n\\begin{matrix}\n1 \\newline\n4 \n\\end{matrix}\n\\right], ~\n\\mathbf{e}_5 = \\left[\n\\begin{matrix}\n1 \\newline\n1 \n\\end{matrix}\n\\right]\n\\]\nKhi đó, hàm mất mát cho hệ số tương ứng với user E là: \n\\[\n\\mathcal{L}_5 = \\frac{1}{4} ||\\left[\n\\begin{matrix}\n0.99 & 0.02 \\newline\n0.01 & 0.99\n\\end{matrix}\n\\right]\\mathbf{w}_5  + b_5\\left[\n\\begin{matrix}\n1 \\newline\n1\n\\end{matrix}\n\\right] -\n\\left[\n\\begin{matrix}\n1 \\newline\n4\n\\end{matrix}\n\\right]||_2^2 + \\frac{\\lambda}{4} ||\\mathbf{w}_5||_2^2\n\\]\nChúng ta sẽ áp dụng những phân tích trên đây để đi tìm nghiệm cho một bài toán gần với thực tế dưới đây.\n\n\n\n\nBộ cơ sở dữ liệu MovieLens 100k được công bố năm 1998 bởi GroupLens. Bộ cơ sở dữ liệu này bao gồm 100,000 (100k) ratings từ 943 users cho 1682 bộ phim. Các bạn cũng có thể tìm thấy các bộ cơ sở dữ liệu tương tự với khoảng 1M, 10M, 20M ratings. Trong bài viết này, tôi sử dụng bộ cơ sở dữ liệu nhỏ nhất này nhằm mục đích minh hoạ.\nSau khi download và giải nén, chúng ta sẽ thu được rất nhiều các file nhỏ, chúng ta chỉ cần quan tâm các file sau:\nu.data: Chứa toàn bộ các ratings của 943 users cho 1682 movies. Mỗi user rate ít nhất 20 movies. Thông tin về thời gian rate cũng được cho nhưng chúng ta không sử dụng trong bài viết này.\nua.base, ua.test, ub.base, ub.test: là hai cách chia toàn bộ dữ liệu ra thành hai tập con, một cho training, một cho test. Chúng ta sẽ thực hành trên ua.base và ua.test. Bạn đọc có thể thử với cách chia dữ liệu còn lại.\nu.user: Chứa thông tin về users, bao gồm: id, tuổi, giới tính, nghề nghiệp, zipcode (vùng miền), vì những thông tin này cũng có thể ảnh hưởng tới sở thích của các users. Tuy nhiên, trong bài viết này, chúng ta sẽ không sử dụng các thông tin này, trừ thông tin về id để xác định các user khác nhau.\nu.genre: Chứa tên của 19 thể loại phim. Các thể loại bao gồm: unknown, Action, Adventure, Animation, Children's, Comedy, Crime, Documentary, Drama, Fantasy, Film-Noir, Horror, Musical, Mystery, Romance, Sci-Fi, Thriller, War, Western,\nu.item: thông tin về mỗi bộ phim. Một vài dòng đầu tiên của file:\nTrong mỗi dòng, chúng ta sẽ thấy id của phim, tên phim, ngày phát hành, link trên imdb, và các số nhị phân 0, 1 phía cuối để chỉ ra bộ phim thuộc các thể loại nào trong 19 thể loại đã cho trong u.genre. Một bộ phim có thể thuộc nhiều thể loại khác nhau. Thông tin về thể loại này sẽ được dùng để xây dựng item profiles.\nVới cơ sở dữ liệu này, chúng ta sẽ sử dụng thư viện pandas để trích xuất dữ liệu, có thể được cài đặt bằng pip install pandas.\n\n\nCông việc quan trọng trong content-based recommendation system là xây dựng profile cho mỗi item, tức feature vector cho mỗi item. Trước hết, chúng ta cần load toàn bộ thông tin về các items vào biến items:\nVì ta đang dựa trên thể loại của phim để xây dựng profile, ta sẽ chỉ quan tâm tới 19 giá trị nhị phân ở cuối mỗi hàng:\nTiếp theo, chúng ta sẽ xây dựng feature vector cho mỗi item dựa trên ma trận thể loại phim và feature TF-IDF. Tôi sẽ mô tả kỹ hơn về TF-IDF trong một bài viết khác. Tạm thời, chúng ta sử dụng thư viện sklearn.\nSau bước này, mỗi hàng của tfidf tương ứng với feature vector của một bộ phim.\nTiếp theo, với mỗi user, chúng ta cần đi tìm những bộ phim nào mà user đó đã rated, và giá trị của các rating đó.\n\n\nBây giờ, ta có thể đi tìm các hệ số của Ridge Regression cho mỗi user:\nSau khi tính được các hệ số W và b, ratings cho mỗi items được dự đoán bằng cách tính:\nDưới đây là một ví dụ với user có id là 10.\n\n\nĐể đánh giá mô hình tìm được, chúng ta sẽ sử dụng Root Mean Squared Error (RMSE), tức căn bậc hai của trung bình cộng bình phương của lỗi. Lỗi được tính là hiệu của true rating và predicted rating:\nNhư vậy, với tập training, sai số vào khoảng 0.9 sao; với tập test, sai số lớn hơn một chút, rơi vào khoảng 1.3. Chúng ta thấy rằng kết quả này chưa thực sự tốt vì chúng ta đã đơn giản hoá mô hình đi quá nhiều. Kết quả tốt hơn có thể được thấy trong bài tiếp theo: Collaborative Filtering.\n\n\nContent-based Recommendation Systems là phương pháp đơn giản nhất trong các hệ thống Recommendation Systems. Đặc điểm của phương pháp này là việc xây dựng mô hình cho mỗi user không phụ thuộc vào các users khác.\nViệc xây dựng mô hình cho mỗi users có thể được coi như bài toán Regression hoặc Classsification với training data là cặp dữ liệu (item profile, rating) mà user đó đã rated. item profile không phụ thuộc vào user, nó thường phụ thuộc vào các đặc điểm mô tả của item hoặc cũng có thể được xác định bằng cách yêu cầu người dùng gắn tag.\nSource code\n\n\n[1] Recommendation Systems - Stanford InfoLab\n[2] Recommendation systems - Machine Learning - Andrew Ng\n[3] The Vector Space Model of text\n[4] Content Based Recommendations - Stanford University"
    },
    {
        "ID": 27,
        "URL": "https://machinelearningcoban.com/2017/04/28/multiclasssmv/",
        "Title": "Machine Learning cơ bản",
        "Content": "Bạn sẽ hiểu rõ hơn nếu đã đọc các bài:\nBài 11: Feature Engineering\nBài 12: Binary Classifiers\nBài 13: Softmax Regression\nBài 20: Soft Margin SVM\nTrong trang này:\n\n\n\nCác phương pháp Support Vector Machine đã đề cập (Hard Margin, Soft Margin, Kernel) đều được xây dựng nhằm giải quyết bài toán Binary Classification, tức bài toán phân lớp với chỉ hai classes. Việc này cũng tương tự như Percetron Learning Algorithm hay Logistic Regression vậy. Các mô hình làm việc với bài toán có 2 classes còn được gọi là Binary classifiers. Một cách tự nhiên để mở rộng các mô hình này áp dụng cho các bài toán multi-class classification, tức có nhiều classes dữ liệu khác nhau, là sử dụng nhiều binary classifiers và các kỹ thuật như one-vs-one hoặc one-vs-rest. Cách làm này có những hạn chế như đã trình bày trong bài Softmax Regression.\n\nSoftmax Regression là mở rộng của Logistic Regression cho bài toán multi-class classification, có thể được coi là một layer của Neural Networks. Nhờ đó, Softmax Regression thường đươc sử dụng rất nhiều trong các bộ phân lớp hiện nay. Các bộ phân lớp cho kết quả cao nhất thường là một Neural Network với rất nhiều layers và layer cuối là một softmax regression, đặc biệt là các Convolutional Neural Networks. Các layer trước thường là kết hợp của các Convolutional layers và các nonlinear activation functions và pooling, các bạn tạm thời chưa cần quan tâm đến các layers phía trước này, tôi sẽ giới thiệu khi có dịp. Có thể coi các layer trước layer cuối là một công cụ giúp trích chọn đặc trưng của dữ liệu (Feature extraction), layer cuối là softmax regression, là một bộ phân lớp tuyến tính đơn giản nhưng rất hiệu quả. Bằng cách này, ta có thể coi là nhiều one-vs-rest classifers được huấn luyện cùng nhau, hỗ trợ lẫn nhau, vì vậy, một cách tự nhiên, sẽ có thể tốt hơn là huấn luyện từng classifier riêng lẻ.\nSự hiệu quả của Softmax Regression nói riêng và Convolutional Neural Networks nói chung là cả bộ trích chọn đặc trưng (feature extractor) và bộ phân lớp (classifier) được huấn luyện đồng thời. Điều này nghĩa là hai bộ phận này bổ trợ cho nhau trong quá trình huấn luyện. Classifier giúp tìm ra các hệ số hợp lý phù hợp với feature vector tìm được, ngược lại, feature extractor lại điều chỉnh các hệ số của các convolutional layer sao cho feature thu được là tuyến tính, phù hợp với classifier ở layer cuối cùng.\nTôi viết đến đây không phải là để giới thiệu về Softmax Regression, mà là đang nói chung đến các mô hình phân lớp hiện đại. Đặc điểm chung của chúng là feature extractor và classifier được huấn luyện một cách đồng thời. Những mô hình như thế này còn được gọi là end-to-end. Cùng xem lại mô hình chung cho các bài toán Machine Learning mà tôi đã đề cập trong Bài 11:\nTrong Hình 1, phần TRAINING PHASE, chúng ta có thể thấy rằng có hai khối chính là Feature Extraction và Classification/Regression/Clustering… Các phương pháp truyền thống thường xây dựng hai khối này qua các bước riêng rẽ. Phần Feature Extraction với dữ liệu ảnh có thể dùng các feature descriptor như SIFT, SURF, HOG; với dữ liệu văn bản thì có thể là Bag of Words hoặc TF-IDF. Nếu là các bài toán classification, phần còn lại có thể là SVM thông thường hay các bộ phân lớp truyền thống khác.\nVới sự phát triển của Deep Learning trong những năm gần đây, người ta cho rằng các hệ thống end-to-end (từ đầu đến cuối) mang lại kết quả tốt hơn nhờ và việc các hai khối phía trên được huấn luyện cùng nhau, bổ trợ lẫn nhau. Thực tế cho thấy, các phương pháp state-of-the-art thường là các mô hình end-to-end.\nCác phương pháp Support Vector Machine được chứng minh là tốt hơn Logistic Regression vì chúng có quan tâm đến việc tạo margin lớn nhất giữa các classes. Câu hỏi đặt ra là:\nLiệu có cách nào giúp kết hợp SVM với Neural Networks để tạo ra một bộ phân lớp tốt với bài toán multi-class classification? Hơn nữa, toàn bộ hệ thống có thể được huấn luyện theo kiểu end-to-end?\nCâu trả lời sẽ được tìm thấy trong bài viết này, bằng một phương pháp được gọi là Multi-class Support Vector Machine.\nVà để cho bài viết hấp dẫn hơn, tôi xin giới thiệu luôn, ở phần cuối, chúng ta sẽ cùng lập trình từ đầu đến cuối để giải quyết bài toán phân lớp với bộ cơ sở dữ liệu nổi tiếng: CIFAR10.\n\nBộ cơ sở dữ liệu CIFAR10 gồm 51000 ảnh khác nhau thuộc 10 classes: plane, car, bird, cat, deer, dog, frog, horse, ship, và truck. Mỗi bức ảnh có kích thước \\(32 \\times 32\\) pixel. Một vài ví dụ cho mỗi class được cho trong Hình 2 dưới đây. 50000 ảnh được sử dụng cho training, 1000 ảnh còn lại được dùng cho test. Trong số 50000 ảnh training, 1000 ảnh sẽ được lấy ra ngẫu nghiên để làm validation set.\nĐây là một bộ cơ sở dữ liệu tương đối khó vì ảnh nhỏ và object trong cùng một class cũng biến đổi rất nhiều về màu sắc, hình dáng, kích thước. Thuật toán tốt nhất hiện nay cho bài toán này đã đạt được độ chính xác trên 90%, sử dụng một Convolutional Neural Network nhiều lớp kết hợp với Softmax regression ở layer cuối cùng. Trong bài này, chúng ta sẽ sử dụng một mô hình neural network đơn giản không có hidden layer nào để giải quyết, kết quả đạt được là khoảng 40%, nhưng cũng là đã rất ấn tượng. Layer cuối là một layer Multi-class SVM. Tôi sẽ hướng dẫn các bạn lập trình cho mô hình này từ đầu đến cuối mà không sử dụng một thư viện đặc biệt nào ngoài numpy.\nBài toán này cũng như nội dung chính của bài viết được lấy từ Lecture notes: Linear Classifier II và Assignment #1 trong khoá học CS231n: Convolutional Neural Networks for Visual Recognition kỳ Winter 2016 của Stanford.\nTrước khi đi vào mục xây dựng hàm mất mát cho Multi-class SVM, tôi muốn nhắc lại một chút về một chút feature engineering cho ảnh trong CIFAR-10 và bias trick nói chung trong Neural Networks.\n\nĐể cho mọi thứ được đơn giản và có được một mô hình hoàn chỉnh, chúng ta sẽ sử dụng phương pháp feature engineering đơn giản nhất: lấy trực tiếp tất cả các pixel trong mỗi ảnh và thêm một chút normalization.\nMỗi ảnh của CIFAR-10 đã có kích thước giống nhau \\(32 \\times 32\\) pixel, vì vậy việc đầu tiên chúng ta cần làm là kéo dài mỗi trong ba channels Red, Green, Blue của bức ảnh ra thành một vector có kích thước là \\(3 \\times 32 \\times 32 = 3072\\).\nVì mỗi pixel có giá trị là một số tự nhiên từ 0 đến 255 nên chúng ta cần một chút chuẩn hóa dữ liệu. Trong Machine Learning, một cách đơn giản nhất để chuẩn hóa dữ liệu là center data, tức làm cho mỗi feature có trung bình cộng bằng 0. Một cách đơn giản để làm việc này là ta tính trung bình cộng của tất cả các ảnh trong tập training để được ảnh trung bình, sau đó trừ từ tất cả các ảnh đi ảnh trung bình này. Tương tự, ta cũng dùng ảnh trung bình này để chuẩn hoá dữ liệu trong validation set và test set.\n\nThông thường, với một ma trận hệ số \\(\\mathbf{W} \\in \\mathbb{R}^{d\\times C}\\), một đầu vào \\(\\mathbf{x} \\in \\mathbb{R}^d\\) và vector bias \\(\\mathbf{b} \\in \\mathbb{R}^C\\), chúng ta có thể tính được đầu ra của layer này là:\n\\[\nf(\\mathbf{x}, \\mathbf{W}, \\mathbf{b}) = \\mathbf{W}^T\\mathbf{x} + \\mathbf{b}\n\\]\nĐể cho biểu thức trên đơn giản hơn, ta có thể thêm một phần từ bằng 1 vào cuối của \\(\\mathbf{x}\\) và ghép vector \\(\\mathbf{b}\\) vào ma trận \\(\\mathbf{W}\\) như ví dụ dưới đây:\nBây giờ thì ta chỉ còn 1 biến dữ liệu là \\(\\mathbf{W}\\) thay vì hai biến dữ liệu như trước. Từ giờ trở đi, khi viết \\(\\mathbf{W}\\) và \\(\\mathbf{x}\\), chúng ta ngầm hiểu là biến mới và dữ liệu mới như ở phần bên phải của Hình 3. \n\nChúng ta cùng quay lại một chút với ý tưởng của Softmax Regression với hàm mất mát Cross-entropy. Sau đó, chúng ta sẽ làm quen với Multi-class SVM với hàm mất mát hinge loss mở rộng.\n\nChúng ta cùng xem lại Softmax layer đã được trình bày trong Bài 13.\nTrong Hình 4 ở trên, dữ liệu trong lớp màu xanh lục được coi như feature vector của dữ liệu. Với dữ liệu CIFAR-10, nếu ta coi mỗi feature là giá trị của từng pixel trong ảnh, tổng số chiều của feature vector cho mỗi bức ảnh là \\(32\\times 32 \\times 3 +1 = 3073\\), với 3 là số channels trong bức ảnh (Red, Green, Blue).\nQua ma trận hệ số \\(\\mathbf{W}\\), dữ liệu ban đầu trở thành \\(\\mathbf{z} = \\mathbf{W}^T\\mathbf{x}\\).\nLúc này, ứng với mỗi một trong \\(C\\) classes, chúng ta nhận được một giá trị tương ứng \\(z_i\\) ứng với class thứ \\(i\\). Giá trị \\(z_i\\) này còn được gọi là score của dữ liệu \\(\\mathbf{x}\\) ứng với class thứ \\(i\\).\nÝ tưởng chính trong Sofftmax Regression là đi tìm ma trận hệ số \\(\\mathbf{W}\\), mỗi cột của ma trận này ứng với một class, sao cho score vector \\(\\mathbf{z}\\) đạt giá trị lớn nhất tại phần tử tương ứng với class chính xác của nó. Sau khi mô hình đã được trained, nhãn của một điểm dữ liệu mới được tính là vị trí của thành phần score có giá trị lớn nhất trong score vector. Xem ví dụ trong Hình 5 dưới đây:\nĐể huấn luyện trên tập các cặp (dữ liệu, nhãn), Softmax Regression sử dụng hàm softmax để đưa score vector về dạng phân phối xác suất có các phần tử là dương và có tổng bằng 1. Sau đó dùng hàm cross entropy để ép vector xác suất này gần với vector xác suất thật sự của dữ liệu - tức one-hot vector mà chỉ có đúng 1 phần tử bằng 1 tại class tương ứng, các phần tử còn lại bằng 0.\n\nVới Multi-class SVM, trong khi tesst, class của một input cũng được xác định bởi thành phần có giá trị lớn nhất trong score vector. Điều này giống với Softmax Regression.\nSoftmax Regression sử dụng cross-entropy để ép hai vector xác suất bằng nhau, tức ép phần tử tương ứng với correct class trong vector xác suất gần với 1, đồng thời, các phần tử còn lại trong vector đó gần với 0. Nói cách khác, cách làm này khiến cho phần tử tương ứng với correct class càng lớn hơn các phần tử còn lại càng tốt. Trong khi đó, Multi-class SVM sử dụng một chiến thuật khác cho mục đích tương tự dựa trên score vector. Điểm khác biệt là Multi-class SVM xây dựng hàm mất mát dựa trên định nghĩa của biên an toàn, giống như trong Hard/Soft Margin vậy. Multi-class SVM muốn thành phần ứng với correct class của score vector lớn hơn các phần tử khác, không những thế, nó còn lớn hơn một đại lượng \\(\\Delta > 0\\) gọi là biên an toàn. Hãy xem Hình 6 dưới đây:\nVới cách xác định biên như trên, Multi-class SVM sẽ cho qua những scores nằm về phía trước vùng màu đỏ. Những điểm có scores nằm phía phải của ngưỡng (chữ x màu đỏ) sẽ bị xử phạt, và càng vi phạm nhiều sẽ càng bị xử lý ở mức cao.\nĐể mô tả các mức vi phạm này dưới dạng toán học, trước hết ta giả sử rằng các thành phần của score vector được đánh số thứ tự từ 1. Các classes cũng được đánh số thứ tự từ 1. Giả sử rằng điểm dữ liệu \\(\\mathbf{x}\\) đang xét thuộc class \\(y\\) và score vector của nó là vector \\(\\mathbf{z}\\). Thế thì score của correct class là \\(z_y\\), scores của các classes khác là các \\(z_i, i \\neq y\\). Xét ví dụ như trong Hình 6 với hai score \\(z_i\\) trong vùng an toàn và \\(z_j\\) trong vùng vi phạm.\nVới mỗi score \\(z_i\\) trong vùng an toàn, loss bằng 0.\nVới mỗi socre \\(z_j\\) vượt quá điểm an toàn (điểm x đỏ), loss do nó gây ra được tính bằng lượng vượt quá so với điểm x đỏ, đại lượng này có thể tính được là: \\(z_j - (z_y - \\Delta) = \\Delta - z_y + z_j\\).\nTóm lại, với một score \\(z_j, j \\neq y\\), loss do nó gây ra có thể được viết gọn thành:\n\\[\n\\max(0, \\Delta - z_y + z_j) = \\max(0, \\Delta - \\mathbf{w}_y^T\\mathbf{x} + \\mathbf{w}_j^T\\mathbf{x}) ~~~~~ (1)\n\\]\ntrong đó \\(\\mathbf{w}_j\\) là cột thứ \\(j\\) của ma trận hệ số \\(\\mathbf{W}\\).\nNhư vậy, với một điểm dữ liệu \\(\\mathbf{x}_n, n = 1, 2, \\dots, N\\), tổng cộng loss do nó gây ra là:\n\\[\n\\mathcal{L}_n = \\sum_{j \\neq y_n} \\max(0, \\Delta  - z_{y_n}^n + z_j^n)\n\\]\ntrong đó \\(\\mathbf{z}^n = \\mathbf{w}^T\\mathbf{x}_n = [z^n_1, z^n_2, \\dots, z^n_C]^T \\in \\mathbb{R}^{C \\times 1}\\) là scores tương ứng với điểm dữ liệu \\(\\mathbf{x}_n\\); \\(y_n\\) là correct class của điểm dữ liệu đó.\nVới toàn bộ các điểm dữ liệu \\(\\mathbf{X} = [\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N ]\\), loss tổng cộng là:\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{y}, \\mathbf{W}) = \\frac{1}{N}\\sum_{n=1}^N \\sum_{j \\neq y_n} \\max(0, \\Delta - z_{y_n}^n + z_j^n) ~~~~~ (2)\n\\]\nvới \\(\\mathbf{y} = [y_1, y_2, \\dots, y_N]\\) là vector chứa corect class của toàn bộ các điểm dữ liệu trong training set. Hệ số \\(\\frac{1}{N}\\) tính trung bình của loss để tránh việc biểu thức này quá lớn gây tràn số máy tính.\nCó một bug trong lỗi này, chúng ta cùng phân tích tiếp.\n\nĐiều gì sẽ xảy ra nếu nghiệm tìm được \\(\\mathbf{w}\\) là hoàn hảo, tức không có score nào vi phạm và biểu thức \\((2)\\) đạt giá trị bằng 0? Nói cách khác: \n\\[\n \\Delta - z_{y_n}^n + z_j^n =  \\leq 0 \\Leftrightarrow \\Delta \\leq \\mathbf{w}_{y_n}^T \\mathbf{x}_n - \\mathbf{w}_j^T\\mathbf{x}_n~\\forall n = 1, 2, \\dots, N; j = 1, 2, \\dots, C; j \\neq y_n\n\\]\nĐiều này có nghĩa là \\(k\\mathbf{W}\\) cũng là một nghiệm của bài toán với \\(k > 1\\) bất kỳ. Việc bài toán có vô số nghiệm và có những nghiệm có những phần tử tiến tới vô cùng khiến cho bài toán rất unstable khi giải. Một phương pháp quen thuộc để tránh hiện tượng này là cộng thêm số hạng regularization vào hàm mất mát. Số hạng này giúp ngăn chặn việc các hệ số của \\(\\mathbf{W}\\) trở nên quá lớn. Và để cho hàm mất mát vẫn có đạo hàm đơn giản, chúng ta lại sử dụng \\(l_2\\) regularization:\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{y}, \\mathbf{W}) = \\underbrace{\\frac{1}{N}\\sum_{n=1}^N \\sum_{j \\neq y_n} \\max(0, \\Delta - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n)}_{\\text{data loss }} + \\underbrace{\\frac{\\lambda}{2} ||\\mathbf{W}||_F^2}_{\\text{regularization loss}}~~~~~ (3)\n\\]\nvới \\(||\\bullet||_F\\) là Frobenius norm, và \\(\\lambda\\) là một giá trị dương giúp cân bằng giữa data loss và regularization loss, thường được chọn bằng cross-validation.\n\nCó hai hyperparameter trong hàm mất mát \\((3)\\) là \\(\\Delta\\) và \\(\\lambda\\), câu hỏi đặt ra là làm thế nào để chọn ra cặp giá trị hợp lý nhất cho từng bài toán. Liệu chúng ta có cần làm cross-validation cho từng giá trị không?\nTrong thực tế, người ta nhận thấy rằng \\(\\Delta\\) có thể được chọn bằng 1 mà không ảnh hưởng nhiều tới chất lượng của nghiệm. Thực tế cho thấy cả hai tham số \\(\\Delta\\) và \\(\\lambda\\) đều giúp cân bằng giữa data loss và regularization loss. Thực vậy, độ lớn của các hệ số trong \\(\\mathbf{W}\\) có tác động trực tiếp lên các score vectors, và vì vậy ảnh hưởng tới sự khác nhau giữa chúng. Khi chúng ta giảm các hệ số của \\(\\mathbf{W}\\), sự khác nhau giữa các scores cũng giảm một tỉ lệ tương tự; và khi ta tăng các hệ số của \\(\\mathbf{W}\\), sự khác nhau giữa các scores cũng tăng lên. Bởi vậy, giá trị chính xác \\(\\Delta\\) của margin giữa các scores trở nên không quan trọng vì chúng ta có thể tăng hoặc giảm \\(\\mathbf{W}\\) một cách tùy ý. Việc quan trọng hơn là hạn chế việc \\(\\mathbf{W}\\) trở nên quá lớn. Việc này đã được điều chỉnh bởi tham số \\(\\lambda\\).\nCuối cùng, chúng ta sẽ đi tối ưu hàm mất mát sau đây cho Multi-class SVM:\n\\[\n\\mathcal{L}(\\mathbf{X}, \\mathbf{y}, \\mathbf{W}) = \\frac{1}{N}\\sum_{n=1}^N \\sum_{j \\neq y_n} \\max(0, 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n) + \\frac{\\lambda}{2} ||\\mathbf{W}||_F^2~~~~~ (4)\n\\]\nMột lần nữa, chúng ta có thể dùng Gradient Descent để tối ưu bài toán tối ưu không ràng buộc này. Chúng ta sẽ đi sâu vào việc tính đạo hàm của hàm mất mát một cách hiệu quả ở mục 3.\nTrước hết, có một nhận xét thú vị:\n\nPhát biểu này có vẻ hiển nhiên vì bài toán phân lớp với hai classes là một trường hợp đặc biệt của bài toán phân lớp với nhiều classes! Nhưng điều tôi muốn nói đến là cách xây dựng hàm mất mát. Điều này có thể được nhận ra bằng cách xét từng điểm dữ liệu.\nTrong \\((4)\\), nếu \\(C = 2\\) (số classes bằng 2), hàm mất mát tại mỗi điểm dữ liệu trở thành (tạm bỏ qua regularization loss):\n\\[\n\\mathcal{L}_n = \\sum_{j \\neq y_n} \\max(0, 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n)\n\\]\nXét hai trường hợp:\n\\(y_n = 1 \\Rightarrow \\mathcal{L}_n = \\max(0, 1 - \\mathbf{w}_1^T\\mathbf{x}_n + \\mathbf{w}_2^T\\mathbf{x}_n) = \\max(0, 1 - (1)(\\mathbf{w}_1 - \\mathbf{w}_2)^T\\mathbf{x})\\)\n\\(y_n = 2 \\Rightarrow \\mathcal{L}_n = \\max(0, 1 - \\mathbf{w}_2^T\\mathbf{x}_n + \\mathbf{w}_1^T\\mathbf{x}_n) = \\max(0, 1 - (-1)(\\mathbf{w}_1 - \\mathbf{w}_2)^T\\mathbf{x})\\)\nNếu ta thay \\(y_n = -1\\) cho dữ liệu thuộc class 2, và đặt \\(\\mathbf{\\bar{w}} = \\mathbf{w}_1 - \\mathbf{w}_2\\), hai trường hợp trên có thể được viết gọn thành: \n\\[\n\\mathcal{L}_n = \\max(0, 1 - y_n\\mathbf{\\bar{w}}^T\\mathbf{x}_n)\n\\]\ntức chính là Hinge loss cho Soft Margin SVM.\n\nĐể tối ưu hàm mất mát, chúng ta sử dụng phương pháp Stochastic Gradient Method. Điều này có nghĩa là chúng ta cần tính gradient tại mỗi vòng lặp. Đồng thời, loss sau mỗi vòng lặp cũng cần được tính để kiểm tra liệu thuật toán có hoạt động như ý muốn hay không.\nViệc tính toán loss và gradient này không những cần phải chính xác mà còn cần được thực hiện càng nhanh càng tốt. Trong khi việc tính loss thường dễ thực hiện, việc tính gradient cần phải được kiểm tra kỹ càng hơn.\nĐể đảm bảo rằng loss và gradient được tính một cách chính xác và nhanh, chúng ta sẽ làm từng bước một. Bước thứ nhất là đảm bảo rằng các tính toán là chính xác, dù cách tính có rất chậm. Bước thứ hai là phải đảm bảo có cách tính hiệu quả để thuật toán chạy nhanh hơn. Hai bước này cần được thực hiện trên một lượng dữ liệu nhỏ để đảm bảo chúng được tính chính xác trước khi áp dụng thuật toán vào dữ liệu thật, thường có số điểm dữ liệu lớn và mỗi điểm dữ liệu cũng có số chiều lớn.\nHai mục nhỏ tiếp theo sẽ mô tả hai bước đã nêu ở trên.\n\nNaive dịch tạm ra tiếng Việt có nghĩa là ngây thơ, hoặc ngây ngô. Trong Machine Learning, từ này cũng hay được sử dụng với ý chỉ sự đơn giản.\nDưới đây là cách tính đơn giản loss và gradient của hàm mất mát trong \\((4)\\). Chú ý thành phần regularization.\nCách tính với hai vòng for lồng nhau như trên mô tả lại chính xác loss trong \\((4)\\) nên sai sót, nếu có, ở đây có thể được kiểm tra và sửa lại dễ dàng. Việc kiểm tra ở cuối cho cái nhìn ban đầu về hàm mất mát: dương và không có regularization sẽ có loss tổng cộng nhỏ hơn.\nVề cách tính gradient cho phần data loss, mặc dù hàm \\(\\max\\) là convex nhưng nó không có đạo hàm tại mọi nơi. Cụ thể:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial }{\\partial \\mathbf{w}_{y_n}}\\max(0, 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n) &=& \n\\left\\{\n\\begin{matrix}\n0 & \\text{if}& 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n < 0 \\newline\n-\\mathbf{x}_n & \\text{if} &1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n > 0\n\\end{matrix}\n\\right. && ~~~~(5)\\newline\n\\frac{\\partial }{\\partial \\mathbf{w}_{j}}\\max(0, 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n) &=& \n\\left\\{\n\\begin{matrix}\n0 & \\text{if}& 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n < 0 \\newline\n\\mathbf{x}_n & \\text{if} &1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n > 0\n\\end{matrix}\n\\right. && ~~~~(6)\n\\end{eqnarray}\n\\]\nRõ ràng là các đạo hàm này không xác định tại các điểm mà \\(1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n = 0\\). Tuy nhiên, khi thực hành, ta có thể giả sử rằng tại 0, các đạo hàm này cũng bằng 0.\nĐể kiểm tra lại cách tính đạo hàm như trên dựa vào \\((5)\\) và \\((6)\\) có chính xác không, chúng ta sẽ làm một bước quen thuộc là so sánh nó với numerical gradient. Nếu sự sai khác là nhỏ, nhỏ hơn 1e-7 thì ta có thể coi là gradient tính được là chính xác:\nSự sai khác là xấp xỉ 0, vậy chúng ta có thể yên tâm khi nói rằng cách tính gradient đã thỏa mãn sự chính xác, chúng ta cần tính nó một cách hiệu quả nữa.\nCác cách tính hiệu quả thường không chứa các vòng for mà được viết gọn lại dưới dạng ma trận và vector, việc này đòi hỏi các kỹ năng về Đại số tuyến tính và numpy một chút. Cách tính này thường được gọi là vectorized.\n\nĐể giúp các bạn dễ hình dung hơn, tôi đã chuẩn bị Hình dưới đây:\nỞ đây, chúng ta tạm quên phần regularization loss đi vì cả loss và gradient của phần này đều có cách tính đơn giản. Với phần data loss, chúng ta cũng bỏ qua hệ số \\(\\frac{1}{N}\\) đi cho dễ hình dung.\nGiả sử rằng có 4 classes và mini-batch gồm có 3 điểm dữ liệu \\(\\mathbf{x}_1, \\mathbf{x}_2, \\mathbf{x}_3\\). 3 điểm này lần lượt thuộc vào các class 1, 3, 2. Các ô có nền màu đỏ nhạt ở mỗi cột tương ứng với correct class của điểm dữ liệu của cột đó. Các bước tính loss và gradient có thể được hình dung như sau:\nBước 1: Tính score matrix \\(\\mathbf{Z} = \\mathbf{W}^T\\mathbf{X}\\).\nBước 2: Với mỗi ô, tính \\(\\max(0, 1 - \\mathbf{w}_{y_n}^T \\mathbf{x}_n + \\mathbf{w}_j^T\\mathbf{x}_n)\\). Chú ý rằng ta không cần tính các ô có nền màu đỏ nhạt vì có thể coi chúng bằng 0 do trong biểu thức data loss. Sau khi tính được giá trị của từng ô, ta chỉ quan tâm tới các ô có giá trị lớn hơn 0 - là các ô được tô nền màu xanh lục. Lấy tổng của tất cả các phần tử ở các ô xanh lục, ta sẽ được data loss. (Có thể bạn sẽ phải dừng lại một chút để hiểu. Không sao, take your time).\nBước 3: Theo công thức \\((6)\\), với ô màu xanh lục ở hàng 2, cột 1, thì đạo hàm theo vector hệ số \\(\\mathbf{w}_2\\) sẽ được cộng thêm một lượng \\(\\mathbf{x}_1\\) và đạo hàm theo vector hệ số \\(\\mathbf{w}_1\\) sẽ được trừ đi một lượng \\(\\mathbf{x}_1\\). Tương tự với các ô màu xanh lục còn lại. Với các ô màu đỏ ở hàng 1 cột 1, chúng ta chú ý rằng trong cùng cột 1, có bao nhiêu ô màu xanh lục thì có bấy nhiêu lần đạo hàm của \\(\\mathbf{w}_1\\) bị trừ đi một lượng \\(\\mathbf{x}_1\\). Điều này được suy ra từ \\((5)\\). Từ đó suy ra trong khối ô vuông thứ 3, giá trị của ô màu đỏ sẽ bằng đối số của tổng số lượng các ô màu xanh lục. Vậy nên ô màu đỏ ở hàng 1 cột 1 phải bằng -2.\nBước 4: Bây giờ cộng theo các hàng, ta sẽ được đạo hàm theo hệ số của class tương ứng.\nTrong đoạn code dưới đây, correct_class_score chính là tập hợp các giá trị trong các ô màu đỏ ở khối thứ nhất.\nSau khi đã viết đoạn code mà chúng ta cho rằng đã hiệu quả (không còn vòng for nào) này, chúng ta cần phải kiểm chứng hai điều:\nKết quả nhận được cho chúng ta thấy rằng cách tính bằng vectorized nhanh hơn rất nhiều (khoảng 120 lần) so với cách tính naive. Hơn nữa, sự chênh lệch giữa kết quả của hai cách tính là rất nhỏ, đều nhỏ hơn 1e-10 (tức \\(10^{-10})\\). Vậy thì chúng ta có thể yên tâm sử dụng cách vectorized này để cập nhật nghiệm.\n\nMọi việc giờ thật là đơn giản, giống như mọi phương pháp giải bằng Gradient Descent tôi đã nêu trước đây:\nChúng ta thử visisualize giá trị của loss sau mỗi vòng lặp:\nTừ lịch sử loss này ta thấy rằng giá trị của loss sau mỗi vòng lặp có xu hướng giảm và hội tụ, đây chính là điều mà chúng ta mong muốn.\nPhần code còn lại để giải quyết bài toán phân loại cho cơ sở dữ liệu CIFAR-10 có thể tìm thấy trong ipython notebook này\n(đây chính là lời giải của tôi cho Assignment #1 của CS231n, WInter 2016, Stanford.)\nKết quả đạt được cho CIFAR-10 là khoảng 40%. Như thế là đã rất tốt với một bài toán khó với 10 classes như thế này, nhất là khi chúng ta chưa phải làm thêm bước feature engineering phức tạp nào. Kết quả của Softmax Regression là khoảng 35%, các bạn cũng có thể tìm thấy tại đây.\nChú ý: Trong các bài tập này, dữ liệu được tính toán theo dạng hàng, tức mỗi hàng của \\(\\mathbf{X}\\) là một điểm dữ liệu. Khi đó, score được tính theo công thức: \\(\\mathbf{Z} = \\mathbf{XW}\\). Các phép biến đổi có khác một chút so với trường hợp dữ liệu ở dạng cột. Hy vọng các bạn không gặp khó khăn nhiều.\n\nĐể ý rằng mỗi \\(\\mathbf{w}_i\\) có chiều giống như chiều của dữ liệu, trong trường hợp này, chúng là các bức ảnh. Bằng cách sắp xếp lại các điểm trong mỗi trong 10 vector hệ số tìm được, chúng ta sẽ thu được bức ảnh cũng có kích thước \\(3\\times 32\\times32\\) như mỗi ảnh nhỏ trong cơ sở dữ liệu. Dưới đây là hình thù của mỗi \\(\\mathbf{w}_i\\):\nTừ đây chúng ta sẽ thấy một điều thú vị.\nHệ số tương ứng với mỗi class đều mang những tính chất giống với các bức ảnh trong class đó, ví dụ như car và truck trông khá giống với các bức ảnh trong class car và truck. Hệ số của ship và plane có mang màu xanh của nước biển và bầu trời. Trong khi horse trông giống như 1 con ngựa 2 đầu; điều này dễ hiểu vì trong tập training, các con ngựa có thể quay đầu về hai phía. Có thể nói theo một cách khác rằng các hệ số tìm được được coi như là các ảnh đại diện cho mỗi class. Vì sao chúng ta có thể nói như vậy?\nNếu chúng ta cùng xem lại cách xác định class cho một dữ liệu mới được thực hiện bằng cách tìm vị trí của giá trị lớn nhất trong score vector \\(\\mathbf{W}^T\\mathbf{x}\\), tức:\n\\[\n\\text{class}(\\mathbf{x}) = \\arg\\max_{i = 1, 2, \\dots, C} \\mathbf{w}_i^T\\mathbf{x}\n\\]\nNếu bạn để ý chút nữa thì tích vô hướng chính là đại lượng đo sự tương quan giữa hai vector. Đại lượng này càng lớn thì sự tương quan càng cao, tức hai vector càng giống nhau. Như vậy, việc đi tìm class của một bức ảnh mới chính là việc đi tìm xem hệ số tìm được nào gần với bức ảnh đó nhất. Nói thêm một cách khác nữa, đây chính là K-nearest neighbors, nhưng thay vì thực hiện KNN trên toàn bộ training data, chúng ta chỉ thực hiện trên 10 bức ảnh đại diện tìm được bằng Multi-class SVM (hoặc Softmax Regression). Chính vì vậy, hai phương pháp này có thể coi là cách đi tìm mỗi điểm dữ liệu đại diện cho mỗi class!\n\nGiống như Softmax Regression,  Multi-class SVM vẫn được coi là một bộ phân lớp tuyến tính vì đường phân chia giữa các class là các đường tuyến tính.\nKernel SVM cũng hoạt động khá tốt, nhưng việc tính toán ma trận kernel có thể tốn nhiều thời gian và bộ nhớ. Hơn nữa, việc mở rộng nó ra cho bài toán multi-class classification thường không hiệu quả bằng Multi-class SVM. Một ưu điểm nữa của Multi-class SVM là nó có thể được tối ưu bằng (Stochastic) Gradient Descnet, tức là nó phù hợp với các bài toán large-scale. Việc boundary giữa các class là tuyến tính có thể được giải quyết bằng cách kết hợp nó với Deep Neurel Networks. Bạn đọc có thể so sánh hiệu quả của hai phương pháp này bằng cách giải quyết bài toán CIFAR-10 bằng thư viện sklearn như tôi đã trình bày trong bài trước. Tôi đã thử, Kernel cho kết quả thấp và tốn hơn 1 giờ để huấn luyện, so với vài phút của Multi-class SVM. Có thể tôi chưa lựa chọn các tham số hợp lý, nhưng chắc chắn một điều rằng, Kernel SVM tốn nhiều thời gian huấn luyện hơn.\nCó một cách nữa mở rộng hinge loss cho bài toán multi-class classification là dùng loss: \\(\\max(0, 1 - \\mathbf{w}_{y_n}^T\\mathbf{x}_n + \\max_{j \\neq y_n}\\mathbf{w}_{j}^T\\mathbf{x}_n)\\). Đây chính là vi phạm lớn nhất, so với tổng vi pham mà chúng ta sử dụng trong bài này.\nTrên thực tế, Multi-class SVM và Softmax Regression có hiệu quả tương đương nhau. Có thể trong một bài toán cụ thể, phương pháp này tốt hơn phương pháp kia, nhưng điều ngược lại xảy ra trong các bài toán khác.\n\n[1] CS231n Convolutional Neural Networks for Visual Recognition\n[2] Hinge loss - Wikipedia"
    },
    {
        "ID": 28,
        "URL": "https://machinelearningcoban.com/2017/04/22/kernelsmv/",
        "Title": "Machine Learning cơ bản",
        "Content": "Bạn đọc được khuyến khích đọc Bài 19 và Bài 20 trước khi đọc bài này.\n\nCó một sự tương ứng thú vị giữa hai nhóm thuật toán phân lớp phổ biến nhất: Neural Network và Support Vector Machine. Chúng đều bắt đầu từ bài toán phân lớp với 2 linearly separable classes, tiếp theo đến 2 almost linear separable classes, đến bài toán có nhiều classes rồi các bài toán với biên không tuyến tính. Sự tương ứng được cho trong bảng dưới đây:\nTrong Bài 21 này, tôi sẽ viết về Kernel SVM, tức việc áp dụng SVM lên bài toán mà dữ liệu giữa hai classes là hoàn toàn không linear separable (tôi tạm dịch là không phân biệt tuyến tính). Bài toán phân biệt nhiều classes sẽ được tôi trình bày trong Bài 22: Multiclass SVM.\nÝ tưởng cơ bản của Kernel SVM và các phương pháp kernel nói chung là tìm một phép biến đổi sao cho dữ liệu ban đầu là không phân biệt tuyến tính được biến sang không gian mới. Ở không gian mới này, dữ liệu trở nên phân biệt tuyến tính.\nXét ví dụ dưới đây với việc biến dữ liệu không phân biệt tuyến tính trong không gian hai chiều thành phân biệt tuyến tính trong không gian ba chiều bằng cách giới thiệu thêm một chiều mới:\nĐể xem ví dụ này một cách sinh động hơn, bạn có thể xem clip nhỏ dưới đây:\nNói một cách ngắn gọn, Kernel SVM là việc đi tìm một hàm số biến đổi dữ liệu \\(\\mathbf{x}\\) từ không gian feature ban đầu thành dữ liệu trong một không gian mới bằng hàm số \\(\\Phi(\\mathbf{x})\\). Trong ví dụ này, hàm \\(\\Phi()\\) đơn giản là giới thiệu thêm một chiều dữ liệu mới (một feature mới) là một hàm số của các features đã biết. Hàm số này cần thỏa mãn mục đích của chúng ta: trong không gian mới, dữ liệu giữa hai classes là phân biệt tuyến tính hoặc gần như phần biệt tuyến tính. Khi đó, ta có thể dùng các bộ phân lớp tuyến tính thông thường như PLA, Logistic Regression, hay Hard/Soft Margin SVM.\nNếu phải so sánh, ta có thể thấy rằng hàm biến đổi \\(\\Phi()\\) tương tự như activation functions trong Neural Networks. Tuy nhiên, có một điểm khác biệt ở đây là: trong khi nhiệm vụ của activation function là phá vỡ tính tuyến tính của mô hình, hàm biến đổi \\(\\Phi()\\) đi biến dữ liệu không phân biệt tuyến tính thành phân biệt tuyến tính. Như vậy là để đạt được mục đích chung, ta có hai cách nhìn khác nhau về cách giải quyết.\nCác hàm \\(\\Phi()\\) thường tạo ra dữ liệu mới có số chiều cao hơn số chiều của dữ liệu ban đầu, thậm chí là vô hạn chiều. Nếu tính toán các hàm này trực tiếp, chắc chắn chúng ta sẽ gặp các vấn đề về bộ nhớ và hiệu năng tính toán. Có một cách tiếp cận là sử dụng các kernel functions mô tả quan hệ giữa hai điểm dữ liệu bất kỳ trong không gian mới, thay vì đi tính toán trực tiếp từng điểm dữ liệu trong không gian mới. Kỹ thuật này được xây dựng dựa trên quan sát về bài toán đối ngẫu của SVM.\nTrong Mục 2 dưới đây, chúng ta cùng tìm hiểu cơ sở toán học của Kernel SVM và Mục 3 sẽ giới thiệu một số hàm Kernel thường được sử dụng.\n\nTôi xin nhắc lại bài toán đối ngẫu trong Soft Margin SVM cho dữ liệu gần phân biệt tuyến tính:\n\\begin{eqnarray}\n     \\lambda &=& \\arg \\max_{\\lambda} \\sum_{n=1}^N \\lambda_n - \\frac{1}{2} \\sum_{n=1}^N\\sum_{m=1}^N \\lambda_n \\lambda_m y_n y_m \\mathbf{x}_n^T \\mathbf{x}_m &&\\newline\n     \\text{subject to:}~ && \\sum_{n=1}^N \\lambda_ny_n = 0 &&\\quad\\quad\\quad\\quad(1)\\newline\n     && 0 \\leq \\lambda_n \\leq C, ~\\forall n= 1, 2, \\dots, N \n \\end{eqnarray}\nTrong đó:\n\\(N\\): số cặp điểm dữ liệu trong tập training.\n\\(\\mathbf{x}_n\\): feature vector của dữ liệu thứ \\(n\\) trong tập training.\n\\(y_n\\): nhãn của dữ liệu thứ \\(n\\), bằng 1 hoặc -1.\n\\(\\lambda_n\\): nhân tử Lagrange ứng với điểm dữ liệu thứ \\(n\\).\n\\(C\\): hằng số dương giúp cân đối độ lớn của margin và sự hy sinh của các điểm nằm trong vùng không an toàn. Khi \\(C = \\infty\\) hoặc rất lớn, Soft Margin SVM trở thành Hard Margin SVM.\nSau khi giải được \\(\\lambda\\) cho bài toán \\((1)\\), nhãn của một điểm dữ liệu mới sẽ được xác định bởi dấu của biểu thức: \n\\[\n\\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T \\mathbf{x} + \\frac{1}{N_{\\mathcal{M}}} \\sum_{n \\in \\mathcal{M}} \\left(y_n - \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T\\mathbf{x}_n\\right)~~~~~~~~~ (2)\n\\]\nTrong đó:\n\\(\\mathcal{M} = \\{n: 0 < \\lambda_n < C\\}\\) là tập hợp những điểm nằm trên margin.\n\\(\\mathcal{S} = \\{n: 0 < \\lambda_n\\}\\) là tập hợp các điểm support.\n\\(N_{\\mathcal{M}}\\) là số phần tử của \\(\\mathcal{M}\\).\nVới dữ liệu thực tế, rất khó để có dữ liệu gần phân biệt tuyến tính, vì vậy nghiệm của bài toán \\((1)\\) có thể không thực sự tạo ra một bộ phân lớp tốt. Giả sử rằng ta có thể tìm được hàm số \\(\\Phi()\\) sao cho sau khi được biến đổi sang không gian mới, mỗi điểm dữ liệu \\(\\mathbf{x}\\) trở thành \\(\\Phi(\\mathbf{x})\\), và trong không gian mới này, dữ liệu trở nên gần phân biệt tuyến tính. Lúc này, hy vọng rằng nghiệm của bài toán Soft Margin SVM sẽ cho chúng ta một bộ phân lớp tốt hơn.\nTrong không gian mới, bài toán \\((1)\\) trở thành: \n \\begin{eqnarray}\n     \\lambda &=& \\arg \\max_{\\lambda} \\sum_{n=1}^N \\lambda_n - \\frac{1}{2} \\sum_{n=1}^N\\sum_{m=1}^N \\lambda_n \\lambda_m y_n y_m \\Phi(\\mathbf{x}_n)^T \\Phi(\\mathbf{x}_m) &&\\newline\n     \\text{subject to:}~ && \\sum_{n=1}^N \\lambda_ny_n = 0 &&\\quad\\quad\\quad\\quad(3)\\newline\n     && 0 \\leq \\lambda_n \\leq C, ~\\forall n= 1, 2, \\dots, N \n \\end{eqnarray}\nvà nhãn của một điểm dữ liệu mới được xác định bởi dấu của biểu thức:\n\\[\n\\mathbf{w}^T\\Phi(\\mathbf{x}) + b = \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\Phi(\\mathbf{x}_m)^T \\Phi(\\mathbf{x}) + \\frac{1}{N_{\\mathcal{M}}} \\sum_{n \\in \\mathcal{M}} \\left(y_n - \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\Phi(\\mathbf{x}_m)^T\\Phi(\\mathbf{x}_n)\\right)~~~~~~~~~ (4)\n\\]\nNhư đã nói ở trên, việc tính toán trực tiếp \\(\\Phi(\\mathbf{x})\\) cho mỗi điểm dữ liệu có thể sẽ tốn rất nhiều bộ nhớ và thời gian vì số chiều của \\(\\Phi(\\mathbf{x})\\) thường là rất lớn, có thể là vô hạn! Thêm nữa, để tìm nhãn của một điểm dữ liệu mới \\(\\mathbf{x}\\), ta lại phải tìm biến đổi của nó \\(\\Phi(\\mathbf{x})\\) trong không gian mới rồi lấy tích vô hướng của nó với tất cả các \\(\\Phi(\\mathbf{x}_m)\\) với \\(m\\) trong tập hợp support. Để tránh việc này, ta quan sát thấy một điều thú vị sau đây.\nTrong bài toán \\((3)\\) và biểu thức \\((4)\\), chúng ta không cần tính trực tiếp \\(\\Phi(\\mathbf{x})\\) cho mọi điểm dữ liệu. Chúng ta chỉ cần tính được \\(\\Phi(\\mathbf{x})^T\\Phi(\\mathbf{z})\\) dựa trên hai điểm dữ liệu \\(\\mathbf{x}, \\mathbf{z}\\) bất kỳ! Kỹ thuật này còn được gọi là kernel trick. Những phương pháp dựa trên kỹ thuật này, tức thay vì trực tiếp tính tọa độ của một điểm trong không gian mới, ta đi tính tích vô hướng giữa hai điểm trong không gian mới, được gọi chung là kernel method.\nLúc này, bằng cách định nghĩa hàm kernel \\(k(\\mathbf{x}, \\mathbf{z}) = \\Phi(\\mathbf{x})^T\\Phi(\\mathbf{z}) \\), ta có thể viết lại bài toán \\((3)\\) và biểu thức \\((4)\\) như sau:\n\\begin{eqnarray}\n    \\lambda &=& \\arg \\max_{\\lambda} \\sum_{n=1}^N \\lambda_n - \\frac{1}{2} \\sum_{n=1}^N\\sum_{m=1}^N \\lambda_n \\lambda_m y_n y_m k(\\mathbf{x}_n,\\mathbf{x}_m) &&\\newline\n    \\text{subject to:}~ && \\sum_{n=1}^N \\lambda_ny_n = 0 &&\\quad\\quad\\quad\\quad(5)\\newline\n    && 0 \\leq \\lambda_n \\leq C, ~\\forall n= 1, 2, \\dots, N &&\n\\end{eqnarray}\nvà:\n\\[\n\\sum_{m \\in \\mathcal{S}} \\lambda_m y_m k(\\mathbf{x}_m, \\mathbf{x}) + \\frac{1}{N_{\\mathcal{M}}} \\sum_{n \\in \\mathcal{M}} \\left(y_n - \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m k(\\mathbf{x}_m, \\mathbf{x}_n)\\right)~~~~~~~~~ (6)\n\\]\nVí dụ: Xét phép biến đổi 1 điểm dữ liệu trong không gian hai chiều \\(\\mathbf{x} = [x_1, x_2]^T\\) thành một điểm trong không gian 5 chiều \\(\\Phi(\\mathbf{x}) = [1, \\sqrt{2} x_1, \\sqrt{2} x_2, x_1^2, \\sqrt{2} x_1x_2, x_2^2]^T\\). Ta có:\n\\begin{eqnarray}\n\\Phi(\\mathbf{x})^T\\Phi(\\mathbf{z}) &=& [1, \\sqrt{2} x_1, \\sqrt{2} x_2, x_1^2, \\sqrt{2} x_1x_2, x_2^2] [1, \\sqrt{2} z_1, \\sqrt{2} z_2, z_1^2, \\sqrt{2} z_1z_2, z_2^2]^T \\newline\n&=& 1 + 2x_1z_1 + 2x_2z_2 + x_1^2x_2^2 + 2x_1z_1x_2z_2 + x_2^2z_2^2 \\newline\n&=& (1 + x_1z_1 + x_2z_2)^2 = (1 + \\mathbf{x}^T\\mathbf{z})^2 = k(\\mathbf{x}, \\mathbf{z})\n\\end{eqnarray}\nTrong ví dụ này, rõ ràng rằng việc tính toán hàm kernel \\(k()\\) cho hai điểm dữ liệu dễ dàng hơn việc tính từng \\(\\Phi()\\) rồi nhân chúng với nhau.\nVậy những hàm số kernel cần có những tính chất gì, và những hàm như thế nào được sử dụng trong thực tế?\n\n\nKhông phải hàm \\(k()\\) bất kỳ nào cũng được sử dụng. Các hàm kerrnel cần có các tính chất:\nĐối xứng: \\(k(\\mathbf{x}, \\mathbf{z}) = k(\\mathbf{z}, \\mathbf{x}) \\). Điều này dễ nhận ra vì tích vô hướng của hai vector có tính đối xứng.\nVề lý thuyết, hàm kerrnel cần thỏa mãn điều kiện Mercer: \n\\[\n\\sum_{n=1}^N \\sum_{m=1}^N k(\\mathbf{x}_m, \\mathbf{x}_n) c_nc_m \\geq 0, ~~ \\forall c_i \\in \\mathbb{R}, i = 1, 2, \\dots, N \\quad \\quad (7)\n\\]\nTính chất này để đảm bảo cho việc hàm mục tiêu của bài toán đối ngẫu \\((5)\\) là lồi.\nTrong thực hành, có một vài hàm số \\(k()\\) không thỏa mãn điều kiện Merrcer nhưng vẫn cho kết quả chấp nhận được. Những hàm số này vẫn được gọi là kernel. Trong bài viết này, tôi chỉ tập trung vào các hàm kernel thông dụng và có sẵn trong các thư viện.\nNếu một hàm kerrnel thỏa mãn điều kiện \\((7)\\), xét \\(c_n = y_n \\lambda_n\\), ta sẽ có: \n\\[\n\\lambda^T \\mathbf{K} \\lambda = \\sum_{n=1}^N \\sum_{m=1}^N k(\\mathbf{x}_m, \\mathbf{x}_n) y_ny_m \\lambda_n \\lambda_m \\geq 0, ~\\forall \\lambda_n \\quad\\quad (8)\n\\]\nvới \\(\\mathbf{K}\\) là một ma trận đối xứng mà phần tử ở hàng thứ \\(n\\) cột thứ \\(m\\) của nó được định nghĩa bởi: \n\\(\nk_{nm} = y_ny_m k(\\mathbf{x}_n, \\mathbf{x}_m)\n\\)\nTừ \\((8)\\) ta suy ra \\(\\mathbf{K}\\) là một ma trận nửa xác định dương. Vì vậy, bài toán tối ưu \\((5)\\) có ràng buộc là lồi và hàm mục tiêu là một hàm lồi (một quadratic form). Vì vậy chúng ta có thể giải quyết bài toán này một cách hiệu quả.\nTrong bài viết này, tôi sẽ không đi sâu vào việc giải quyết bài toán \\((5)\\) vì nó hoàn toàn tương tự như bài toán đối ngẫu của Soft Margin SVM. Thay vào đó, tôi sẽ trình bày các hàm kernel thông dụng và hiệu năng của chúng trong các bài toán thực tế. Việc này sẽ được thực hiện thông qua các ví dụ và cách sử dụng thư viện sklearn.\n\n\nĐây là trường hợp đơn giản với kernel chính tích vô hướng của hai vector: \n\\[\nk(\\mathbf{x}, \\mathbf{z}) = \\mathbf{x}^T\\mathbf{z}\n\\]\nHàm số này, như đã chứng minh trong Bài 19, thỏa mãn điều kiện \\((7)\\).\nKhi sử dụng hàm sklearn.svm.SVC, kernel này được chọn bằng cách đặt kernel = 'linear'\n\n\\[\nk(\\mathbf{x}, \\mathbf{z}) = (r + \\gamma \\mathbf{x}^T\\mathbf{z})^d\n\\]\nVới \\(d\\) là một số dương để chỉ bậc của đa thức. \\(d\\) có thể không là số tự nhiên vì mục đích chính của ta không phải là bậc của đa thức mà là cách tính kernel. Polynomial kernel có thể dùng để mô tả hầu hết các đa thức có bậc không vượt quá \\(d\\) nếu \\(d\\) là một số tự nhiên.\nPhần kiểm tra liệu hàm này có thỏa mãn điều kiện \\((7)\\) hay không xin được bỏ qua.\nKhi sử dụng thư viện sklearn, kerrnel này được chọn bằng cách đặt kernel = 'poly'. Thông tin cụ thể về cách sử dụng có thể xem tại đây.\n\nRadial Basic Function (RBF) kernel hay Gaussian kernel được sử dụng nhiều nhất trong thực tế, và là lựa chọn mặc định trong sklearn. Nó được định nghĩa bởi:\n\\[\nk(\\mathbf{x}, \\mathbf{z}) = \\exp(-\\gamma ||\\mathbf{x} - \\mathbf{z}||_2^2), ~~ \\gamma > 0\n\\]\nTrong sklearn, kernel = 'rbf'.\n\nSigmoid function cũng được sử dụng làm kernel:\n\\[\nk(\\mathbf{x}, \\mathbf{z}) = \\text{tanh}(\\gamma \\mathbf{x}^T\\mathbf{z} + r)\n\\]\nkernel = 'sigmoid'\n\nDưới đây là bảng tóm tắt các kernel thông dụng và cách sử dụng trong sklearn.\nNếu bạn muốn sử dụng các thư viện cho C/C++, các bạn có thể tham khảo LIBSVM và LIBLINEAR\n\nNgoài các hàm kernel thông dụng như trên, chúng ta cũng có thể tự định nghĩa các kernel của mình như trong hướng dẫn này. \n\n\nChúng ta cùng quay lại với bài toán XOR. Chúng ta biết rằng bài toán XOR không thể giải quyết nếu chỉ dùng một bộ phân lớp tuyến tính. Neurrel Network cần 2 layers để giải quyết bài toán này. Với SVM, chúng ta có cách để chỉ cần sử dụng một bộ phân lớp. Dưới đây là ví dụ:\nKết quả được cho trong Hình 2 dưới đây:\nTa có các nhận xét đối với mỗi kernel như sau:\nsigmoid: nghiệm tìm được không thật tốt vì có 3 trong 4 điểm nằm chính xác trên đường phân chia. Nói cách khác, nghiệm này rất nhạy cảm với nhiễu.\npoly: Nghiệm này có tốt hơn nghiệm của sigmoid nhưng kết quả có phần giống với overfitting.\nrbf: Dữ liệu được tạo ra một cách đối xứng, đường phân lớp tìm được cũng tạo ra các vùng đối xứng với mỗi class. Nghiệm này được cho là hợp lý hơn. Trên thực tế, các rbf kernel được sử dụng nhiều nhất và cũng là lựa chọn mặc định trong hàm sklearn.svm.SVC.\n\nXét một ví dụ khác với dữ liệu giữa hai classes là gần phân biệt tuyến tính như HÌnh 3 dưới đây:\nTrong ví dụ này, kernel = 'poly' cho kết quả tốt hơn kernel = 'rbf' vì trực quan cho ta thấy rằng nửa bên phải của mặt phẳng nên hoàn thoàn thuộc vào class xanh. sigmoid kernel cho kết quả không thực sự tốt và ít được sử dụng.\n\nBài toán này đã được đề cập ở Bài 12 với dữ liệu đầu vào là các ảnh khuôn mặt. Vì tôi không được phép phân phối cơ sở dữ liệu gốc này, tôi sẽ chia sẻ cho các bạn về dữ liệu đã qua xử lý, được lưu trong file myARgender.mat, có thể được download tại đây. Dưới đây là ví dụ về cách sử dụng thư viện sklearn.svm.SVC để giải quyết bài toán:\nKết quả không tệ! Các bạn thử thay các kernel và thiết lập các tham số khác xem kết quả thay đổi như thế nào. Vì dữ liệu giữa hai classes là gần phân biệt tuyến tính nên không có sự khác nhau nhiều giữa các kernel.\n\nNếu dữ liệu của hai lớp là không phân biệt tuyến tính, chúng ta có thể tìm cách biến đổi dữ liệu sang một không gian mới sao cho trong không gian mới ấy, dữ liệu của hai lớp là phân biệt tuyến tính hoặc gần phân biệt tuyến tính.\nViệc tính toán trực tiếp hàm \\(\\Phi()\\) đôi khi phức tạp và tốn nhiều bộ nhớ. Thay vào đó, ta có thể sử dụng kernel trick. Trong cách tiếp cận này, ta chỉ cần tính tích vô hướng của hai vector bất kỳ trong không gian mới: \\(k(\\mathbf{x}, \\mathbf{z}) = \\Phi(\\mathbf{x})^T\\Phi(\\mathbf{z})\\).\nThông thường, các hàm \\(k()\\) thỏa mãn điều kiện Merrcer, và được gọi là kernel. Cách giải bài toán SVM với kernel hoàn toàn giống với cách giải bài toán Soft Margin SVM.\nCó 4 loại kernel thông dụng: linear, poly, rbf, sigmoid. Trong đó, rbf được sử dụng nhiều nhất và là lựa chọn mặc định trong các thư viện SVM.\nVới dữ liệu gần phân biệt tuyến tính, linear và poly kernels cho kết quả tốt hơn.\nSource code.\n\n[1] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer  (2006). (book)\n[2] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012.\n[3] sklearn.svm.SVC\n[4] LIBSVM – A Library for Support Vector Machines\n[5] Bennett, K. P. (1992). “Robust linear programming discrimination of two linearly separable sets”. Optimization Methods and Software 1, 23–34.\n[6] Sch¨olkopf, B., A. Smola, R. C.Williamson, and P. L. Bartlett (2000). “New support vector algorithms”. Neural Computation 12(5), 1207–1245\n[7]  Rosasco, L.; De Vito, E. D.; Caponnetto, A.; Piana, M.; Verri, A. (2004). “Are Loss Functions All the Same?”. Neural Computation. 16 (5): 1063–1076\n[8] slearn Kernel functions\n[9] Kernel method\n[10] http://www.support-vector-machines.org/"
    },
    {
        "ID": 29,
        "URL": "https://machinelearningcoban.com/2017/04/13/softmarginsmv/",
        "Title": "Machine Learning cơ bản",
        "Content": "\nGiống như Perceptron Learning Algorithm (PLA), Support Vector Machine (SVM) thuần chỉ làm việc khi dữ liệu của 2 classes là linearly separable. Một cách tự nhiên, chúng ta cũng mong muốn rằng SVM có thể làm việc với dữ liệu gần linearly separable giống như Logistic Regression đã làm được.\nBạn được khuyến khích đọc bài Support Vector Machine trước khi đọc bài này.\nXét 2 ví dụ trong Hình 1 dưới đây:\nCó hai trường hợp dễ nhận thấy SVM làm việc không hiệu quả hoặc thậm chí không làm việc:\nTrường hợp 1: Dữ liệu vẫn linearly separable như Hình 1a) nhưng có một điểm nhiễu của lớp tròn đỏ ở quá gần so với lớp vuông xanh. Trong trường hợp này, nếu ta sử dụng SVM thuần thì sẽ tạo ra một margin rất nhỏ. Ngoài ra, đường phân lớp nằm quá gần lớp vuông xanh và xa lớp tròn đỏ. Trong khi đó, nếu ta hy sinh điểm nhiễu này thì ta được một margin tốt hơn rất nhiều được mô tả bởi các đường nét đứt. SVM thuần vì vậy còn được coi là nhạy cảm với nhiễu (sensitive to noise).\nTrường hợp 2: Dữ liệu không linearly separable nhưng gần linearly separable như Hình 1b). Trong trường hợp này, nếu ta sử dụng SVM thuần thì rõ ràng bài toán tối ưu là infeasible, tức feasible set là một tập rỗng, vì vậy bài toán tối ưu SVM trở nên vô nghiệm. Tuy nhiên, nếu ta lại chịu hy sinh một chút những điểm ở gần biên giữa hai classes, ta vẫn có thể tạo được một đường phân chia khá tốt như đường nét đứt đậm. Các đường support đường nét đứt mảnh vẫn giúp tạo được một margin lớn cho bộ phân lớp này. Với mỗi điểm nằm lần sang phía bên kia của các đường suport (hay đường margin, hoặc đường biên) tương ứng, ta gọi điểm đó rơi vào vùng không an toàn. Chú ý rằng vùng an toàn của hai classes là khác nhau, giao nhau ở phần nằm giữa hai đường support.\n\nTrong cả hai trường hợp trên, margin tạo bởi đường phân chia và đường nét đứt mảnh còn được gọi là soft margin (biên mềm). Cũng theo cách gọi này, SVM thuần còn được gọi là Hard Margin SVM (SVM biên cứng).\nTrong bài này, chúng ta sẽ tiếp tục tìm hiểu một biến thể của Hard Margin SVM có tên gọi là Soft Margin SVM.\nBài toán tối ưu cho Soft Margin SVM có hai cách tiếp cận khác nhau, cả hai đều mang lại những kết quả thú vị và có thể phát triển tiếp thành các thuật toán SVM phức tạp và hiệu quả hơn.\nCách giải quyết thứ nhất là giải một bài toán tối ưu có ràng buộc bằng cách giải bài toán đối ngẫu giống như Hard Margin SVM; cách giải dựa vào bài toán đối ngẫu này là cơ sở cho phương pháp Kernel SVM cho dữ liệu thực sự không linearly separable mà tôi sẽ đề cập trong bài tiếp theo. Hướng giải quyết này sẽ được tôi trình bày trong Mục 3 bên dưới.\nCách giải quyết thứ hai là đưa về một bài toán tối ưu không ràng buộc. Bài toán này có thể giải bằng các phương pháp Gradient Descent. Nhờ đó, cách giải quyết này có thể được áp dụng cho các bài toán large cale. Ngoài ra, trong cách giải này, chúng ta sẽ làm quen với một hàm mất mát mới có tên là hinge loss. Hàm mất mát này có thể mở rộng ra cho bài toán multi-class classification mà tôi sẽ đề cập sau 2 bài nữa (Multi-class SVM). Cách phát triển từ Soft Margin SVM thành Multi-class SVM có thể so sánh với cách phát triển từ Logistic Regression thành Softmax Regression. Hướng giải quyết này sẽ được tôi trình bày trong Mục 4 bên dưới.\nTrước hết, chúng ta cùng đi phân tích bài toán.\n\nNhư đã đề cập phía trên, để có một margin lớn hơn trong Soft Margin SVM, chúng ta cần hy sinh một vài điểm dữ liệu bằng cách chấp nhận cho chúng rơi vào vùng không an toàn. Tất nhiên, chúng ta phải hạn chế sự hy sinh này, nếu không, chúng ta có thể tạo ra một biên cực lớn bằng cách hy sinh hầu hết các điểm. Vậy hàm mục tiêu nên là một sự kết hợp để tối đa margin và tối thiểu sự hy sinh.\nGiống như với Hard Margin SVM, việc tối đa margin có thể đưa về việc tối thiểu \\(||\\mathbf{w}||_2^2\\). Để xác định sự hy sinh, chúng ta cùng theo dõi Hình 2 dưới đây:\nVới mỗi điểm \\(\\mathbf{x}_n\\) trong tập toàn bộ dữ liệu huấn luyện, ta giới thiệu thêm một biến đo sự hy sinh \\(\\xi_n\\) tương ứng. Biến này còn được gọi là slack variable. Với những điểm \\(\\mathbf{x}_n\\) nằm trong vùng an toàn, \\(\\xi_n = 0\\). Với mỗi điểm nằm trong vùng không an toàn như \\(\\mathbf{x}_1, \\mathbf{x}_2\\) hay \\(\\mathbf{x}_3\\), ta có \\(\\xi_i > 0\\). \n\nNhận thấy rằng nếu \\(y_i= \\pm 1\\) là nhãn của \\(\\mathbf{x}_i\\) trong vùng không an toàn thì \\(\\xi_i = |\\mathbf{w}^T\\mathbf{x}_i + b - y_i|\\). (Bạn có nhận ra không?)\nNhắc lại bài toán tối ưu cho Hard Margin SVM:\n\\[\n\\begin{eqnarray}\n    (\\mathbf{w}, b) &=& \\arg \\min_{\\mathbf{w}, b} \\frac{1}{2}{||\\mathbf{w}||_2^2}   \\newline\n    \\text{subject to:}~ && y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\geq 1, \\forall n = 1, 2, \\dots, N ~~~~(1)\n\\end{eqnarray}\n\\]\nVới Soft Margin SVM, hàm mục tiêu sẽ có thêm một số hạng nữa giúp tối thiểu sự hy sinh. Từ đó ta có hàm mục tiêu:\n\\[\n\\frac{1}{2}{||\\mathbf{w}||_2^2} + C \\sum_{n=1}^N \\xi_n\n\\]\ntrong đó \\(C\\) là một hằng số dương và \\(\\xi = [\\xi_1, \\xi_2, \\dots, \\xi_N]\\).\nHằng số \\(C\\) được dùng để điều chỉnh tầm quan trọng giữa margin và sự hy sinh. Hằng số này được xác định từ trước bởi người lập trình hoặc có thể được xác định bởi cross-validation.\nĐiều kiện ràng buộc sẽ thay đổi một chút. Với mỗi cặp dữ liệu \\((\\mathbf{x}_n, y_n)\\), thay vì ràng buộc cứng \\(y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\geq 1\\), chúng ta sẽ có ràng buộc mềm: \n\\[\ny_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\geq 1 - \\xi_n \\Leftrightarrow 1 - \\xi_n - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\leq 0, ~~ \\forall n = 1, 2, \\dots, n\n\\]\nVà ràng buộc phụ \\(\\xi_n \\geq 0, ~\\forall n = 1, 2, \\dots, N\\).\nTóm lại, ta sẽ có bài toán tối ưu ở dạng chuẩn cho Soft-margin SVM:\n\\[\n\\begin{eqnarray}\n    (\\mathbf{w}, b, \\xi) &=& \\arg \\min_{\\mathbf{w}, b, \\xi} \\frac{1}{2}{||\\mathbf{w}||_2^2} + C \\sum_{n=1}^N \\xi_n  \\newline\n    \\text{subject to:}~ && 1 - \\xi_n - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\leq 0, \\forall n = 1, 2, \\dots, N ~~~~(2) \\newline\n    && -\\xi_n \\leq 0,  ~\\forall n = 1, 2, \\dots, N\n\\end{eqnarray}\n\\]\nNhận xét:\nNếu \\(C\\) nhỏ, việc sự hy sinh cao hay thấp không gây ảnh hưởng nhiều tới giá trị của hàm mục tiêu, thuật toán sẽ điều chỉnh sao cho \\(||\\mathbf{x}||_2^2\\) là nhỏ nhất, tức margin là lớn nhất, điều này sẽ dẫn tới \\(\\sum_{n=1}^N\\xi_n\\) sẽ lớn theo. Ngược lại, nếu \\(C\\) quá lớn, để hàm mục tiêu đạt giá trị nhỏ nhất, thuật toán sẽ tập trung vào làm giảm \\(\\sum_{n=1}^N\\xi_n\\). Trong trường hợp \\(C\\) rất rất lớn và hai classes là linearly separable, ta sẽ thu được \\(\\sum_{n=1}^N\\xi_n = 0\\). Chú ý rằng giá trị này không thể nhỏ hơn 0. Điều này đồng nghĩa với việc không có điểm nào phải hy sinh, tức ta thu được nghiệm cho Hard Margin SVM. Nói cách khác, Hard Margin SVM chính là một trường hợp đặc biệt của Soft Margin SVM.\nBài toán tối ưu \\((2)\\) có thêm sự xuất hiện của slack variables \\(\\xi_n\\). Những \\(\\xi_n = 0\\) tương ứng với những điểm dữ liệu nằm trong vùng an toàn. Những \\(0 < \\xi_n \\leq 1\\) tương ứng với những điểm nằm trong vùng không an toàn những vẫn được phân loại đúng, tức vẫn nằm về đúng phía so với đường phân chia. Những \\(\\xi_n > 1\\) tương ứng với các điểm bị phân loại sai.\nHàm mục tiêu trong bài toán tối ưu \\((2)\\) là một hàm lồi vì nó là tổng của hai hàm lồi: hàm norm và hàm tuyến tính. Các hàm ràng buộc cũng là các hàm tuyến tính theo \\((\\mathbf{w}, b, \\xi)\\). Vì vậy bải toán tối ưu \\((2)\\) là một bài toán lồi, hơn nữa nó có thể biểu diễn dưới dạng một Quadratic Programming (QP).\nDưới đây, chúng ta sẽ cùng giải quyết bài toán tối ưu \\((2)\\) bằng hai cách khác nhau.\n\nChú ý rằng bài toán này có thể giải trực tiếp bằng các toolbox hỗ trợ QP, nhưng giống như với Hard Margin SVM, chúng ta sẽ quan tâm hơn tới bài toán đối ngẫu.\nTrước kết, ta cần kiểm tra tiêu chuẩn Slater cho bài toán tối ưu lồi \\((2)\\). Nếu tiêu chuẩn này được thoả mãn, strong duality sẽ thoả mãn, và ta sẽ có nghiệm của bài toán tối ưu \\((2)\\) là nghiệm của hệ điều kiện KKT. (Những kiến thức được đề cập trong mục này có thể được tìm thấy trong Bài 18).\n\nRõ ràng là với mọi \\(n = 1, 2, \\dots, N\\) và mọi \\((\\mathbf{w}, b)\\), ta luôn có thể tìm được các số dương \\(\\xi_n, n = 1, 2, \\dots, N\\) đủ lớn sao cho:\n\\[\ny_n(\\mathbf{w}^T\\mathbf{x}_n + b) + \\xi_n > 1, ~\\forall n = 1, 2, \\dots, N\n\\]\nVậy nên bài toán này thoả mãn tiêu chuẩn Slater.\n\nLagrangian cho bài toán \\((2)\\) là:\n\\[\n\\mathcal{L}(\\mathbf{w}, b, \\xi, \\lambda, \\mu) = \\frac{1}{2}{||\\mathbf{w}||_2^2} + C \\sum_{n=1}^N \\xi_n + \\sum_{n=1}^N \\lambda_n ( 1 - \\xi_n - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)) - \\sum_{n=1}^N \\mu_n \\xi_n ~ (3)\n\\]\nvới \\(\\lambda = [\\lambda_1, \\lambda_2, \\dots, \\lambda_N]^T \\succeq 0\\) và \\(\\mu = [\\mu_1, \\mu_2, \\dots, \\mu_N]^T \\succeq 0\\) là các biến đối ngẫu Lagrange (vector nhân tử Lagrange).\n\nHàm số đối ngẫu của bài toán tối ưu \\((2)\\) là:\n\\[\ng(\\lambda, \\mu) = \\min_{\\mathbf{w}, b, \\xi} \\mathcal{L}(\\mathbf{w}, b, \\xi, \\lambda, \\mu)\n\\]\nVới mỗi cặp \\((\\lambda,\\mu)\\), chúng ta sẽ quan tâm tới \\((\\mathbf{w}, b, \\xi)\\) thoả mãn điều kiện đạo hàm của Lagrangian bằng 0:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{w}} & = & 0 \\Leftrightarrow \\mathbf{w} = \\sum_{n=1}^N \\lambda_n y_n \\mathbf{x}_n &&(4)\\newline\n\\frac{\\partial \\mathcal{L}}{\\partial b} & = & 0 \\Leftrightarrow \\sum_{n=1}^N \\lambda_n y_n = 0 && (5)\\newline\n\\frac{\\partial \\mathcal{L}}{\\partial \\xi_n} & = & 0 \\Leftrightarrow \\lambda_n = C - \\mu_n && (6)\n\\end{eqnarray}\n\\]\nTừ \\((6)\\) ta thấy rằng ta chỉ quan tâm tới những cặp \\((\\lambda, \\mu)\\) sao cho \\(\\lambda_n = C - \\mu_n\\). Từ đây ta cũng suy ra \\(0 \\leq \\lambda_n, \\mu_n \\leq C, n = 1, 2, \\dots, N\\). Thay các biểu thức này vào Lagrangian ta sẽ thu được hàm đối ngẫu: \n\\[\ng(\\lambda, \\mu) = \\sum_{n=1}^N \\lambda_n - \\frac{1}{2} \\sum_{n=1}^N\\sum_{m=1}^N \\lambda_n \\lambda_m y_n y_m \\mathbf{x}_n^T\\mathbf{x}_m\n\\]\nChú ý rằng hàm này không phụ thuộc vào \\(\\mu\\) nhưng ta cần lưu ý ràng buộc \\((6)\\), ràng buộc này và điều kiện không âm của \\(\\lambda\\) có thể được viết gọn lại thành \\(0 \\leq \\lambda_n \\leq C\\), và ta đã giảm được biến \\(\\mu\\). Lúc này, bài toán đối ngẫu được xác định bới:\n\\[\n \\begin{eqnarray}\n     \\lambda &=& \\arg \\max_{\\lambda} g(\\lambda)   &&\\newline\n     \\text{subject to:}~ && \\sum_{n=1}^N \\lambda_ny_n = 0 && (7)\\newline\n     && 0 \\leq \\lambda_n \\leq C, ~\\forall n= 1, 2, \\dots, N && (8)\n \\end{eqnarray}\n \\]\nBài toán này gần giống với bài toán đối ngẫu của Hard Margin SVM, chỉ khác là ta có chặn trên cho mỗi \\(\\lambda_n\\). Khi \\(C\\) rất lớn, ta có thể coi hai bài toán là như nhau. Ràng buộc \\((8)\\) còn được gọi là box constraint vì không gian các điểm \\(\\lambda\\) thoả mãn ràng buộc này giống như một hình hộp chữ nhật trong không gian nhiều chiều.\nBài toán này cũng hoàn toàn giải được bằng các công cụ giải QP thông thường, ví dụ CVXOPT như tôi đã thực hiện trong bài Hard Margin SVM.\nSau khi tìm được \\(\\lambda\\) của bài toán đối ngẫu, ta vẫn phải quay lại tìm nghiệm \\((\\mathbf{w}, b, \\xi)\\) của bài toán gốc. Để làm điều này, chúng ta cùng xem xét hệ điều kiện KKT.\n\nHệ điều kiện KKT của bài toán tối ưu Soft Margin SVM là, với mọi \\(n = 1, 2, \\dots, N\\): \n\\[\n\\begin{eqnarray}\n1 - \\xi_n - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) &\\leq& 0 && (9) \\newline\n-\\xi_n &\\leq& 0 &&(10)\\newline\n\\lambda_n &\\geq& 0 &&(11)\\newline\n\\mu_n &\\geq & 0 && (12)\\newline\n\\lambda_n ( 1 - \\xi_n - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)) &=& 0 && (13)\\newline\n\\mu_n \\xi_n &=& 0 &&(14)\\newline\n\\mathbf{w} &=& \\sum_{n=1}^N \\lambda_n y_n \\mathbf{x}_n &&(4)\\newline\n\\sum_{n=1}^N \\lambda_n y_n &=& 0 && (5)\\newline\n\\lambda_n &=& C - \\mu_n && (6)\n\\end{eqnarray}\n\\]\n(Để cho dễ hình dung, tôi đã viết lại các điều kiện \\((4), (5), (6)\\) trong hệ này.)\nTa có một vài quan sát như sau:\nNếu \\(\\lambda_n = 0\\) thì từ \\((6)\\) ta suy ra \\(\\mu_n = C \\neq 0\\). Kết hợp với \\((14)\\) ta suy ra \\(\\xi_n = 0\\). Nói cách khác, không có sự hy sinh nào xảy ra ở \\(\\mathbf{x}_n\\), tức \\(\\mathbf{x}_n\\) nằm trong vùng an toàn.\nNếu \\(\\lambda_n > 0\\), từ \\((13)\\) ta có:\n\\[\ny_n(\\mathbf{w}^T\\mathbf{x}_n + b) = 1 - \\xi_n\n\\]\nNgoài ra, những điểm tương ứng với \\(0 < \\lambda_n \\leq C\\) bây giờ là sẽ là các support vectors. Mặc dù những điểm này có thể không nằm trên margins, chúng vẫn được coi là support vectors vì có công đóng góp cho việc tính toán \\(\\mathbf{w}\\) thông qua phương trình \\((4)\\).\nNhư vậy, dựa trên các giá trị của \\(\\lambda_n\\) ta có thể dự đoán được vị trí tương đối của \\(\\mathbf{x}_n\\) so với hai margins.\nĐặt \\(\\mathcal{M} = \\{n: 0 < \\lambda_n < C \\}\\) và \\(\\mathcal{S} = \\{m: 0 < \\lambda_m \\leq C\\}\\). Tức \\(\\mathcal{M}\\) là tập hợp các chỉ số của các điểm nằm chính xác trên margins - hỗ trợ cho việc tính \\(b\\), \\(\\mathcal{S}\\) là tập hợp các chỉ số của các support vectors - hỗ trợ trực tiếp cho việc tính \\(\\mathbf{w}\\). Tương tự như với Hard Margin SVM, các hệ số \\(\\mathbf{w}, b\\) có thể được xác định bởi:\n\\[\n\\begin{eqnarray}\n\\mathbf{w} &=& \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m & ~~~(15)  \\newline\nb &=& \\frac{1}{N_{\\mathcal{M}}} \\sum_{n \\in \\mathcal{M}} (y_n - \\mathbf{w}^T\\mathbf{x}_n) = \\frac{1}{N_{\\mathcal{M}}} \\sum_{n \\in \\mathcal{M}} \\left(y_n - \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T\\mathbf{x}_n\\right) & ~~~ (16)\n\\end{eqnarray}\n\\]\nNhắc lại rằng mục đích cuối cùng là xác định nhãn cho một điểm mới chứ không phải là tính \\(\\mathbf{w}\\) và \\(b\\) nên ta quan tâm hơn tới cách xác định giá trị của biếu thức sau với một điểm dữ liệu \\(\\mathbf{x}\\) bất kỳ:\n\\[\n\\mathbf{w}^T\\mathbf{x} + b = \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T \\mathbf{x} + \\frac{1}{N_{\\mathcal{M}}} \\sum_{n \\in \\mathcal{M}} \\left(y_n - \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T\\mathbf{x}_n\\right)\n\\]\nVà trong cách tính này, ta chỉ cần quan tâm tới tích vô hướng của hai điểm bất kỳ. Ở bài sau các bạn sẽ thấy rõ lợi ích của việc này nhiều hơn.\n\nTrong mục này, chúng ta sẽ đưa bài toán tối ưu có ràng buộc \\((2)\\) về một bài toán tối ưu không ràng buộc, và có có khả năng giải được bằng các phương pháp Gradient Descent.\n\nĐể ý thấy rằng điều kiện ràng buộc thứ nhất:\n\\[\n1 - \\xi_n -y_n(\\mathbf{w}^T\\mathbf{x} + b)) \\leq 0 \\Leftrightarrow \\xi_n \\geq 1 - y_n(\\mathbf{w}^T\\mathbf{x} + b))\n\\]\nKết hợp với điều kiện \\(\\xi_n \\geq 0\\) ta sẽ thu được bài toán ràng buộc tương đương với bài toán \\((2)\\) như sau:\n\\[\n\\begin{eqnarray}\n    (\\mathbf{w}, b, \\xi) &=& \\arg \\min_{\\mathbf{w}, b, \\xi} \\frac{1}{2}{||\\mathbf{w}||_2^2} + C \\sum_{n=1}^N \\xi_n  \\newline\n    \\text{subject to:}~ && \\xi_n \\geq \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x} + b)), ~\\forall n = 1, 2, \\dots, N~~~ (17)\n\\end{eqnarray}\n\\]\nTiếp theo, để đưa bài toán \\((17)\\) về dạng không ràng buộc, chúng ta sẽ chứng minh nhận xét sau đây bằng phương pháp phản chứng:\nNếu \\((\\mathbf{w}, b, \\xi)\\) là nghiệm của bài toán tối ưu \\((17)\\), tức tại đó hàm mục tiêu đạt giá trị nhỏ nhất, thì:\n\\[\n\\xi_n = \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)), ~\\forall n = 1, 2, \\dots, N ~~~ (18)\n\\]\nThật vậy, giả sử ngược lại, tồn tại \\(n\\) sao cho: \n\\[\n\\xi_n > \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b))\n\\]\nta chọn \\(\\xi_n’ = \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b))\\), ta sẽ thu được một giá trị thấp hơn của hàm mục tiêu, trong khi tất cả các ràng buộc vẫn được thoả mãn. Điều này mâu thuẫn với việc hàm mục tiêu đã đạt giá trị nhỏ nhất!\nVậy nhận xét \\((18)\\) được chứng minh.\nKhi đó, ta thay toàn bộ các giá trị của \\(\\xi_n\\) trong \\((18)\\) vào hàm mục tiêu: \n\\[\n\\begin{eqnarray}\n    (\\mathbf{w}, b, \\xi) &=& \\arg \\min_{\\mathbf{w}, b, \\xi} \\frac{1}{2}{||\\mathbf{w}||_2^2} + C \\sum_{n=1}^N \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)) \\newline\n    \\text{subject to:}~ && \\xi_n = \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)), ~\\forall n = 1, 2, \\dots, N~~~ (19)\n\\end{eqnarray}\n\\]\nRõ ràng rằng biến số \\(\\xi\\) không còn quan trọng trong bài toán này nữa, ta có thể lược bỏ nó mà không làm thay đổi nghiệm của bài toán: \n\\[\n(\\mathbf{w}, b)= \\arg \\min_{\\mathbf{w}, b} \\frac{1}{2}{||\\mathbf{w}||_2^2} + C \\sum_{n=1}^N \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)) \\triangleq \\arg\\min_{\\mathbf{w}, b} J(\\mathbf{w}, b) ~~~~ (20)\n\\]\nĐây là một bài toán tối ưu không ràng buộc với hàm mất mát \\(J(\\mathbf{w}, b)\\). Bài toán này có thể giải được bằng các phương pháp Gradient Descent. Nhưng trước hết, chúng ta cùng xem xét hàm mất mát này từ một góc nhìn khác, bằng định nghĩa của một hàm gọi là hinge loss\n\nNhắc lại một chút về hàm cross entropy chúng ta đã biết từ bài Logistic Regression và Softmax Regression. Với mỗi cặp hệ số \\((\\mathbf{w}, b)\\) và cặp dữ liệu, nhãn \\((\\mathbf{x}_n, y_n)\\), đặt \\(z_n = \\mathbf{w}^T\\mathbf{x}_n + b\\) và \\(a_n = \\sigma(z_n)\\) ( \\(\\sigma\\) là sigmoid function). Hàm cross entropy được định nghĩa là: \n\\[\nJ_n^1(\\mathbf{w}, b) = -(y_n \\log(a_n) + (1 - y_n) \\log(1 - a_n))\n\\]\nChúng ta đã biết rằng, hàm cross entropy đạt giá trị càng nhỏ nếu xác suất \\(a_n\\) càng gần với \\(y_n\\) \\((0 < a_n < 1)\\).\nỞ đây, chúng ta làm quen với một hàm số khác cũng được sử dụng nhiều trong các classifiers:\n\\[\nJ_n(\\mathbf{w}, b) = \\max(0, 1 - y_nz_n)\n\\]\nHàm này có tên là hinge loss. Trong đó, \\(z_n\\) có thể được coi là score của \\(\\mathbf{x}_n\\) ứng với cặp hệ số \\((\\mathbf{w}, b)\\), \\(y_n\\) chính là đầu ra mong muốn.\nHình 3 đưới dây mô tả hàm số hinge loss \\(f(ys) = \\max(0, 1 - ys)\\) và so sánh với hàm zero-one loss. Hàm zero-one loss là hàm đếm các điểm bị misclassified.\nTrong Hình 3, biến số là \\(y\\) là tích của đầu ra mong muốn (ground truth) và đầu ra tính được (score). Những điểm ở phía phải của trục tung ứng với những điểm được phân loại đúng, tức \\(s\\) tìm được cùng dấu với \\(y\\). Những điểm ở phía trái của trục tung ứng với các điểm bị phân loại sai. Ta có các nhận xét:\nVới hàm zero-one loss, các điểm có score ngược dấu với đầu ra mong muốn sẽ gây ra mất mát như nhau (bằng 1), bất kể chúng ở gần hay xa đường phân chia (trục tung). Đây là một hàm rời rạc, rất khó tối ưu và ta cũng khó có thể đo đếm được sự hy sinh như đã định nghĩa ở phần đầu.\nVới hàm hinge loss, những điểm nằm trong vùng an toàn, ứng với \\(ys \\geq 1\\), sẽ không gây ra mất mát gì. Những điểm nằm giữa margin của class tương ứng và đường phân chia tương ứng với \\(0 < y < 1\\), những điểm này gây ra một mất mát nhỏ. Những điểm bị misclassifed, tức \\(y < 0\\) sẽ gây ra mất mát lớn hơn, vì vậy, khi tối thiểu hàm mất mát, ta sẽ tránh được những điểm bị misclassifed và lấn sang phần class còn lại quá nhiều. Đây chính là một ưu điểm của hàm hinge loss.\nHàm hinge loss là một hàm liên tục, và có đạo hàm tại gần như mọi nơi (almost everywhere differentiable) trừ điểm có hoành độ bằng 1. Ngoài ra, đạo hàm của hàm này cũng rất dễ xác định: bằng -1 tại các điểm nhỏ hơn 1 và bằng 0 tại các điểm lớn hơn 1. Tại 1, ta có thể coi như đạo hàm của nó bằng 0 giống như cách tính đạo hàm của hàm ReLU.\n\nBây giờ, nếu ta xem xét bài toán Soft Margin SVM dưới góc nhìn hinge loss:\nVới mỗi cặp \\((\\mathbf{w}, b)\\), đặt: \n\\[\nL_n(\\mathbf{w}, b) = \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b))\n\\] \nLấy tổng tất cả các loss này (giống như cách mà Logistic Regression hay Softmax Regression lấy tổng của tất cả các cross entropy loss) theo \\(n\\) ta được: \n\\[\nL(\\mathbf{w}, b) = \\sum_{n=1}^N L_i = \\sum_{n=1}^N \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b))\n\\]\nCâu hỏi đặt ra là, nếu ta trực tiếp tối ưu tổng các hinge loss này thì điều gì sẽ xảy ra?\nTrong trường hợp dữ liệu trong hai class là linearly separable, ta sẽ có giá trị tối ưu tìm được của \\(L(\\mathbf{w}, b)\\) là bằng 0. Điều này có nghĩa là: \n\\[\n1 - y_n (\\mathbf{w}^T\\mathbf{x}_n + b) \\leq 0, ~\\forall n = 1, 2, \\dots, N\n\\]\nNhân cả hai về với một hằng số \\(a > 1\\) ta có: \n\\[\n\\begin{eqnarray}\na - y_n (a\\mathbf{w}^T\\mathbf{x}_n + ab) &\\leq& 0, ~\\forall n = 1, 2, \\dots, N \\newline\n\\Rightarrow 1 - y_n (a\\mathbf{w}^T\\mathbf{x}_n + ab) &\\leq& 1 - a < 0, ~\\forall n = 1, 2, \\dots, N\n\\end{eqnarray}\n\\]\nĐiều này nghĩa là \\((a\\mathbf{w}, ab)\\) cũng là nghiệm của bài toán. Nếu không có điều kiện gì thêm, bài toán có thể dẫn tới nghiệm không ổn định vì các hệ số của nghiệm có thể lớn tuỳ ý!\nĐể tránh bug này, chúng ta cần thêm một số hạng nữa vào \\(L(\\mathbf{w}, b)\\) gọi là số hạng regularization, giống như cách chúng ta đã làm để tránh overfitting trong neural networks. Lúc này, ta sẽ có hàm mất mát tổng cộng là: \n\\[\nJ(\\mathbf{w}, b) = L(\\mathbf{w}, b) + \\lambda R(\\mathbf{w}, b)\n\\]\nvới \\(\\lambda\\) là một số dương, gọi là regularization parameter, hàm \\(R()\\) sẽ giúp hạn chế việc các hệ số \\((\\mathbf{w}, b)\\) trở nên quá lớn. Có nhiều cách chọn hàm \\(R()\\), nhưng cách phổ biến nhất là \\(l_2\\), khi đó hàm mất mát của Soft Margin SVM sẽ là:\n\\[\nJ(\\mathbf{w}, b) = \\sum_{n=1}^N \\max(0, 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)) + \\frac{\\lambda}{2} ||\\mathbf{w}||_2^2 ~~~~~~~~~~~(21)\n\\]\nKỹ thuật này còn gọi là weight decay. Chú ý rằng weight decay thường không được áp dụng lên thành phần bias \\(b\\).\nTa thấy rằng hàm mất mát \\((21)\\) giống với hàm mất mát \\((20)\\) với \\(\\lambda = \\frac{1}{C}\\). Ở đây, tôi đã lấy \\(\\lambda /2\\) để biểu thức đạo hàm được đẹp hơn.\nTrong phần tiếp theo của mục này, chúng ta sẽ quan tâm tới bài toán tối ưu hàm mất mát được cho trong \\((21)\\).\nNhận thấy rằng ta có thể khiến biểu thức \\((19)\\) gọn hơn một chút bằng cách sử dụng bias trick như đã làm trong Linear Regression hay các bài về neurel networks. Bằng cách mở rộng thêm một thành phần bằng 1 vào các điểm dữ liệu \\(\\mathbf{x}_n \\in \\mathbb{R}^d\\) để được \\(\\bar{\\mathbf{x}}_n \\in \\mathbb{R}^{d+1}\\) và kết hợp \\(\\mathbf{w}, b\\) thành một vector \\(\\bar{\\mathbf{w}} = [\\mathbf{w}^T, b]^T \\in \\mathbb{R}^{d+1}\\) ta sẽ có một biểu thức gọn hơn. Khi đó, hàm mất mát trong \\((21)\\) có thể được viết gọn thành: \n\\[\nJ(\\mathbf{\\bar{w}}) = \\underbrace{\\sum_{n=1}^N \\max(0, 1 - y_n\\bar{\\mathbf{w}}^T\\mathbf{\\bar{x}}_n)}_{\\text{hinge loss}} + \\underbrace{\\frac{\\lambda}{2} ||\\mathbf{w}||_2^2}_{\\text{regularization}}\n\\]\nCác bạn có thể nhận thấy rằng đây là một hàm lồi theo \\(\\mathbf{\\bar{w}}\\) vì:\n\\(1 - y_n\\bar{\\mathbf{w}}^T\\mathbf{\\bar{x}}_n\\) là 1 hàm tuyến tính nên nó là một hàm lồi. Hàm hằng số là một hàm lồi, \\(\\max\\) cuả hai hàm lồi là một hàm lồi. Vậy biểu thức hinge loss là một hàm lồi.\nNorm là một hàm lồi, vậy số hạng regularization cũng là một hàm lồi.\nTổng của hai hàm lồi là một hàm lồi.\nVì bài toán tối ưu bây giờ là không ràng buộc, chúng ta có thể sử dụng các phương pháp Gradient Descent để tối ưu. Hơn nữa, vì tính chất lồi của hàm mất mát, nếu chọn learning rate không quá lớn và số vòng lặp đủ nhiều, thuật toán sẽ hội tụ tới điểm global optimal của bài toán.\n\nTrước hết ta cần tính được đạo hàm của hàm mất mát theo \\(\\mathbf{\\bar{w}}\\). Việc này thoáng qua có vẻ hơi phức tạp vì ta cần tính đạo hàm của hàm \\(\\max\\), nhưng nếu chúng ta nhìn vào đạo hàm của hinge loss, ta có thể tính được đạo hàm theo \\(\\mathbf{\\bar{w}}\\) một cách đơn giản.\nChúng ta tạm quên đi đạo hàm của phần regularization vì nó đơn giản bằng \\(\\lambda \\left[\\begin{matrix}\n\\mathbf{w}\\newline\n0\n\\end{matrix}\\right]\\) với thành phần 0 ở cuối chính là đạo hàm theo bias của thành phần regularization.\nVới phần hinge loss, xét từng điểm dữ liệu, ta có hai trường hợp:\nTH1: Nếu \\( 1 - y_n \\mathbf{\\bar{w}}^T\\mathbf{\\bar{x}}_n \\leq 0\\), ta có ngay đạo hàm theo \\(\\mathbf{\\bar{w}}\\) bằng 0.\nTH2: Nếu \\( 1 - y_n \\mathbf{\\bar{w}}^T\\mathbf{\\bar{x}}_n > 0\\), đạo hàm theo \\(\\mathbf{w}\\) chính là \\(-y_n\\mathbf{x}_n\\).\nĐể tính gradient cho toàn bộ dữ liệu, chúng ta cần một chút kỹ năng biến đổi đại số tuyến tính.\nĐặt: \n\\[\n\\begin{eqnarray}\n\\mathbf{Z} &=& [y_1 \\mathbf{\\bar{x}}_1, y_2 \\mathbf{\\bar{x}}_2, \\dots, y_N\\mathbf{\\bar{x}}_N] & ~~~(22) \\newline\n\\mathbf{u} &=& [y_1\\mathbf{\\bar{w}}^T\\mathbf{\\bar{x}}_1,y_2\\mathbf{\\bar{w}}^T\\mathbf{\\bar{x}}_2, \\dots, y_N \\mathbf{\\bar{w}}^T \\mathbf{\\bar{x}}_N] = \\mathbf{\\bar{w}}^T\\mathbf{Z} & ~~~ (23)\n\\end{eqnarray}\n\\]\nvới chú ý rằng \\(\\mathbf{u}\\) là một vector hàng.\nTiếp tục, ta cần xác định các vị trí của \\(\\mathbf{u}\\) có giá trị nhỏ hơn 1, tức ứng với TH2 ở trên. Bằng cách đặt: \n\\[\n\\mathcal{H} = \\{n: u_n < 1\\}\n\\]\nta có thể suy ra cách tính đạo hàm theo \\(\\mathbf{\\bar{w}}\\) của hàm mất mát là\n\\[\n\\nabla J(\\mathbf{\\bar{w}}) = \\sum_{n \\in \\mathcal{H}} - y_n\\mathbf{\\bar{x}}_n  + \\lambda \n\\left[\\begin{matrix}\n\\mathbf{w}\\newline\n0\n\\end{matrix}\\right] ~~~ (24)\n\\]\nCác bạn sẽ thấy cách tính toán giá trị này một cách hiệu quả trong phần lập trình.\nVậy quy tắc cập nhật của \\(\\mathbf{\\bar{w}}\\) sẽ là: \n\\[\n\\mathbf{\\bar{w}} = \\mathbf{\\bar{w}} - \\eta \\left(\\sum_{n \\in \\mathcal{H}} - y_n\\mathbf{\\bar{x}}_n  + \\lambda \\left[\\begin{matrix}\n\\mathbf{w}\\newline\n0\n\\end{matrix}\\right]\\right) ~~~ (25)\n\\]\nvới \\(\\eta\\) là learning rate.\nVới các bài toán large-scale, ta có thể sử dụng phương pháp Mini-batch Gradient Descent để tối ưu. Đây chính là một ưu điểm của hướng tiếp cận theo hinge loss.\n\nTrong mục này, chúng ta cùng làm hai thí nghiệm nhỏ. Thứ nghiệm thứ nhất sẽ đi tìm nghiệm của một bài toán Soft Margin SVM bằng ba cách khác nhau: Sử dụng thư viện sklearn, Giải bài toán đối ngẫu bằng CVXOPT, và Tối ưu hàm mất mát không ràng  bằng phương pháp Gradient Descent. Nếu mọi tính toán ở trên là chính xác, nghiệm của ba cách làm này sẽ giống nhau, khác nhau có thể một chút bởi sai số trong tính toán. Ở thí nghiệm thứ hai, chúng ta sẽ thay \\(C\\) bởi những giá trị khác nhau và cùng xem các margin thay đổi như thế nào.\n\nSource code cho phần này có thể được tìm thấy tại đây.\n\nHình 4 minh hoạ các điểm dữ liệu của hai classes.\n\nTa chọn \\(C = 100\\) trong thí nghiệm này:\nNghiệm tìm được:\n\nTương tự như việc giải bài toán Hard Margin SVM, chỉ khác rằng ta có thêm ràng buộc về chặn trên của các nhân thử Lagrange:\nTrong các thành phần của lambda tìm được, có rất nhiều thành phần nhỏ tới 1e-6 hay 1e-7. Đây chính là các lambda_i = 0. Có rất nhiều phần tử xấp xỉ 9.99e+01, đây chính là các lambda_i bằng với C = 100, tương ứng với các support vectors không nằm trên margins, các sai số nhỏ xảy ra do tính toán. Các giá trị còn lại nằm giữa 0 và 100 là các giá trị tương ứng với các điểm nằm chính xác trên hai margins.\nTiếp theo, ta cần tính w và b theo công thức \\((15)\\) và \\((16)\\). Trước đó ta cần tìm tập hợp các điểm support và những điểm nằm trên margins.\nKết quả:\nKết quả này gần giống với kết quả tìm được bằng sklearn.\n\nTrong phương pháp này, chúng ta cần tính gradient của hàm mất mát. Như thường lệ, chúng ta cần kiểm chứng  này bằng cách so sánh  với numerical gradient.\nChú ý rằng trong phương pháp này, ta cần dùng tham số lam = 1/C.\nVì sự khác nhau giữa hai cách tính gradient là bằng 0, ta có thể yên tâm rằng gradient tính được là chính xác.\nSau khi chắc chắn rằng gradient tìm được đã chính xác, ta có thể bắt đầu làm Gradient Descent:\nKết quả:\nTa thấy rằng kết quả tìm được bằng ba cách là như nhau. Hình 5 dưới đây minh hoạ kết quả bằng ba cách tính:\nTrong thực hành, phương pháp 1 chắc chắn được lựa chọn. Hai phương pháp còn lại được dùng làm cơ sở cho các phương pháp SVM nâng cao hơn trong các bài sau.\n\nHình 6 dưới đây minh hoạ nghiệm tìm được cho bài toán phía trên nhưng với các giá trị \\(C\\) khác nhau. Nghiệm được tìm bằng thư viện sklearn.\nChúng ta nhận thấy rằng khi (C) càng lớn thì biên càng nhỏ đi. Điều này phù hợp với suy luận của chúng ta ở Mục 2.\n\nSVM thuần (Hard Margin SVM) hoạt động không hiệu quả khi có nhiễu ở gần biên hoặc thậm chí khi dữ liệu giữa hai lớp gần linearly separable. Soft Margin SVM có thể giúp khắc phục điểm này.\nTrong Soft Margin SVM, chúng ta chấp nhận lỗi xảy ra ở một vài điểm dữ liệu. Lỗi này được xác định bằng khoảng cách từ điểm đó tới đường biên tương ứng. Bài toán tối ưu sẽ tối thiểu lỗi này bằng cách sử dụng thêm các biến được gọi là slack varaibles.\nĐể giải bài toán tối ưu, có hai cách khác nhau. Mỗi cách có những ưu, nhược điểm riêng, các bạn sẽ thấy trong các bài tới.\nCách thứ nhất là giải bài toán đối ngẫu. Bài toán đối ngẫu của Soft Margin SVM rất giống với bài toán đối ngẫu của Hard Margin SVM, chỉ khác ở ràng buộc chặn trên của các nhân tử Laggrange. Ràng buộc này còn được gọi là box costraint.\nCách thứ hai là đưa bài toán về dạng không ràng buộc dựa trên một hàm mới gọi là hinge loss. Với cách này, hàm mất mát thu được là một hàm lồi và có thể giải được khá dễ dàng và hiệu quả bằng các phương pháp Gradient Descent.\nTrong Soft Margin SVM, có một hằng số phải được chọn, đó là \\(C\\). Hướng tiếp cận này còn được gọi là C-SVM. Ngoài ra, còn có một hướng tiếp cận khác cũng hay được sử dụng, gọi là \\(\\nu\\)-SVM, bạn đọc có thể đọc thêm tại đây.\nSource code\n\n[1] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer  (2006). (book)\n[2] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012.\n[3] sklearn.svm.SVC\n[4] LIBSVM – A Library for Support Vector Machines\n[5] Bennett, K. P. (1992). “Robust linear programming discrimination of two linearly separable sets”. Optimization Methods and Software 1, 23–34.\n[6] Sch¨olkopf, B., A. Smola, R. C.Williamson, and P. L. Bartlett (2000). “New support vector algorithms”. Neural Computation 12(5), 1207–1245\n[7]  Rosasco, L.; De Vito, E. D.; Caponnetto, A.; Piana, M.; Verri, A. (2004). “Are Loss Functions All the Same?”. Neural Computation. 16 (5): 1063–1076"
    },
    {
        "ID": 30,
        "URL": "https://machinelearningcoban.com/2017/04/09/smv/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong loạt bài tiếp theo, tôi sẽ trình bày về một trong những thuật toán classification phổ biến nhất (cùng với softmax regression). Có rất nhiều suy luận toán học trong phần này yêu cầu bạn cần có kiến thức về Duality cũng như về tối ưu lồi. Bạn được khuyến khích đọc các Bài 16, 17, và 18 trước khi đọc bài này.\nNếu không muốn đi sâu vào phần toán, bạn có thể bỏ qua mục 3.\nTrong trang này:\n\n\nTrước khi đi vào phần ý tưởng chính của Support Vector Machine, tôi xin một lần nữa nhắc lại kiến thức về hình học giải tích mà chúng ta đã quá quen khi ôn thi đại học.\n\nTrong không gian 2 chiều, ta biết rằng khoảng cách từ một điểm có toạ độ \\((x_0, y_0)\\) tới đường thẳng có phương trình \\(w_1x + w_2y + b = 0\\) được xác định bởi: \n\\[\n\\frac{|w_1x_0 + w_2y_0 + b|}{\\sqrt{w_1^2 + w_2^2}}\n\\]\nTrong không gian ba chiều, khoảng cách từ một điểm có toạ độ \\((x_0, y_0, z_0)\\) tới một mặt phẳng có phương trình \\(w_1x + w_2y + w_3 z + b = 0\\) được xác định bởi: \n\\[\n\\frac{|w_1x_0 + w_2y_0 + w_3z_0 + b |}{\\sqrt{w_1^2 + w_2^2 + w_3^2}}\n\\]\nHơn nữa, nếu ta bỏ dấu trị tuyệt đối ở tử số, chúng ta có thể xác định được điểm đó nằm về phía nào của đường thẳng hay mặt phẳng đang xét. Những điểm làm cho biểu thức trong dấu giá trị tuyệt đối mang dấu dương nằm về cùng 1 phía (tôi tạm gọi đây là phía dương của đường thẳng), những điểm làm cho biểu thức trong dấu giá trị tuyệt đối mang dấu âm nằm về phía còn lại (tôi gọ là phía âm). Những điểm nằm trên đường thẳng/măt phẳng sẽ làm cho tử số có giá trị bằng 0, tức khoảng cách bằng 0.\nViệc này có thể được tổng quát lên không gian nhiều chiều: Khoảng cách từ một điểm (vector) có toạ độ \\(\\mathbf{x}_0\\) tới siêu mặt phẳng (hyperplane) có phương trình \\(\\mathbf{w}^T\\mathbf{x} + b = 0\\) được xác định bởi: \n\\[\n\\frac{|\\mathbf{w}^T\\mathbf{x}_0 + b|}{||\\mathbf{w}||_2}\n\\]\nVới \\(||\\mathbf{w}||_2 = \\sqrt{\\sum_{i=1}^d w_i^2}\\) với \\(d\\) là số chiều của không gian.\n\nChúng ta cùng quay lại với bài toán trong Perceptron Learning Algorithm (PLA). Giả sử rằng có hai class khác nhau được mô tả bởi các điểm trong không gian nhiều chiều, hai classes này linearly separable, tức tồn tại một siêu phẳng phân chia chính xác hai classes đó. Hãy tìm một siêu mặt phẳng phân chia hai classes đó, tức tất cả các điểm thuộc một class nằm về cùng một phía của siêu mặt phẳng đó và ngược phía với toàn bộ các điểm thuộc class còn lại. Chúng ta đã biết rằng, thuật toán PLA có thể làm được việc này nhưng nó có thể cho chúng ta vô số nghiệm như Hình 1 dưới đây:\nCâu hỏi đặt ra là: trong vô số các mặt phân chia đó, đâu là mặt phân chia tốt nhất theo một tiêu chuẩn nào đó? Trong ba đường thẳng minh họa trong Hình 1 phía trên, có hai đường thẳng khá lệch về phía class hình tròn đỏ. Điều này có thể khiến cho lớp màu đỏ không vui vì lãnh thổ xem ra bị lấn nhiều quá. Liệu có cách nào để tìm được đường phân chia mà cả hai classes đều cảm thấy công bằng và hạnh phúc nhất hay không?\nChúng ta cần tìm một tiêu chuẩn để đo sự hạnh phúc của mỗi class. Hãy xem Hình 2 dưới đây:\nNếu ta định nghĩa mức độ hạnh phúc của một class tỉ lệ thuận với khoảng cách gần nhất từ một điểm của class đó tới đường/mặt phân chia, thì ở Hình 2 trái, class tròn đỏ sẽ không được hạnh phúc cho lắm vì đường phân chia gần nó hơn class vuông xanh rất nhiều. Chúng ta cần một đường phân chia sao cho khoảng cách từ điểm gần nhất của mỗi class (các điểm được khoanh tròn) tới đường phân chia là như nhau, như thế thì mới công bằng. Khoảng cách như nhau này được gọi là margin (lề).\nĐã có công bằng rồi, chúng ta cần văn minh nữa. Công bằng mà cả hai đều kém hạnh phúc như nhau thì chưa phải là văn mình cho lắm.\nChúng ta xét tiếp Hình 2 bên phải khi khoảng cách từ đường phân chia tới các điểm gần nhất của mỗi class là như nhau. Xét hai cách phân chia bởi đường nét liền màu đen và đường nét đứt màu lục, đường nào sẽ làm cho cả hai class hạnh phúc hơn? Rõ ràng đó phải là đường nét liền màu đen vì nó tạo ra một margin rộng hơn.\nViệc margin rộng hơn sẽ mang lại hiệu ứng phân lớp tốt hơn vì sự phân chia giữa hai classes là rạch ròi hơn. Việc này, sau này các bạn sẽ thấy, là một điểm khá quan trọng giúp Support Vector Machine mang lại kết quả phân loại tốt hơn so với Neural Network với 1 layer, tức Perceptron Learning Algorithm.\nBài toán tối ưu trong Support Vector Machine (SVM) chính là bài toán đi tìm đường phân chia sao cho margin là lớn nhất. Đây cũng là lý do vì sao SVM còn được gọi là Maximum Margin Classifier. Nguồn gốc của tên gọi Support Vector Machine sẽ sớm được làm sáng tỏ.\n\nGiả sử rằng các cặp dữ liệu của training set là \\((\\mathbf{x}_1, y_1), (\\mathbf{x}_2, y_2), \\dots, (\\mathbf{x}_N, y_N)\\) với vector \\(\\mathbf{x}_i \\in \\mathbb{R}^d\\) thể hiện đầu vào của một điểm dữ liệu và \\(y_i\\) là nhãn của điểm dữ liệu đó. \\(d\\) là số chiều của dữ liệu và \\(N\\) là số điểm dữ liệu. Giả sử rằng nhãn của mỗi điểm dữ liệu được xác định bởi \\(y_i = 1\\) (class 1) hoặc \\(y_i = -1\\) (class 2) giống như trong PLA.\nĐể giúp các bạn dễ hình dung, chúng ta cùng xét trường hợp trong không gian hai chiều dưới đây. Không gian hai chiều để các bạn dễ hình dung, các phép toán hoàn toàn có thể được tổng quát lên không gian nhiều chiều.\nGiả sử rằng các điểm vuông xanh thuộc class 1, các điểm tròn đỏ thuộc class -1 và mặt \\(\\mathbf{w}^T\\mathbf{x} + b = w_1x_1 + w_2x_2 + b = 0\\) là mặt phân chia giữa hai classes (Hình 3). Hơn nữa, class 1 nằm về phía dương, class -1 nằm về phía âm của mặt phân chia. Nếu ngược lại, ta chỉ cần đổi dấu của \\(\\mathbf{w}\\) và \\(b\\). Chú ý rằng chúng ta cần đi tìm các hệ số \\(\\mathbf{w}\\) và \\(b\\).\nTa quan sát thấy một điểm quan trọng sau đây: với cặp dữ liệu \\((\\mathbf{x}_n, y_n)\\) bất kỳ, khoảng cách từ điểm đó tới mặt phân chia là: \n\\[\n\\frac{y_n(\\mathbf{w}^T\\mathbf{x}_n + b)}{||\\mathbf{w}||_2}\n\\]\nĐiều này có thể dễ nhận thấy vì theo giả sử ở trên, \\(y_n\\) luôn cùng dấu với phía của \\(\\mathbf{x}_n\\). Từ đó suy ra \\(y_n\\) cùng dấu với \\((\\mathbf{w}^T\\mathbf{x}_n + b)\\), và tử số luôn là 1 số không âm.\nVới mặt phần chia như trên, margin được tính là khoảng cách gần nhất từ 1 điểm tới mặt đó (bất kể điểm nào trong hai classes):\n\\[\n\\text{margin} = \\min_{n} \\frac{y_n(\\mathbf{w}^T\\mathbf{x}_n + b)}{||\\mathbf{w}||_2}\n\\]\nBài toán tối ưu trong SVM chính là bài toán tìm \\(\\mathbf{w}\\) và \\(b\\) sao cho margin này đạt giá trị lớn nhất: \n\\[\n(\\mathbf{w}, b) = \\arg\\max_{\\mathbf{w}, b} \\left\\{\n    \\min_{n} \\frac{y_n(\\mathbf{w}^T\\mathbf{x}_n + b)}{||\\mathbf{w}||_2} \n\\right\\}\n= \\arg\\max_{\\mathbf{w}, b}\\left\\{\n    \\frac{1}{||\\mathbf{w}||_2} \\min_{n} y_n(\\mathbf{w}^T\\mathbf{x}_n + b)\n\\right\\} ~~~ (1)\n\\]\nViệc giải trực tiếp bài toán này sẽ rất phức tạp, nhưng các bạn sẽ thấy có cách để đưa nó về bài toán đơn giản hơn.\nNhận xét quan trọng nhất là nếu ta thay vector hệ số \\(\\mathbf{w}\\) bởi \\(k\\mathbf{w}\\) và \\(b\\) bởi \\(kb\\) trong đó \\(k\\) là một hằng số dương thì mặt phân chia không thay đổi, tức khoảng cách từ từng điểm đến mặt phân chia không đổi, tức margin không đổi. Dựa trên tính chất này, ta có thể giả sử: \n\\[\ny_n(\\mathbf{w}^T\\mathbf{x}_n + b) = 1\n\\]\nvới những điểm nằm gần mặt phân chia nhất như Hình 4 dưới đây:\nNhư vậy, với mọi \\(n\\), ta có: \n\\[\ny_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\geq 1\n\\]\nVậy bài toán tối ưu \\((1)\\) có thể đưa về bài toán tối ưu có ràng buộc sau đây: \n\\[\n\\begin{eqnarray}\n    (\\mathbf{w}, b) &=& \\arg \\max_{\\mathbf{w}, b} \\frac{1}{||\\mathbf{w}||_2}   \\newline\n    \\text{subject to:}~ && y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\geq 1, \\forall n = 1, 2, \\dots, N ~~~~(2)\n\\end{eqnarray}\n\\]\nBằng 1 biến đổi đơn giản, ta có thể đưa bài toán này về bài toán dưới đây:\n\\[\n\\begin{eqnarray}\n    (\\mathbf{w}, b) &=& \\arg \\min_{\\mathbf{w}, b} \\frac{1}{2}||\\mathbf{w}||_2^2   \\newline\n    \\text{subject to:}~ && 1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\leq 0, \\forall n = 1, 2, \\dots, N ~~~~ (3)\n\\end{eqnarray}\n\\]\nỞ đây, chúng ta đã lấy nghịch đảo hàm mục tiêu, bình phương nó để được một hàm khả vi, và nhân với \\(\\frac{1}{2}\\) để biểu thức đạo hàm đẹp hơn.\nQuan sát quan trọng: Trong bài toán \\((3)\\), hàm mục tiêu là một norm, nên là một hàm lồi. Các hàm bất đẳng thức ràng buộc là các hàm tuyến tính theo \\(\\mathbf{w}\\) và \\(b\\), nên chúng cũng là các hàm lồi. Vậy bài toán tối ưu \\((3)\\) có hàm mục tiêu là lồi, và các hàm ràng buộc cũng là lồi, nên nó là một bài toán lồi. Hơn nữa, nó là một Quadratic Programming. Thậm chí, hàm mục tiêu là strictly convex vì \\(||\\mathbf{w}||_2^2 = \\mathbf{w}^T\\mathbf{I}\\mathbf{w}\\) và \\(\\mathbf{I}\\) là ma trận đơn vị - là một ma trận xác định dương. Từ đây có thể suy ra nghiệm cho SVM là duy nhất.\nĐến đây thì bài toán này có thể giải được bằng các công cụ hỗ trợ tìm nghiệm cho Quadratic Programing, ví dụ CVXOPT.\nTuy nhiên, việc giải bài toán này trở nên phức tạp khi số chiều \\(d\\) của không gian dữ liệu và số điểm dữ liệu \\(N\\) tăng lên cao.\nNgười ta thường giải bài toán đối ngẫu của bài toán này. Thứ nhất, bài toán đối ngẫu có những tính chất thú vị hơn khiến nó được giải hiệu quả hơn. Thứ hai, trong quá trình xây dựng bài toán đối ngẫu, người ta thấy rằng SVM có thể được áp dụng cho những bài toán mà dữ liệu không linearly separable, tức các đường phân chia không phải là một mặt phẳng mà có thể là các mặt có hình thù phức tạp hơn.\nĐến đây, bạn đọc có thể bắt đầu hiểu tại sao tôi cần viết 3 bài 16-18 trước khi viết bài này. Nếu bạn muốn hiểu sâu hơn về SVM, tôi khuyến khích đọc Mục 3 dưới đây. Nếu không, bạn có thể sang Mục 4 để xem ví dụ về cách sử dụng SVM khi lập trình.\nXác định class cho một điểm dữ liệu mới: Sau khi tìm được mặt phân cách \\(\\mathbf{w}^T\\mathbf{x} + b = 0\\), class của bất kỳ một điểm nào sẽ được xác định đơn giản bằng cách:\n\\[\n\\text{class}(\\mathbf{x}) = \\text{sgn} (\\mathbf{w}^T\\mathbf{x} + b )\n\\]\nTrong đó hàm \\(\\text{sgn}\\) là hàm xác định dấu, nhận giá trị 1 nếu đối số là không âm và -1 nếu ngược lại.\n\nNhắc lại rằng bài toán tối ưu \\((3)\\) là một bài toán lồi. Chúng ta biết rằng: nếu một bài toán lồi thoả mãn tiêu chuẩn Slater thì strong duality thoả mãn. Và nếu strong duality thoả mãn thì nghiệm của bài toán chính là nghiệm của hệ điều kiện KKT.\n\nBước tiếp theo, chúng ta sẽ chứng minh bài toán tối ưu \\((3)\\) thoả mãn điều kiện Slater. Điều kiện Slater nói rằng, nếu tồn tại \\(\\mathbf{w}, b\\) thoả mãn:\n\\[\n1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) < 0, ~~\\forall n = 1, 2, \\dots, N\n\\]\nthì strong duality thoả mãn.\nViệc kiểm tra này tương đối đơn giản. Vì ta biết rằng luôn luôn có một (siêu) mặt phẳng phân chia hai classes nếu hai class đó là linearly separable, tức bài toán có nghiệm, nên feasible set của bài toán tối ưu \\((3)\\) phải khác rỗng. Tức luôn luôn tồn tại cặp \\((\\mathbf{w}_0, b_0)\\) sao cho:\n\\[\n\\begin{eqnarray}\n1 - y_n(\\mathbf{w}_0^T\\mathbf{x}_n + b_0) &\\leq& 0, ~~\\forall n = 1, 2, \\dots, N \\newline\n\\Leftrightarrow 2 - y_n(2\\mathbf{w}_0^T\\mathbf{x}_n + 2b_0) &\\leq& 0, ~~\\forall n = 1, 2, \\dots, N \n\\end{eqnarray}\n\\]\nVậy chỉ cần chọn \\(\\mathbf{w}_1 = 2\\mathbf{w}_0\\) và \\(b_1 = 2b_0\\), ta sẽ có: \n\\[\n1 - y_n(\\mathbf{w}_1^T\\mathbf{x}_n + b_1) \\leq -1 < 0, ~~\\forall n = 1, 2, \\dots, N\n\\]\nTừ đó suy ra điều kiện Slater thoả mãn.\n\nLagrangian của bài toán \\((3)\\) là: \n\\[\n\\mathcal{L}(\\mathbf{w}, b, \\lambda) = \\frac{1}{2} ||\\mathbf{w}||_2^2 + \\sum_{n=1}^N \\lambda_n(1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) ) ~~~~~~(4)\n\\]\nvới \\(\\lambda = [\\lambda_1, \\lambda_2, \\dots, \\lambda_N]^T\\) và \\(\\lambda_n \\geq 0, ~\\forall n = 1, 2, \\dots, N\\).\n\nHàm đối ngẫu Lagrange được định nghĩa là: \n\\[\ng(\\lambda) = \\min_{\\mathbf{w}, b} \\mathcal{L}(\\mathbf{w}, b, \\lambda) \n\\]\nvới \\(\\lambda \\succeq 0\\).\nViệc tìm giá trị nhỏ nhất của hàm này theo \\(\\mathbf{w}\\) và \\(b\\) có thể đựợc thực hiện bằng cách giải hệ phương trình đạo hàm của \\(\\mathcal{L}(\\mathbf{w}, b, \\lambda)\\) theo \\(\\mathbf{w}\\) và \\(b\\) bằng 0:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial \\mathcal{L}(\\mathbf{w}, b, \\lambda)}{\\partial \\mathbf{w}} &=& \\mathbf{w} - \\sum_{n=1}^N \\lambda_n y_n \\mathbf{x}_n = 0 \\Rightarrow \\mathbf{w} = \\sum_{n=1}^N \\lambda_n y_n \\mathbf{x}_n  ~~~~~ (5)\\newline\n\\frac{\\partial \\mathcal{L}(\\mathbf{w}, b, \\lambda)}{\\partial b} &=& \n-\\sum_{n=1}^N \\lambda_ny_n = 0 ~~~~~~~~~~(6)\n\\end{eqnarray}\n\\]\nThay \\((5)\\) và \\((6)\\) vào \\((4)\\) ta thu được \\(g(\\lambda)\\)(phần này tôi rút gọn, coi như một bài tập nhỏ cho bạn nào muốn hiểu sâu):\n\\[\ng(\\lambda) = \\sum_{n=1}^N \\lambda_n  -\\frac{1}{2}\\sum_{n=1}^N \\sum_{m=1}^N \\lambda_n\\lambda_m y_n y_m \\mathbf{x}_n^T\\mathbf{x}_m~~~~~~~~~(7)\n\\]\nĐây là hàm số quan trọng nhất trong SVM, các bạn sẽ thấy rõ hơn ở bài sau.\nXét ma trận:\n\\[\n\\mathbf{V} = \\left[y_1 \\mathbf{x}_1, y_2 \\mathbf{x}_2, \\dots, y_N \\mathbf{x}_N \\right]\n\\]\nvà vector \\(\\mathbf{1} = [1, 1, \\dots, 1]^T\\), ta có thể viết lại \\(g(\\lambda)\\) dưới dạng: \n\\[\ng(\\lambda) = -\\frac{1}{2}\\lambda^T\\mathbf{V}^T\\mathbf{V}\\mathbf{\\lambda} + \\mathbf{1}^T\\lambda. ~~~~~~~~~~~~~~~(8)\n\\]\n(Nếu khó tin, bạn có thể viết ra để quen dần với các biểu thức đại số tuyến tính.)\nĐặt \\(\\mathbf{K} = \\mathbf{V}^T\\mathbf{V}\\), ta có một quan sát quan trọng: \\(\\mathbf{K}\\) là một ma trận nửa xác định dương. Thật vậy, với mọi vector \\(\\lambda\\), ta có:\n\\[\n\\lambda^T\\mathbf{K}\\mathbf{\\lambda} = \\lambda^T\\mathbf{V}^T\\mathbf{V}\\mathbf{\\lambda} = ||\\mathbf{V}\\lambda||_2^2 \\geq 0.\n\\]\n(Đây chính là định nghĩa của ma trận nửa xác định dương.)\nVậy \\(g(\\lambda) = -\\frac{1}{2}\\lambda^T\\mathbf{K}\\mathbf{\\lambda} + \\mathbf{1}^T\\lambda\\) là một hàm concave.\n\nTừ đó, kết hợp hàm đối ngẫu Lagrange và các điều kiện ràng buộc của \\(\\lambda\\), ta sẽ thu được bài toán đối ngẫu Lagrange:\n\\[\n \\begin{eqnarray}\n     \\lambda &=& \\arg \\max_{\\lambda} g(\\lambda)   \\newline\n     \\text{subject to:}~ && \\lambda \\succeq 0~~~~~~~~~~ (9)\\newline\n     && \\sum_{n=1}^N \\lambda_ny_n = 0 \n \\end{eqnarray}\n \\] \nRàng buộc thứ hai được lấy từ \\((6)\\).\nĐây là một bài toán lồi vì ta đang đi tìm giá trị lớn nhất của một hàm mục tiêu là concave trên một polyhedron.\nBài toán này cũng được là một Quadratic Programming và cũng có thể được giải bằng các thư viện như CVXOPT.\nTrong bài toán đối ngẫu này, số tham số (parameters) phải tìm là \\(N\\), là chiều của \\(\\lambda\\), tức số điểm dữ liệu. Trong khi đó, với bài toán gốc \\((3)\\), số tham số phải tìm là \\(d + 1\\), là tổng số chiều của \\(\\mathbf{w}\\) và \\(b\\), tức số chiều của mỗi điểm dữ liệu cộng với 1. Trong rất nhiều trường hợp, số điểm dữ liệu có được trong training set lớn hơn số chiều dữ liệu rất nhiều. Nếu giải trực tiếp bằng các công cụ giải Quadratic Programming, có thể bài toán đối ngẫu còn phức tạp hơn (tốn thời gian hơn) so với bài toàn gốc. Tuy nhiên, điều hấp dẫn của bài toán đối ngẫu này đến từ phần Kernel Support Vector Machine (Kernel SVM), tức cho các bài toán mà dữ liệu không phải là linearly separable hoặc gần linearly separable. Phần Kernel SVM sẽ được tôi trình bày sau 1 hoặc 2 bài nữa. Ngoài ra, dựa vào tính chất đặc biệt của hệ điều kiện KKT mà SVM có thể được giải bằng nhiều phương pháp hiệu quả hơn.\n\nQuay trở lại bài toán, vì đây là một bài toán lồi và strong duality thoả mãn, nghiệm của bài toán sẽ thoả mãn hệ điều kiện KKT sau đây với biến số là \\(\\mathbf{w}, b\\) và \\(\\lambda\\): \n\\[\n\\begin{eqnarray}\n1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) &\\leq& 0, ~ \\forall n = 1, 2, \\dots, N ~~~~(10) \\newline\n\\lambda_n &\\geq& 0, ~\\forall n = 1, 2, \\dots, N  \\newline\n\\lambda_n (1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b)) &=& 0, ~\\forall n = 1, 2, \\dots, N ~~~~(11) \\newline\n \\mathbf{w} &=& \\sum_{n=1}^N \\lambda_n y_n \\mathbf{x}_n ~~~~~~~~~~~(12)\\newline \n \\sum_{n=1}^N \\lambda_ny_n &=& 0 ~~~~~~~~~~~~~~~~~~~(13)\n\\end{eqnarray}\n\\]\nTrong những điều kiện trên, điều kiện \\((11)\\) là thú vị nhất. Từ đó ta có thể suy ra ngay, với \\(n\\) bất kỳ, hoặc \\(\\lambda_n =0\\) hoặc \\(1 - y_n(\\mathbf{w}^T\\mathbf{x}_n + b) = 0\\). Trường hợp thứ hai chính là:\n\\[\n\\mathbf{w}^T\\mathbf{x}_n + b = y_n~~~~ (14)\n\\] \nvới chú ý rằng \\(y_n^2 = 1, ~\\forall n\\).\nNhững điểm thoả mãn \\((14)\\) chính là những điểm nằm gần mặt phân chia nhất, là những điểm được khoanh tròn trong Hình 4 phía trên. Hai đường thẳng \\(\\mathbf{w}^T\\mathbf{x}_n + b = \\pm 1\\) tựa lên các điểm thoả mãn \\((14)\\). Vậy nên những điểm (vectors) thoả mãn \\((14)\\) còn được gọi là các Support Vectors. Và từ đó, cái tên Support Vector Machine ra đời.\nMột quan sát khác, số lượng những điểm thoả mãn \\((14)\\) thường chiếm số lượng rất nhỏ trong số \\(N\\) điểm. Chỉ cần dựa trên những support vectors này, chúng ta hoàn toàn có thể xác định được mặt phân cách cần tìm. Nhìn theo một cách khác, hầu hết các \\(\\lambda_n\\) bằng 0. Vậy là mặc dù vector \\(\\lambda \\in \\mathbb{R}^N\\) có số chiều có thể rất lớn, số lượng các phần tử khác 0 của nó rất ít. Nói cách khác, vector \\(\\lambda\\) là một sparse vector. Support Vector Machine vì vậy còn được xếp vào Sparse Models. Các Sparse Models thường có cách giải hiệu quả (nhanh) hơn các mô hình tương tự với nghiệm là dense (hầu hết khác 0). Đây chính là lý do thứ hai của việc bài toán đối ngẫu SVM được quan tâm nhiều hơn là bài toán gốc.\nTiếp tục phân tích, với những bài toán có số điểm dữ liệu \\(N\\) nhỏ, ta có thể giải hệ điều kiện KKT phía trên bằng cách xét các trường hợp \\(\\lambda_n = 0\\) hoặc \\(\\lambda_n \\neq 0\\). Tổng số trường hợp phải xét là \\(2^N\\). Với \\(N > 50\\) (thường là như thế), đây là một con số rất lớn, giải bằng cách này sẽ không khả thi. Tôi sẽ không đi sâu tiếp vào việc giải hệ KKT như thế nào, trong phần tiếp theo chúng ta sẽ giải bài toán tối ưu \\((9)\\) bằng CVXOPT và bằng thư viện sklearn.\nSau khi tìm được \\(\\lambda\\) từ bài toán \\((9)\\), ta có thể suy ra được \\(\\mathbf{w}\\) dựa vào \\((12)\\) và \\(b\\) dựa vào \\((11)\\) và \\((13)\\). Rõ ràng ta chỉ cần quan tâm tới \\(\\lambda_n \\neq 0\\).\nGọi tập hợp \\(\\mathcal{S} = \\{n: \\lambda_n \\neq 0\\}\\) và \\(N_{\\mathcal{S}}\\) là số phần tử của tập \\(\\mathcal{S}\\). Với mỗi \\(n \\in \\mathcal{S}\\), ta có:\n\\[\n1 = y_n(\\mathbf{w}^T\\mathbf{x}_n + b) \\Leftrightarrow b + \\mathbf{w}^T\\mathbf{x}_n = y_n \n\\]\nMặc dù từ chỉ một cặp \\((\\mathbf{x}_n, y_n)\\), ta có thể suy ra ngay được \\(b\\) nếu đã biết \\(\\mathbf{w}\\), một phiên bản khác để tính \\(b\\) thường được sử dụng và được cho là ổn định hơn trong tính toán (numerically more stable) là:\n\\[\nb = \\frac{1}{N_{\\mathcal{S}}} \\sum_{n \\in \\mathcal{S}}(y_n - \\mathbf{w}^T\\mathbf{x}_n) = \\frac{1}{N_{\\mathcal{S}}} \\sum_{n \\in \\mathcal{S}} \\left(y_n - \\sum_{m\\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T \\mathbf{x}_n\\right)~~~~~ (15)\n\\]\ntức trung bình cộng của mọi cách tính \\(b\\).\nTrước đó, \\(\\mathbf{w}\\) đã được tính bằng: \n\\[\n\\mathbf{w} = \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m ~~~~~~ (16)\n\\]\ntheo \\((12)\\).\nQuan sát quan trọng: Để xác định một điểm \\(\\mathbf{x}\\) mới thuộc vào class nào, ta cần xác định dấu của biểu thức: \n\\[\n\\mathbf{w}^T\\mathbf{x} + b = \\sum_{m \\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T \\mathbf{x} + \\frac{1}{N_{\\mathcal{S}}} \\sum_{n \\in \\mathcal{S}} \\left(y_n - \\sum_{m\\in \\mathcal{S}} \\lambda_m y_m \\mathbf{x}_m^T \\mathbf{x}_n\\right)\n\\]\nBiểu thức này phụ thuộc vào cách tính tích vô hướng giữa các cặp vector \\(\\mathbf{x}\\) và từng \\(\\mathbf{x}_n \\in \\mathcal{S}\\). Nhận xét quan trọng này sẽ giúp ích cho chúng ta trong bài Kernal SVM.\n\nTrong mục này, tôi sẽ trình bày hai cách tính nghiệm cho SVM. Cách thứ nhất dựa theo bài toán \\((9)\\) và các công thức \\((15)\\) và \\((16)\\). Cách thứ hai sử dụng trực tiếp thư viện sklearn. Cách thứ nhất chỉ là để chứng minh nãy giờ tôi không viết nhảm, bằng cách minh hoạ kết quả tìm được và so sánh với nghiệm tìm được bằng cách thứ hai.\n\nTrước tiên chúng ta gọi các modules cần dùng và tạo dữ liệu giả (dữ liệu này chính là dữ liệu tôi dùng trong các hình phía trên nên chúng ta biết chắc rằng hai classes là linearly separable):\nTiếp theo, chúng ta giải bài toán \\((9)\\) bằng CVXOPT:\nKết quả:\nTa nhận thấy rằng hầu hết các giá trị của lambda đều rất nhỏ, tới \\(10^{-9}\\) hoặc \\(10^{-10}\\). Đây chính là các giá trị bằng 0 nhưng vì sai số tính toán nên nó khác 0 một chút. Chỉ có 3 giá trị khác 0, ta dự đoán là sẽ có 3 điểm là support vectors.\nTa đi tìm support set \\(\\mathcal{S}\\) rồi tìm nghiệm của bài toán:\nMinh hoạ kết quả:\nĐường màu đen đậm ở giữa chính là mặt phân cách tìm được bằng SVM. Từ đây có thể thấy nhiều khả năng là các tính toán của ta là chính xác. Để kiểm tra xem các tính toán phía trên có chính xác không, ta cần tìm nghiệm bằng các công cụ có sẵn, ví dụ như sklearn.\nSource code cho phần này có thể được tìm thấy ở đây.\n\nChúng ta sẽ sử dụng hàm sklearn.svm.SVC ở đây. Các bài toán thực tế thường sử dụng thư viện libsvm được viết trên ngôn ngữ C, có API cho Python và Matlab.\nNếu dùng thư viện thì sẽ như sau:\nKết quả này khá giống với kết quả chúng ta tìm được ở phần trên. Có rất nhiều tuỳ chọn cho SVM, các bạn sẽ dần thấy trong các bài sau.\n\nVới bài toán binary classification mà 2 classes là linearly separable, có vô số các siêu mặt phẳng giúp phân biệt hai classes, tức mặt phân cách. Với mỗi mặt phân cách, ta có một classifier. Khoảng cách gần nhất từ 1 điểm dữ liệu tới mặt phân cách ấy được gọi là margin của classifier đó.\nSupport Vector Machine là bài toán đi tìm mặt phân cách sao cho margin tìm được là lớn nhất, đồng nghĩa với việc các điểm dữ liệu an toàn nhất so với mặt phân cách.\nBài toán tối ưu trong SVM là một bài toán lồi với hàm mục tiêu là stricly convex, nghiệm của bài toán này là duy nhất. Hơn nữa, bài toán tối ưu đó là một Quadratic Programming (QP).\nMặc dù có thể trực tiếp giải SVM qua bài toán tối ưu gốc này, thông thường người ta thường giải bài toán đối ngẫu. Bài toán đối ngẫu cũng là một QP nhưng nghiệm là sparse nên có những phương pháp giải hiệu quả hơn.\nVới các bài toán mà dữ liệu gần linearly separable hoặc nonlinear separable, có những cải tiền khác của SVM để thích nghi với dữ liệu đó. Mời bạn đón đọc bài tiếp theo.\nSource code.\n\n[1] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer  (2006). (book)\n[2] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012.\n[3] sklearn.svm.SVC\n[4] LIBSVM – A Library for Support Vector Machines"
    },
    {
        "ID": 31,
        "URL": "https://machinelearningcoban.com/2017/04/02/duality/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong bài viết này, chúng ta giả sử rằng các đạo hàm tồn tại.\nBài viết này chủ yếu được dịch lại từ Chương 5 của cuốn Convex Optimization trong tài liệu tham khảo.\nBạn đọc có thể xem bản pdf tại đây.\nNếu bạn gặp khó khăn trong việc hiểu đạo hàm trong bài viết này, bạn được khuyến khích đọc Đạo hàm của hàm nhiều biến. Ngoài ra, các kiến thức trong Bài 16 và Bài 17 là quan trọng để hiểu rõ hơn bài viết này.\n\nTrong Bài 16, chúng ta đã làm quen với các khái niệm về tập hợp lồi và hàm số lồi. Tiếp theo đó, trong Bài 17, tôi cũng đã trình bày về các bài toán tối ưu lồi, cách nhận dạng và cách sử dụng thư viện để giải các bài toán lồi cơ bản. Trong bài này, chúng ta sẽ tiếp tục tiếp cận một cách sâu hơn: các điều kiện về nghiệm của các bài toán tối ưu, cả lồi và không lồi; bài toán đối ngẫu (dual problem) và điều kiện KKT.\nTrước tiên, chúng ta lại bắt đầu bằng những kỹ thuật đơn giản cho các bài toán cơ bản. Kỹ thuật này có lẽ các bạn đã từng nghe đến: Phương pháp nhân tử Lagrange (method of Lagrange multipliers). Đây là một phương pháp giúp tìm các điểm cực trị của hàm mục tiêu trên feasible set của bài toán.\nNhắc lại rằng giá trị lớn nhất và nhỏ nhất (nếu có) của một hàm số \\(f_0(\\mathbf{x})\\) khả vi (và tập xác định là một tập mở) đạt được tại một trong các điểm cực trị của nó. Và điều kiện cần để một điểm là điểm cực trị là đạo hàm của hàm số tại điểm này \\(f_0’(x) = 0\\). Chú ý rằng một điểm thoả mãn \\(f_0’(\\mathbf{x})\\) = 0 thì được gọi là điểm dừng hay stationary point. Điểm cực trị là một điểm dừng nhưng không phải điểm dừng nào cũng là điểm cực trị. Ví dụ hàm \\(f(x) = x^3\\) có \\(0\\) là một điểm dừng nhưng không phải là điểm cực trị.\nVới hàm nhiều biến, ta cũng có thể áp dụng quan sát này. Tức chúng ta cần đi tìm nghiệm của phương trình đạo hàm theo mỗi biến bằng 0. Tuy nhiên, đó là với các bài toán không ràng buộc (unconstrained optimization problems), với các bài toán có ràng buộc như chúng ta đã gặp trong Bài 17 thì sao?\nTrước tiên chúng ta xét bài toán mà ràng buộc chỉ là một phương trình:\n\\[\n\\begin{eqnarray}\n    \\mathbf{x}=& \\arg\\min_{\\mathbf{x}} f_0(\\mathbf{x}) \\newline\n    \\text{subject to:}~& f_1(\\mathbf{x}) = 0~~~~~~~~~(1)\n\\end{eqnarray}\n\\]\nBài toán này là bài toán tổng quát, không nhất thiết phải lồi. Tức hàm mục tiêu và hàm ràng buộc không nhất thiết phải lồi. \n\nNếu chúng ta đưa được bài toán này về một bài toán không ràng buộc thì chúng ta có thể tìm được nghiệm bằng cách giải hệ phương trình đạo hàm theo từng thành phần bằng 0 (giả sử rằng việc giải hệ phương trình này là khả thi).\nĐiều này là động lực để nhà toán học Lagrange sử dụng hàm số: \\(\\mathcal{L}(\\mathbf{x}, \\lambda) = f_0(\\mathbf{x}) + \\lambda f_1(\\mathbf{x})\\). Chú ý rằng, trong hàm số này, chúng ta có thêm một biến nữa là \\(\\lambda\\), biến này được gọi là nhân tử Lagrange (Lagrange multiplier). Hàm số \\(\\mathcal{L}(\\mathbf{x}, \\lambda)\\) được gọi là hàm hỗ trợ (auxiliary function), hay the Lagrangian. Người ta đã chứng minh được rằng, điểm optimal value của bài toán \\((1)\\) thoả mãn điều kiện \\(\\nabla_{\\mathbf{x}, \\lambda} \\mathcal{L}(\\mathbf{x}, \\lambda) = 0\\) (tôi xin được bỏ qua chứng minh của phần này). Điều này tương đương với:\n\\[\n\\begin{eqnarray}\n    \\nabla_{\\mathbf{x}}f_0(\\mathbf{x}) + \\lambda \\nabla_{\\mathbf{x}} f_1(\\mathbf{x}) &=& 0~~~~(2) \\newline\n    f_1(\\mathbf{x}) & = & 0  ~~~~(3)\n\\end{eqnarray}\n\\]\nĐể ý rằng điều kiện thứ hai chính là \\(\\nabla_{\\lambda}\\mathcal{L}(\\mathbf{x}, \\lambda) = 0\\), và cũng chính là ràng buộc trong bài toán \\((1)\\).\nViệc giải hệ phương trình \\((2) - (3)\\), trong nhiều trường hợp, đơn giản hơn việc trực tiếp đi tìm optimal value của bài toán \\((1)\\).\nXét các ví dụ đơn giản sau đây.\n\nVí dụ 1: Tìm giá trị lớn nhất và nhỏ nhất của hàm số \\(f_0(x, y) = x + y\\) thoả mãn điều kiện \\(f_1(x, y) = x^2 + y^2 = 2\\). Ta nhận thấy rằng đây không phải là một bài toán tối ưu lồi vì feasible set \\(x^2 + y^2 = 2\\) không phải là một tập lồi (nó chỉ là một đường tròn).\nLời giải:\nLagrangian của bài toán này là: \\(\\mathcal{L}(x, y, \\lambda) = x + y + \\lambda(x^2 + y^2 - 2)\\). Các điểm cực trị của hàm số Lagrange phải thoả mãn điều kiện:\n\\[\n\\nabla_{x, y, \\lambda} \\mathcal{L}(x, y, \\lambda) = 0 \\Leftrightarrow\n\\left\\{\n\\begin{matrix}\n    1 + 2\\lambda x &= 0~~~ (4) \\newline\n    1 + 2\\lambda y &= 0~~~ (5) \\newline\n    x^2 + y^2 &=     2 ~~~~(6)\n\\end{matrix}\n\\right.\n\\]\nTừ \\((4)\\) và \\((5)\\) ta suy ra \\(x = y = \\frac{-1}{2\\lambda}\\). Thay vào \\((6)\\) ta sẽ có \\(\\lambda^2 = \\frac{1}{4} \\Rightarrow \\lambda = \\pm \\frac{1}{2}\\). Vậy ta được 2 cặp nghiệm \\((x, y) \\in \\{(1, 1), (-1, -1)\\}\\). Bằng cách thay các giá trị này vào hàm mục tiêu, ta tìm được giá trị nhỏ nhất và lớn nhất của hàm số cần tìm.\nVí dụ 2: Cross-entropy. Trong Bài 10 và Bài 13, chúng ta đã được biết đến hàm mất mát ở dạng cross entropy. Chúng ta cũng đã biết rằng hàm cross entropy được dùng để đo sự giống nhau của hai phân phối xác suất với giá trị của hàm số này càng nhỏ thì hai xác suất càng gần nhau. Chúng ta cũng đã phát biểu rằng giá trị nhỏ nhất của hàm cross entropy đạt được khi từng cặp xác suất là giống nhau. Bây giờ, tôi xin phát biểu lại và chứng minh nhận định trên.\nCho một phân bố xác xuất \\(\\mathbf{p} = [p_1, p_2, \\dots, p_n]^T\\) với \\(p_i \\in [0, 1]\\) và \\(\\sum_{i=1}^n p_i = 1\\). Với một phân bố xác suất bất kỳ \\(\\mathbf{q} = [q_1, q_2, \\dots, q_n]\\) và giả sử rằng \\(q_i \\neq 0, \\forall i\\), hàm số cross entropy được định nghĩa là:\n\\[\nf_0(\\mathbf{q}) = -\\sum_{i=1}^n p_i \\log(q_i)\n\\]\nHãy tìm \\(\\mathbf{q}\\) để hàm cross entropy đạt giá trị nhỏ nhất.\nTrong bài toán này, ta có ràng buộc là \\(\\sum_{i=1}^n q_i = 1\\). Lagrangian của bài toán là: \n\\[\n\\mathcal{L}(q_1, q_2, \\dots, q_n, \\lambda) = -\\sum_{i=1}^n p_i \\log(q_i) + \\lambda(\\sum_{i=1}^n q_i - 1)\n\\]\nTa cần giải hệ phương trình:\n\\[\n\\nabla_{q_1, \\dots, q_n, \\lambda} \\mathcal{L}(q_1, \\dots, q_n, \\lambda) = 0 \\Leftrightarrow\n\\left\\{\n\\begin{matrix}\n   -\\frac{p_i}{q_i} + \\lambda &=& 0, ~~ i = 1, \\dots, n ~~~(7)\\newline\n   q_1 + q_2 + \\dots + q_n &=& 1 ~~~~~~ (8)\n\\end{matrix}\n\\right.\n\\]\nTừ \\((7)\\) ta có \\(p_i = \\lambda q_i\\). Vậy nên: \\( 1 = \\sum_{i=1}^n p_i = \\lambda\\sum_{i=1}^n q_i = \\lambda \\Rightarrow \\lambda = 1 \\Rightarrow q_i = p_i, \\forall i\\).\nQua đây, chúng ta đã hiểu rằng vì sao hàm số cross entropy được dùng để ép hai xác suất gần nhau.\n\n\nVới bài toán tối ưu tổng quát:\n\\[\n\\begin{eqnarray}\n\\mathbf{x}^* &=& \\arg\\min_{\\mathbf{x}} f_0(\\mathbf{x}) \\newline\n\\text{subject to:}~ && f_i(\\mathbf{x}) \\leq 0, ~~ i = 1, 2, \\dots, m ~~~(9)\\newline\n&& h_j(\\mathbf{x}) = 0, ~~ j = 1, 2, \\dots, p\n\\end{eqnarray}\n\\]\nvới miền xác đinh \\(\\mathcal{D} = (\\cap_{i=0}^m \\text{dom}f_i) \\cap (\\cap_{j=1}^p \\text{dom}h_j)\\). Chú ý rằng, chúng ta đang không giả sử về tính chất lồi của hàm tối ưu hay các hàm ràng buộc ở đây. Giả sử duy nhất ở đây là \\(\\mathcal{D} \\neq \\emptyset\\) (tập rỗng).\nLagrangian cũng được xây dựng tương tự với mỗi nhân tử Lagrange cho một (bất) phương trình ràng buộc:\n\\[\n\\mathcal{L}(\\mathbf{x}, \\lambda, \\nu) = f_0(\\mathbf{x}) + \\sum_{i=1}^m \\lambda_if_i(\\mathbf{x}) + \\sum_{j=1}^p \\nu_j h_j(\\mathbf{x})\n\\]\nvới \\(\\lambda = [\\lambda_1, \\lambda_2, \\dots, \\lambda_m]; \\nu = [\\nu_1, \\nu_2, \\dots, \\nu_p]\\) (ký hiệu \\(\\nu\\) này không phải là chữ v mà là chữ nu trong tiếng Hy Lạp, đọc như từ new) là các vectors và được gọi là dual variables (biến đối ngẫu) hoặc Lagrange multiplier vectors (vector nhân tử Lagrange). Lúc này nếu biến chính \\(\\mathbf{x} \\in \\mathbb{R}^n\\) thì tổng số biến của hàm số này sẽ là \\(n + m + p\\).\n(Thông thường, tôi dùng các chữ cái viết thường in đậm để biểu diễn một vector, trong trường hợp này tôi không bôi đậm được \\(\\lambda\\) và \\(\\nu\\) do hạn chế của LaTeX khi viết cùng markdown. Tôi lưu ý điều này để hạn chế nhầm lẫn cho bạn đọc)\n\nHàm đối ngẫu Lagrange của bài toán tối ưu (hoặc gọn là hàm số đối ngẫu) \\((9)\\) là một hàm của các biến đối ngẫu, được định nghĩa là giá trị nhỏ nhất theo \\(\\mathbf{x}\\) của Lagrangian:\n\\[\n\\begin{eqnarray}\ng(\\lambda, \\nu) &=& \\inf_{\\mathbf{x} \\in \\mathcal{D}} \\mathcal{L}(\\mathbf{x}, \\lambda, \\nu)\\newline\n&=& \\inf_{\\mathbf{x} \\in \\mathcal{D}}\\left( f_0(\\mathbf{x}) + \\sum_{i=1}^m \\lambda_if_i(\\mathbf{x}) + \\sum_{j=1}^p \\nu_j h_j(\\mathbf{x})\\right)\n\\end{eqnarray}\n\\]\nNếu Lagrangian không bị chặn dưới, hàm đối ngẫu tại \\(\\lambda, \\nu\\) sẽ lấy giá trị \\(-\\infty\\).\nĐặc biệt quan trọng:\n\\(\\inf\\) được lấy trên miền \\(x \\in \\mathcal{D}\\), tức miền xác định của bài toán (là giao của miền xác định của mọi hàm trong bài toán). Miền xác định này khác với feasible set. Thông thường, feasible set là tập con của miền xác định \\(\\mathcal{D}\\).\nVới mỗi \\(\\mathbf{x}\\), Lagrangian là một hàm affine của \\((\\lambda, \\nu)\\), tức là một hàm concave. Vậy, hàm đối ngẫu chính là pointwise infimum của (có thể vô hạn) các hàm concave, tức là một hàm concave. Vậy hàm đối ngẫu của một bài toán tối ưu bất kỳ là một hàm concave, bất kể bài toán ban đầu có phải là convex hay không. Nhắc lại rằng pointwise supremum của các hàm convex là một hàm convex, và một hàm là concave nếu khi đổi dấu hàm đó, ta được một hàm convex.\n\nNếu \\(p^*\\) là optimal value (giá trị tối ưu) của bài toán \\((9)\\), thì với các biến đối ngẫu \\(\\lambda_i \\geq 0, \\forall i\\) và \\(\\nu\\) bất kỳ, chúng ta sẽ có: \n\\[\ng(\\lambda, \\nu) \\leq p^*~~~~ (10)\n\\]\nTính chất này có thể được chứng minh dễ dàng. Giả sử \\(\\mathbf{x}_0\\) là một điểm feasible bất kỳ của bài toán \\((9)\\), tức thoả mãn các điều kiện ràng buộc \\(f_i(\\mathbf{x}_0) \\leq 0, \\forall i = 1, \\dots, m; h_j(\\mathbf{x}_0) = 0, \\forall j = 1, \\dots, p\\), ta sẽ có: \n\\[\n\\sum_{i=1}^m \\lambda_if_i(\\mathbf{x}_0) + \\sum_{j=1}^p \\nu_j h_j(\\mathbf{x}_0) \\leq 0 \\Rightarrow \\mathcal{L}(\\mathbf{x}_0, \\lambda, \\nu) \\leq f_0(\\mathbf{x}_0)\n\\]\nVì điều này đúng với mọi \\(\\mathbf{x}_0\\) feasible, ta sẽ có tính chất quan trọng sau đây: \n\\[\ng(\\lambda, \\nu) = \\inf_{\\mathbf{x} \\in \\mathcal{D}} \\mathcal{L}(\\mathbf{x}, \\lambda, \\nu) \\leq \\mathcal{L}(\\mathbf{x}_0, \\lambda, \\nu) \\leq f_0(\\mathbf{x}_0).\n\\]\nKhi \\(\\mathbf{x}_0 = \\mathbf{x}^*\\), ta có bất đẳng thức \\((10)\\).\n\n\nXét bài toán tối ưu sau:\n\\[\n\\begin{eqnarray}\n    x=& \\arg\\min_{x} x^2 + 10\\sin(x) + 10 \\newline\n    \\text{subject to:}~& (x-2)^2 \\leq 4 \n\\end{eqnarray}\n\\]\nChú ý: Với bài toán này, miền xác định \\(\\mathcal{D} = \\mathbb{R}\\) nhưng feasible set là \\(0 \\leq x \\leq 4\\).\nVới hàm mục tiêu là đường đậm màu xanh lam trong Hình 1 dưới đây. Ràng buộc thực ra \\(0 \\leq x \\leq 4\\), nhưng tôi viết ở dạng này để bài toán thêm phần thú vị. Hàm số ràng buộc \\(f_1(x) = (x-2)^2 - 4\\) được cho bởi đường nét đứt màu xanh lục. Optimal value của bài toán này có thể được nhận ra là điểm trên đồ thị có hoành độ bằng 0. Chú ý rằng hàm mục tiêu ở đây không phải là hàm lồi nên bài toán tối ưu này cũng không phải là lồi, mặc dù hàm bất phương trình ràng buộc \\(f_1(x)\\) là lồi.\nLagrangian của bài toàn này có dạng:\n\\[\n\\mathcal{L}(x, \\lambda) = x^2 + 10\\sin(x) +10+ \\lambda((x-2)^2 - 4) \n\\]\nCác đường dấu chấm màu đỏ trong Hình 1 là các đường ứng với các \\(\\lambda \\) khác nhau. Vùng bị chặn giữa hai đường thẳng đứng màu đen thể hiện miền feasible của bài toán tối ưu.\nVới mỗi \\(\\lambda\\), dual function được định nghĩa là:\n\\[\ng(\\lambda) = \\inf_{x} \\left(x^2 + 10\\sin(x) + 10+ \\lambda((x-2)^2 - 4) \\right), ~~ \\lambda \\geq 0.\n\\]\nTừ hình 1 bên trái, ta có thể thấy ngay rằng với các \\(\\lambda\\) khác nhau, \\(g(\\lambda)\\) hoặc tại điểm có hoành độ bằng 0, hoặc tại một điểm thấp hơn điểm tối ưu của bài toán. Đồ thị của hàm \\(g(\\lambda)\\) được cho bởi đường liền màu đỏ ở Hình 1 bên phải. Đường nét đứt màu lam thể hiện optimal value của bài toán tối ưu ban đầu. Ta có thể thấy ngay hai điều:\nĐường liền màu đỏ luôn nằm dưới (hoặc có đoạn trùng) với đường nét đứt màu lam.\nHàm \\(g(\\lambda)\\) có dạng một hàm concave, tức nếu ta lật đồ thị này theo hướng trên-dưới thì ta sẽ có đồ thị của một hàm convex. (Mặc dù bài toán tối ưu gốc là không phải là một bài toán lồi.)\n(Để vẽ được hình bên phải, tôi đã dùng Gradient Descent để tìm giá trị nhỏ nhất ứng với mỗi \\(\\lambda\\))\n\nXét một bài toán Linear Programming:\n\\[\n\\begin{eqnarray}\n    x &=& \\arg \\min_{\\mathbf{x}}{\\mathbf{c}^T\\mathbf{x}} \\newline\n    \\text{s.t.:} ~ &&\\mathbf{Ax} = \\mathbf{b} \\newline\n                && \\mathbf{x} \\succeq 0 \n\\end{eqnarray}\n\\]\nHàm ràng buộc cuối cùng có thể được viết lại là: \\(f_i(\\mathbf{x}) = -x_i, i = 1, \\dots, n\\). Lagrangigan của bài toán này là: \n\\[\n\\mathcal{L}(\\mathbf{x}, \\lambda, \\nu) = \\mathbf{c}^T\\mathbf{x} - \\sum_{i=1}^n \\lambda_i x_i + \\nu^T(\\mathbf{Ax} - \\mathbf{b})  = -\\mathbf{b}^T\\nu + (\\mathbf{c} + \\mathbf{A}^T\\nu - \\lambda)^T\\mathbf{x}\n\\]\n(đừng quên điều kiện \\(\\lambda \\succeq 0\\).)\nDual function là: \n\\[\n\\begin{eqnarray}\ng(\\lambda, \\nu) &=& \\inf_{\\mathbf{x}}\\mathcal{L}(\\mathbf{x}, \\lambda, \\nu) \\newline\n&=&  -\\mathbf{b}^T\\nu + \\inf_{\\mathbf{x}} (\\mathbf{c} + \\mathbf{A}^T\\nu - \\lambda)^T\\mathbf{x}\n\\end{eqnarray}\n\\]\nNhận thấy rằng một hàm tuyến tính \\(\\mathbf{d}^T\\mathbf{x}\\) của \\(\\mathbf{x}\\) bị chặn dưới khi vào chỉ khi \\(\\mathbf{d} = 0\\). Vì chỉ nếu một phần tử \\(d_i\\) của \\(\\mathbf{d}\\) khác 0, ta chỉ cần chọn \\(x_i\\) rất lớn và ngược dấu với \\(d_i\\), ta sẽ có một giá trị nhỏ tuỳ ý.\nNói cách khác, \\(g(\\lambda, \\nu) = -\\infty\\) trừ khi \\(\\mathbf{c} + \\mathbf{A}^T\\nu - \\lambda = 0\\). Tóm lại:\n\\[\n\\begin{eqnarray}\n    g(\\lambda, \\nu) = \\left\\{\n    \\begin{matrix}\n     -\\mathbf{b}^T\\nu & ~\\text{if}~  \\mathbf{c}+ \\mathbf{A}^T\\nu - \\lambda = 0\\newline\n    -\\infty &\\text{otherwise}\n    \\end{matrix} \\right.\n\\end{eqnarray}\n\\]\nTrường hợp thứ hai khi \\(g(\\lambda,\\nu) = -\\infty\\) các bạn sẽ gặp rất nhiều sau này. Trường hợp này không nhiều thú vị vì hiển nhiên \\(g(\\lambda, \\nu) \\leq p^*\\). Vì mục đích chính là đi tìm chặn dưới của \\(p^*\\) nên ta sẽ chỉ quan tâm tới các giá trị của \\(\\lambda\\) và \\(\\nu\\) sao cho \\(g(\\lambda, \\nu)\\) càng lớn càng tốt. Trong bài toán này, ta sẽ quan tâm tới các \\(\\lambda\\) và \\(\\nu\\) sao cho \\(\\mathbf{c}+ \\mathbf{A}^T\\nu - \\lambda = 0\\).\n\nVới mỗi cặp \\((\\lambda, \\nu)\\), hàm đối ngẫu Lagrange cho chúng ta một chặn dưới cho optimal value \\(p^*\\) của bài toán gốc \\((9)\\). Câu hỏi đặt ra là: với cặp giá trị nào của \\((\\lambda, \\nu)\\), chúng ta sẽ có một chặn dưới tốt nhất của \\(p^*\\)? Nói cách khác, ta đi cần giải bài toán:\n\\[\n\\begin{eqnarray}\n    \\lambda^*, \\nu^* &=& \\arg \\max_{\\lambda, \\nu} g(\\lambda, \\nu)   \\newline\n    \\text{subject to:}~ && \\lambda \\succeq 0 ~~~~~~~~~(11)\n\\end{eqnarray}\n\\]\nMột điểm quan trọng: vì \\(g(\\lambda, \\nu)\\) là concave và hàm ràng buộc \\(f_i(\\lambda) = -\\lambda_i\\) là các hàm convex. Vậy bài toán \\((11)\\) chính là một bài toán lồi. Vì vậy trong nhiều trường hợp, lời giải có thể dễ tìm hơn là bài toán gốc. Chú ý rằng, bài toán đối ngẫu \\((11)\\) là lồi bất kể bài toán gốc \\((9)\\) có là lồi hay không.\nBài toán này dược gọi là Lagrange dual problem (bài toán đối ngẫu Largange) ứng với bài toán \\((9)\\). Bài toán \\((9)\\) còn có tên gọi khác là primal problem (bài toán gốc). Ngoài ra, có một khái niệm nữa, gọi là dual feasible tức là feasible set của bài toán đối ngẫu, bao gồm điều kiện \\(\\lambda \\succeq 0 \\) và điều kiện ẩn \\(g(\\lambda, \\nu) > -\\infty\\) (vì ta đang đi tìm giá trị lớn nhất của hàm số nên \\(g(\\lambda, \\nu) = -\\infty\\) rõ ràng là không thú vị).\nNghiệm của bài toán \\((11)\\), ký hiệu là \\(\\lambda^*, \\nu^*\\) được gọi là dual optimal hoặc optimal Lagrange multipliers.\nChú ý rằng điều kiện ẩn \\(g(\\lambda, \\nu) > -\\infty\\), trong nhiều trường hợp, cũng có thể được viết cụ thể. Quay lại với ví dụ phía trên, điệu kiện ẩn có thể được viết thành \\(\\mathbf{c}+ \\mathbf{A}^T\\nu - \\lambda = 0\\). Đây là một hàm affine. Vì vậy, khi có thêm ràng buộc này, ta vẫn được một bài toán lồi.\n\nKý hiệu giá trị tối ưu của bài toán đối ngẫu \\((11)\\) là \\(d^*\\). Theo \\((11)\\), ta đã biết rằng:\n\\[\nd^* \\leq p^*\n\\]\nngay cả khi bài toán gốc không phải là lồi.\nTính chất đơn giản này được gọi là weak duality. Tuy đơn giản nhưng nó cực kỳ quan trọng.\nTừ đây ta quan sát thấy hai điều:\nNếu bài toán gốc không bị chặn dưới, tức \\(p^* = -\\infty\\), ta phải có \\(d^* = -\\infty\\), tức là bài toán đối ngẫu Lagrange là infeasible (tức không có giá trị nào thoả mãn ràng buộc).\nNếu bài toàn đối ngẫu là không bị chặn trên, tức \\(d^* = +\\infty\\), chúng ta phải có \\(p^* = +\\infty\\), tức bài toán gốc là infeasible.\nGiá trị \\(p^* - d^*\\) được gọi là optimal duality gap (dịch thô là khoảng cách đối ngẫu tối ưu). Khoảng cách này luôn luôn là một số không âm.\nĐôi khi có những bài toán (lồi hoặc không) rất khó giải, nhưng ít nhất nếu ta có thể tìm được \\(d^*\\), ta có thể biết được chặn dưới của bài toán gốc. Việc tìm \\(d^*\\) thường có thể thực hiện được vì bài toán đối ngẫu luôn luôn là lồi.\n\nNếu đẳng thức \\(p^* = d^*\\) thoả mãn, the optimal duality gap bằng không, ta nói rằng strong duality xảy ra. Lúc này, việc giải bài toán đối ngẫu đã giúp ta tìm được chính xác giá trị tối ưu của bài toán gốc.\nThật không may, strong duality không thường xuyên xảy ra trong các bài toán tối ưu. Tuy nhiên, nếu bài toán gốc là lồi, tức có dạng:\n\\[\n\\begin{eqnarray}\n    x &=& \\arg \\min_{\\mathbf{x}} f_0(\\mathbf{x})   \\newline\n    \\text{subject to:}~ && f_i(\\mathbf{x}) \\leq 0, i = 1, 2, \\dots, m ~~~~~ (12)\\newline\n    && \\mathbf{Ax} = \\mathbf{b}\n\\end{eqnarray}\n\\]\ntrong đó \\(f_0, f_1, \\dots, f_m\\) là các hàm lồi, chúng ta thường (không luôn luôn) có strong duality. Có rất nhiều nghiên cứu thiết lập các điều kiện, ngoài tính chất lồi, để strong duality xảy ra. Những điều kiện đó thường có tên là constraint qualifications.\nMột trong các constraint qualification đơn giản nhất là Slater’s condition.\nĐịnh nghĩa: Một điểm feasible của bài toán \\((12)\\) được gọi là strictly feasible nếu: \n\\[\nf_i(\\mathbf{x}) < 0, ~i = 1, 2, \\dots, m, ~~~ \\mathbf{Ax} = \\mathbf{b}\n\\]\nĐịnh lý Slater: Nếu tồn tại một điểm strictly feasible (và bài toán gốc là lồi), thì strong duality xảy ra.\nĐiều kiện khá đơn giản sẽ giúp ích cho nhiều bài toán tối ưu sau này.\nChú ý:\n\n\nGiả sử rằng strong duality xảy ra. Gọi \\(\\mathbf{x}^*\\) là một điểm optimal của bài toán gốc và \\((\\lambda^*, \\nu^*)\\) là cặp điểm optimal của bài toán đối ngẫu. Ta có: \n\\[\n\\begin{eqnarray}\n    f_0(\\mathbf{x}^*) &=& g(\\lambda^*,\\nu^*) \\newline\n    &=& \\inf_{\\mathbf{x}} \\left(f_0(\\mathbf{x}) + \\sum_{i=1}^m \\lambda_i^* f_i(\\mathbf{x}) + \\sum_{j=1}^p \\nu_j^* h_i(\\mathbf{x})\\right)\\newline\n    &\\leq& f_0(\\mathbf{x}^*) + \\sum_{i=1}^m \\lambda_i^* f_i(\\mathbf{x}^*) + \\sum_{j=1}^p \\nu_j^* h_j(\\mathbf{x}^*) \\newline\n    &\\leq& f_0(\\mathbf{x}^*)\n\\end{eqnarray}\n\\]\nDòng đầu là do chính là strong duality.\nDòng hai là do định nghĩa của hàm đối ngẫu.\nDòng ba là hiển nhiên vì infimum của một hàm nhỏ hơn giá trị của hàm đó tại bất kỳ một điểm nào khác.\nDòng bốn là vì các ràng buộc \\(f_i(\\mathbf{x}^*) \\leq 0, \\lambda_i \\geq 0, i = 1, 2, \\dots, m\\) và \\(h_j(\\mathbf{x}^*) = 0\\).\nTừ đây có thể thế rằng dấu đẳng thức ở dòng ba và dòng bốn phải đồng thời xảy ra. Và ta lại có thêm hai quan sát thú vị nữa:\n\\(\\mathbf{x}^*\\) chính là một điểm optimal của \\(g(\\lambda^*, \\nu^*)\\).\nThú vị hơn: \n\\[\n\\sum_{i=1}^m \\lambda_i^* f_i(\\mathbf{x}^*) = 0\n\\]\nVì mỗi phần tử trong tổng trên là không dương do \\(\\lambda_i^* \\geq 0, f_i \\leq 0\\), ta kết luận rằng: \n\\[\n\\lambda_i^*f_i(\\mathbf{x}^*) = 0, i = 1, 2, \\dots, m\n\\]\nĐiều kiện cuối cùng này được gọi là complementary slackness. Từ đây có thể suy ra: \n\\[\n\\begin{eqnarray}\n\\lambda_i^* > 0 &\\Rightarrow& f_i(\\mathbf{x}^*) = 0 \\newline\nf_i(\\mathbf{x}^*) < 0 &\\Rightarrow& \\lambda_i^* = 0 \n\\end{eqnarray}\n\\]\nTức ta luôn có một trong hai giá trị này bằng 0.\n\nChúng ta vẫn giả sử rằng các hàm đang xét có đạo hàm và bài toán tối ưu không nhất thiết là lồi.\n\nGiả sử rằng strong duality xảy ra. Gọi \\(\\mathbf{x}^*\\) và \\((\\lambda^*, \\nu^*)\\) là bất kỳ primal và dual optimal points. Vì \\(\\mathbf{x}^*\\) tối ưu hàm khả vi \\(\\mathcal{L}(\\mathbf{x}, \\lambda^*, \\nu^*)\\), ta có đạo hàm  của Lagrangian tại \\(\\mathbf{x}^*\\) phải bằng 0.\nĐiều kiện Karush-Kuhn-Tucker (KKT)) nói rằng \\(\\mathbf{x}^*, \\lambda^*, \\nu^*\\) phải thoả mãn điều kiện:\n\\[\n\\begin{eqnarray}\n    f_i(\\mathbf{x}^*) &\\leq& 0, i = 1, 2, \\dots, m \\newline\n    h_j(\\mathbf{x}^*) &=& 0, j = 1, 2, \\dots, p \\newline\n    \\lambda_i^* &\\geq& 0, i = 1, 2, \\dots, m \\newline\n    \\lambda_i^*f_i(\\mathbf{x}^*) &=& 0, i = 1, 2, \\dots, m \\newline\n    \\nabla f_0(\\mathbf{x}^*) + \\sum_{i=1}^m \\lambda_i^* \\nabla f_i(\\mathbf{x}^*) + \\sum_{j=1}^p\\nu_j^* \\nabla h_j(\\mathbf{x}^*) &=& 0 \n\\end{eqnarray}\n\\]\nĐây là điều kiện cần để \\(\\mathbf{x}^*, \\lambda^*, \\nu^*\\) là nghiệm của hai bài toán.\n\nVới các bài toán lồi và strong duality xảy ra, các điệu kiện KKT phía trên cũng là điều kiện đủ. Vậy với các bài toán lồi với hàm mục tiêu và hàm ràng buộc là khả vi, bất kỳ điểm nào thoả mãn các điều kiện KKT đều là primal và dual optimal của bài toán gốc và bài toán đối ngẫu.\nTừ đây ta có thể thấy rằng: Với một bài toán lồi và điều kiện Slater thoả mãn (suy ra strong duality) thì các điều kiện KKT là điều cần và đủ của nghiệm.\nCác điều kiện KKT rất quan trọng trong tối ưu. Trong một vài trường hợp đặc biệt (chúng ta sẽ thấy trong bài Support Vector Machine sắp tới), việc giải hệ (bất) phương trình các điều kiện KKT là khả thi. Rất nhiều các thuật toán tối ưu được xây dựng giả trên việc giải hệ điều kiện KKT.\nVí dụ: Equality constrained convex quadratic minimization. Xét bài toán: \n\\[\n\\begin{eqnarray}\n    \\mathbf{x} &=& \\arg \\min_{\\mathbf{x}} \\frac{1}{2}\\mathbf{x}^T\\mathbf{Px} + \\mathbf{q}^T\\mathbf{x} + r  \\newline\n    \\text{subject to:}~ && \\mathbf{Ax} = \\mathbf{b}\n\\end{eqnarray}\n\\]\ntrong đó \\(\\mathbf{P} \\in \\mathbb{S}_+^n\\) (tập các ma trận đối xứng nửa xác định dương).\nLagrangian: \n\\[\n\\mathcal{L}(\\mathbf{x}, \\nu) = \\frac{1}{2}\\mathbf{x}^T\\mathbf{Px} + \\mathbf{q}^T\\mathbf{x} + r  + \\nu^T(\\mathbf{Ax} - \\mathbf{b})\n\\] \nĐIều kiện KKT cho bài toán này là: \n\\[\n\\begin{eqnarray}\n    \\mathbf{Ax}^* &=& \\mathbf{b} \\newline\n    \\mathbf{P}\\mathbf{x}^* + \\mathbf{q} + \\mathbf{A}^T\\nu^* &=& 0\n\\end{eqnarray}\n\\]\nPhương trình thứ hai chính là phương trình đạo hàm của Lagrangian tại \\(\\mathbf{x}^*\\) bằng 0.\nHệ phương trình này có thể được viết lại đơn giản là: \n\\[\n\\left[\\begin{matrix}\n\\mathbf{P} & \\mathbf{A}^T \\newline \n\\mathbf{A} & \\mathbf{0}\n\\end{matrix} \\right]\n\\left[\\begin{matrix}\n\\mathbf{x}^* \\newline\n\\nu^*\n\\end{matrix}\\right]\n= \n\\left[\\begin{matrix}\n-\\mathbf{q} \\newline\n\\mathbf{b}\n\\end{matrix}\\right]\n\\]\nđây là một phương trình tuyến tính đơn giản!\n\nGiả sử rằng các hàm số đều khả vi:\nCác bài toán tối ưu với chỉ ràng buộc là đẳng thức có thể được giải quyết bằng phương pháp nhân tử Lagrange. Ta cũng có định nghĩa về Lagrangian. Điều kiện cần để một điểm là nghiệm của bài toán tối ưu là nó phải làm cho đạo hàm của Lagrangian bằng 0.\nVới các bài toán tối ưu có thêm ràng buộc là bất đẳng thức (không nhất thiết là lồi), chúng ta có Lagrangian tổng quát và các biến Lagrange \\(\\lambda, \\nu\\). Với các giá trị \\((\\lambda, \\nu)\\) cố định, ta có định nghĩa về hàm đối ngẫu Lagrange (Lagrange dual function) \\(g(\\lambda, \\nu)\\) được xác định là infimum của Lagrangian khi \\(\\mathbf{x}\\) thay đổi trên miền xác định của bài toán.\nMiền xác định và tập các điểm feasible thường khác nhau. Feasible set là tập con của tập xác định.\nVới mọi \\((\\lambda, \\nu)\\), \\(g(\\lambda, \\nu) \\leq p^*\\).\nHàm số \\(g(\\lambda,\\nu)\\) là lồi bất kể bài toán tối ưu có là lồi hay không. Hàm số này được gọi là dual Lagrange fucntion hay hàm đối ngẫu Lagrange.\nBài toán đi tìm giá trị lớn nhất của hàm đối ngẫu Lagrange với điều kiện \\(\\lambda \\succeq 0\\) được gọi là bài toán đối ngẫu (dual problem). Bài toán này là lồi bất kể bài toán gốc có lồi hay không.\nGọi giá trị tối ưu của bài toán đối ngẫu là \\(d^*\\) thì ta có: \\(d^* \\leq p^*\\). Đây được gọi là weak duality.\nStrong duality xảy ra khi \\(d^* = p^*\\). Thường thì strong duality không xảy ra, nhưng với các bài toán lồi thì strong duality thường (không luôn luôn) xảy ra.\nNếu bài toán là lồi và điều kiện Slater thoả mãn, thì strong duality xảy ra.\nNếu bài toán lồi và có strong duality thì nghiệm của bài toán thoả mãn các điều kiện KKT (điều kiện cần và đủ).\nRất nhiều các bài toán tối ưu được giải quyết thông qua KKT conditions.\n\nTrong ba bài 16, 17, 18, tôi đã giới thiệu sơ lược về tập lồi, hàm lồi, bài toán lồi, và các điệu kiện tối ưu được xây dựng thông qua duality. Ý định ban đầu của tôi là tránh phần này vì khá nhiều toán, tuy nhiên trong quá trình chuẩn bị cho bài Support Vector Machine, tôi nhận thấy rằng cần phải giải thích về Lagrangian - kỹ thuật được sử dụng rất nhiều trong Tối ưu. Thêm nữa, để giải thích về Lagrangian, tôi cần nói về các bài toán lồi. Chính vì vậy tôi thấy có trách nhiệm phải viết về ba bài này.\nTrong loạt bài tiếp theo, chúng ta sẽ lại quay lại với các thuật toán Machine Learning với rất nhiều ví dụ, hình vẽ và code mẫu. Nếu bạn nào có cảm thấy hơi đuối sau ba bài tối ưu này thì cũng đừng lo, mọi chuyện rồi sẽ ổn cả thôi.\n\n[1] Convex Optimization – Boyd and Vandenberghe, Cambridge University Press, 2004.\n[2] Lagrange Multipliers - Wikipedia."
    },
    {
        "ID": 32,
        "URL": "https://machinelearningcoban.com/2017/03/19/convexopt/",
        "Title": "Machine Learning cơ bản",
        "Content": "Bạn được khuyến khích đọc Bài 16 trước khi đọc bài này. Nội dung trong bài viết này chủ yếu được dịch từ Chương 4 của cuốn Convex Optimization trong phần Tài liệu tham khảo..\nBài này cũng có rất nhiều khái niệm mới và nhiều lý thuyết nên có thể không hấp dẫn như các bài khác. Tuy nhiên, tôi không thể bỏ qua vì không muốn các bạn hoàn toàn mất phương hướng khi đọc các bài sau.\nBạn đọc có thể xem bản pdf tại đây.\n\nTôi xin bắt đầu bài viết này bằng ba bài toán khá gần với thực tế:\n\n\nMột nhà xuất bản (NXB) nhận được đơn hàng 600 bản của cuốn “Machine Learning cơ bản” tới Thái Bình và 400 bản tới Hải Phòng. NXB đó có 800 cuốn ở kho Nam Định và 700 cuốn ở kho Hải Dương. Giá chuyển phát một cuốn sách từ Nam Định tới Thái Bình là 50,000 VND (50k), tới Hải Phòng là 100k. Giá chuyển phát một cuốn từ Hải Dương  tới Thái Bình là 150k, trong khi tới Hải Phòng chỉ là 40k. Hỏi để tốn ít chi phí chuyển phát nhất, công ty đó nên phân phối mỗi kho chuyển bao nhiêu cuốn tới mỗi địa điểm?\n\nĐể cho đơn giản, ta xây dựng bảng số lượng chuyển sách từ nguồn tới đích như sau:\nTổng chi phí (objective function) sẽ là \\(f(x, y, z, t) = 5x + 10y + 15z + 4t\\). Các điều kiện ràng buộc (constraints) viết dưới dạng biểu thức toán học là:\nChuyển 600 cuốn tới Thái Bình: \\(x + z = 600\\).\nChuyển 400 cuốn tới Hải Phòng: \\(y + t = 400\\).\nLấy từ kho Nam Định không quá 800: \\(x + y \\leq 800\\).\nLấy từ kho Hải Dương không quá 700: \\(z + t \\leq 700\\).\n\\(x, y, z, t\\) là các số tự nhiên. Ràng buộc là số tự nhiên sẽ khiến cho bài toán rất khó giải nếu số lượng biến là rất lớn. Với bài toán này, ta giả sử rằng \\(x, y, z, t\\) là các số thực dương. Khi tìm được nghiệm, nếu chúng không phải là số tự nhiên, ta sẽ lấy các giá trị tự nhiên gần nhất.\nVậy ta cần giải bài toán tối ưu sau đây:\nBài toán NXB:\n\\[\n\\begin{align}\n    (x, y, z, t) =& \\arg\\min_{x, y, z, t} 5x + 10y + 15z + 4t ~~~~ (1)\\newline\n    \\text{subject to:}~ & x + z = 600 ~~~~ (2)\\newline\n                        & y + t = 400 ~~~~ (3) \\newline\n                        & x + y \\leq 800 ~~~(4) \\newline\n                        & z + t \\leq 700 ~~~ (5)\\newline\n                        & x, y, z, t \\geq 0 ~~~ (6)\n\\end{align}\n\\]\nNhận thấy rằng hàm mục tiêu (objective function) là một hàm tuyến tính của các biến \\(x, y, z, t\\). Các điều kiện ràng buộc đều có dạng hyperplanes hoặc halfspaces, đều là các ràng buộc tuyến tính (linear constraints). Bài toán tối ưu với cả objective function và constraints đều là linear được gọi là Linear Programming (LP). Dạng tổng quát và cách thức lập trình để giải một bài toán thuộc loại này sẽ được cho trong phần sau của bài viết này.\nNghiệm cho bài toán này có thể nhận thấy ngay là \\(x = 600, y = 0, z = 0, t = 400\\). Nếu ràng buộc nhiều hơn và số biến nhiều hơn, chúng ta cần một lời giải có thể tính được bằng cách lập trình.\n\n\nMột anh nông dân có tổng cộng 10ha (10 hecta) đất canh tác. Anh dự tính trồng cà phê và hồ tiêu trên số đất này với tổng chi phí cho việc trồng này là không quá 16T (triệu đồng). Chi phí để trồng cà phê là 2T cho 1ha, để trồng hồ tiêu là 1T/ha. Thời gian trồng cà phê là 1 ngày/ha và hồ tiêu là 4 ngày/ha; trong khi anh chỉ có thời gian tổng cộng là 32 ngày. Sau khi trừ tất cả các chi phí (bao gồm chi phí trồng cây), mỗi ha cà phê mang lại lợi nhuận 5T, mỗi ha hồ tiêu mang lại lợi nhuận 3T. Hỏi anh phải trồng như thế nào để tối đa lợi nhuận? (Các số liệu có thể vô lý vì chúng đã được chọn để bài toán ra nghiệm đẹp)\n\nGọi \\(x\\) và \\(y\\) lần lượt là số ha cà phê và hồ tiêu mà anh nông dân nên trồng. Lợi nhuận anh ấy thu được là \\(f(x, y) = 5x + 3y\\) (triệu đồng).\nCác ràng buộc trong bài toán này là:\nTổng diện tích trồng không vượt quá 10: \\(x + y \\leq 10\\).\nTổng chi phí trồng không vượt quá 16T: \\(2x + y \\leq 16\\).\nTổng thời gian trồng không vượt quá 32 ngày: \\(x + 4y \\leq 32\\).\nDiện tích cà phê và hồ tiêu là các số không âm: \\(x, y \\geq 0\\).\nVậy ta có bài toán tối ưu sau đây:\nBài toán canh tác:\n\\[\n\\begin{eqnarray}\n    (x, y) =& \\arg\\max_{x, y} 5x + 3y ~~~~ (7)\\newline\n    \\text{subject to:}~ & x + y \\leq 10 ~~~~ (8)\\newline\n                        & 2x + y \\leq 16 ~~~(9) \\newline\n                        & x + 4y \\leq 32 ~~~ (10)\\newline\n                        & x, y \\geq 0 ~~~ (11)\n\\end{eqnarray}\n\\]\nBài toán này hơi khác một chút là ta cần tối đa hàm mục tiêu thay vì tối thiểu nó. Việc chuyển bài toán này về bài toán tối thiểu có thể được thực hiện đơn giản bằng cách đổi dấu hàm mục tiêu. Khi đó hàm mục tiêu vẫn là linear, các ràng buộc vẫn là các linear constraints, ta lại có một bài toán Linear Programming (LP) nữa.\nBạn cũng có thể dựa vào hình minh hoạ dưới đây để suy ra nghiệm của bài toán:\nVùng màu xám có dạng polyhedron (trong trường hợp này là đa giác) chính là tập hợp các điểm thoả mãn các ràng buộc từ \\(8)\\) đến \\((11)\\). Các đường nét đứt có màu chính là các đường đồng mức của hàm mục tiêu \\(5x + 3y\\), mỗi đường ứng với một giá trị khác nhau với đường càng đỏ ứng với giá trị càng cao. Một cách trực quan, nghiệm của bài toán có thể tìm được bằng cách di chuyển đường nét đứt màu xanh về phía bên phải (phía làm cho giá trị của hàm mục tiêu lớn hơn) đến khi nó không còn điểm chung với phần đa giác màu xám nữa.\nCó thể nhận thấy nghiệm của bài toán chính là điểm màu xanh là giao điểm của hai đường thẳng \\(x + y = 10\\) và \\(2x + y = 16\\). Giải hệ phương trình này ta có \\(x^* = 6\\) và \\(y^* = 4\\). Tức anh nông dân nên trồng 6ha cà phê và 4ha hồ tiêu. Lúc đó lợi nhuận thu được là \\(5x^* + 3y^* = 42 \\) triệu đồng, trong khi anh chỉ mất thời gian là 22 ngày. (Chịu tính toán cái là khác ngay, làm ít, hưởng nhiều).\nĐây chính là cách giải trong sách toán lớp 10 (ngày tôi học lớp 10).\nVới nhiều biến hơn và nhiều ràng buộc hơn, chúng ta liệu có thể vẽ được hình như thế này để nhìn ra nghiệm hay không? Câu trả lời của tôi là nên tìm một công cụ để với nhiều biến hơn và với các ràng buộc khác nhau, chúng ta có thể tìm ra nghiệm gần như ngay lập tức.\n\n\nMột công ty phải chuyển 400 \\(m^3\\) cát tới địa điểm xây dựng ở bên kia sông bằng cách thuê một chiếc xà lan. Ngoài chi phí vận chuyển một lượt đi về là 100k của chiếc xà lan, công ty đó phải thiết kế một thùng hình hộp chữ nhật đặt trên xà lan để đựng cát. Chiếc thùng này không cần nắp, chi phí cho các mặt xung quanh là 1T/\\(m^2\\), cho mặt đáy là 2T/\\(m^2\\). Hỏi kích thước của chiếc thùng đó như thế nào để tổng chi phí vận chuyển là nhỏ nhất. Để cho đơn giản, giả sử cát chỉ được đổ ngang hoặc thấp hơn với phần trên của thành thùng, không có ngọn. Giả sử thêm rằng xà lan rộng vô hạn và chứa được sức nặng vô hạn, giả sử này khiến bài toán dễ giải hơn.\n\nGiả sử chiếc thùng cần làm có chiều dài là \\(x\\) (\\(m\\)), chiều rộng là \\(y\\) và chiều cao là \\(z\\). Thể tích của thùng là \\(xyz\\) (đơn vị là \\(m^3\\)). Có hai loại chi phí là:\nChi phí thuê xà lan: số chuyến xà lan phải thuê là \\(\\frac{400}{xyz}\\) (ta hãy tạm giả sử rằng đây là một số tự nhiên, việc làm tròn này sẽ không thay đổi kết quả đáng kể vì chi phí vận chuyển một chuyến là nhỏ so với chi phí làm thùng). Số tiền phải trả cho xà lan sẽ là \\(0.1\\frac{400}{xyz} = \\frac{40}{xyz}\\).\nChi phí làm thùng: Diện tích xung quanh của thùng là \\(2 (x + y)z \\). Diện tích đáy là \\(xy\\). Vậy tổng chi phí làm thùng là \\(2(x +y)z + 2xy = 2(xy + yz + zx)\\).\nTổng toàn bộ chi phí là \\(f(x, y, z) = 40x^{-1}y^{-1}z^{-1} + 2(xy + yz + zx)\\). Điều kiện ràng buộc duy nhất là kích thước thùng phải là các số dương. Vậy ta có bài toán tối ưu sau:\nBài toán vận chuyển:\n\\[\n\\begin{eqnarray}\n    (x, y) =& \\arg\\min_{x, y, z} 40x^{-1}y^{-1}z^{-1} + 2(xy + yz + zx) ~~~~ (13)\\newline\n    \\text{subject to:}~ & x, y, z > 0 ~~~~ (14)\\newline\n\\end{eqnarray}\n\\]\nBài toán này thuộc loại Geometric Programming (GP). Định nghĩa của GP và cách dùng công cụ tối ưu sẽ được trình bày trong phần sau của bài viết.\nNhận thấy rằng bài này hoàn toàn có thể dùng bất đẳng thức Cauchy để giải được, nhưng tôi vẫn muốn một lời giải cho bài toán tổng quát sao cho có thể lập trình được.\n(Lời giải:\n\\[\n\\begin{eqnarray}\n    f(x, y, z) &=& \\frac{20}{xyz} + \\frac{20}{xyz} + 2xy + 2yz + 2zx \\newline\n               &\\geq & 5\\sqrt[5]{3200}\n\\end{eqnarray}\n\\]\ndấu bằng xảy ra khi và chỉ khi \\(x = y = z = \\sqrt[5]{10}\\). Bài này có lẽ hợp với các kỳ thi vì dữ kiện quá đẹp. Cá nhân tôi thích các đề bài ra kiểu này hơn là yêu cầu đi tìm giá trị nhỏ nhất của một biểu thức nhàm chán, nhiều học sinh cho rằng không biết học bất đẳng thức để làm gì!)\n\nNếu có các ràng buộc về kích thước của thùng và trọng lượng mà xà lan tải được thì có thể tìm được lời giải đơn giản như thế này không?\nNhững bài toán trên đây đều là các bài toán tối ưu. Chính xác hơn nữa, chúng đều là các bài toán tối ưu lồi (convex optimization problems) như các bạn sẽ thấy ở phần sau. Và việc tìm lời giải có thể không mấy khó khăn, thậm chí giải bằng tay cũng có thể ra kết quả. Tuy nhiên, mục đích của bài viết này không phải là hướng dẫn các bạn giải các bài toán trên bằng tay, mà là cách nhận diện các bài toán và đưa chúng về các dạng mà các toolboxes sẵn có có thể giúp chúng ta. Trên thực tế, lượng dữ kiện và số biến cần tối ưu lớn hơn nhiều, chúng ta không thể giải các bài toán trên bằng tay được.\nTrước hết, chúng ta cần hiểu các khái niệm về convex optimization problems và tại sao convex lại quan trọng. (Bạn đọc có thể đọc tới phần 4 nếu không muốn biết các khái niệm và định lý toán  trong phần 2 và 3.)\n\n\nTôi xin nhắc lại bài toán tối ưu ở dạng tổng quát:\n\\[\n\\begin{eqnarray}\n\\mathbf{x}^* &=& \\arg\\min_{\\mathbf{x}} f_0(\\mathbf{x}) \\newline\n\\text{subject to:}~ && f_i(\\mathbf{x}) \\leq 0, ~~ i = 1, 2, \\dots, m ~~~(15)\\newline\n&& h_j(\\mathbf{x}) = 0, ~~ j = 1, 2, \\dots, p\n\\end{eqnarray}\n\\]\nPhát biểu bằng lời: Tìm giá trị của biến \\(\\mathbf{x}\\) để tối thiểu hàm \\(f_0(\\mathbf{x})\\) trong số các giá trị của \\(\\mathbf{x}\\) thoả mãn các điều kiện ràng buộc. Ta có bảng các tên gọi tiếng Anh và tiếng Việt như sau:\nNgoài ra:\nKhi \\(m = p = 0\\), bài toán \\((15)\\) được gọi là unconstrained optimization problem (bài toán tối ưu không ràng buộc).\n\\(\\mathcal{D}\\) chỉ là tập xác định, tức giao của tất cả các tập xác định của mọi hàm số xuất hiện trong bài toán. Tập hợp các điểm thoả mãn mọi điều kiện ràng buộc, thông thường, là một tập con của \\(\\mathcal{D}\\) được gọi là feasible set hoặc constraint set. Khi feasible set là một tập rỗng thì ta nói bài toán tối ưu \\((15)\\) là infeasible. Nếu một điểm nằm trong feasible set, ta gọi điểm đó là feasible.\nOptimal value (giá trị tối ưu) của bài toán tối ưu \\((15)\\) được định nghĩa là:\n\\[\np^* = \\text{inf}\\{f_0(\\mathbf{x}) | f_i(\\mathbf{x}) \\leq 0, i = 1, \\dots, m; h_j(\\mathbf{x}) = 0, j = 1, \\dots, p\\}\n\\]\ntrong đó \\(\\text{inf}\\) là viết tắt của hàm infimum. \\(p^*\\) có thể nhận các giá trị \\(\\pm \\infty\\). Nếu bài toán là infeasible, ta coi \\(p^* = + \\infty\\), Nếu hàm mục tiêu không bị chặn dưới (unbounded below) trong tập xác định, ta coi \\(p^* = - \\infty\\).\n\nMột điểm \\(\\mathbf{x}^*\\) được gọi là một điểm optimal point (điểm tối ưu), hoặc là nghiệm của bài toán \\((15)\\) nếu \\(\\mathbf{x}^*\\) là feasible và \\(f_0(\\mathbf{x}^*) = p^*\\). Tập hợp tất cả các optimal points được gọi là optimal set.\nNếu optimal set là một tập không rỗng, ta nói bài toán \\((15)\\) là solvable (giải được). Ngược lại, nếu optimal set là một tập rỗng, ta nói optimal value là không thể đạt được (not attained/ not achieved).\nVí dụ: xét hàm mục tiêu \\(f(x) = 1/x\\) với ràng buộc \\(x > 0\\). Optimal value của bài toán này là \\(p^* = 0\\) nhưng optimal set là một tập rỗng vì không có giá trị nào của \\(x\\) để hàm mục tiêu đạt giá trị 0. Lúc này ta nói giá trị tối ưu là không đạt được.\nVới hàm một biến, một điểm là cực tiểu của một hàm số nếu tại đó, hàm số đạt giá trị nhỏ nhất trong một lân cận (và lân cận này thuộc tập xác định của hàm số). Trong không gian 1 chiều, lân cận được hiểu là trị tuyệt tối của hiệu 2 điểm nhỏ hơn một giá trị nào đó.\nTrong toán tối ưu (thường là không gian nhiều chiều), ta gọi một điểm \\(\\mathbf{x}\\) là locally optimal (cực tiểu) nếu tồn tại một giá trị (thường được gọi là bán kinh) \\(R\\) sao cho:\n\\[\n\\begin{eqnarray}\n    f_0(\\mathbf{x}) = &\\text{inf}\\{f_0(\\mathbf{z}) | f_i(\\mathbf{z}) \\leq 0, i = 1, \\dots, m, \\newline\n                 & h_j(\\mathbf{z}) = 0, j = 1, \\dots, p, ||\\mathbf{z} - \\mathbf{x}||_2 \\leq R\\}\n\\end{eqnarray}\n\\]\nNếu một điểm feasible \\(\\mathbf{x}\\) thoả mãn \\(f_i(\\mathbf{x}) = 0\\), ta nói rằng bất đẳng thức ràng buộc thứ \\(i: f_i(\\mathbf{x}) = 0\\) là active. Nếu \\(f_i(\\mathbf{x}) < 0\\), ta nói rằng ràng buộc này là inactive tại \\(\\mathbf{x}\\).\n\nMặc dù trong định nghĩa bài toán tối ưu \\((15)\\) là cho bài toán tối thiểu hàm mục tiêu với các ràng buộc thoả mãn các điều kiện nhỏ hơn hoặc bằng 0, các bài toán tối ưu với tối đa hàm mục tiêu và điều kiện ràng buộc ở dạng khác đều có thể đưa về được dạng này:\n\\(\\max f_0(\\mathbf{x}) \\Leftrightarrow\\min -f_0(\\mathbf{x}) \\).\n\\(f_i(\\mathbf{x}) \\leq g(\\mathbf{x}) \\Leftrightarrow\\ f_i(\\mathbf{x}) - g(\\mathbf{x}) \\leq 0\\).\n\\(f_i(\\mathbf{x}) \\geq 0 \\Leftrightarrow\\ -f_i(\\mathbf{x}) \\leq 0 \\).\n\\(a \\leq f_i(\\mathbf{x}) \\leq b \\Leftrightarrow\\ f_i(\\mathbf{x}) -b \\leq 0\\) và \\(a - f_i(\\mathbf{x}) \\leq 0\\).\n\\(f_i(\\mathbf{x}) \\leq 0 \\Leftrightarrow f_i(\\mathbf{x}) + s_i = 0 \\) và \\(s_i \\geq 0\\). \\(s_i\\) được gọi là slack variable. Phép biến đổi đơn giản này trong nhiều trường hợp lại tỏ ra hiệu quả vì bất đẳng thức \\(s_i \\geq 0\\) thường dễ giải quyết hơn là \\(f_i(\\mathbf{x}) \\leq 0\\).\n\nTrong toán tối ưu, chúng ta đặc biệt quan tâm tới những bài toán mà hàm mục tiêu là một hàm lồi, và feasible set cũng là một tập lồi.\n\nMột bài toán tối ưu lồi (convex optimization problem) là một bài toán tối ưu có dạng:\n\\[\n\\begin{eqnarray}\n\\mathbf{x}^* &=& \\arg\\min_{\\mathbf{x}} f_0(\\mathbf{x}) \\newline\n\\text{subject to:}~ && f_i(\\mathbf{x}) \\leq 0, ~~ i = 1, 2, \\dots, m ~~~(16)\\newline\n&& h_j(\\mathbf{z}) = \\mathbf{a}_j^T\\mathbf{x} - b_j = 0, j = 1, \\dots, p\n\\end{eqnarray}\n\\]\ntrong đó \\(f_0, f_1, \\dots, f_m\\) là các hàm lồi.\nSo với bài toán tối ưu \\((15)\\), bài toán tối ưu lồi \\((16)\\) có thêm ba điều kiện nữa:\nHàm mục tiêu là một hàm lồi.\nCác hàm bất đẳng thức ràng buộc \\(f_i\\) là các hàm lồi.\nHàm đẳng thức ràng buộc \\(h_j\\) là affine (hàm linear cộng với một hằng số nữa được gọi là affine).\nMột vài nhận xét:\nTập hợp các điểm thoả mãn \\(h_j(\\mathbf{x}) = 0\\) là một tập lồi vì nó có dạng một hyperplane.\nKhi \\(f_i\\) là một hàm lồi thì tập hợp các điểm thoả mãn \\(f_i(\\mathbf{x}) \\leq 0 \\) chính là 0-sublevel set của \\(f_i\\) và là một tập lồi.\nNhư vậy tập hợp các điểm thoả mãn mọi điều kiện ràng buộc chính là giao điểm của các tập lồi, vì vậy nó là một tập lồi.\nVậy, trong một bài toán tối ưu lồi, ta tối thiểu một hàm mục tiêu lồi trên một tập lồi.\n\nTính chất quan trọng nhất của bài toán tối ưu lồi chính là bất kỳ locally optimal point chính là một điểm (globally) optimal point.\nTính chất quan trọng này có thể chứng minh bằng phản chứng như sau. Gọi  \\(\\mathbf{x}_0\\) là một điểm locally optimal, tức:\n\\[\nf_0(\\mathbf{x}_0) = \\text{inf} \\{f_0(\\mathbf{x}) | \\mathbf{x} ~\\text{is feasible}, ||\\mathbf{x} - \\mathbf{x}_0||_2 \\leq R\\}\n\\]\nvới \\(R > 0\\) nào đó. Giả sử \\(\\mathbf{x}_0\\) không phải là globally optimal point, tức tồn tại một feasible point \\(\\mathbf{y}\\) sao cho \\(f(\\mathbf{y}) < f(\\mathbf{x}_0)\\) (hiển nhiên rằng \\(\\mathbf{y}\\) không nằm trong lân cận đang xét). Ta có thể tìm được \\(\\theta \\in [0, 1]\\) đủ nhỏ sao cho \\(\\mathbf{z} = (1 - \\theta)\\mathbf{x}_0 + \\theta\\mathbf{y}\\) nằm trong lân cận của \\(\\mathbf{x}_0\\), tức \\(||\\mathbf{z} - \\mathbf{x}_0||_2 < R\\). Chú ý rằng \\(\\mathbf{z}\\) cũng là một feasible point vì feasible set là một tập lồi. Hơn nữa, vì hàm mục tiêu \\(f_0\\) là một hàm lồi, ta có:\n\\[\n\\begin{eqnarray}\n    f_0(\\mathbf{z}) &=& f_0((1 - \\theta)\\mathbf{x}_0 + \\theta \\mathbf{y})  \\newline\n                    &\\leq& (1 - \\theta)f_0(\\mathbf{x}_0) + \\theta f_0(\\mathbf{y})\\newline\n                    & < & (1 - \\theta)f_0(\\mathbf{x}_0) + \\theta f_0(\\mathbf{x}_0) \\newline\n                    &=& f_0(\\mathbf{x}_0)\n\\end{eqnarray}\n\\]\nđiều này mâu thuẫn với giả thiết \\(\\mathbf{x}_0\\) là một điểm cực tiểu. Vậy giả sử sai, tức \\(\\mathbf{x}_0\\) chính là globally optimal point và ta có điều phải chứng minh.\nChứng minh bằng lời: giả sử một điểm cực tiểu không phải là điểm làm cho hàm số đạt giá trị nhỏ nhất. Với điều kiện feasible set và hàm mục tiêu là lồi, ta luôn tìm được một điểm khác trong lân cận của điểm cực tiểu đó sao cho giá trị của hàm mục tiêu tại điểm mới này nhỏ hơn giá trị của hàm mục tiêu tại điểm cực tiểu. Sự mâu thuẫn này chỉ ra rằng với một bài toán tối ưu lồi, điểm cực tiểu phải là điểm làm cho hàm số đạt giá trị nhỏ nhất.\n\nNếu hàm mục tiêu \\(f_0\\) là khả vi (differentiable), theo first-order condition, với mọi \\(\\mathbf{x}, \\mathbf{y} \\in \\text{dom}f_0\\), ta có:\n\\[\nf_0(\\mathbf{x}) \\geq f_0(\\mathbf{x}_0) + \\nabla f_0(\\mathbf{x}_0)^T (\\mathbf{x} - \\mathbf{x}_0)~~~(17)\n\\]\nĐặt \\(\\mathcal{X}\\) là feasible set. Điều kiện cần và đủ để một điểm \\(\\mathbf{x}_0 \\in \\mathcal{X}\\) là optimal point là:\n\\[\n\\nabla f_0(\\mathbf{x}_0)^T(\\mathbf{x} - \\mathbf{x}_0) \\geq 0, ~\\forall \\mathbf{x} \\in \\mathcal{X} ~~~(18)\n\\]\nTôi xin được bỏ qua việc chứng minh điều kiện cần và đủ này, bạn đọc có thể tìm trong trang 139-140 của cuốn Convex Optimization trong Tài liệu tham khảo.\nXem hình vẽ dưới đây:\nMột cách hình học, điều kiện này nói rằng: Nếu \\(\\mathbf{x}_0\\) là điểm optimal thì với mọi \\(\\mathbf{x} \\in \\mathcal{X}\\), vector đi từ \\(\\mathbf{x}_0\\) tới \\(\\mathbf{x}\\) hợp với vector \\(-\\nabla f_0 (\\mathbf{x}_0)\\) một góc tù. Nói cách khác, nếu ta vẽ mặt tiếp tuyến của hàm mục tiêu tại \\(\\mathbf{x}_0\\) thì mọi điểm feasible nằm về một phía so với mặt tiếp tuyến này. Hơn nữa, feasible set nằm về phía làm cho hàm mục tiêu đạt giá trị cao hơn \\(f_0(\\mathbf{x}_0)\\). Mặt tiếp tuyến này chính là supporting hyperplane của feasible set tại điểm \\(\\mathbf{x}_0\\). Nhắc lại rằng khi vẽ các level set, tôi thường dùng màu lam để chỉ giá trị nhỏ, màu đỏ để chỉ giá trị lớn của hàm số.\n(Một mặt phẳng đi qua một điểm trên biên của một tập hợp sao cho mọi điểm trong tập hợp đó nằm về một phía (hoặc nằm trên) so với mặt phẳng đó được gọi là supporting hyperplane (siêu phẳng hỗ trợ). Nếu một tập hợp là lồi, tồn tại supporting hyperplane tại mọi điểm trên biên của nó.)\nNếu tồn tại một điểm \\(\\mathbf{x}_0\\) trong feasible set sao cho \\(\\nabla f_0(\\mathbf{x}_0) = 0\\), đây chính là optimal point. Điều này dễ hiểu vì đó chính là điểm làm cho gradient bằng 0, tức điểm cực tiểu của hàm mục tiêu. Nếu \\(\\nabla f_0(\\mathbf{x}_0) \\neq 0\\), vector \\(-\\nabla f_0 (\\mathbf{x}_0)\\) chính là vector pháp tuyến của supporting hyperplane tại \\(\\mathbf{x}_0\\).\n\nCVXOPT là một thư viện miễn phí trên Python giúp giải rất nhiều các bài toán trong cuốn sách Convex Optimization ở phần Tài liệu tham khảo. Tác giả thứ hai của cuốn sách này, Lieven Vandenberghe, chính là đồng tác giả của thư viện này. Hướng dẫn cài đặt, tài liệu hướng dẫn, và các ví dụ mẫu của thư viện này cũng có đầy đủ trên trang web CVXOPT.\nTrong phần còn lại của bài viết, tôi sẽ giới thiệu 3 bài toán rất cơ bản trong Convex Optimization: Linear Programming, Quadratic Programming, và Geometric Programming. Tôi cũng sẽ cùng các bạn lập trình để giải các ví dụ đã nêu ở phần đầu bài viết dựa trên thư viện CVXOPT này.\n\nChúng ta cùng bắt đầu với lớp các bài toán đơn giản nhất trong Convex Optimization - Linear Programming (LP, một số tài liệu cũng gọi là Linear Program), trong đó hàm mục tiêu \\(f_0\\) và hàm bất đẳng thức ràng buộc \\(f_i, i = 1, \\dots, m\\) đều là các hàm tuyến tính cộng với một hằng số (tức hàm affine).\n\nA general LP:\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\arg\\min_{\\mathbf{x}} \\mathbf{c}^T\\mathbf{x} + d \\newline\n\\text{subject to:}~ && \\mathbf{Gx} \\preceq \\mathbf{h} ~~~~~~~~~~~~~~~~~~~~(19)\\newline\n&& \\mathbf{Ax} = \\mathbf{b}\n\\end{eqnarray}\n\\]\nTrong đó \\(\\mathbf{G} \\in \\mathbb{R}^{m\\times n}, \\mathbf{h} \\in \\mathbb{R}^m\\) và, \\(\\mathbf{A}\\in \\mathbb{R}^{p\\times n}, \\mathbf{b} \\in\\mathbb{R}^p\\). \\(\\mathbf{c}, \\mathbf{x} \\in\\mathbb{R}^n\\) và \\(d\\) là một số vô hướng (số vô hướng này có thể bỏ qua vì nó không ảnh hưởng tới nghiệm của bài toán tối ưu, nó chỉ làm thay đổi giá trị của hàm mục tiêu). Nhắc lại rằng ký hiệu \\(\\preceq\\) nghĩa là mỗi phần tử trong vector (ma trận) ở vế trái nhỏ hơn hoặc bằng phần tử tương ứng trong vector (ma trân) ở về phải.\nChú ý rằng nhiều bất đẳng thức dạng \\(\\mathbf{g}_i\\mathbf{x} \\leq h_i\\), với \\(\\mathbf{g}_i\\) là các vector hàng, có thể viết gộp dưới dạng \\(\\mathbf{Gx} \\preceq \\mathbf{h}\\) trong đó mỗi hàng của \\(\\mathbf{G}\\) ứng với một \\(\\mathbf{g}_i\\), mỗi phần tử của \\(\\mathbf{h}\\) tương ứng với một \\(h_i\\).\n\nTrong dạng tiêu chuẩn (standard form) LP, các bất đẳng thức ràng buộc chỉ là điều kiện các nghiệm có thành phần không âm:\nA standard form LP:\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\arg\\min_{\\mathbf{x}} \\mathbf{c}^T\\mathbf{x} \\newline\n\\text{subject to:}~ && \\mathbf{Ax} = \\mathbf{b} ~~~~~~~~~~~~~~~~~~~~(20)\\newline\n&& \\mathbf{x} \\succeq \\mathbf{0}\n\\end{eqnarray}\n\\]\nBài toán \\((19)\\) có thể đưa về bài toán \\((20)\\) bằng cách đặt thêm biến slack \\(\\mathbf{s}\\)\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\arg\\min_{\\mathbf{x}, \\mathbf{s}} \\mathbf{c}^T\\mathbf{x} \\newline\n\\text{subject to:}~ && \\mathbf{Ax} = \\mathbf{b} ~~~~~~~~~~~~~~~~~~~~(21)\\newline\n&& \\mathbf{Gx} + \\mathbf{s} = \\mathbf{h} \\newline\n&& \\mathbf{s} \\succeq \\mathbf{0}\n\\end{eqnarray}\n\\]\nTiếp theo, nếu ta biểu diễn \\(\\mathbf{x}\\) dưới dạng hiệu của hai vector mà thành phần của nó đều không âm, tức: \\(\\mathbf{x} = \\mathbf{x}^+ - \\mathbf{x}^-\\), với \\(\\mathbf{x}^+, \\mathbf{x}^- \\succeq 0\\). Ta có thể tiếp tục viết lại \\((21)\\) dưới dạng:\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\arg\\min_{\\mathbf{x}^+,\\mathbf{x}^-, \\mathbf{s}} \\mathbf{c}^T\\mathbf{x}^+ - \\mathbf{c}^T\\mathbf{x}^- \\newline\n\\text{subject to:}~ && \\mathbf{Ax}^+ - \\mathbf{Ax}^- = \\mathbf{b} ~~~~~~~~~~~~~~~~~~~~(22)\\newline\n&& \\mathbf{Gx}^+ - \\mathbf{Gx}^- + \\mathbf{s} = \\mathbf{h} \\newline\n&& \\mathbf{x}^+ \\succeq 0, \\mathbf{x}^- \\succeq 0, \\mathbf{s} \\succeq \\mathbf{0}\n\\end{eqnarray}\n\\]\nTới đây, bạn đọc có thể thấy rằng \\((22)\\) có thể viết gọn lại như \\((20)\\).\nBài toán nhà xuất bản và Bài toán canh tác trong phần đầu của bài viết này chính là các LP.\n\nCác bài toán LP có thể được minh hoạ như hình dưới đây:\nĐiểm \\(\\mathbf{x}_0\\) chính là điểm làm cho hàm mục tiêu đạt giá trị nhỏ nhất, điểm \\(\\mathbf{x}_1\\) chính là điểm làm cho hàm mục tiêu đạt giá trị lớn nhất. Với các bài toán LP, nghiệm, nếu có, thường là một điểm ở đỉnh của polyheron hoặc là một mặt của polyhedron đó (trong trường hợp các đường level sets của hàm mục tiêu song song với mặt đó, và trên mặt đó, hàm mục tiêu đạt giá trị tối ưu).\nVề LP, các bạn có thể tìm thấy rất nhiều tài liệu cả tiếng Việt (Quy hoạch tuyến tính) và tiếng Anh. Có rất nhiều các bài toán trong thực tế có thể đưa về dạng LP. Phương pháp thường được dùng để giải bài toán này có tên là simplex (đơn hình). Tôi sẽ không đề cập đến các phương pháp này, thay vào đó, tôi sẽ hướng dẫn các bạn dùng thư viện CVXOPT để giải quyết các bài toán thuộc dạng này.\n\nTôi sẽ dùng thư viện CVPOPT để giải Bài toán canh tác ở phía trên. Nhắc lại bài toán canh tác:\nBài toán canh tác:\n\\[\n\\begin{eqnarray}\n(x, y) =& \\arg\\max_{x, y} 5x + 3y \\newline\n\\text{subject to:}~ & x + y \\leq 10 \\newline\n                    & 2x + y \\leq 16  \\newline\n                    & x + 4y \\leq 32 \\newline\n                    & x, y \\geq 0\n\\end{eqnarray}\n\\]\nCác điều kiện ràng buộc có thể viết lại dưới dạng \\( \\mathbf{Gx} \\preceq \\mathbf{h}\\), trong đó:\n\\[\n\\mathbf{G} = \\left[\\begin{matrix}\n1 & 1 \\newline\n2 & 1 \\newline\n1 & 4 \\newline\n-1 & 0 \\newline\n0 & -1\n\\end{matrix}\\right], ~~~~\n\\mathbf{h} = \\left[\\begin{matrix}\n10\\newline\n16 \\newline\n32 \\newline\n0 \\newline\n0\n\\end{matrix}\\right]\n\\]\nLời giải cho bài toán này khi dùng CVXOPT là:\nNghiệm này chính là nghiệm mà tôi đã tìm được trong phần đầu của bài viết.\nMột vài lưu ý:\nHàm solvers.lp của cvxopt giải bài toán \\((21)\\).\nTrong bài toán của chúng ta, vì ta cần tìm giá trị lớn nhất nên ta phải đổi hàm mục tiêu về dạng \\(-5x - 3y\\). Chính vì vậy mà c = matrix([-5., -3.]).\nHàm matrix nhận đầu vào là một list (trong Python), list này thể hiện một vector cột. Nếu muốn biểu diễn một ma trận, đầu vào của matrix là một list của list, trong đó mỗi list bên trong thể hiện một vector cột của ma trận đó.\nCác hằng số trong bài toán cần ở dạng số thực. Nếu chúng là các số nguyên, ta cần thêm dấu . vào sau các số đó thể thể hiện đó là số thực. (Tôi thấy điểm này hơi thừa, nhưng nếu không có dấu . thì chương trình sẽ báo lỗi.)\nVới đẳng thức ràng buộc \\(\\mathbf{Ax} = \\mathbf{b}\\), solvers.lp lấy giá trị mặc định của A và b là None, tức nếu không khái báo thì nghĩa là không có đẳng thức ràng buộc nào.\nVới các tuỳ chọn khác, bạn đọc có thể tìm trong Tài liệu của CVXOPT.\nViệc giải Bài toán nhà xuất bản bằng CVXOPT xin nhường lại cho bạn đọc như một bài tập đơn giản.\n\n\nMột dạng Convex Optimization mà các bạn sẽ gặp rất nhiều trong các bài sau của blog là Quadratic Programming (QP, hoặc Quadratic Program). Khác biệt duy nhất của QP so với LP là hàm mục tiêu có dạng Quadratic form:\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\arg\\min_{\\mathbf{x}} \\frac{1}{2} \\mathbf{x}^T\\mathbf{P}\\mathbf{x} + \\mathbf{q}^T\\mathbf{x} + \\mathbf{r} \\newline\n\\text{subject to:} &&\\mathbf{Gx} \\preceq \\mathbf{h} ~~~~~~~~~~~~~(23)\\newline\n&& \\mathbf{Ax} = \\mathbf{b}\n\\end{eqnarray}\n\\]\nTrong đó \\(\\mathbf{P} \\in \\mathbb{S}_+^n\\) (tập các ma trận vuông nửa xác định dương có số cột là \\(n\\)), \\(\\mathbf{G}\\in \\mathbb{R}^{m\\times n}, \\mathbf{A}\\in\\mathbb{R}^{p \\times n}\\). Điều kiện \\(\\mathbf{P}\\) là nửa xác định dương để đảm bảo hàm mục tiêu là convex.\nChúng ta có thể thấy rằng LP chính là một trường hợp đặc biệt của QP với \\(\\mathbf{P} = \\mathbf{0}\\).\nDiễn đạt bằng lời: trong QP, chúng ta tối thiểu một hàm quadratic lồi trên một polyhedron. Xem hình dưới đây:\n\nBài toán vui: Có một hòn đảo mà hình dạng của nó có dạng một đa giác lồi. Một con thuyền ở ngoài biển thì cần đi theo hướng nào để tới đảo nhanh nhất, giả sử rằng tốc độ của sóng và gió bằng 0.\nBài toán khoảng cách từ một điểm tới một polyhedron được phát biểu như sau:\nCho một polyhedron được biểu diễn bởi \\(\\mathbf{Ax} \\preceq \\mathbf{b}\\) và một điểm \\(\\mathbf{u}\\), tìm điểm \\(\\mathbf{x}\\) thuộc polyhedron đó sao cho khoảng cách Euclidean giữa \\(\\mathbf{x}\\) và \\(\\mathbf{u}\\) là nhỏ nhất.\nBài toán này có thể phát biểu như sau:\n\\[\n\\begin{eqnarray}\n\\mathbf{x} &=& \\arg\\min_{\\mathbf{x}} \\frac{1}{2}||\\mathbf{x} - \\mathbf{u}||_2^2 \\newline\n\\text{subject to:} &&\\mathbf{Gx} \\preceq \\mathbf{h}\\newline\n\\end{eqnarray}\n\\]\nHàm mục tiêu đạt giá trị nhỏ nhất bằng 0 nếu \\(\\mathbf{u}\\) nằm trong polyheron đó và optimal point chính là \\(\\mathbf{x} = \\mathbf{u}\\). Khi \\(\\mathbf{u}\\) không nằm trong polyhedron, ta viết:\n\\[\n\\frac{1}{2} ||\\mathbf{x} - \\mathbf{u}||_2^2 = \\frac{1}{2} (\\mathbf{x} - \\mathbf{u})^T(\\mathbf{x} - \\mathbf{u}) = \\frac{1}{2} \\mathbf{x}^T\\mathbf{x} - \\mathbf{u}^T\\mathbf{x} + \\frac{1}{2} \\mathbf{u}^T\\mathbf{u}\n\\]\nBiểu thức này có dạng hàm mục tiêu như trong \\((23)\\) với \\(\\mathbf{P = I}, \\mathbf{q} = - \\mathbf{u}, \\mathbf{r} = \\frac{1}{2} \\mathbf{u}^T\\mathbf{u}\\), trong đó \\(\\mathbf{I}\\) là ma trận đơn vị.\n\nXét bài toán sau đây:\n\\[\n\\begin{eqnarray}\n(x, y) &=& \\arg\\min_{x, y} (x - 10)^2 + (y - 10)^2 \\newline\n\\text{subject to:}~&&\n\\left[\\begin{matrix}\n1 & 1 \\newline\n2 & 1 \\newline\n1 & 4 \\newline\n-1 & 0 \\newline\n0 & -1\n\\end{matrix}\\right]\n\\left[\n\\begin{matrix}\nx \\newline\ny\n\\end{matrix}\n\\right]\n\\preceq\n\\left[\\begin{matrix}\n10\\newline\n16 \\newline\n32 \\newline\n0 \\newline\n0\n\\end{matrix}\\right]\n\\end{eqnarray}\n\\]\nFeasible set trong bài toán này tôi lấy trực tiếp từ Bài toán canh tác và \\(\\mathbf{u} = [10, 10]^T\\).\nBài toán này có thể được giải bằng CVXOPT như sau:\nTrong các thuật toán Machine Learning, các bạn sẽ gặp các bài toán về tìm hình chiếu (projection) của một điểm lên một tập lồi nói chung rất nhiều. Tới từng phần, tôi sẽ đề cập hướng giải quyết của các bài toán đó.\n\nTrong mục này, chúng ta sẽ thấy một lớp các bài toán không lồi khi nhìn vào hàm mục tiêu và các hàm ràng buộc, nhưng có thể được biến đổi về dạng lồi bằng một vài kỹ thuật.\nTrước hết, chúng ta cần có một vài định nghĩa:\n\nMột hàm số \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) với tập xác đinh \\(\\text{dom}f = \\mathbf{R}_{++}^n\\) (tất cả các phần tử đều là số dương) có dạng:\n\\[\nf(\\mathbf{x}) = c x_1^{a_1} x_2^{a_2} \\dots x_n^{a_n}~~~~~~~~(24)\n\\]\ntrong đó \\(c > 0\\) và \\(a_i \\in \\mathbb{R}\\), được gọi là một monomial function (khái niệm này khá giống với đơn thức khi tôi học lớp 8, nhưng khi đó SGK định nghĩa với \\(c\\) bất kỳ và \\(a_i\\) là các số tự nhiên).\nTổng của các monomials:\n\\[\nf(\\mathbf{x}) = \\sum_{k=1}^K c_k x_1^{a_{1k}}x_2^{a_{2k}}\\dots x_n^{a_{nk}}~~~~~~~~~~(24)\n\\]\ntrong đó các \\(c_k > 0\\) được gọi là posynomial function (đa thức), hoặc đơn giản là posynomial.\n\nMột bài toán tối ưu có dạng:\n\\[\n\\begin{eqnarray}\n\\mathbf{x}   &=& \\arg\\min_{\\mathbf{x}} f_0(\\mathbf{x}) \\newline\n\\text{subject to:}~ && f_i(x) \\leq 1,  ~~ i = 1, 2, \\dots, m ~~~~~~~~~~~(25)\\newline\n                    && h_j(x) = 1, ~~ j = 1, 2, \\dots, p\n\\end{eqnarray}\n\\]\ntrong đó \\(f_0, f_1, \\dots, f_m\\) là các posynomials và \\(h_1, \\dots, h_p\\) là các monomials, được gọi là Geometric Programming (GP). Điều kiện \\(\\mathbf{x} \\succ 0\\) được ẩn đi.\nChú ý rằng nếu \\(f\\) là một posynomial, \\(h\\) là một monomial thì \\(f/h\\) là một posynomial.\nVí dụ:\n\\[\n\\begin{eqnarray}\n    (x, y, z)    &=& \\arg\\min_{x, y, z} x/y                          \\newline\n\\text{subject to:}~ && 1 \\leq x \\leq 2 \\newline\n && x^3 + 2y/z \\leq \\sqrt{y} \\newline\n && x/y = z\n\\end{eqnarray}\n\\]\nCó thể được viết lại dưới dạng GP:\n\\[\n\\begin{eqnarray}\n    (x, y, z)    &=& \\arg\\min_{x, y, z} xy ^{-1}                        \\newline\n\\text{subject to:}~ && x^{-1} \\leq 1 \\newline\n&& (1/2)x \\leq 1 \\newline\n&& x^3y^{-1/2} + 2y^{1/2}z^{-1} \\leq 1 \\newline\n&& xy^{-1}z^{-1} = 1\n\\end{eqnarray}\n\\]\nBài toán này rõ ràng là nonconvex vì cả hàm mục tiêu và điều kiển ràng buộc đều không lồi.\n\nGP có thể được biến đổi về dạng lồi như sau:\nĐặt \\(y_i = \\log(x_i)\\), tức \\(x_i = \\exp({y_i})\\). Nếu \\(f\\) là một monomial function của \\(\\mathbf{x}\\) thì:\n\\[\nf(\\mathbf{x}) = c(\\exp({y_1}))^{a_1} \\dots (\\exp({y_n}))^{a_n} = \\exp({\\mathbf{a}^T\\mathbf{y} + b})\n\\]\nvới \\(b = \\log(c)\\). Lúc này, hàm số \\(g(y) = \\exp({\\mathbf{a}^T\\mathbf{y} + b})\\) là một hàm lồi theo \\(\\mathbf{y}\\). (Bạn đọc có thể chứng minh theo định nghĩa rằng hợp của hai hàm lồi là một hàm lồi. Trong trường hợp này, hàm \\(\\exp\\) và hàm affine trên đều là các hàm lồi.)\nTương tự như thế, posynomial trong đẳng thức \\((24)\\) có thể viết dưới dạng:\n\\[\nf(\\mathbf{x}) = \\sum_{k = 1}^K \\exp(\\mathbf{a}_k^T\\mathbf{y} + b_k)\n\\]\ntrong đó \\(\\mathbf{a}_k = [a_{1k}, \\dots, a_{nk}]^T\\) và \\(b_k = \\log(c_k)\\). Lúc này, posynomial đã được viết dưới dạng tổng của các hàm \\(\\exp\\) của các hàm affine (và vì vậy là một hàm lồi, nhớ lại rằng tổng của các hàm lồi là một hàm lồi).\nBài toán GP \\((25)\\) được viết lại dưới dạng:\n\\[\n\\begin{eqnarray}\n    \\mathbf{y}    &=& \\arg\\min_{\\mathbf{y}} \\sum_{k=1}^{K_0} \\exp(\\mathbf{a}_{0k}^T\\mathbf{y} + b_{0k})                      \\newline\n\\text{subject to:}~ && \\sum_{k=1}^{K_i} \\exp(\\mathbf{a}_{ik}^T\\mathbf{y} + b_{ik}) \\leq 1, ~~, i = 1, \\dots, m ~~~~~~(26)\\newline\n&& \\exp(\\mathbf{g}_j^T\\mathbf{y} + h_j) = 1, ~ j= 1, \\dots, p\n\\end{eqnarray}\n\\]\nvới \\(\\mathbf{a}_{ik} \\in \\mathbb{R}^n, i = 1, \\dots, p\\) và \\(\\mathbf{g}_i \\in \\mathbb{R}^n\\).\nVới chú ý rằng hàm số \\(\\log \\sum_{i=1}^m \\exp(g_i(\\mathbf{x}))\\) là môt hàm lồi nếu \\(g_i\\) là các hàm lồi (tôi xin bỏ qua phần chứng minh), ta có thể viết lại bài toán \\((26)\\) dưới dạng lồi bằng cách lấy \\(\\log\\) của các hàm như sau:\nGP in convex form:\n\\[\n\\begin{eqnarray}\n    \\text{minimize}_{\\mathbf{y}} \\tilde{f}_0(\\mathbf{y}) &=& \\log\\left(\\sum_{k=1}^{K_0} \\exp(\\mathbf{a}_{0k}^T \\mathbf{y} + b_{i0})\\right)                          \\newline\n\\text{subject to:}~ \\tilde{f}_i(\\mathbf{y}) &=& \\log \\left(\\sum_{k=1}^{K_i} \\exp(\\mathbf{a}_{ik}^T \\mathbf{y} + b_{ik})\\right) \\leq 0, ~~ i = 1, \\dots, m ~~~~ (27)\\newline\n\\tilde{h}_j(\\mathbf{y}) &=& \\mathbf{g}_j^T\\mathbf{y} + h_j = 0,~~ j = 1, \\dots, p\n\\end{eqnarray}\n\\]\nLúc này, ta có thể nói rằng GP tương đương với một bài toán tối ưu lồi vì hàm mục tiêu và các hàm bất đẳng thức ràng buộc trong \\((27)\\) đều là hàm lồi, đồng thời điều hiện đẳng thức cuối cùng chính là dạng affine. Dạng này thường được gọi là geometric program in convex form (để phân biệt nó với định nghĩa của GP).\n\nChúng ta quay lại ví dụ về Bài toán đóng thùng không có ràng buộc và hàm mục tiêu là \\(f(x, y, z) = 40x^{-1}y^{-1}z^{-1} + 2xy + 2yz + 2zx\\) là một posynomial. Vậy đây là một GP.\nCode cho việc tìm optimal point của bài toán này bằng CVXOPT như sau:\nNghiệm thu được chính là \\(x = y = z = \\sqrt[5]{10}\\). Bạn đọc được khuyến khích đọc thêm chỉ dẫn của hàm solvers.gp để hiểu cách thiết lập bài toán.\n\nCác bài toán tối ưu xuất hiện rất nhiều trong thực tế, trong đó Tối Ưu Lồi đóng một vai trò quan trọng. Trong bài toán Tối Ưu Lồi, nếu tìm được cực trị thì cực trị đó chính là một điểm optimal của bài toán (nghiệm của bài toán).\nCó nhiều bài toán tối ưu không được viết dưới dạng convex nhưng có thể biến đổi về dạng convex, ví dụ như bài toán Geometric Programming.\nLinear Programming và Quadratic Programming đóng một vài trò quan trọng trong toán tối ưu, được sử dụng nhiều trong các thuật toán Machine Learning.\nThư viện CVXOPT được dùng để tối ưu nhiều bài toán tối ưu lồi, rất dễ sử dụng và thời gian chạy tương đối nhanh.\n\n[1] Convex Optimization – Boyd and Vandenberghe, Cambridge University Press, 2004.\n[2] CVXOPT."
    },
    {
        "ID": 33,
        "URL": "https://machinelearningcoban.com/2017/03/12/convexity/",
        "Title": "Machine Learning cơ bản",
        "Content": "Bài này có khá nhiều khái niệm mới, mong bạn đọc thông cảm khi tôi sử dụng các khái niệm này ở cả tiếng Anh và tiếng Việt.\nBài chủ yếu nói về toán, nếu bạn đọc không hiểu ngay cũng không sao, ngày đầu tôi làm quen với những khái niệm này cũng không thể hấp thụ được ngay. Làm nhiều, đọc nhiều rồi sẽ ngấm dần.\nBạn đọc có thể xem bản pdf tại đây.\n\nTừ đầu đến giờ, chúng ta đã làm quen với rất nhiều bài toán tối ưu. Học Machine Learning là phải học Toán Tối Ưu, và để hiểu hơn về Toán Tối Ưu, với tôi cách tốt nhất là tìm hiểu các thuật toán Machine Learning. Cho tới lúc này, những bài toán tối ưu các bạn đã nhìn thấy trong blog đều là các bài toán tối ưu không ràng buộc (unconstrained optimization problems), tức tối ưu hàm mất mát mà không có điều kiện ràng buộc (constraints) nào về nghiệm cả.\nKhông chỉ trong Machine Learning, trên thực tế các bài toán tối ưu thường có rất nhiều ràng buộc khác nhau. Ví dụ:\nTôi muốn thuê một ngôi nhà cách trung tâm Hà Nội không quá 5km với giá càng thấp càng tốt. Trong bài toán này, giá thuê nhà chính là hàm mất mát (loss function, đôi khi người ta cũng dùng cost function để chỉ hàm số cần tối ưu), điều kiện khoảng cách không quá 5km chính là ràng buộc (constraint).\nQuay lại bài toán dự đoán giá nhà theo Linear Regression, giá nhà là một hàm tuyến tính của diện tích, số phòng ngủ và khoảng cách tới trung tâm. Rõ ràng, khi làm bài toán này, ta dự đoán rằng giá nhà tăng theo diện tích và số phòng ngủ, giảm theo khoảng cách. Vậy nên một nghiệm được gọi là có lý một chút nếu hệ số tương ứng với diện tích và số phòng ngủ là dương, hệ số tương ứng với khoảng cách là âm. Để tránh các nghiệm ngoại lai không mong muốn, khi giải bài toán tối ưu, ta nên cho thêm các điều kiện ràng buộc này.\nTrong Tối Ưu, một bài toán có ràng buộc thường được viết dưới dạng:\n\\[\n\\begin{eqnarray}\n\\mathbf{x}^* &=& \\arg\\min_{\\mathbf{x}} f_0(\\mathbf{x})\\newline\n\\text{subject to:}~ && f_i(\\mathbf{x}) \\leq 0, ~~ i = 1, 2, \\dots, m \\newline\n&& h_j(\\mathbf{x}) = 0, ~~ j = 1, 2, \\dots, p\n\\end{eqnarray}\n\\]\nTrong đó, vector \\(\\mathbf{x} = [x_1, x_2, \\dots, x_n]^T\\) được gọi là biến tối ưu (optimization variable). Hàm số \\(f_0: \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) được gọi là hàm mục tiêu (objective function, các hàm mục tiêu trong Machine Learning thường được gọi là hàm mất mát). Các hàm số \\(f_i, h_j: \\mathbb{R}^n \\rightarrow \\mathbb{R}, i = 1, 2, \\dots, m; j = 1, 2, \\dots, p\\) được gọi là các hàm ràng buộc (hoặc đơn giản là ràng buộc - constraints). Tập hợp các điểm \\(\\mathbf{x}\\) thỏa mãn các ràng buộc được gọi là feasible set. Mỗi điểm trong feasible set được gọi là feasible point, các điểm không trong feasible set được gọi là infeasible points.\nChú ý:\nNếu bài toán là tìm giá trị lớn nhất thay vì nhỏ nhất, ta chỉ cần đổi dấu của \\(f_0(\\mathbf{x})\\).\nNếu ràng buộc là lớn hơn hoặc bằng, tức \\(f_i(\\mathbf{x}) \\geq b_i\\), ta chỉ cần đổi dấu của ràng buộc là sẽ có điều kiện nhỏ hơn hoặc bằng \\(-f_i(\\mathbf{x}) \\leq -b_i\\).\nCác ràng buộc cũng có thể là lớn hơn hoặc nhỏ hơn.\nNếu ràng buộc là bằng nhau, tức \\(h_j(\\mathbf{x}) = 0\\), ta có thể viết nó dưới dạng hai bất đẳng thức \\(h_j(\\mathbf{x}) \\leq 0\\) và \\(-h_j(\\mathbf{x}) \\leq 0\\). Trong một vài tài liệu, người ta bỏ các phương trình ràng buộc \\(h_j(\\mathbf{x})= 0\\) đi.\nTrong bài viết này, \\(\\mathbf{x}, \\mathbf{y}\\) được dùng chủ yếu để ký hiệu các biến số, không phải là dữ liệu như trong các bài trước. Biến tối ưu chính là biến được ghi dưới dấu \\(\\arg \\min\\). Khi viết một bài toán Tối Ưu, ta cần chỉ rõ biến nào cần được tối ưu, biến nào là cố định.\nCác bài toán tối ưu, nhìn chung không có cách giải tổng quát, thậm chí có những bài chưa có lời giải. Hầu hết các phương pháp tìm nghiệm không chứng minh được nghiệm tìm được có phải là global optimal hay không, tức đúng là điểm làm cho hàm số đạt giá trị nhỏ nhất hay lớn nhất hay không. Thay vào đó, nghiệm thường là các local optimal, tức các điểm cực trị.\nĐể bắt đầu học Tối Ưu, chúng ta cần học một mảng rất quan trọng trong đó, có tên là Tối Ưu Lồi (convex optimization), trong đó hàm mục tiêu là một hàm lồi (convex function), feasible set là một tập lồi (convex set). Những tính chất đặc biệt về local optimal và global optimal của một hàm lồi khiến Tối Ưu Lồi trở nên cực kỳ quan trọng. Trong bài viết này, tôi sẽ giới thiệu tới các bạn các định nghĩa và tính chất cơ bản của tập lồi và hàm lồi. Bài toán tối ưu lồi (convex optimization problems) sẽ được đề cập trong bài tiếp theo.\n\n\nKhái niệm về convex sets có lẽ không xa lạ với các bạn học sinh Việt Nam khi chúng ta đã nghe về đa giác lồi. Lồi, hiểu đơn giản là phình ra ngoài, hoặc nhô ra ngoài. Trong toán học, bằng phẳng cũng được coi là lồi.\nĐịnh nghĩa 1: Một tập hợp được gọi là tập lồi (convex set) nếu đoạn thẳng nối hai điểm bất kỳ trong tập hợp hợp đó nằm trọn vẹn trong tập hợp đó.\nMột vài ví dụ về convex sets:\nCác hình với đường biên màu đen thể hiện việc bao gồm cả biên, biên màu trắng thể hiện việc biên đó không nằm trong tập hợp đang xét. Đường hoặc đoạn thằng cũng là một tập lồi theo định nghĩa phía trên.\nMột vài ví dụ thực tế:\nGiả sử có một căn phòng có dạng hình lồi, nếu ta đặt một bóng đèn đủ sáng ở bất kỳ vị trí nào trong phòng, mọi điểm trong căn phòng đều được chiếu sáng.\nNếu một đất nước có bản đồ dạng một hình lồi thì đường bay nối giữa hai thành phố bất kỳ trong đất nước đó đều nằm trọn vẹn trong không phận của nước đó. (Không như Việt Nam, muốn bay thẳng Hà Nội - Hồ Chí Minh phải bay qua không phận Campuchia).\nDưới đây là một vài ví dụ về nonconvex sets, tức tập hợp mà không phải là lồi:\nBa hình đầu tiên không phải là lồi vì các đường nét đứt chứa nhiều điểm không nằm trong các tập đó. Hình thứ tư, hình vuông không có biên ở đáy, không phải là tập lồi vì đoạn thẳng nối hai điểm ở đáy có thể chứa phần ở giữa không thuộc tập đang xét (Nếu không có biên thì thình vuông vẫn là một tập lồi, nhưng biên nửa vời như ví dụ này thì hãy chú ý). Một đường cong bất kỳ cũng không phải là tập lồi vì dễ thấy đường thẳng nối hai điểm bất kỳ không thuộc đường cong đó.\nĐể mô tả một tập lồi dưới dạng toán học, ta sử dụng:\nĐịnh nghĩa 2: Một tập hợp \\(\\mathcal{C}\\) được gọi là convex nếu với hai điểm bất kỳ \\(\\mathbf{x}_1, \\mathbf{x}_2 \\in \\mathcal{C}\\), điểm \\( \\mathbf{x}_{\\theta} = \\theta \\mathbf{x}_1 + (1 - \\theta) \\mathbf{x}_2\\) cũng nằm trong \\(\\mathcal{C}\\) với bất kỳ \\(0 \\leq \\theta \\leq 1\\).\nCó thể thấy rằng, tập hợp các điểm có dạng \\(\\left(\\theta \\mathbf{x}_1 + (1 - \\theta) \\mathbf{x}_2\\right)\\) chính là đoạn thẳng nối hai điểm \\(\\mathbf{x}_1\\) và \\(\\mathbf{x}_2\\).\nVới các định nghĩa này thì toàn bộ không gian là một tập lồi vì đoạn thằng nào cũng nằm trong không gian đó. Tập rỗng cũng có thể coi là một trường hợp đặc biệt của tập lồi.\nDưới đây là một vài ví dụ hay gặp về tập lồi.\n\n\nMột hyperplane (siêu mặt phẳng) trong không gian \\(n\\) chiều là tập hợp các điểm thỏa mãn phương trình:\n\\[\na_1 x_1 + a_2 x_2 + \\dots + a_n x_n = \\mathbf{a}^T\\mathbf{x} = b\n\\]\nvới \\(b, a_i, i = 1, 2, \\dots, n\\) là các số thực.\nHyperplanes là các tập lồi. Điều này có thể dễ dàng suy ra từ Định nghĩa 1. Với Định nghĩa 2, chúng ta cũng dễ dàng nhận thấy. Nếu:\n\\[\n\\mathbf{a}^T\\mathbf{x}_1 = \\mathbf{a}^T\\mathbf{x}_2 = b\n\\]\nthì với \\(0 \\leq \\theta \\leq 1\\) bất kỳ:\n\\[\n\\mathbf{a}^T\\mathbf{x}_{\\theta} = \\mathbf{a}^T(\\theta \\mathbf{x}_1 + (1 - \\theta)\\mathbf{x}_2)) = \\theta b + (1 - \\theta) b  = b\n\\]\nMột halfspace (nửa không gian) trong không gian \\(n\\) chiều là tập hợp các điểm thỏa mãn bất phương trình:\n\\[\na_1 x_1 + a_2 x_2 + \\dots + a_n x_n = \\mathbf{a}^T\\mathbf{x} \\leq b\n\\]\nvới \\(b, a_i, i = 1, 2, \\dots, n\\) là các số thực.\nCác halfspace cũng là các tập lồi, bạn đọc có thể dễ dàng nhận thấy theo Định nghĩa 1 hoặc chứng minh theo Định nghĩa 2.\n\nEuclidean balls (hình tròn trong mặt phẳng, hình cầu trong không gian ba chiều) là tập hợp các điểm có dạng:\n\\[\nB(\\mathbf{x}_c, r) = \\{\\mathbf{x} ~\\big|~ ||\\mathbf{x} - \\mathbf{x}_c||_2 \\leq r \\} = \\{\\mathbf{x}_c + r\\mathbf{u} ~\\big|~ ||\\mathbf{u}||_2 \\leq 1\\}\n\\]\nTheo Định nghĩa 1, chúng ta có thể thấy Euclidean balls là các tập lồi, nếu phải chứng minh, ta dùng Định nghĩa 2 và các tính chất của norms. Với \\(\\mathbf{x}_1, \\mathbf{x}_2\\) bất kỳ thuộc \\(B(\\mathbf{x}_c, r)\\) và \\(0 \\leq \\theta \\leq 1\\) bất kỳ:\n\\[\n\\begin{eqnarray}\n||\\mathbf{x}_{\\theta} - \\mathbf{x}_c||_2 &=& ||\\theta(\\mathbf{x}_1 - \\mathbf{x}_c)  + (1 - \\theta) (\\mathbf{x}_2 - \\mathbf{x}_c)||_2 \\newline\n&\\leq& \\theta ||\\mathbf{x}_1 - \\mathbf{x}_c||_2 + (1 - \\theta)||\\mathbf{x}_2 - \\mathbf{x}_c||_2 \\newline\n&\\leq& \\theta r + ( 1 - \\theta) r = r\n\\end{eqnarray}\n\\]\nVậy nên \\(\\mathbf{x}_{\\theta} \\in B(\\mathbf{x}_c, r)\\).\nEuclidean ball sử dụng norm 2 làm khoảng cách. Nếu sử dụng norm bất kỳ là khoảng cách, ta vẫn được một tập lồi.\nKhi sử dụng norm p:\n\\[\n||\\mathbf{x}||_p = (|x_1|^p + |x_2|^p + \\dots |x_n|^p)^{\\frac{1}{p}} ~~(1)\n\\]\nvới p là một số thực bất kỳ không nhỏ hơn 1 ta cũng thu được các tập lồi.\nHình dưới đây minh họa tập hợp các điểm có tọa độ \\((x, y)\\) trong không gian hai chiều thỏa mãn:\n\\[\n(|x|^p + |y|^p)^{1/p} \\leq 1 ~~~(1)\n\\]\nvới hàng trên là các tập với \\(0 < p < 1\\) (không phải norm) và hàng dưới tương ứng với \\(p \\geq 1\\):\nChúng ta có thể thấy rằng khi \\(p\\) nhỏ gần bằng 0, tập hợp các điểm thỏa mãn bất đẳng thức (1) gần như nằm trên các trục tọa độ và bị chặn trong đoạn \\([0, 1]\\). Quan sát này sẽ giúp ích cho các bạn khi làm việc với (giả) norm 0 sau này. Khi \\(p \\rightarrow \\infty\\), các tập hợp hội tụ về hình vuông.\nĐây cũng là một trong các lý do vì sao cần có điều kiện \\(p \\geq 1\\) khi định nghĩa norm.\nEllipsoids\nCác ellipsoids (ellipse trong không gian nhiều chiều) cũng là các tập lồi. Thực chất, ellipsoides có mối quan hệ mật thiết tới Khoảng cách Mahalanobis. Khoảng cách này vốn dĩ là một norm nên ta có thể chứng minh theo Định nghĩa 2 được tính chất lồi của các ellipsoids.\nMahalanobis norm của một vector \\(\\mathbf{x} \\in \\mathbb{R}^n\\) được định nghĩa là:\n\\[\n||\\mathbf{x}||_{\\mathbf{A}} = \\sqrt{\\mathbf{x}^T\\mathbf{A}^{-1}\\mathbf{x}}\n\\]\nVới \\(\\mathbf{A}\\) là một ma trận thỏa mãn:\n\\[\n\\mathbf{x}^T\\mathbf{A}^{-1}\\mathbf{x} \\geq 0, ~~\\forall \\mathbf{x} \\in \\mathbb{R}^n ~~ (2)\n\\]\nKhi một ma trận \\(\\mathbf{A}\\) thỏa mãn điều kiện \\((2)\\), ta nói ma trận đó xác định dương (positive definite). \n\nNhân tiện, một ma trận \\(\\mathbf{B}\\) được gọi là nửa xác định dương (positive semidefinite) nếu các trị riêng của nó là không âm. Khi đó \\(\\mathbf{x}^T \\mathbf{Bx} \\geq 0, \\forall \\mathbf{x}\\). Nếu dấu bằng xảy ra khi và chỉ khi \\(\\mathbf{x} = 0\\) thì ta nói ma trận đó xác định dương. Trong biểu thức \\((2)\\), vì ma trận \\(\\mathbf{A}\\) có nghịch đảo nên mọi trị riêng của nó phải khác không. Vì vậy, \\(\\mathbf{A}\\) là một ma trận xác định dương.\nMột ma trận \\(\\mathbf{A}\\) là xác định dương hoặc nửa xác định dương sẽ được ký hiệu lần lượt như sau:\n\\[\n\\mathbf{A} \\succ 0, ~~~~~ \\mathbf{A} \\succeq 0.\n\\]\nCũng lại nhân tiện, khoảng cách Mahalanobis có liên quan đến khoảng cách từ một điểm tới một phân phối xác suất (from a point to a distribution). \n\nViệc này có thể nhận dễ nhận thấy với Hình 4 (trái) dưới đây. Giao của hai trong ba hoặc cả ba tập lồi đều là các tập lồi.\nViệc chứng minh việc này theo Định nghĩa 2 cũng không khó. Nếu \\(\\mathbf{x}_1, \\mathbf{x}_2\\) thuộc vào giao của các tập lồi, tức thuộc tất cả các tập lồi đã cho, thì \\(\\theta\\mathbf{x}_1 + (1 - \\theta) \\mathbf{x}_2)\\) cũng thuộc vào tất cả các tập lồi, tức thuộc vào giao của chúng!\nTừ đó suy ra giao của các halfspaces và các hyperplanes cũng là một tập lồi. Trong không gian hai chiều, tập lồi này chính là đa giác lồi, trong không gian ba chiều, nó có tên là đa diện lồi.\nTrong không gian nhiều chiều, giao của các halfspaces và hyperplanes được gọi là polyhedra.\nGiả sử có \\(m\\) halfspaces và \\(p\\) hyperplanes. Mỗi một haflspace, theo như đã trình bày phía trên, có thể viết dưới dạng \\(\\mathbf{a}_i^T\\mathbf{x} \\leq b_i, ~\\forall i = 1, 2, \\dots, m\\). Mỗi một hyperplane có thể viết dưới dạng: \\(\\mathbf{c}_i^T\\mathbf{x} = d_i, ~\\forall i = 1, 2, \\dots, p\\).\nVậy nếu đặt \\(\\mathbf{A} = [\\mathbf{a}_1, \\mathbf{a}_2, \\dots, \\mathbf{a}_m]\\), \\(\\mathbf{b} = [b_1, b_2, \\dots, b_m]^T, \\mathbf{C} = [\\mathbf{c}_1, \\mathbf{c}_2, \\dots, \\mathbf{c}_p]\\) và \\(\\mathbf{d} = [d_1, d_2, \\dots, d_p]^T\\), ta có thể viết polyhedra dưới dạng tập hợp các điểm \\(\\mathbf{x}\\) thỏa mãn:\n \\[\n \\mathbf{A}^T\\mathbf{x} \\preceq \\mathbf{b}, ~~~~  \\mathbf{C}^T\\mathbf{x} = \\mathbf{d}\n \\]\ntrong đó \\(\\preceq\\) là element-wise, tức mỗi phần tử trong vế trái nhỏ hơn hoặc bằng phần tử tương ứng trong vế phải.\n\nMột điểm được gọi là convex combination (tổ hợp lồi) của các điểm \\(\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_k\\) nếu nó có thể viết dưới dạng:\n\\[\n\\mathbf{x} = \\theta_1 \\mathbf{x}_1 + \\theta_2 \\mathbf{x}_2 + \\dots  + \\theta_k \\mathbf{x}_k, ~~ \\text{with} ~~ \\theta_1 + \\theta_2 + \\dots + \\theta_k = 1\n\\]\nConvex hull của một tập hợp bất kỳ là tập hợp tất cả các điểm là convex combination của tập hợp đó. Convex hull là một convex set. Convexhull của một convex set là chính nó. Một cách dễ nhớ, convex hull của một tập hợp là một convex set nhỏ nhất chứa tập hợp đó. Khái niệm nhỏ nhất rất khó định nghĩa, nhưng nó cũng là một cách nhớ trực quan.\nHai tập hợp được gọi là linearly separable nếu các convex hulls của chúng không có điểm chung.\nTrong hình trên, convex hull của các điểm màu xanh là vùng màu xám bao với các đa giác lồi. Ở hình bên phải thì vùng màu xám nằm dưới vùng màu xanh.\nSeparating hyperplane theorem: Định lý này nói rằng nếu hai tập lồi không rỗng \\(\\mathcal{C}, \\mathcal{D}\\) là disjoint (không giao nhau), thì tồn tại vector \\(\\mathbf{a}\\) và số \\(b\\) sao cho:\n\\[\n\\mathbf{a}^T\\mathbf{x} \\leq b, \\forall \\mathbf{x} \\in \\mathcal{C}, ~~ \\text{and}~~ \\mathbf{a}^T\\mathbf{x} \\geq b, \\forall \\mathbf{x} \\in \\mathcal{D}\n\\]\nTập hợp tất cả các điểm \\(\\mathbf{x}\\) thỏa mãn \\(\\mathbf{a}^T\\mathbf{x} = b\\) chính là một hyperplane. Hyperplan này được gọi là separating hyperplane.\nNgoài ra còn nhiều tính chất thú vị của các tập lồi và các phép toán bảo toàn chính chất lồi của một tập hợp, các bạn được khuyến khích đọc thêm Chương 2 của cuốn Convex Optimization trong phần tài liệu tham khảo.\n\nHẳn các bạn đã nghe tới khái niệm này khi ôn thi đại học môn toán. Khái niệm hàm lồi có quan hệ tới đạo hàm bậc hai và Bất đẳng thức Jensen (nếu bạn chưa nghe tới phần này, không sao, bây giờ bạn sẽ biết).\n\nĐể trực quan, trước hết ta xem xét các hàm 1 biến, đồ thị của nó là một đường trong một mặt phẳng. Một hàm số được gọi là lồi nếu tập xác định của nó là một tập lồi và nếu ta nối hai điểm bất kỳ trên đồ thị hàm số đó, ta được một đoạn thẳng nằm về phía trên hoặc nằm trên đồ thị (xem Hình 6).\nTập xác định (domain) của một hàm số \\(f(.)\\) thường được ký hiệu là \\(\\text{dom} f\\).\nĐịnh nghĩa theo toán học:\nĐịnh nghĩa convex function: Một hàm số \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R} \\) được gọi là một hàm lồi (convex function) nếu \\(\\text{dom} f\\) là một tập lồi, và:\n\\[\nf(\\theta\\mathbf{x} + (1 - \\theta) \\mathbf{y}) \\leq \\theta f(\\mathbf{x}) + (1 - \\theta)f(\\mathbf{y})\n\\]\nvới mọi \\(\\mathbf{x, y} \\in \\text{dom}f, 0 \\leq \\theta \\leq 1\\).\nĐiều kiện \\(\\text{dom} f\\) là một tập lồi là rất quan trọng, vì nếu không có nó, ta không định nghĩa được \\(f(\\theta\\mathbf{x} + (1 - \\theta) \\mathbf{y}) \\).\n\nMột hàm số \\(f\\) được gọi là concave (nếu bạn muốn dịch là lõm cũng được, tôi không thích cách dịch này) nếu \\(-f\\) là convex. Một hàm số có thể không thuộc hai loại trên. Các hàm tuyến tính vừa convex, vừa concave.\nĐịnh nghĩa strictly convex function: (tiếng Việt có một số tài liệu gọi là hàm lồi mạnh, hàm lồi chặt) Một hàm số \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R} \\) được gọi là strictly convex  nếu \\(\\text{dom} f\\) là một tập lồi, và:\n\\[\nf(\\theta\\mathbf{x} + (1 - \\theta) \\mathbf{y}) < \\theta f(\\mathbf{x}) + (1 - \\theta)f(\\mathbf{y})\n\\]\nvới mọi \\(\\mathbf{x, y} \\in \\text{dom}f, \\mathbf{x} \\neq \\mathbf{y},  0 < \\theta < 1\\).\nTương tự với định nghĩa strictly concave.\nĐây là một điểm quan trọng: Nếu một hàm số là strictly convex và có điểm cực trị, thì điểm cực trị đó là duy nhất và cũng là global minimum.\n\nNếu \\(f(\\mathbf{x})\\) là convex thì \\(af(\\mathbf{x})\\) là convex nếu \\(a > 0\\) và là concave nếu \\(a < 0\\). Điều này có thể suy ra trực tiếp từ định nghĩa.\nTổng của hai hàm lồi là một hàm lồi, với tập xác định là giao của hai tập xác định kia (nhắc lại rằng giao của hai tập lồi là một tập lồi)\nPointwise maximum and supremum: Nếu các hàm số \\(f_1, f_2, \\dots, f_m\\) là convex thì:\n\\[\nf(\\mathbf{x}) = \\max\\{f_1(\\mathbf{x}), f_2(\\mathbf{x}), \\dots, f_m(\\mathbf{x})\\}\n\\]\ncũng là convex trên tập xác định là giao của tất cả các tập xác định của các hàm số trên. Hàm \\(\\max\\) phía trên cũng có thể thay thế bằng hàm \\(\\text{sup}\\). Tính chất này có thể chứng minh được theo Định nghĩa. Bạn cũng có thể nhận ra dựa vào hình ví dụ dưới đây. Mọi đoạn thẳng nối hai điểm bất kì trên đường màu xanh đều không nằm dưới đường màu xanh.\n\n\nCác ví dụ về các convex functions một biến:\nHàm \\( y = ax + b\\) là một hàm lồi vì đường nối hai điểm bất kỳ nằm trên chính đồ thị đó.\nHàm \\(y = e^{ax}\\) với \\(a \\in \\mathbb{R}\\) bất kỳ.\nHàm \\(y = x^a\\) trên tập các số thực dương và \\(a \\geq 1\\) hoặc \\(a \\leq 0\\).\nHàm negative entropy \\(y = x \\log x\\) trên tập các số thực dương.\nDưới đây là đồ thị của một vài convex functions:\nCác ví dụ về các concave functions một biến:\nHàm \\(y = ax + b\\) là một concave function vì \\(-y\\) là một convex function.\nHàm \\(y = x^a\\) trên tập số dương và \\(0 \\leq a \\leq 1\\).\nHàm logarithm \\(y = \\log(x)\\) trên tập các số dương.\nDưới đây là đồ thị của một vài concave functions:\n\nCác hàm số dạng \\(f(\\mathbf{x}) = \\mathbf{a}^T\\mathbf{x} + b \\) vừa là convex, vừa là concave.\nKhi biến là một ma trận \\(\\mathbf{X}\\), các hàm affine được định nghĩa có dạng:\n\\[\nf(\\mathbf{X}) = \\text{trace}(\\mathbf{A}^T\\mathbf{X}) + b\n\\]\ntrong đó \\(\\text{trace}\\) là hàm số tính tổng các giá trị trên đường chéo của một ma trận vuông, \\(\\mathbf{A}\\) là một ma trận có cùng chiều với \\(\\mathbf{X}\\) (để đảm bảo phép nhân ma trận thực hiện được và kết quả là một ma trận vuông).\n\nHàm bậc hai một biến có dạng \\(f(x) = a x^2 + bx + c\\) là convex nếu \\(a > 0\\), là concave nếu \\(a < 0\\).\nVới biến là một vector \\(\\mathbf{x} = [x_1, x_2, \\dots, x_n]\\), một quadratic form là một hàm số có dạng:\n\\[\nf(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{A}\\mathbf{x} + \\mathbf{b}^T\\mathbf{x} + c\n\\]\nVới \\(\\mathbf{A}\\) thường là một ma trận đối xứng, tức \\(a_{ij} = a_{ji}, \\forall i, j\\), có số hàng bằng số phẩn tử của \\(\\mathbf{x}\\), \\(\\mathbf{b}\\) là một ma trận bất kỳ cùng chiều với \\(\\mathbf{x}\\) và \\(c\\) là một hằng số bất kỳ.\nNếu \\(\\mathbf{A}\\) là một ma trận (nửa) xác định dương thì \\(f(\\mathbf{x})\\) là một convex function.\nNếu \\(\\mathbf{A}\\) là một ma trận (nửa) xác định âm, tức \\(\\mathbf{x}^T\\mathbf{A}\\mathbf{x} \\leq 0, \\forall \\mathbf{x}\\), thì \\(f(\\mathbf{x})\\) là một concave function.\nCác bạn có thể tìm đọc về ma trận xác định dương và các tính chất của nó trong sách Đại số tuyến tính bất kỳ. Nếu bạn gặp nhiều khó khăn trong phần này, hãy đọc lại kiến thức về Đại số tuyến tính, rất rất quan trọng trong Tối Ưu và Machine Learning.\nHàm mất mát trong Linear Regression có dạng:\n\\[\n\\begin{eqnarray}\n\\mathcal{L}(\\mathbf{w}) &=& \\frac{1}{2} ||\\mathbf{y} - \\mathbf{X}\\mathbf{w}||_2^2 = \\frac{1}{2} (\\mathbf{y} - \\mathbf{X}\\mathbf{w})^T(\\mathbf{y} - \\mathbf{X}\\mathbf{w})  \\newline\n&=& \\frac{1}{2} \\mathbf{w}^T\\mathbf{X}^T\\mathbf{Xw} - \\mathbf{y}^T\\mathbf{Xw} + \\frac{1}{2}\\mathbf{y}^T\\mathbf{y}\n\\end{eqnarray}\n\\]\nvì \\(\\mathbf{X}^T\\mathbf{X}\\) là một ma trận xác định dương, hàm mất mát của Linear Regression chính là một convex function.\n\nVâng, lại là norms. Một hàm số bất kỳ thỏa mãn ba điều kiện của norm đều là một convex function. Bạn đọc có thể chứng minh điều này bằng định nghĩa.\nDưới đây là hai ví dụ về norm 1 (trái) và norm 2 (phải) với số chiều là 2 (chiều thứ ba trong hình dưới đây là giá trị của hàm số).\nNhận thấy rằng các bề mặt này đều có một đáy duy nhất tương ứng với gốc tọa độ (đây chính là điều kiện đầu tiên của norm). Các hàm strictly convex khác cũng có dạng tương tự, tức có một đáy duy nhất. Điều này cho thấy nếu ta thả một hòn bi ở vị trí bất kỳ trên các bề mặt này, cuối cùng nó sễ lăn về đáy. Nếu liên tưởng tới thuật toán Gradient Descent thì việc áp dụng thuật toán này vào các bài toán không ràng buộc với hàm mục tiêu là strictly convex (và giả sửa là khả vi, tức có đạo hàm) sẽ cho kết quả rất tốt nếu learning rate không quá lớn. Đây chính là một trong các lý do vì sao các convex functions là quan trọng, cũng là lý do vì sao tôi dành bài viết này chỉ để nói về convexity. (Bạn đọc được khuyến khích đọc hai bài về Gradient Descent trong blog này).\nTiện đây, tôi cũng lấy thêm hai ví dụ về các hàm không phải convex (cũng không phải concave). Hàm thứ nhất \\(f(x, y) = x^2 - y^2\\) là một hyperbolic, hàm thứ hai \\(f(x,y) = \\frac{1}{10}(x^2 + 2y^2 - 2\\sin(xy)) \\).\nContours - level sets\nVới các hàm số phức tạp hơn, khi vẽ các mặt trong không gian ba chiều sẽ khó tưởng tượng hơn, tức khó nhìn được tính convexity của nó. Một phương pháp thường được sử dụng là dùng contours hay level sets. Tôi cũng đã đề cập đến khái niệm này trong Bài Gradient Descent, phần đường đồng mức.\nContours là cách mô tả các mặt trong không gian ba chiều bằng cách chiều nó xuống không gian hai chiều. Trong không gian hai chiều, các điểm thuộc cùng một đường tương ứng với các điểm làm cho hàm số có giá trị bằng nhau. Mỗi đường đó còn được gọi là một level set. Trong Hình 9 và Hình 10, các đường của các mặt lên mặt phẳng \\(0xy\\) chính là các level sets. Một cách hiểu khác, mỗi đường level set là một vết cắt nếu ta cắt các bề mặt bởi một mặt phẳng song song với mặt phẳng \\(0xy\\).\nKhi thể hiện một hàm số hai biến để kiểm tra tính convexity của nó, hoặc để tìm điểm cực trị của nó, người ta thường vẽ contours thay vì vẽ các mặt trong không gian ba chiều. Dưới đây là một vài ví dụ về contours:\nCác đường màu càng xanh đậm thì tương ứng với các giá trị càng nhỏ, các đường màu càng đỏ đậm thì tương ứng các giá trị càng lớn.\nỞ hàng trên, các đường level sets là các đường khép kín (closed). Khi các đường kín này tập trung nhỏ dần ở một điểm thì các điểm đó là các điểm cực trị. Với các convex functions như trong ba ví dụ này, chỉ có 1 điểm cực trị và đó cũng là điểm làm cho hàm số đạt giá trị nhỏ nhất (global optimal). Nếu để ý, bạn sẽ thấy các đường khép kín này tạo thành một vùng lồi!\nỞ hàng dưới, các đường không phải khép kín. Hình bên trái tương ứng với một hàm tuyến tính \\(f(x, y) = x + y\\) và đó là một convex function. Hình ở giữa cũng là một convex function (bạn có thể chứng minh điều này sau khi tính đạo hàm bậc hai, tôi sẽ nói ở phía dưới) nhưng các level sets là các đường không kín. Hàm này có \\(\\log\\) nên tập xác định là góc phần tư thứ nhất tương ứng với các tọa độ dương (chú ý rằng tập hợp các điểm có tọa độ dương cũng là một tập lồi). Các đường không kín này nếu kết hợp với trục \\(Ox, Oy\\) sẽ tạo thành biên của các tập lồi. Hình cuối cùng là contours của một hàm hyperbolic, hàm này không phải là hàm lồi.\n\nĐịnh nghĩa: \\(\\alpha-\\)sublevel set của một hàm số \\(f : \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) được định nghĩa là:\n\\[\n\\mathcal{C}_{\\alpha} = \\{\\mathbf{x} \\in \\text{dom} f ~\\big|~ f(\\mathbf{x}) \\leq \\alpha \\}\n\\]\nTức tập hợp các điểm trong tập xác định của \\(f\\) mà tại đó, \\(f\\) đạt giá trị nhỏ hơn hoặc bằng \\(\\alpha\\).\nQuay lại với Hình 12, hàng trên, các \\(\\alpha-\\) sublevel sets chính là phần bị bao bởi các level sets.\nỞ hàng dưới, bên trái, các \\(\\alpha-\\) sublevel sets chính là phần nửa mặt phẳng phía dưới xác định bởi các đường thẳng level sets. Ở hình giữa, các \\(\\alpha-\\) sublevel sets chính là các vùng bị giới hạn bởi các trục tọa độ và các level sets.\nHàng dưới, bên phải, các \\(\\alpha-\\) sublevel sets hơi khó tưởng tượng chút. Với \\(\\alpha > 0\\), các level sets là các đường màu vàng hoặc đỏ. Các \\(\\alpha-\\) sublevel sets tương ứng là phần bị bóp vào trong, giới hạn bởi các đường đỏ cùng màu. Các vùng này, có thể dễ nhận thấy, là không lồi.\nĐịnh lý: Nếu một hàm số là lồi thì mọi \\(\\alpha-\\) sublevel sets của nó là lồi. Ngược lại chưa chắc đã đúng, tức nếu các \\(\\alpha-\\) sublevel sets của một hàm số là lồi thì hàm số đó chưa chắc đã lồi.\nĐiều này chỉ ra rằng nếu tồn tại một giá trị \\(\\alpha\\) sao cho một \\(\\alpha-\\) sublevel set của một hàm số là không lồi, thì hàm số đó là không lồi (không lồi nhưng không có nghĩa là concave, chú ý). Vậy nên Hyperbolic không phải là hàm lồi.\nCác ví dụ ở hình 12, trừ hình cuối cùng, đều tương ứng với các hàm lồi.\nMột ví dụ về việc một hàm số không convex nhưng mọi \\(\\alpha-\\) sublevel sets là convex là hàm \\(f(x, y) = -e^{x+y}\\). Hàm này có mọi \\(\\alpha-\\) sublevel sets là nửa mặt phẳng - là convex, nhưng nó không phải là convex (trong trường hợp này nó là concave).\nDưới đây là một ví dụ khác về việc một hàm số có mọi \\(\\alpha-\\) sublevel sets là lồi nhưng không phải hàm lồi.\nMọi \\(\\alpha-\\) sublevel sets của hàm số này đều là các hình tròn - convex nhưng hàm số đó không phải là lồi. Vì có thể tìm được hai điểm trên mặt này sao cho đoạn thẳng nối hai điểm nằm hoàn toàn phía dưới của mặt (một điểm ở cánh và 1 điểm ở đáy chẳng hạn).\nNhững hàm số có tập xác định là một tập lồi và có mọi có \\(\\alpha-\\) sublevel sets là lồi được gọi chung là quasiconvex. Mọi convex function đều là quasiconvex nhưng ngược lại không đúng. Định nghĩa chính thức của quasiconvex function được phát biểu như sau: \n\nQuasiconvex function:\nMột hàm số \\(f: \\mathcal{C} \\rightarrow \\mathbb{R}\\) với \\(\\mathcal{C}\\) là một tập con lồi của \\(\\mathbb{R}^n\\) được gọi là quasiconvex nếu với mọi \\(\\mathbf{x}, \\mathbf{y}) \\in \\mathcal{C}\\) và mọi \\(\\theta \\in [0, 1]\\), ta có: \n\\[\nf(\\theta\\mathbf{x} + (1 - \\theta)\\mathbf{y}) \\leq \\max\\{f(\\mathbf{x}), f(\\mathbf{y})\\}\n\\]\nĐịnh nghĩa này khác với định nghĩa về convex function một chút.\n\nCó một cách để nhận biết một hàm số khả vi có là hàm lồi hay không dựa vào các đạo hàm bậc nhất hoặc đạo hàm bậc hai của nó.\n\nTrước hết chúng ta định nghĩa phương trình đường (mặt) tiếp tuyến của một hàm số \\(f\\) khả vi tại một điểm nằm trên đồ thị (mặt) của hàm số đó \\((\\mathbf{x}_0, f(\\mathbf{x}_0)\\). Với hàm một biến, bạn đọc đã quen thuộc:\n\\[\ny = f’(x_0)(x - x_0) + f(x_0)\n\\]\nVới hàm nhiều biến, đặt \\(\\nabla f(\\mathbf{x}_0)\\) là gradient của hàm số \\(f\\) tại điểm \\(\\mathbf{x}_0\\), phương trình mặt tiếp tuyến được cho bởi:\n\\[\ny = \\nabla f(\\mathbf{x}_0)^T (\\mathbf{x} - \\mathbf{x}_0) + f(\\mathbf{x}_0)\n\\]\nFirst-order condition nói rằng: Giả sử hàm số \\(f\\) có tập xác định là một tập lồi, có đạo hàm tại mọi điểm trên tập xác định đó. Khi đó, hàm số \\(f\\) là lồi nếu và chỉ nếu với mọi \\(\\mathbf{x}, \\mathbf{x}_0\\) trên tập xác định của hàm số đó, ta có:\n\\[\nf(\\mathbf{x}) \\geq f(\\mathbf{x}_0) + \\nabla f(\\mathbf{x}_0)^T(\\mathbf{x} - \\mathbf{x}_0) ~~ (6)\n\\]\nTương tự như thế, một hàm số là stricly convex nếu dấu bằng trong \\((6)\\) xảy ra khi và chỉ khi \\(\\mathbf{x} = \\mathbf{x}_0\\).\nNói một cách trực quan hơn, một hàm số là lồi nếu đường (mặt) tiếp tuyến tại một điểm bất kỳ trên đồ thị (mặt) của hàm số đó nằm dưới đồ thị (mặt) đó.\n(Đừng quên điều kiện về tập xác định là lồi)\nDưới đây là ví dụ về hàm lồi và hàm không lồi.\nHàm bên trái là một hàm lồi. Hàm bên phải không phải là hàm lồi vì đồ thị của nó vừa nằm trên, vừa nằm dưới tiếp tuyến.\n(iff là viết tắt của if and only if)\nVí dụ: Nếu ma trận đối xứng \\(\\mathbf{A}\\) là xác định dương thì hàm số \\(f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) là hàm lồi.\nChứng minh: Đạo hàm bậc nhất của hàm số trên là:\n\\[\n\\nabla f(\\mathbf{x}) = 2\\mathbf{A} \\mathbf{x}\n\\]\nVậy first-order condition có thể viết dưới dạng (chú ý rằng \\(\\mathbf{A}\\) là một ma trận đối xứng):\n\\[\n\\begin{eqnarray}\n\\mathbf{x}^T\\mathbf{Ax} &\\geq& 2(\\mathbf{A}\\mathbf{x}_0)^T (\\mathbf{x} - \\mathbf{x}_0) + \\mathbf{x}_0^T\\mathbf{A}\\mathbf{x}_0 \\newline\n⇔ \\mathbf{x}^T\\mathbf{Ax} &\\geq& 2\\mathbf{x}_0^T\\mathbf{A}\\mathbf{x} -\\mathbf{x}_0^T\\mathbf{A}\\mathbf{x}_0  \\newline\n⇔(\\mathbf{x} - \\mathbf{x}_0)^T\\mathbf{A}(\\mathbf{x} - \\mathbf{x}_0) &\\geq& 0\n\\end{eqnarray}\n\\]\nBất đẳng thức cuối cùng là đúng dựa trên định nghĩa của một ma trận xác định dương. Vậy hàm số \\(f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{A}\\mathbf{x}\\) là hàm lồi.\nFirst-order condition ít được sử dụng để tìm tính chất lồi của một hàm số, thay vào đó, người ta thường dùng Second-order condition với các hàm có đạo hàm tới bậc hai.\n\nVới hàm nhiều biến, tức biến là một vector, giả sử có chiều là \\(d\\), đạo hàm bậc nhất của nó là một vector cũng có chiều là \\(d\\). Đạo hàm bậc hai của nó là một ma trận vuông có chiều là \\(d\\times d\\). Đạo hàm bậc hai của hàm số \\(f(\\mathbf{x})\\) được ký hiệu là \\(\\nabla^2 f(\\mathbf{x})\\). Đạo hàm bậc hai còn được gọi là Hessian.\nSecond-order condition: Một hàm số có đạo hàm bậc hai là convex nếu dom\\(f\\) là convex và Hessian của nó là một ma trận nửa xác định dương với mọi \\(\\mathbf{x}\\) trong tập xác định:\n\\[\n\\nabla^2 f(\\mathbf{x}) \\succeq 0.\n\\]\nNếu Hessian là một ma trận xác định dương thì hàm số đó strictly convex.\nTương tự, nếu Hessian là một ma trận xác định âm thì hàm số đó là strictly concave.\nVới hàm số một biến \\(f(x)\\), điều kiện này tương đương với \\(f”(x) \\geq 0\\) với mọi \\(x\\) thuộc tập xác định (và tập xác định là lồi).\nVí dụ:\nHàm negative entropy \\(f(x) = x\\log(x)\\) là stricly convex vì tập xác định là \\(x > 0\\) là một tập lồi và \\(f”(x) = 1/x\\) là một số dương với mọi \\(x\\) thuộc tập xác định.\nHàm \\(f(x) = x^2 + 5\\sin(x)\\) không là hàm lồi vì đạo hàm bậc hai \\(f”(x) = 2 - 5\\sin(x)\\) có thể nhận giá trị âm.\nHàm cross entropy là một hàm strictly convex. Xét ví dụ đơn giản với chỉ hai xác suất \\(x\\) và \\(1 - x\\) với \\(a\\) là một hằng số thuộc đoạn \\([0, 1]\\) và \\(0 < x < 1\\): \\(f(x) = -(a \\log(x) + (1 - a) \\log(1 - x))\\) có đạo hàm bậc hai là \\(\\frac{a}{x^2} + \\frac{1 - a}{(1-x)^2}\\) là một số dương.\nNếu \\(\\mathbf{A}\\) là một ma trận xác định dương thì \\(f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T\\mathbf{Ax}\\) là lồi vì Hessian của nó chính là \\(\\mathbf{A}\\) là một ma trận xác định dương.\nXét hàm số negative entropy với hai biến: \\(f(x, y) = x \\log(x) + y \\log(y)\n\\) trên tập các giá trị dương của \\(x\\) và \\(y\\). Hàm số này có đạo hàm bậc nhất là \\([\\log(x) + 1, \\log(y) + 1]^T\\) và Hessian là:\n\\[\n\\left[\n\\begin{matrix}\n1/x & 0 \\newline\n0 & 1/y\n\\end{matrix}\n\\right]\n\\]\nlà một ma trận đường chéo với các thành phần trên đường chéo là dương nên là một ma trận xác định dương. Vậy negative entropy là một hàm strictly convex.(Chú ý rằng một ma trận là xác định dương nếu các trị riêng của nó đều dương. Với một ma trận là ma trận đường chéo thì các trị riêng của nó chính là các thành phần trên đường chéo.)\nNgoài ra còn nhiều tính chất thú vị của các hàm lồi, các bạn được khuyến khích đọc thêm Chương 3 của cuốn Convex Optimization trong phần tài liệu tham khảo.\n\nMachine Learning và Optimization có quan hệ mật thiết với nhau. Trong Optimization, Convex Optimization là quan trọng nhất. Một bài toán là convex optimization nếu hàm mục tiêu là convex và tập hợp các điểm thỏa mãn các điều kiện ràng buộc là một convex set.\nTrong convex set, mọi đoạn thẳng nối hai điểm bất kỳ trong tập đó sẽ nằm hoàn toàn trong tập đó. Tập hợp các giao điểm của các convex sets là một convex set.\nMột hàm số là convex nếu đoạn thẳng nối hai điểm bất kỳ trên đồ thì hàm số đó không nằm dưới đồ thị đó.\nMột hàm số khả vi là convex nếu tập xác định của nó là convex và đường (mặt) tiếp tuyến không nằm phía trên đồ thị (bề mặt) của hàm số đó.\nCác norms là các hàm lồi, được sử dụng nhiều trong tối ưu.\n\n[1] Convex Optimization – Boyd and Vandenberghe, Cambridge University Press, 2004."
    },
    {
        "ID": 34,
        "URL": "https://machinelearningcoban.com/2017/03/04/overfitting/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\nOverfitting không phải là một thuật toán trong Machine Learning. Nó là một hiện tượng không mong muốn thường gặp, người xây dựng mô hình Machine Learning cần nắm được các kỹ thuật để tránh hiện tượng này.\n\n\nĐây là một câu chuyện của chính tôi khi lần đầu biết đến Machine Learning.\nNăm thứ ba đại học, một thầy giáo có giới thiệu với lớp tôi về Neural Networks. Lần đầu tiên nghe thấy khái niệm này, chúng tôi hỏi thầy mục đích của nó là gì. Thầy nói, về cơ bản, từ dữ liệu cho trước, chúng ta cần tìm một hàm số để biến các các điểm đầu vào thành các điểm đầu ra tương ứng, không cần chính xác, chỉ cần xấp xỉ thôi.\nLúc đó, vốn là một học sinh chuyên toán, làm việc nhiều với đa thức ngày cấp ba, tôi đã quá tự tin trả lời ngay rằng Đa thức Nội suy Lagrange có thể làm được điều đó, miễn là các điểm đầu vào khác nhau đôi một! Thầy nói rằng “những gì ta biết chỉ là nhỏ xíu so với những gì ta chưa biết”. Và đó là những gì tôi muốn bắt đầu trong bài viết này.\nNhắc lại một chút về Đa thức nội suy Lagrange: Với \\(N\\) cặp điểm dữ liệu \\((x_1, y_1), (x_2, y_2), \\dots, (x_N, y_N)\\) với các \\(x_i\\) kháu nhau đôi một, luôn tìm được một đa thức \\(P(.)\\) bậc không vượt quá \\(N-1\\) sao cho \\(P(x_i) = y_i, ~\\forall i = 1, 2, \\dots, N\\). Chẳng phải điều này giống với việc ta đi tìm một mô hình phù hợp (fit) với dữ liệu trong bài toán Supervised Learning hay sao? Thậm chí điều này còn tốt hơn vì trong Supervised Learning ta chỉ cần xấp xỉ thôi.\nSự thật là nếu một mô hình quá fit với dữ liệu thì nó sẽ gây phản tác dụng! Hiện tượng quá fit này trong Machine Learning được gọi là overfitting, là điều mà khi xây dựng mô hình, chúng ta luôn cần tránh. Để có cái nhìn đầu tiên về overfitting, chúng ta cùng xem Hình dưới đây. Có 50 điểm dữ liệu được tạo bằng một đa thức bậc ba cộng thêm nhiễu. Tập dữ liệu này được chia làm hai, 30 điểm dữ liệu màu đỏ cho training data, 20 điểm dữ liệu màu vàng cho test data. Đồ thị của đa thức bậc ba này được cho bởi đường màu xanh lục. Bài toán của chúng ta là giả sử ta không biết mô hình ban đầu mà chỉ biết các điểm dữ liệu, hãy tìm một mô hình “tốt” để mô tả dữ liệu đã cho.\nVới những gì chúng ta đã biết từ bài Linear Regression, với loại dữ liệu này, chúng ta có thể áp dụng Polynomial Regression. Bài toán này hoàn toàn có thể được giải quyết bằng Linear Regression với dữ liệu mở rộng cho một cặp điểm \\((x, y)\\) là \\((\\mathbf{x}, y)\\) với \\(\\mathbf{x} = [1, x, x^2, x^3, \\dots, x^d]^T\\) cho đa thức bậc \\(d\\). Điều quan trọng là chúng ta cần tìm bậc \\(d\\) của đa thức cần tìm.\nRõ ràng là một đa thức bậc không vượt quá 29 có thể fit được hoàn toàn với 30 điểm trong training data. Chúng ta cùng xét vài giá trị \\(d = 2, 4, 8, 16\\). Với \\(d = 2\\), mô hình không thực sự tốt vì mô hình dự đoán quá khác so với mô hình thực. Trong trường hợp này, ta nói mô hình bị underfitting. Với \\(d = 8\\), với các điểm dữ liệu trong khoảng của training data, mô hình dự đoán và mô hình thực là khá giống nhau. Tuy nhiên, về phía phải, đa thức bậc 8 cho kết quả hoàn toàn ngược với xu hướng của dữ liệu. Điều tương tự xảy ra trong trường hợp \\(d = 16\\). Đa thức bậc 16 này quá fit dữ liệu trong khoảng đang xét, và quá fit, tức không được mượt trong khoảng dữ liệu training. Việc quá fit trong trường hợp bậc 16 không tốt vì mô hình đang cố gắng mô tả nhiễu hơn là dữ liệu. Hai trường hợp đa thức bậc cao này được gọi là Overfitting.\nNếu bạn nào biết về Đa thức nội suy Lagrange thì có thể hiểu được hiện tượng sai số lớn với các điểm nằm ngoài khoảng của các điểm đã cho. Đó chính là lý do phương pháp đó có từ “nội suy”, với các trường hợp “ngoại suy”, kết quả thường không chính xác.\nVới \\(d = 4\\), ta được mô hình dự đoán khá giống với mô hình thực. Hệ số bậc cao nhất tìm được rất gần với 0 (xem kết quả trong source code), vì vậy đa thức bậc 4 này khá gần với đa thức bậc 3 ban đầu. Đây chính là một mô hình tốt.\nOverfitting là hiện tượng mô hình tìm được quá khớp với dữ liệu training. Việc quá khớp này có thể dẫn đến việc dự đoán nhầm nhiễu, và chất lượng mô hình không còn tốt trên dữ liệu test nữa. Dữ liệu test được giả sử là không được biết trước, và không được sử dụng để xây dựng các mô hình Machine Learning.\nVề cơ bản, overfitting xảy ra khi mô hình quá phức tạp để mô phỏng training data. Điều này đặc biệt xảy ra khi lượng dữ liệu training quá nhỏ trong khi độ phức tạp của mô hình quá cao. Trong ví dụ trên đây, độ phức tạp của mô hình có thể được coi là bậc của đa thức cần tìm. Trong Multi-layer Perceptron, độ phức tạp của mô hình có thể được coi là số lượng hidden layers và số lượng units trong các hidden layers.\nVậy, có những kỹ thuật nào giúp tránh Overfitting?\nTrước hết, chúng ta cần một vài đại lượng để đánh giá chất lượng của mô hình trên training data và test data. Dưới đây là hai đại lượng đơn giản, với giả sử \\(\\mathbf{y}\\) là đầu ra thực sự (có thể là vector), và \\(\\mathbf{\\hat{y}}\\) là đầu ra dự đoán bởi mô hình:\nTrain error: Thường là hàm mất mát áp dụng lên training data. Hàm mất mát này cần có một thừa số \\(\\frac{1}{N_{\\text{train}}} \\) để tính giá trị trung bình, tức mất mát trung bình trên mỗi điểm dữ liệu. Với Regression, đại lượng này thường được định nghĩa:\n\\[\n\\text{train error}= \\frac{1}{N_{\\text{train}}} \\sum_{\\text{training set}} \\|\\mathbf{y} - \\mathbf{\\hat{y}}\\|_p^2\n\\]\nvới \\(p\\) thường bằng 1 hoặc 2.\nVới Classification, trung bình cộng của cross entropy có thể được sử dụng.\nTest error: Tương tự như trên nhưng áp dụng mô hình tìm được vào test data. Chú ý rằng, khi xây dựng mô hình, ta không được sử dụng thông tin trong tập dữ liệu test. Dữ liệu test chỉ được dùng để đánh giá mô hình. Với Regression, đại lượng này thường được định nghĩa:\n\\[\n\\text{test error}= \\frac{1}{N_{\\text{test}}} \\sum_{\\text{test set}} \\|\\mathbf{y} - \\mathbf{\\hat{y}}\\|_p^2\n\\]\nvới \\(p\\) giống như \\(p\\) trong cách tính train error phía trên.\nViệc lấy trung bình là quan trọng vì lượng dữ liệu trong hai tập hợp training và test có thể chênh lệch rất nhiều.\nMột mô hình được coi là tốt (fit) nếu cả train error và test error đều thấp. Nếu train error thấp nhưng test error cao, ta nói mô hình bị overfitting. Nếu train error cao và test error cao, ta nói mô hình bị underfitting. Nếu train error cao nhưng test error thấp, tôi không biết tên của mô hình này, vì cực kỳ may mắn thì hiện tượng này mới xảy ra, hoặc có chỉ khi tập dữ liệu test quá nhỏ.\nChúng ta cùng đi vào phương pháp đầu tiên\n\n\n\n\nChúng ta vẫn quen với việc chia tập dữ liệu ra thành hai tập nhỏ: training data và test data. Và một điều tôi vẫn muốn nhắc lại là khi xây dựng mô hình, ta không được sử dụng test data. Vậy làm cách nào để biết được chất lượng của mô hình với unseen data (tức dữ liệu chưa nhìn thấy bao giờ)?\nPhương pháp đơn giản nhất là trích từ tập training data ra một tập con nhỏ và thực hiện việc đánh giá mô hình trên tập con nhỏ này. Tập con nhỏ được trích ra từ training set này được gọi là validation set. Lúc này, training set là phần còn lại của training set ban đầu. Train error được tính trên training set mới này, và có một khái niệm nữa được định nghĩa tương tự như trên validation error, tức error được tính trên tập validation.\nViệc này giống như khi bạn ôn thi. Giả sử bạn không biết đề thi như thế nào nhưng có 10 bộ đề thi từ các năm trước. Để xem trình độ của mình trước khi thi thế nào, có một cách là bỏ riêng một bộ đề ra, không ôn tập gì. Việc ôn tập sẽ được thực hiện dựa trên 9 bộ còn lại. Sau khi ôn tập xong, bạn bỏ bộ đề đã để riêng ra làm thử và kiểm tra kết quả, như thế mới “khách quan”, mới giống như thi thật. 10 bộ đề ở các năm trước là “toàn bộ” training set bạn có. Để tránh việc học lệch, học tủ theo chỉ 10 bộ, bạn tách 9 bộ ra làm training set thật, bộ còn lại là validation test. Khi làm như thế thì mới đánh giá được việc bạn học đã tốt thật hay chưa, hay chỉ là học tủ. Vì vậy, Overfitting còn có thể so sánh với việc Học tủ của con người.\nVới khái niệm mới này, ta tìm mô hình sao cho cả train error và validation error đều nhỏ, qua đó có thể dự đoán được rằng test error cũng nhỏ. Phương pháp thường được sử dụng là sử dụng nhiều mô hình khác nhau. Mô hình nào cho validation error nhỏ nhất sẽ là mô hình tốt.\nThông thường, ta bắt đầu từ mô hình đơn giản, sau đó tăng dần độ phức tạp của mô hình. Tới khi nào validation error có chiều hướng tăng lên thì chọn mô hình ngay trước đó. Chú ý rằng mô hình càng phức tạp, train error có xu hướng càng nhỏ đi.\nHình dưới đây mô tả ví dụ phía trên với bậc của đa thức tăng từ 1 đến 8. Tập validation bao gồm 10 điểm được lấy ra từ tập training ban đầu.\nChúng ta hãy tạm chỉ xét hai đường màu lam và đỏ, tương ứng với train error và validation error. Khi bậc của đa thức tăng lên, train error có xu hướng giảm. Điều này dễ hiểu vì đa thức bậc càng cao, dữ liệu càng được fit. Quan sát đường màu đỏ, khi bậc của đa thức là 3 hoặc 4 thì validation error thấp, sau đó tăng dần lên. Dựa vào validation error, ta có thể xác định được bậc cần chọn là 3 hoặc 4. Quan sát tiếp đường màu lục, tương ứng với test error, thật là trùng hợp, với bậc bằng 3 hoặc 4, test error cũng đạt giá trị nhỏ nhất, sau đó tăng dần lên. Vậy cách làm này ở đây đã tỏ ra hiệu quả.\nViệc không sử dụng test data khi lựa chọn mô hình ở trên nhưng vẫn có được kết quả khả quan vì ta giả sử rằng validation data và test data có chung một đặc điểm nào đó. Và khi cả hai đều là unseen data, error trên hai tập này sẽ tương đối giống nhau.\nNhắc lại rằng, khi bậc nhỏ (bằng 1 hoặc 2), cả ba error đều cao, ta nói mô hình bị underfitting.\n\n\nTrong nhiều trường hợp, chúng ta có rất hạn chế số lượng dữ liệu để xây dựng mô hình. Nếu lấy quá nhiều dữ liệu trong tập training ra làm dữ liệu validation, phần dữ liệu còn lại của tập training là không đủ để xây dựng mô hình. Lúc này, tập validation phải thật nhỏ để giữ được lượng dữ liệu cho training đủ lớn. Tuy nhiên, một vấn đề khác nảy sinh. Khi tập validation quá nhỏ, hiện tượng overfitting lại có thể xảy ra với tập training còn lại. Có giải pháp nào cho tình huống này không?\nCâu trả lời là cross-validation.\nCross validation là một cải tiến của validation với lượng dữ liệu trong tập validation là nhỏ nhưng chất lượng mô hình được đánh giá trên nhiều tập validation khác nhau. Một cách thường đường sử dụng là chia tập training ra \\(k\\) tập con không có phần tử chung, có kích thước gần bằng nhau. Tại mỗi lần kiểm thử , được gọi là run, một trong số \\(k\\) tập con được lấy ra làm validate set. Mô hình sẽ được xây dựng dựa vào hợp của \\(k-1\\) tập con còn lại. Mô hình cuối được xác định dựa trên trung bình của các train error và validation error. Cách làm này còn có tên gọi là k-fold cross validation.\nKhi \\(k\\) bằng với số lượng phần tử trong tập training ban đầu, tức mỗi tập con có đúng 1 phần tử, ta gọi kỹ thuật này là leave-one-out.\nSklearn hỗ trợ rất nhiều phương thức cho phân chia dữ liệu và tính toán scores của các mô hình. Bạn đọc có thể xem thêm tại Cross-validation: evaluating estimator performance.\n\n\nMột nhược điểm lớn của cross-validation là số lượng training runs tỉ lệ thuận với \\(k\\). Điều đáng nói là mô hình polynomial như trên chỉ có một tham số cần xác định là bậc của đa thức. Trong các bài toán Machine Learning, lượng tham số cần xác định thường lớn hơn nhiều, và khoảng giá trị của mỗi tham số cũng rộng hơn nhiều, chưa kể đến việc có những tham số có thể là số thực. Như vậy, việc chỉ xây dựng một mô hình thôi cũng là đã rất phức tạp rồi. Có một cách giúp số mô hình cần huấn luyện giảm đi nhiều, thậm chí chỉ một mô hình. Cách này có tên gọi chung là regularization.\nRegularization, một cách cơ bản, là thay đổi mô hình một chút để tránh overfitting trong khi vẫn giữ được tính tổng quát của nó (tính tổng quát là tính mô tả được nhiều dữ liệu, trong cả tập training và test). Một cách cụ thể hơn, ta sẽ tìm cách di chuyển nghiệm của bài toán tối ưu hàm mất mát tới một điểm gần nó. Hướng di chuyển sẽ là hướng làm cho mô hình ít phức tạp hơn mặc dù giá trị của hàm mất mát có tăng lên một chút.\nMột kỹ thuật rất đơn giản là early stopping.\n\n\nTrong nhiều bài toán Machine Learning, chúng ta cần sử dụng các thuật toán lặp để tìm ra nghiệm, ví dụ như Gradient Descent. Nhìn chung, hàm mất mát giảm dần khi số vòng lặp tăng lên. Early stopping tức dừng thuật toán trước khi hàm mất mát đạt giá trị quá nhỏ, giúp tránh overfitting.\nVậy dừng khi nào là phù hợp?\nMột kỹ thuật thường được sử dụng là tách từ training set ra một tập validation set như trên. Sau một (hoặc một số, ví dụ 50) vòng lặp, ta tính cả train error và validation error, đến khi validation error có chiều hướng tăng lên thì dừng lại, và quay lại sử dụng mô hình tương ứng với điểm và validation error đạt giá trị nhỏ.\nHình trên đây mô tả cách tìm điểm stopping. Chúng ta thấy rằng phương pháp này khá giống với phương pháp tìm bậc của đa thức ở phần trên của bài viết.\n\n\nKỹ thuật regularization phổ biến nhất là thêm vào hàm mất mát một số hạng nữa. Số hạng này thường dùng để đánh giá độ phức tạp của mô hình. Số hạng này càng lớn, thì mô hình càng phức tạp. Hàm mất mát mới này thường được gọi là regularized loss function, thường được định nghĩa như sau:\n\\[\nJ_{\\text{reg}}(\\theta) = J(\\theta) + \\lambda R(\\theta)\n\\]\nNhắc lại rằng \\(\\theta\\) được dùng để ký hiệu các biến trong mô hình, chẳng hạn như các hệ số \\(\\mathbf{w}\\) trong Neural Networks. \\(J(\\theta)\\) ký hiệu cho hàm mất mát (loss function) và \\(R(\\theta)\\) là số hạng regularization. \\(\\lambda\\) thường là một số dương để cân bằng giữa hai đại lượng ở vế phải.\nViệc tối thiểu regularized loss function, nói một cách tương đối, đồng nghĩa với việc tối thiểu cả loss function và số hạng regularization. Tôi dùng cụm “nói một cách tương đối” vì nghiệm của bài toán tối ưu loss function và regularized loss function là khác nhau.  Chúng ta vẫn mong muốn rằng sự khác nhau này là nhỏ, vì vậy tham số regularization (regularization parameter) \\(\\lambda\\) thường được chọn là một số nhỏ để biểu thức regularization không làm giảm quá nhiều chất lượng của nghiệm.\nVới các mô hình Neural Networks, một số kỹ thuật regularization thường được sử dụng là:\n\n\nTrong kỹ thuật này:\n\\[\nR(\\mathbf{w}) = \\|\\mathbf{w}\\|_2^2\n\\]\ntức norm 2 của hệ số.\nNếu bạn đọc chưa quen thuộc với khái niệm norm, bạn được khuyến khích đọc phần phụ lục này.\nHàm số này có một vài đặc điểm đang lưu ý:\n\\(l_2\\) regularization là kỹ thuật được sử dụng nhiều nhất để giúp Neural Networks tránh được overfitting. Nó còn có tên gọi khác là weight decay. Decay có nghĩa là tiêu biến.\nTrong Xác suất thống kê, Linear Regression với \\(l_2\\) regularization được gọi là Ridge Regression. Hàm mất mát của Ridge Regression có dạng:\n\\[\nJ(\\mathbf{w}) = \\frac{1}{2} \\|\\mathbf{y} - \\mathbf{Xw}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n\\]\ntrong đó, số hạng đầu tiên ở vế phải chính là hàm mất mát của Linear Regression. Số hạng thứ hai chính là phần regularization.\n\n\nChúng ta sử dụng mô hình MLP giống như bài trước nhưng dữ liệu có khác đi đôi chút.\nDữ liệu được tạo là ba cụm tuân theo phân phối chuẩn có tâm ở [[-1, -1], [1, -1], [0, 1]].\nTrong ví dụ này, chúng ta sử dụng số hạng regularization:\n\\[\n\\lambda R(\\mathbf{W}) = \\lambda \\sum_{l=1}^L \\|\\mathbf{W}^{(l)}\\|_F^2\n\\]\nvới \\(\\|.\\|_F\\) là Frobenius norm, là căn bậc hai của tổng bình phường các phẩn tử của ma trận.\n(Bạn đọc được khuyến khích đọc bài MLP để hiểu các ký hiệu).\nChú ý rằng weight decay ít khi được áp dụng lên biases. Tôi thay đổi tham số regularization \\(\\lambda\\) và nhận được kết quả như sau:\nKhi \\(\\lambda = 0\\), tức không có regularization, ta nhận thấy gần như toàn bộ dữ liệu trong tập training được phân lớp đúng. Việc này khiến cho các class bị phân làm nhiều mảnh không được tự nhiên. Khi \\(\\lambda = 0.001\\), vẫn là một số nhỏ, các đường phân chia trông tự nhiên hơn, nhưng lớp màu xanh lam vẫn bị chia làm hai bởi lớp màu xanh lục. Đây chính là biểu hiện của overfitting.\nKhi \\(\\lambda\\) tăng lên, tức sự ảnh hưởng của regularization tăng lên (xem hàng dưới), đường ranh giới giữa các lớp trở lên tự nhiên hơn. Nói cách khác, với \\(\\lambda\\) đủ lớn, weight decay có tác dụng hạn chế overfitting trong MLP.\nBạn đọc hãy thử vào trong Source code, thay \\(\\lambda = 1\\) bằng cách thay dòng cuối cùng:\nrồi chạy lại toàn bộ code, xem các đường phân lớp trông như thế nào. Gợi ý: underfitting.\nKhi \\(\\lambda\\) quá lớn, tức ta xem phần regularization quan trọng hơn phần loss fucntion, một hiện tượng xấu xảy ra là các phần tử của \\(\\mathbf{w}\\) tiến về 0 để thỏa mãn regularization là nhỏ.\nSklearn có cung cấp rất nhiều chức năng cho MLP, trong đó ta có thể lựa chọn số lượng hidden layers và số lượng hidden units trong mỗi layer, activation functions, weight decay, learning rate, hệ số momentum, nesterovs_momentum, có early stopping hay không, lượng dữ liệu được tách ra làm validation set, và nhiều chức năng khác.\n\n\n\\[\n\\lambda R(\\mathbf{w}) = \\|\\Gamma \\mathbf{w}\\|_2^2\n\\]\nVới \\(\\Gamma\\) (viết hoa của gamma) là một ma trận. Ma trận \\(\\Gamma\\) hay được dùng nhất là ma trận đường chéo. Nhận thấy rằng \\(l_2\\) regularization chính là một trường hợp đặc biệt của Tikhonov regularization với \\(\\Gamma = \\lambda \\mathbf{I}\\) với \\(\\mathbf{I}\\) là ma trận đơn vị (the identity matrix), tức các phần tử trên đường chéo của \\(\\Gamma\\) là như nhau.\nKhi các phần tử trên đường chéo của \\(\\Gamma\\) là khác nhau, ta có một phiên bản gọi là weighted \\(l_2\\) regularization, tức đánh trọng số khác nhau cho mỗi phần tử trong \\(\\mathbf{w}\\). Phần tử nào càng bị đánh trọng số cao thì nghiệm tương ứng càng nhỏ (để đảm bảo rằng hàm mất mát là nhỏ). Với Polynomial Regression, các phần tử ứng với hệ số bậc cao sẽ được đánh trọng số cao hơn, khiến cho xác suất để chúng gần 0 là lớn hơn.\n\n\nTrong nhiều trường hợp, ta muốn các hệ số thực sự bằng 0 chứ không phải là nhỏ gần 0 như \\(l_2\\) regularization đã làm phía trên. Lúc đó, có một regularization khác được sử dụng, đó là \\(l_0\\) regularization:\n\\[\nR(\\mathbf{W}) = \\|\\mathbf{w}\\|_0\n\\]\nNorm 0 không phải là một norm thực sự mà là giả norm. (Bạn được khuyến khích đọc thêm về norms (chuẩn)). Norm 0 của một vector là số các phần tử khác không của vector đó. Khi norm 0 nhỏ, tức rất nhiều phần tử trong vector đó bằng 0, ta nói vector đó là sparse.\nViệc giải bài toán tổi thiểu norm 0 nhìn chung là khó vì hàm số này không convex, không liên tục. Thay vào đó, norm 1 thường được sử dụng:\n\\[\nR(\\mathbf{W}) = \\|\\mathbf{w}\\|_1 = \\sum_{i=0}^d |w_i|\n\\]\nNorm 1 là tổng các trị tuyệt đối của tất cả các phần tử. Người ta đã chứng minh được rằng tối thiểu norm 1 sẽ dẫn tới nghiệm có nhiều phần tử bằng 0. Ngoài ra, vì norm 1 là một norm thực sự (proper norm) nên hàm số này là convex, và hiển nhiên là liên tục, việc giải bài toán này dễ hơn việc giải bài toán tổi thiểu norm 0. Về \\(l_1\\) regularization, bạn đọc có thể đọc thêm trong lecture note này. Việc giải bài toán \\(l_1\\) regularization nằm ngoài mục đích của tôi trong bài viết này. Tôi hứa sẽ quay lại phần này sau. (Vì đây là phần chính trong nghiên cứu của tôi).\nTrong Thống Kê, việc sử dụng \\(l_1\\) regularization còn được gọi là LASSO (Least Absolute Shrinkage and Selection Operator).\nKhi cả \\(l_2\\) và \\(l_1\\) regularization được sử dụng, ta có mô hình gọi là Elastic Net Regression.\n\n\nTrong sklearn, ví dụ Logistic Regression, bạn cũng có thể sử dụng các \\(l_1\\) và \\(l_2\\) regularizations bằng cách khai báo biến penalty='l1' hoặc penalty = 'l2' và biến C, trong đó C là nghịch đảo của \\(\\lambda\\). Trong các bài trước khi chưa nói về  Overfitting và Regularization, tôi có sử dụng C = 1e5 để chỉ ra rằng \\(\\lambda\\) là một số rất nhỏ.\n\n\nNgoài các phương pháp đã nêu ở trên, với mỗi mô hình, nhiều phương pháp tránh overfitting khác cũng được sử dụng. Điển hình là Dropout trong Deep Neural Networks mới được đề xuất gần đây. Một cách ngắn gọn, dropout là một phương pháp tắt ngẫu nhiên các units trong Networks. Tắt tức cho các unit giá trị bằng không và tính toán feedforward và backpropagation bình thường trong khi training. Việc này không những giúp lượng tính toán giảm đi mà còn làm giảm việc overffitng. Tôi xin được quay lại vấn đề này nếu có dịp nói  sâu về Deep Learning trong tương lai.\nBạn đọc có thể tìm đọc thêm với các từ khóa: pruning (tránh overfitting trong Decision Trees), VC dimension (đo độ phức tạp của mô hình, độ phức tạp càng lớn thì càng dễ bị overfitting).\n\n\nMột mô hình mô tốt là mộ mô hình có tính tổng quát, tức mô tả được dữ liệu cả trong lẫn ngoài tập training. Mô hình chỉ mô tả tốt dữ liệu trong tập training được gọi là overfitting.\nĐể tránh overfitting, có rất nhiều kỹ thuật được sử dụng, điển hình là cross-validation và regularization. Trong Neural Networks, weight decay và dropout thường được dùng.\n\n\n[1] Overfitting - Wikipedia\n[2] Cross-validation - Wikipedia\n[3] Pattern Recognition and Machine Learning\n[4] Krogh, Anders, and John A. Hertz. “A simple weight decay can improve generalization.” NIPS. Vol. 4. 1991.\n[5] Srivastava, Nitish, et al. “Dropout: A Simple Way to Prevent Neural Networks from  Overfitting” Journal of Machine Learning Research 15.1 (2014): 1929-1958."
    },
    {
        "ID": 35,
        "URL": "https://machinelearningcoban.com/2017/02/24/mlp/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\nVì bài này sử dụng khá nhiều công thức toán, bạn đọc được khuyến khích đọc Lưu ý về ký hiệu toán học.\n\nBài toán Supervised Learning, nói một cách ngắn gọn, là việc đi tìm một hàm số để với mỗi input, ta sử dụng hàm số đó để dự đoán output. Hàm số này được xây dựng dựa trên các cặp dữ liệu \\((\\mathbf{x}\n_i, \\mathbf{y}_i)\\) trong training set. Nếu đầu ra dự đoán (predicted output) gần với đầu ra thực sự (ground truth) thì đó được gọi là một thuật toán tốt (nhưng khi đầu ra dự đoán quá giống với đầu ra thực sự thì không hẳn đã tốt, tôi sẽ đề cập kỹ về hiện tượng trong bài tiếp theo).\n\nChúng ta cùng xét khả năng biểu diễn (representation) của Perceptron Learning Algorithm (PLA) cho các bài toán binary vô cùng đơn giản: biểu diễn các hàm số logic NOT, AND, OR, và XOR (output bằng 1 nếu và chỉ nếu hai input khác nhau). Để có thể sử dụng PLA (output là 1 hoặc -1), chúng ta sẽ thay các giá trị bằng 0 của output của các hàm này bởi -1. Trong hàng trên của Hình 1 dưới đây, các điểm hình vuông màu xanh là các điểm có label bằng 1, các điểm hình tròn màu đỏ là các điểm có label bằng -1. Hàng dưới của Hình 1 là các mô hình perceptron với các hệ số tương ứng.\nNhận thấy rằng với các bài toán OR, AND, và OR, dữ liệu là linearly separable, vì vậy ta có thể tìm được các hệ số cho perceptron giúp biểu diễn chính xác mỗi hàm số. Xem ví dụ với hàm NOT, khi \\(x_1 = 0\\), ta có \\(a = \\text{sgn}(-2 \\times 0+1) = 1\\). Khi \\(x_1 = 1\\), \\(a = \\text{sgn}(-2\\times 1 + 1) = -1\\). Trong cả hai trường hợp, predicted output đều giống với ground truth. Bạn đọc có thể tự kiểm chứng các hệ số trong hình với hàm AND và OR.\n\nVới hàm XOR, vì dữ liệu không linearly separable, tức không thể tìm được 1 đường thằng giúp phân chia hai lớp xanh đỏ, nên bài toán vô nghiệm. Nếu thay PLA bằng Logistic Regression, tức thay hàm activation function từ sgn sang sigmoid, ta cũng không tìm được các hệ số thỏa mãn, vì về bản chất, Logistic Regression cũng chỉ tạo ra các đường biên có dạng tuyến tính. Như vậy là các mô hình Neural Network chúng ta đã biết không thể biểu diễn được hàm số logic đơn giản này.\nNhận thấy rằng nếu cho phép sử dụng hai đường thẳng, bài toán biểu diễn hàm XOR sẽ được giải quyết như Hình 2 (trái) dưới đây:\nCác hệ số tương ứng với hai đường thẳng trong Hình 2 (trái) được minh họa trên Hình 2 (phải) tại các node màu xanh (có hai loại màu xanh). Đầu ra \\(a_1^{(1)}\\) bằng 1 với các điểm nằm về phía (+) của đường thẳng \\(-2x_1 -2x_2 +3 = 0\\), bằng -1 với các điểm nằm về phía (-) của đường thẳng này. Tương tự, đầu ra \\(a_2^{(1)}\\) bằng 1 với các điểm nằm về phía (+) của đường thẳng \\(2x_1 + 2x_2 - 1 = 0\\). Như vậy, hai đường thằng này tạo ra hai đầu ra tại các node \\(a_1^{(1)}, a_2^{(1)}\\). Vì hàm XOR chỉ có một đầu ra nên ta cần làm thêm một bước nữa: coi \\(a_1, a_2\\) như là input của một PLA khác. Trong PLA mới này, input là các node màu lam (đừng quên node bias có giá trị bằng 1), output là các node màu đỏ. Các hệ số được cho trên Hình 2 (phải). Kiểm tra lại một chút, với các điểm hình vuông xanh (hình trái), \\(a^{(1)}_1 = a^{(1)}_2 = 1\\), khi đó \\(a^{(2)} = \\text{sgn}(1 + 1 - 1) = 1\\). Với các điểm hình tròn đỏ, \\(a^{(1)}_1 = -a^{(1)}_2\\), vậy nên \\(a^{(2)} = \\text{sgn}(a^{(1)}_1 + a^{(1)}_2 - 1) = \\text{sgn}(-1) = -1\\). Trong cả hai trường hợp, predicted ouput đều giống với ground truth. Vậy, nếu ta sử dụng 3 PLA tương ứng với các output \\(a^{(1)}_1, a^{(1)}_2, a^{(2)}\\), ta sẽ biểu diễn được hàm XOR.\nBa PLA kể trên được xếp vào hai layers. Layer thứ nhất: input - lục, output - lam. Layer thứ hai: input - lam, output - đỏ. Ở đây, output của layer thứ nhất chính là input của layer thứ hai. Tổng hợp lại ta được một mô hình mà ngoài layer input (lục) và output (đỏ), ta còn có một layer nữa (lam). Mô hình này có tên gọi là Multi-layer Perceptron (MLP). Layer trung gian ở giữa còn được gọi là hidden layer.\nMột vài lưu ý:\nPerceptron Learing Algorithm là một trường hợp của single-layer neural network với activation fucntion là hàm sgn. Trong khi đó, Perceptron là tên chung để chỉ các Neural Network với chỉ một input layer và một output tại output layer, không có hidden layer.\nCác activation function có thể là các nonlinear function khác, ví dụ như sigmoid function hoặc tanh function. Các activation function phải là nonlinear (phi tuyến), vì nếu không, nhiều layer hay một layer cũng là như nhau. Ví dụ với hai layer trong Hình 2, nếu activation function là một hàm linear (giả sử hàm \\(f(s) = s\\)), thì cả hai layer có thể được thay bằng một layer với ma trận hệ số \\(\\mathbf{W} = \\mathbf{W}^{(1)}\\mathbf{W}^{(2)}\\) (tạm bỏ qua biases).\nĐể cho đơn giản, tôi đã sử dụng ký hiệu \\(\\mathbf{W}^{(l)T}\\) để thay cho \\((\\mathbf{W}^{(l)})^T\\) (ma trận chuyển vị). Trong Hình 2 (phải), tôi sử dụng ký hiệu ma trận \\(\\mathbf{W}^{(2)}\\), mặc dù đúng ra nó phải là vector, để biểu diễn tổng quát cho trường hợp output layer có thể có nhiều hơn 1 node. Tương tự với bias \\(\\mathbf{b}^{(2)}\\).\nKhác với các bài trước về Neural Networks, khi làm việc với MLP, ta nên tách riêng phần biases và ma trận hệ số ra. Điều này đồng nghĩa với việc vector input \\(\\mathbf{x}\\) là vector KHÔNG mở rộng.\n\n\nNgoài Input layers và Output layers, một Multi-layer Perceptron (MLP) có thể có nhiều Hidden layers ở giữa. Các Hidden layers theo thứ tự từ input layer đến output layer được đánh số thứ thự là Hidden layer 1, Hidden layer 2, … Hình 3 dưới đây là một ví dụ với 2 Hidden layers.\nSố lượng layer trong một MLP được tính bằng số hidden layers cộng với 1. Tức là khi đếm số layers của một MLP, ta không tính input layers. Số lượng layer trong một MLP thường được ký hiệu là \\(L\\). Trong Hình 3 trên đây, \\(L = 3\\).\n\nMột node hình tròn trong một layer được gọi là một unit. Unit ở các input layer, hidden layers, và output layer được lần lượt gọi là input unit, hidden unit, và output unit. Đầu vào của các hidden layer được ký hiệu bởi \\(z\\), đầu ra của mỗi unit thường được ký hiệu là \\(a\\) (thể hiện activation, tức giá trị của mỗi unit sau khi ta áp dụng activation function lên \\(z\\)). Đầu ra của unit thứ \\(i\\) trong layer thứ \\(l\\) được ký hiệu là \\(a_i^{(l)}\\). Giả sử thêm rằng số unit trong layer thứ \\(l)\\) (không tính bias) là \\(d^{(l)}\\). Vector biểu diễn output của layer thứ \\(l\\) được ký hiệu là \\(\\mathbf{a}^{(l)} \\in \\mathbb{R}^{d^{(l)}}\\).\nKhi làm việc với những Neural Networks phức tạp, cách tốt nhất để hạn chế lỗi là viết cụ thể chiều của mỗi ma trận hay vector ra, bạn sẽ thấy rõ hơn trong phần sau.\n\nCó \\(L\\) ma trận trọng số cho một MLP có \\(L\\) layers. Các ma trận này được ký hiệu là \\(\\mathbf{W}^{(l)} \\in \\mathbb{R}^{d^{(l-1)}\\times d^{(l)}}, l = 1, 2, \\dots, L\\) trong đó \\(\\mathbf{W}^{(l)}\\) thể hiện các kết nối từ layer thứ \\(l-1\\) tới layer thứ \\(l\\) (nếu ta coi input layer là layer thứ \\(0\\)). Cụ thể hơn, phần tử \\(w^{(l)}_{ij}\\) thể hiện kết nối từ node thứ \\(i\\) của layer thứ \\((l-1)\\) tới node từ \\(j\\) của layer thứ \\((l)\\). Các biases của layer thứ \\((l)\\) được ký hiệu là \\(\\mathbf{b}^{(l)} \\in \\mathbb{R}^{d^{(l)}}\\). Các trọng số này được ký hiệu như trên Hình 4. Khi tối ưu một MLP cho một công việc nào đó, chúng ta cần đi tìm các weghts và biases này.\nTập hợp các weights và biases lần lượt được ký hiệu là \\(\\mathbf{W}\\) và \\(\\mathbf{b}\\).\n\n(Phần này chú yếu được dịch lại từ: http://cs231n.github.io/neural-networks-1/ )\nMỗi output của một unit (trừ các input units) được tính dựa vào công thức:\n\\[\na_i^{(l)} = f(\\mathbf{w}_i^{(l)T}\\mathbf{a}^{(l-1)} + b_i^{(l)})\n\\]\nTrong đó \\(f(.)\\) là một (nonlinear) activation function. Ở dạng vector, biểu thức bên trên được viết là:\n\\[\n\\mathbf{a}^{(l)} = f(\\mathbf{W}^{(l)T}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)})\n\\]\nKhi activation function \\(f(.)\\) được áp dụng cho một ma trận (hoặc vector), ta hiểu rằng nó được áp dụng cho từng thành phần của ma trận đó. Sau đó các thành phần này được sắp xếp lại đúng theo thứ tự để được một ma trận có kích thước bằng với ma trận input. Trong tiếng Anh, việc áp dụng lên từng phần tử như thế này được gọi là element-wise.\n\nHàm sgn (còn gọi là hard-threshold) chỉ được sử dụng trong PLA, mang mục đích giáo dục nhiều hơn. Trong thực tế, hàm sgn không được sử dụng vì hai lý do: đầu ra là discrete, và đạo hàm tại hầu hết các điểm bằng 0 (trừ điểm 0 không có đạo hàm). Việc đạo hàm bằng 0 này khiến cho các thuật toán gradient-based (ví dụ như Gradient Descent) không hoạt động!\n\nHàm sigmoid có dạng \\(f(s) = 1/(1 + \\exp(-s))\\) với đồ thị như trong Hình 5 (trái). Nếu đầu vào lớn, hàm số sẽ cho đầu ra gần với 1. Với đầu vào nhỏ (rất âm), hàm số sẽ cho đầu ra gần với 0. Hàm số này được sử dụng nhiều trong quá khứ ví có đạo hàm rất đẹp. Những năm gần đây, hàm số này ít khi được sử dụng. Nó có một nhược điểm cơ bản:\nHàm tanh cũng có nhược điểm tương tự về việc gradient rất nhỏ với các đầu vào có trị tuyệt đối lớn.\n\nReLU (Rectified Linear Unit) được sử dụng rộng rãi gần đây vì tính đơn giản của nó. Đồ thị của hàm ReLU được minh họa trên Hình 5 (trái)). Nó có công thức toán học \\(f(s) = \\max(0, s)\\) - rất đơn giản. Ưu điểm chính của nó là:\nReLU được chứng minh giúp cho việc training các Deep Networks nhanh hơn rất nhiều (theo Krizhevsky et al.). Hình 5 (phải) so sánh sự hội tụ của SGD khi sử dụng hai activation function khác nhau: ReLU và tanh. Sự tăng tốc này được cho là vì ReLU được tính toán gần như tức thời và gradient của nó cũng được tính cực nhanh với gradient bằng 1 nếu đầu vào lớn hơn 0, bằng 0 nếu đầu vào nhỏ hơn 0.\nMặc dù hàm ReLU không có đạo hàm tại \\(s = 0\\), trong thực nghiệm, người ta vẫn thường định nghĩa \\(\\text{ReLU}’(0) = 0\\) và khẳng định thêm rằng, xác suất để input của một unit bằng 0 là rất nhỏ.\nHàm ReLU có nhiều biến thể khác như Noisy ReLU, Leaky ReLu, ELUs. Tôi xin phép dừng phần này ở đây vì chưa có ý định đi sâu vào Deep Neural Networks.\n\nOutput layer nhiều khi không có activation function mà sử dụng trực tiếp giá trị đầu vào \\(z_i^{(l)}\\) của mỗi unit. Hoặc nói một cách khác, activation function chính là hàm identity, tức đầu ra bằng đầu vào. Với các bài toán classification, output layer thường là một Softmax Regression layer giúp tính xác suất để một điểm dữ liệu rơi vào mỗi class.\nMặc dù activation function cho mỗi unit có thể khác nhau, trong cùng một network, activation như nhau thường được sử dụng. Điều này giúp cho việc tính toán được đơn giản hơn.\n\nPhần này khá nặng về Đại Số Tuyến Tính, bạn đọc không muốn hiểu backpropagation có thể bỏ qua để đọc tiếp phần Ví dụ với Python.\nPhương pháp phổ biến nhất để tối ưu MLP vẫn là Gradient Descent (GD). Để áp dụng GD, chúng ta cần tính được gradient của hàm mất mát theo từng ma trận trọng số \\(\\mathbf{W}^{(l)}\\) và vector bias \\(\\mathbf{b}^{(l)}\\). Trước hết, chúng ta cần tính predicted output \\( \\mathbf{\\hat{y}}\\)  với một input \\(\\mathbf{x}\\):\n\\[\n\\begin{eqnarray}\n\\mathbf{a}^{(0)} &=& \\mathbf{x} \\newline\nz_{i}^{(l)} &=& \\mathbf{w}_i^{(l)T}\\mathbf{a}^{(l-1)} + b_i^{(l)} \\newline\n\\mathbf{z}^{(l)}  &=& \\mathbf{W}^{(l)T}\\mathbf{a}^{(l-1)} + \\mathbf{b}^{(l)},~~ l =  1, 2, \\dots, L \\newline\n\\mathbf{a}^{(l)} &=& f(\\mathbf{z}^{(l)}), ~~ l =  1, 2, \\dots, L \\newline\n\\mathbf{\\hat{y}} &=& \\mathbf{a}^{(L)}\n\\end{eqnarray}\n\\]\nBước này được gói là feedforward vì cách tính toán được thực hiện từ đầu đến cuối của network. MLP cũng được gọi\nGiả sử \\(J(\\mathbf{W, b, X, Y})\\) là một hàm mất mát của bài toán, trong đó \\(\\mathbf{W, b}\\) là tập hợp tất cả các ma trận trọng số giữa các layers và biases của mỗi layer. \\(\\mathbf{X, Y}\\) là cặp dữ liệu huấn luyện với mỗi cột tương ứng với một điểm dữ liệu. Để có thể áp dụng các gradient-based methods (mà Gradient Descent là một ví dụ), chúng ta cần tính được:\n\\[\n\\frac{\\partial J}{\\partial \\mathbf{W}^{(l)}} ; \\frac{\\partial J}{\\partial \\mathbf{b}^{(l)}},~~ l = 1, 2, \\dots, L\n\\]\nMột ví dụ của hàm mất mát là hàm Mean Square Error (MSE) tức trung bình của bình phương lỗi.\n\\[\n\\begin{eqnarray}\nJ(\\mathbf{W, b, X, Y}) &=& \\frac{1}{N}\\sum_{n=1}^N || \\mathbf{y}_n - \\mathbf{\\hat{y}}_n||_2^2 \\newline\n&=&\\frac{1}{N}\\sum_{n=1}^N || \\mathbf{y}_n - \\mathbf{a}_n^{(L)}||_2^2\n\\end{eqnarray}\n\\]\nVới \\(N\\) là số cặp dữ liệu \\((\\mathbf{x}, \\mathbf{y})\\) trong tập training.\nTheo những công thức ở trên, việc tính toán trực tiếp giá trị này là cực kỳ phức tạp vì hàm mất mát không phụ thuộc trực tiếp vào các hệ số. Phương pháp phổ biến nhất được dùng có tên là Backpropagation giúp tính gradient ngược từ layer cuối cùng đến layer đầu tiên. Layer cuối cùng được tính toán trước vì nó gần gũi hơn với predicted outputs và hàm mất mát. Việc tính toán gradient của các layer trước được thực hiện dựa trên một quy tắc quen thuộc có tên là chain rule, tức đạo hàm của hàm hợp.\nStochastic Gradient Descent có thể được sử dụng để tính gradient cho các ma trận trọng số và biases dựa trên một cặp điểm training \\(\\mathbf{x, y}\\). Để cho đơn giản, ta coi \\(J\\) là hàm mất mát nếu chỉ xét cặp điểm này, ở đây \\(J\\) là hàm mất mát bất kỳ, không chỉ hàm MSE như ở trên.\nĐạo hàm của hàm mất mát theo chỉ một thành phần của ma trận trọng số của lớp cuối cùng:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial J}{\\partial w_{ij}^{(L)}} &=& \\frac{\\partial J}{\\partial z_j^{(L)}}. \\frac{\\partial z_j^{(L)}}{\\partial w_{ij}^{(L)}} \\newline\n&=& e_j^{(L)} a_i^{(L-1)}\n\\end{eqnarray}\n\\]\nTrong đó \\(e_j^{(L)} = \\frac{\\partial J}{\\partial z_j^{(L)}} \\) thường là một đại lượng dễ tính toán và \\(\\frac{\\partial z_j^{(L)}}{\\partial w_{ij}^{(L)}}  = a_i^{(L-1)}\\) vì \\(z_j^{(L)} = \\mathbf{w}_j^{(L)T}\\mathbf{a}^{(L-1)} + b_j^{(L)}\\).\nTương tự như thế, đạo hàm của hàm mất mát theo bias của layer cuối cùng là:\n\\[\n\\frac{\\partial J}{\\partial b_{j}^{(L)}} = \\frac{\\partial J}{\\partial z_j^{(L)}}. \\frac{\\partial z_j^{(L)}}{\\partial b_{j}^{(L)}} = e_j^{(L)}\n\\]\nVới đạo hàm theo hệ số ở các lớp \\(l\\) thấp hơn, chúng ta hay xem hình dưới đây. Ở đây, tại mỗi unit, tôi đã viết riêng đầu vào \\(z\\) và đầu ra \\(a\\) để các bạn tiện theo dõi.\nDựa vào hính trên, ta có thể tính được:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial J}{\\partial w_{ij}^{(l)}} &=& \\frac{\\partial J}{\\partial z_j^{(l)}}. \\frac{\\partial z_j^{(l)}}{\\partial w_{ij}^{(l)}} \\newline\n&=& e_j^{(l)} a_i^{(l-1)}\n\\end{eqnarray}\n\\]\nvới:\n\\[\n\\begin{eqnarray}\ne_j^{(l)} &=& \\frac{\\partial J}{\\partial z_j^{(l)}} = \\frac{\\partial J}{\\partial a_j^{(l)}} . \\frac{\\partial a_j^{(l)}}{\\partial z_j^{(l)}} \\newline\n&=& \\left( \\sum_{k = 1}^{d^{(l+1)}} \\frac{\\partial J}{\\partial z_k^{(l+1)}} .\\frac{\\partial z_k^{(l+1)}}{\\partial a_j^{(l)}} \\right) f’(z_j^{(l)}) \\newline\n &=&\\left( \\sum_{k = 1}^{d^{(l+1)}} e_k^{(l+1)} w_{jk}^{(l+1)} \\right) f’(z_j^{(l)}) \\newline\n &=&\\left( \\mathbf{w}_{j:}^{(l+1)} \\mathbf{e}^{(l+1)} \\right) f’(z_j^{(l)}) \\newline\n\\end{eqnarray}\n\\]\ntrong đó \\(\\mathbf{e}^{(l+1)} = [e_1^{(l+1)}, e_2^{(l+1)}, …, e_{d^{(l+1)}}^{(l+1)}]^T \\in \\mathbb{R}^{d^{(l+1)}\\times 1} \\) và \\(\\mathbf{w}_{j:}^{(l+1)}\\) được hiểu là hàng thứ \\(j\\) của ma trận \\(\\mathbf{W}^{(l+1)}\\) (Chú ý dấu hai chấm, khi không có dấu này, tôi mặc định ký hiệu nó cho vector cột).\nDấu sigma tính tổng ở hàng thứ hai trong phép tính trên xuất hiện vì \\(a_{j}^{(l)}\\) đóng góp vào việc tính tất cả các \\(z_k^{(l+1)}, k = 1, 2, \\dots, d^{(l+1)}\\). Biểu thức đạo hàm ngoài dấu ngoặc lớn là vì \\(a_j^{(l)}  = f(z_j^{(l)})\\). Tới đây, ta có thể thấy rằng việc activation function có đạo hàm đơn giản sẽ có ích rất nhiều trong việc tính toán.\nVới cách làm tương tự, bạn đọc có thể suy ra:\n\\[\n\\frac{\\partial J}{\\partial b_j^{(l)}} = e_j^{(l)}\n\\]\nNhận thấy rằng trong các công thức trên đây, việc tính các \\(e_j^{(l)}\\) đóng một vài trò quan trọng. Hơn nữa, để tính được giá trị này, ta cần tính được các \\(e_j^{(l+1)}\\). Nói cách khác, ta cần tính ngược các giá trị này từ cuối. Cái tên backpropagation cũng xuất phát từ việc này.\nViệc tính toán các đạo hàm khi sử dụng SGD có thể tóm tắt như sau:\n\n\n\nViệc tính toán theo từng hệ số như trên chỉ phù hợp cho việc hiểu nguyên lý tính toán, trong khi lập trình, ta cần tìm cách thu gọn chúng về dạng vector và ma trận để tăng tốc độ cho thuật toán. Đặt \\(\\mathbf{e}^{(l)} = [e_1^{(l)}, e_2^{(l)}, …, e_{d^{(l)}}^{(l)}]^T \\in \\mathbb{R}^{d^{(l)}\\times 1} \\). Ta sẽ có quy tắc tính như sau:\nChú ý: Biểu thức tính đạo hàm trong dòng trên của bước 3 có thể khiến bạn đặt câu hỏi: tại sao lại là \\(\\mathbf{a}^{(L-1)}\\mathbf{e}^{(L)T}\\) mà không phải là \\(\\mathbf{a}^{(L-1)T}\\mathbf{e}^{(L)}\\), \\(\\mathbf{e}^{(L)T}\\mathbf{a}^{(L-1)}\\), hay \\(\\mathbf{e}^{(L)}\\mathbf{a}^{(L-1)T}\\)? Quy tắc bỏ túi cần nhớ là chiều của hai ma trận ở hai vế phải như nhau. Thử một chút, vế trái là đạo hàm theo \\(\\mathbf{W}^{(L)}\\) là một đại lượng có chiều (dimension, not afternoon) bằng chiều của ma trận này, tức chiều là \\(\\mathbb{R}^{d^{(L-1)}\\times d^{(L)}}\\). Vế phải, \\(\\mathbf{e}^{(L)} \\in \\mathbf{R}^{d^{(L)} \\times 1}\\), \\(\\mathbf{a}^{(L-1)} \\in \\mathbb{R}^{d^{(L-1)} \\times 1}\\). Để hai vế có chiều bằng nhau thì ta phải lấy \\(\\mathbf{a}^{(L-1)} \\mathbf{e}^{(L)T}\\). Cũng chú ý thêm rằng đạo hàm theo một ma trận của một hàm số nhận giá trị thực (scalar) sẽ có chiều bằng với chiều của ma trận đó!!\n\nNếu chúng ta muốn thực hiện Batch hoặc mini-batch Gradient Descent thì sao? Trong thực tế, mini-batch GD được sử dụng nhiều nhất. Nếu lượng dữ liệu là nhỏ, Batch GD trực tiếp được sử dụng.\nKhi đó, cặp (input, output) sẽ ở dạng ma trận \\((\\mathbf{X, Y})\\). Giả sử rằng mỗi lần tính toán, ta lấy \\(N\\) dữ liệu để tính toán. Khi đó, \\(\\mathbf{X} \\in \\mathbb{R}^{d^{(0)} \\times N}, \\mathbf{Y} \\in \\mathbb{R}^{d^{(L)}\\times N}\\). Với \\(d^{(0)} = d\\) là chiều của dữ liệu đầu vào (không tính bias).\nKhi đó các activation sau mỗi layer sẽ có dạng \\(\\mathbf{A}^{(l)} \\in \\mathbb{R}^{d^{(l)} \\times N}\\). Tương tự thế, \\(\\mathbf{E}^{(l)} \\in \\mathbb{R}^{d^{(l)}\\times N}\\). Và ta cũng có thể suy ra công thức cập nhật như sau.\nMặc dù khi làm thực nghiệm, các công cụ có hỗ trợ việc tự động tính Backpropagation, tôi vẫn không muốn bỏ qua phần này. Hiểu backpropagation rất quan trọng! Xem thêm Yes you should understand backprop.\n\nSource code cho ví dụ này có thể được xem tại đây.\nVí dụ tôi nêu trong mục này mang mục đích giúp các bạn hiểu thực sự cách lập trình cho backpropagation. Khi làm thực nghiệm, chúng ta sử dụng các thư viện sẵn có giúp tính backpropagation. Ví dụ như Sklearn cho MLP.\nĐể kiểm chứng lại những gì tôi viết trên đây có đúng không, chúng ta cùng xem một ví dụ. Ý tưởng trong ví dụ này được lấy từ CS231n Convolutional Neural Networks for Visual Recognition, phần code dưới đây tôi viết lại cho phù hợp với những tính toán và ký hiệu phía trên.\n\nTrước hết, ta tạo dữ liệu cho 3 classes mà không có hai class nào là linearly separable:\nVới dữ liệu được phân bố thế này, Softmax Regression không thể thực hiện được vì Bounray giữa các class tạo bởi Softmax Regression có dạng linear. Chúng ta hãy làm một thí nghiệm nhỏ bằng cách thêm một Hidden layer vào giữa Input layer vả output layer của Softmax Regression. Activation function của Hidden layer là hàm ReLU: \\(f(s) = \\max(s, 0)\\), \\(f’(s) = 0 ~~\\text{if}~ s \\leq 0\\), \\(f’(s) = 1 ~\\text{otherwise}\\).\nBây giờ chúng ta sẽ áp dụng Batch Gradient Descent cho bài toán này (vì lượng dữ liệu là nhỏ). Trước hết cần thực tìm công thức tính các activation và output.\n\n\\[\n\\begin{eqnarray}\n\\mathbf{Z}^{(1)} &=& \\mathbf{W}^{(1)T}\\mathbf{X} \\newline\n\\mathbf{A}^{(1)} &=& \\max(\\mathbf{Z}^{(1)}, \\mathbf{0}) \\newline\n\\mathbf{Z}^{(2)} &=& \\mathbf{W}^{(2)T}\\mathbf{A}^{(1)} \\newline\n\\mathbf{\\hat{Y}} = \\mathbf{A}^{(2)} &=& \\text{softmax}(\\mathbf{Z}^{(2)})\n\\end{eqnarray}\n\\]\nHàm mất mát được tính như sau:\n\\[\nJ \\triangleq J(\\mathbf{W, b}; \\mathbf{X, Y}) = -\\frac{1}{N}\\sum_{i = 1}^N \\sum_{j = 1}^C y_{ji}\\log(\\hat{y}_{ji})\n\\]\nỞ đây, tôi đã cho thêm thừa số \\(\\frac{1}{N}\\) để tránh hiện tượng tổng quá lớn với Batch GD. Về mặt toán học, thừa số này không làm thay đổi nghiệm của bài toán.\n\nÁp dụng quy tắc như đã trình bày ở trên và\n và đạo hàm theo ma trận trọng số của Softmax Regression, ta có:\n\\[\n\\begin{eqnarray}\n\\mathbf{E}^{(2)} &=& \\frac{\\partial J}{\\partial \\mathbf{Z}^{(2)}} =\\frac{1}{N}(\\mathbf{\\hat{Y}} - \\mathbf{Y}) \\newline\n\\frac{\\partial J}{\\partial \\mathbf{W}^{(2)}} &=& \\mathbf{A}^{(1)}  \\mathbf{E}^{(2)T} \\newline\n\\frac{\\partial J}{\\partial \\mathbf{b}^{(2)}} &=& \\sum_{n=1}^N\\mathbf{e}_n^{(2)} \\newline\n\\mathbf{E}^{(1)} &=& \\left(\\mathbf{W}^{(2)}\\mathbf{E}^{(2)}\\right) \\odot f’(\\mathbf{Z}^{(1)}) \\newline\n\\frac{\\partial J}{\\partial \\mathbf{W}^{(1)}} &=& \\mathbf{A}^{(0)}  \\mathbf{E}^{(1)T} = \\mathbf{X}\\mathbf{E}^{(1)T}\\newline\n\\frac{\\partial J}{\\partial \\mathbf{b}^{(1)}} &=& \\sum_{n=1}^N\\mathbf{e}_n^{(1)} \\newline\n\\end{eqnarray}\n\\]\nTừ đó ta có thể bắt đầu lập trình như sau:\n\n\n\nNhư vậy hàm mất mát giảm dần khi số vòng lặp tăng lên. Bây giờ chúng ta cùng áp dụng ngược network này vào phân loại dữ liệu training:\nVậy là trong 300 điểm, chỉ có 2 điểm bị phân loại sai! Dưới đây là hình minh hoạ khu vực của mỗi class:\nHai điểm bị phân lớp sai có lẽ nằm gần khu vực trung tâm.\nVậy là chỉ thêm 1 hidden layer, Neural Network đã có thể xây dựng được boundary phi tuyến. Kết luận đầu tiên ở đây là khả năng biểu diễn của MLP tốt hơn rất nhiều so với 1-layer Neural Network.\nKết quả bên trên được thực hiện khi số lượng units trong hidden layer là d1 = 100. Chúng ta thử thay đổi giá trị này bởi d1 = 5, 10, 15, 20 xem kết quả khác nhau như thế nào. Dưới đây là hình mình họa:\nCó một vài nhận xét như sau:\nKhi số lượng hidden units tăng lên, độ chính xác của mô hình tạo được cũng tăng lên.\nVới d1 = 5, đường phân định giữa ba classes gần như là đường thẳng.\nVới d1 = 15, mặc dù kết quả đã đạt 99.33%, vẫn có một vùng đỏ nhỏ nằm giữa nhánh màu lục và màu lam, và một vùng màu lam khá lớn giữa màu đỏ và lục. Khi một điểm dữ liệu test rơi vào những vùng này, nó sẽ bị phân loại sai.\nVới d1 = 20, kết quả nhận được đã tương đối giống với d1 = 100. Mặc dù các đường boundary không được trơn tru cho lắm.\n\nNgười ta đã chứng minh được rằng, với một hàm số liên tục bất kỳ \\(f(x)\\) và một số \\(\\varepsilon >0\\), luôn luôn tồn tại một Neural Network với predicted output có dạng \\(g(x)\\) với một hidden layer (với số hidden units đủ lớn và nonlinear activation function phù hợp) sao cho với mọi \\(x, |f(x) - g(x)| < \\varepsilon\\). Nói một cách khác, Neural Network có khả năng xấp xỉ hầu hết các hàm liên tục.\nTrên thực tế, việc tìm ra số lượng hidden units và nonlinear activation function nói trên nhiều khi bất khả thi. Thay vào đó, thực nghiệm chứng minh rằng Neural Networks với nhiều hidden layers kết hợp với các nonlinear activation function (đơn giản như ReLU) có khả năng xấp xỉ (khả năng biểu diễn) training data tốt hơn.\nKhi số lượng hidden layers lớn lên, số lượng hệ số cần tối ưu cũng lớn lên và mô hình sẽ trở nên phức tạp. Sự phức tạp này ảnh hưởng tới hai khia cạnh. Thứ nhất, tốc độ tính toán sẽ bị chậm đi rất nhiều. Thứ hai, nếu mô hình quá phức tạp, nó có thể biểu diễn rất tốt training data, nhưng lại không biểu diễn tốt test data. Hiện tượng này gọi là Overfitting, tôi sẽ trình bày trong bài sau.\nNếu mọi units của một layer được kết nối với mọi unit của layer tiếp theo (như chúng ta đang xét trong baì này), ta gọi đó là fully connected layer (kết nối hoàn toàn). Neural Networks với toàn fully connected layer ít được sử dụng trong thực tế. Thay vào đó, có nhiều phương pháp giúp làm giảm độ phức tạp của mô hình bằng cách giảm số lượng kết nối bằng cách cho nhiều kết nối bằng 0 (ví dụ, sparse autoencoder), hoặc các hệ số được ràng buộc giống nhau (để giảm số hệ số cần tối ưu) (ví dụ, Convolutional Neural Networks (CNNs / ConvNets)). Bạn đọc muốn tìm hiểu thêm có thể bắt đầu tại đây.\nĐây là bài cuối cùng trong chuỗi bài về Neural Networks. Viết một bài về Deep Learning sẽ tốn thời gian hơn rất nhiều, trong 1 tuần tôi không đủ khả năng hoàn thành được. Bài tiếp theo tôi sẽ nói về Overfitting, sau đó chuyển sang một phương pháp classification rất phổ biến khác: Support Vector Machine.\nVề backpropagation, có rất nhiều điều phải nói nữa. Nếu có thể, tôi xin phép được trình bày sau. Bài này cũng đã đủ dài.\n\n[1] Neural Networks Part 1: Setting up the Architecture - Andrej Karpathy\n[2] Neural Networks, Case study - Andrej Karpathy\n[3] Lecture Notes on Sparse Autoencoders - Andrew Ng\n[4] Yes you should understand backprop\n[5] Backpropagation, Intuitions - Andrej Karpathy\n[6] How the backpropagation algorithm works - Michael Nielsen "
    },
    {
        "ID": 36,
        "URL": "https://machinelearningcoban.com/2017/02/17/softmax/",
        "Title": "Machine Learning cơ bản",
        "Content": "Các bài toán classification thực tế thường có rất nhiều classes (multi-class), các binary classifiers mặc dù có thể áp dụng cho các bài toán multi-class, chúng vẫn có những hạn chế nhất định. Với binary classifiers, kỹ thuật được sử dụng nhiều nhất one-vs-rest có một hạn chế về tổng các xác suất. Trong post này, một phương pháp mở rộng của Logistic Regression sẽ được giới thiệu giúp khắc phục hạn chế trên. Một lần nữa, dù là Softmax Regression, phương pháp này được sử dụng rộng rãi như một phương pháp classification.\nTrong trang này:\n\nMột lưu ý nhỏ: Hàm mất mát của Softmax Regression trông có vẻ khá phức tạp, nhưng nếu  kiên trì đọc đến phần phương pháp tối ưu, các bạn sẽ thấy vẻ đẹp ẩn sau sự phức tạp đó. Gradient của hàm mất mát và công thức cập nhật ma trận trọng số là rất đơn giản. (Đơn giản sau vài bước biến đổi toán học trông có vẻ phức tạp).\nNếu có điểm nào khó hiểu, bạn đọc được khuyến khích đọc lại các bài trước, trong đó quan trọng nhất là Bài 10: Logistic Regression.\n\nTôi xin phép được bắt đầu từ mô hình one-vs-rest được trình bày trong bài trước. Output layer (màu đỏ nhạt) có thể phân tách thành hai sublayer như hình dưới đây:\nDữ liệu \\(\\mathbf{x}\\) có số chiều là \\((d +1)\\) vì có phần tử 1 được thêm vào phía trước, thể hiện hệ số tự do trong hàm tuyến tính. Hệ số tự do \\(w_{0j}\\) còn được gọi là bias.\nGiả sử số classes là \\(C\\). Với one-vs-rest, chúng ta cần xây dựng \\(C\\) Logistic Regression khác nhau. Các đầu ra dự đoán được tính theo hàm sigmoid:\n\\[\na_i = \\text{sigmoid}(z_i) = \\text{sigmoid}(\\mathbf{w}_i^T\\mathbf{x})\n\\]\nTrong kỹ thuật này, các phần tử \\(a_i, i = 1, 2, \\dots, C\\) được suy ra trực tiếp chỉ với \\(z_i\\). Vì vậy, không có mối quan hệ chặt chẽ nào giữa các \\(a_i\\), tức tổng của chúng có thể nhỏ hơn hoặc lớn hơn 1. Nếu ta có thể khai thác được mỗi quan hệ giữa các \\(z_i\\) thì kết quả của bài toán classification có thể tốt hơn.\nChú ý rằng các mô hình Linear Regression, PLA, Logistic Regression chỉ có 1 node ở output layer. Trong các trường hợp đó, tham số mô hình chỉ là 1 vector \\(\\mathbf{w}\\). Trong trường hợp output layer có nhiều hơn 1 node, tham số mô hình sẽ là tập hợp \ntham số \\(\\mathbf{w}_i\\) ứng với từng node. Lúc này, ta có ma trận trọng số \\(\\mathbf{W} = [\\mathbf{w}_1, \\mathbf{w}_2, \\dots, \\mathbf{w}_C]\\).\n\n\nChúng ta cần một mô hình xác suất sao cho với mỗi input \\(\\mathbf{x}\\), \\(a_i\\) thể hiện xác suất để input đó rơi vào class \\(i\\). Vậy điều kiện cần là các \\(a_i\\) phải dương và tổng của chúng bằng 1. Để có thể thỏa mãn điều kiện này, chúng ta cần nhìn vào mọi giá trị \\(z_i\\) và dựa trên quan hệ giữa các \\(z_i\\) này để tính toán giá trị của \\(a_i\\). Ngoài các điều kiện \\(a_i\\) lớn hơn 0 và có tổng bằng 1, chúng ta sẽ thêm một điều kiện cũng rất tự nhiên nữa, đó là: giá trị \\(z_i = \\mathbf{w}_i^T\\mathbf{x}\\) càng lớn thì xác suất dữ liệu rơi vào class \\(i\\) càng cao. Điều kiện cuối này chỉ ra rằng chúng ta cần một hàm đồng biến ở đây.\nChú ý rằng \\(z_i \\) có thể nhận giá trị cả âm và dương. Một hàm số mượt đơn giản có thể chắc chắn biến  \\(z_i \\) thành một giá trị dương, và hơn nữa, đồng biến, là hàm \\(\\exp(z_i) = e^{z_i}\\). Điều kiện mượt để thuận lợi hơn trong việc tính đạo hàm sau này. Điều kiện cuối cùng, tổng các \\(a_i\\) bằng 1 có thể được đảm bảo nếu:\n\\[\na_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^C \\exp(z_j)}, ~~ \\forall i = 1, 2, \\dots, C\n\\]\nHàm số này, tính tất cả các \\(a_i\\) dựa vào tất cả các \\(z_i\\), thõa mãn tất cả các điều kiện đã xét: dương, tổng bằng 1, giữ được thứ tự của \\(z_i\\). Hàm số này được gọi là softmax function. Chú ý rằng với cách định nghĩa này, không có xác suất \\(a_i\\) nào tuyệt đối bằng 0 hoặc tuyệt đối bằng 1, mặc dù chúng có thể rất gần 0 hoặc 1 khi \\(z_i\\) rất nhỏ hoặc rất lớn khi so sánh với các \\(z_j, j \\neq i\\).\nLúc này, ta có thể giả sử rằng:\n\\[\nP(y_k = i | \\mathbf{x}_k; \\mathbf{W}) = a_i\n\\]\nTrong đó, \\(P(y = i | \\mathbf{x}; \\mathbf{W})\\) được hiểu là xác suất để một điểm dữ liệu \\(\\mathbf{x}\\) rơi vào class thứ \\(i\\) nếu biết tham số mô hình (ma trận trọng số) là \\(\\mathbf{W}\\).\nHình vẽ dưới đây thể hiện mạng Softmax Regression dưới dạng neural network:\nỞ phần bên phải, hàm tuyến tính \\(\\Sigma\\) và hàm softmax (activation function) được tách riêng ra để phục vụ cho mục đích minh họa. Dạng short form ở bên phải là dạng hay được sử dụng trong các Neural Networks, lớp \\(\\mathbf{a}\\) được ngầm hiểu là bao gồm cả lớp \\(\\mathbf{z}\\).\n\nDưới đây là một đoạn code viết hàm softmax. Đầu vào là một ma trận với mỗi cột là một vector \\(\\mathbf{z}\\), đầu ra cũng là một ma trận mà mỗi cột có giá trị là \\(\\mathbf{a} = \\text{softmax}(\\mathbf{z})\\). Các giá trị của \\(\\mathbf{z}\\) còn được gọi là scores.\n\nHình 3 dưới đây là một vài ví dụ về mối quan hệ giữa đầu vào và đầu ra của hàm softmax. Hàng trên màu xanh nhạt thể hiện các scores \\(z_i\\) với giả sử rằng số classes là 3. Hàng dưới màu đỏ nhạt thể hiện các giá trị đầu ra \\(a_i\\) của hàm softmax.\nCó một vài quan sát như sau:\nCột 1: Nếu các \\(z_i\\) bằng nhau, thì các \\(a_i\\) cũng bằng nhau và bằng 1/3.\nCột 2: Nếu giá trị lớn nhất trong các \\(z_i\\) là \\(z_1\\) vẫn bằng 2, nhưng các giá trị khác thay đổi, thì mặc dù xác suất tương ứng \\(a_1\\) vẫn là lớn nhất, nhưng nó đã thay đổi lên hơn 0.5. Đây chính là một lý do mà tên của hàm này có từ soft. (max vì phẩn từ lớn nhất vẫn là phần tử lớn nhất).\nCột 3: Khi các giá trị \\(z_i\\) là âm thì các giá trị \\(a_i\\) vẫn là dương và thứ tự vẫn được đảm bảo.\nCột 4: Nếu \\(z_1 = z_2\\), thì \\(a_1 = a_2\\).\nBạn đọc có thể thử với các giá trị khác trực tiếp trên trình duyệt trong link này, kéo xuống phần Softmax.\n\nKhi một trong các \\(z_i\\) quá lớn, việc tính toán \\(\\exp(z_i)\\) có thể gây ra hiện tượng tràn số (overflow), ảnh hưởng lớn tới kết quả của hàm softmax. Có một cách khắc phục hiện tượng này bằng cách dựa trên quan sát sau:\n\\[\n\\begin{eqnarray}\n\\frac{\\exp(z_i)}{\\sum_{j=1}^C \\exp(z_j)} &=& \\frac{\\exp(-c)\\exp(z_i)}{\\exp(-c)\\sum_{j=1}^C \\exp(z_j)}\\newline\n&=& \\frac{\\exp(z_i-c)}{\\sum_{j=1}^C \\exp(z_j-c)}\n\\end{eqnarray}\n\\]\nvới \\(c\\) là một hằng số bất kỳ.\nVậy một phương pháp đơn giản giúp khắc phục hiện tượng overflow là trừ tất cả các \\(z_i\\) đi một giá trị đủ lớn. Trong thực nghiệm, giá trị đủ lớn này thường được chọn là \\(c = \\max_i z_i\\). Vậy chúng ta có thể sửa đoạn code cho hàm softmax phía trên bằng cách trừ mỗi cột của ma trận đầu vào Z đi giá trị lớn nhất trong cột đó. Ta có phiên bản ổn định hơn là softmax_stable:\ntrong đó axis = 0 nghĩa là lấy max theo cột (axis = 1 sẽ lấy max theo hàng), keepdims = True để đảm bảo phép trừ giữa ma trận Z và vector  thực hiện được.\n\n\nVới cách biểu diễn network như trên, mỗi output sẽ không còn là một giá trị tương ứng với mỗi class nữa mà sẽ là một vector có đúng 1 phần tử bằng 1, các phần tử còn lại bằng 0. Phần tử bằng 1 năm ở vị trí tương ứng với class đó, thể hiện rằng điểm dữ liệu đang xét rơi vào class này với xác suất bằng 1 (sự thật là như thế, không cần dự đoán). Cách mã hóa output này chính là one-hot coding mà tôi đã đề cập trong bài K-means clustering và bài trước.\nKhi sử dụng mô hình Softmax Regression, với mỗi đầu vào \\(\\mathbf{x}\\), ta sẽ có đầu ra dự đoán là \\(\\mathbf{a} = \\text{softmax}(\\mathbf{W}^T\\mathbf{x})\\). Trong khi đó, đầu ra thực sự chúng ta có là vector \\(\\mathbf{y}\\) được biểu diễn dưới dạng one-hot coding.\nHàm mất mát sẽ được xây dựng để tối thiểu sự khác nhau giữa đầu ra dự đoán \\(\\mathbf{a}\\) và đầu ra thực sự \\(\\mathbf{y}\\). Một lựa chọn đầu tiên ta có thể nghĩ tới là:\n\\[\nJ(\\mathbf{W}) = \\sum_{i=1}^N ||\\mathbf{a}_i - \\mathbf{y}_i||_2^2\n\\]\nTuy nhiên đây chưa phải là một lựa chọn tốt. Khi đánh giá sự khác nhau (hay khoảng cách) giữa hai phân bố xác suất (probability distributions), chúng ta có một đại lượng đo đếm khác hiệu quả hơn. Đại lượng đó có tên là cross entropy.\n\nCross entropy giữa hai phân phối \\(\\mathbf{p}\\) và \\(\\mathbf{q}\\) được định nghĩa là:\n\\[\nH(\\mathbf{p}, \\mathbf{q}) = \\mathbf{E_p}[-\\log \\mathbf{q}]\n\\]\nVới \\(\\mathbf{p}\\) và \\(\\mathbf{q}\\) là rời rạc (như \\(\\mathbf{y}\\) và \\(\\mathbf{a}\\) trong bài toán của chúng ta), công thức này được viết dưới dạng:\n\\[\nH(\\mathbf{p}, \\mathbf{q}) =-\\sum_{i=1}^C p_i \\log q_i ~~~ (1)\n\\]\nĐể hiểu rõ hơn ưu điểm của hàm cross entropy và hàm bình phương khoảng cách thông thường, chúng ta cùng xem Hình 4 dưới đây. Đây là ví dụ trong trường hợp \\(C = 2\\) và \\(p_1\\) lần lượt nhận các giá trị \\(0.5, 0.1\\) và \\(0.8\\).\nCó hai nhận xét quan trọng sau đây:\nGiá trị nhỏ nhất của cả hai hàm số đạt được khi \\(q = p\\) tại hoành độ của các điểm màu xanh lục.\nQuan trọng hơn, hàm cross entropy nhận giá trị rất cao (tức loss rất cao) khi \\(q\\) ở xa \\(p\\). Trong khi đó, sự chênh lệch giữa các loss ở gần hay xa nghiệm của hàm bình phương khoảng cách \\((q - p)^2\\) là không đáng kể. Về mặt tối ưu, hàm cross entropy sẽ cho nghiệm gần với \\(p\\) hơn vì những nghiệm ở xa bị trừng phạt rất nặng.\nHai tính chất trên đây khiến cho cross entropy được sử dụng rộng rãi khi tính khoảng cách giữa hai phân phối xác suất.\nChú ý: Hàm cross entropy không có tính đối xứng \\(H(\\mathbf{p}, \\mathbf{q}) \\neq H(\\mathbf{q}, \\mathbf{p})\\). Điều này có thể dễ dàng nhận ra ở việc các thành phần của \\(\\mathbf{p}\\) trong công thức \\((1)\\) có thể nhận giá trị bằng 0, trong khi đó các thành phần của \\(\\mathbf{q}\\) phải là dương vì \\(\\log(0)\\) không xác định. Chính vì vậy, khi sử dụng cross entropy trong các bài toán supervised learning, \\(\\mathbf{p}\\) thường là đầu ra thực sự vì đầu ra thực sự chỉ có 1 thành phần bằng 1, còn lại bằng 0 (one-hot), \\(\\mathbf{q}\\) thường là đầu ra dự đoán, khi mà không có xác suất nào tuyệt đối bằng 1 hoặc tuyệt đối bằng 0 cả.\nTrong Logistic Regression, chúng ta cũng có hai phân phối đơn giản. (i) Đầu ra thực sự của điểm dữ liệu đầu vào \\(\\mathbf{x}_i\\) có phân phối xác suất là \\([y_i; 1 - y_i]\\) với \\(y_i\\) là xác suất để điểm dữ liệu đầu vào rơi vào class thứ nhất (bằng 1 nếu \\(y_i = 1\\), bằng 0 nếu \\(y_i = 0\\)). (ii). Đầu ra dự đoán của điểm dữ liệu đó là \\(a_i = \\text{sigmoid}(\\mathbf{w}^T\\mathbf{x})\\) là xác suất để điểm đó rơi vào class thứ nhất. Xác suất để điểm đó rơi vào class thứ hai có thể được dễ dàng suy ra lf \\(1 - a_i\\). Vì vậy, hàm mất mát trong Logistic Regression:\n\\[\nJ(\\mathbf{w}) = -\\sum_{i=1}^N(y_i \\log {a}_i + (1-y_i) \\log (1 - {a}_i))\n\\]\nchính là một trường hợp đặc biệt của Cross Entropy. (\\(N\\) được dùng để thể hiện số điểm dữ liệu trong tập training).\nVới Softmax Regression, trong trường hợp có \\(C\\) classes, loss giữa đầu ra dự đoán và đầu ra thực sự của một điểm dữ liệu \\(\\mathbf{x}_i\\) được tính bằng:\n\\[\nJ(\\mathbf{W};\\mathbf{x}_i, \\mathbf{y}_i) = -\\sum_{j=1}^C y_{ji}\\log(a_{ji})\n\\]\nVới \\(y_{ji}\\) và \\( a_{ji}\\) lần lượt là là phần tử thứ \\(j\\) của vector (xác suất) \\(\\mathbf{y}_i\\) và \\(\\mathbf{a}_i\\). Nhắc lại rằng đầu ra \\(\\mathbf{a}_i\\) phụ thuộc vào đầu vào \\(\\mathbf{x}_i\\) và ma trận trọng số \\(\\mathbf{W}\\).\n\nKết hợp tất cả các cặp dữ liệu \\(\\mathbf{x}_i, \\mathbf{y}_i, i = 1, 2, \\dots, N\\), chúng ta sẽ có hàm mất mát cho Softmax Regression như sau:\n\\[\n\\begin{eqnarray}\nJ(\\mathbf{W}; \\mathbf{X}, \\mathbf{Y}) = -\\sum_{i = 1}^N \\sum_{j = 1}^C y_{ji}\\log(a_{ji}) \\newline\n= -\\sum_{i = 1}^N \\sum_{j = 1}^C y_{ji}\\log\\left(\\frac{\\exp(\\mathbf{w}_j^T\\mathbf{x}_i)}{\\sum_{k=1}^C \\exp(\\mathbf{w}_k^T\\mathbf{x}_i)}\\right)\n\\end{eqnarray}\n\\]\nVới ma trận trọng số \\(\\mathbf{W}\\) là biến cần tối ưu. Hàm mất mát này trông có vẻ đáng sợ, nhưng đừng sợ, đọc tiếp các bạn sẽ thấy đạo hàm của nó rất đẹp (và đáng yêu).\n\nMột lần nữa, chúng ta lại sử dụng Stochastic Gradient Descent (SGD) ở đây.\nVới chỉ một cặp dữ liệu \\((\\mathbf{x}_i, \\mathbf{y}_i)\\), ta có: \n\\[\nJ_i(\\mathbf{W}) \\triangleq J(\\mathbf{W}; \\mathbf{x}_i, \\mathbf{y}_i) = \n\\]\n\\[\n\\begin{eqnarray}\n&=& -\\sum_{j = 1}^C y_{ji}\\log\\left(\\frac{\\exp(\\mathbf{w}_j^T\\mathbf{x}_i)}{\\sum_{k=1}^C \\exp(\\mathbf{w}_k^T\\mathbf{x}_i)}\\right) \\newline\n&=& -\\sum_{j=1}^C\\left(y_{ji} \\mathbf{w}_j^T\\mathbf{x}_i - y_{ji}\\log\\left(\\sum_{k=1}^C \\exp(\\mathbf{w}_k^T\\mathbf{x}_i)\\right)\\right) \\newline\n&=& -\\sum_{j=1}^C y_{ji} \\mathbf{w}_j^T\\mathbf{x}_i + \\log\\left(\\sum_{k=1}^C \\exp(\\mathbf{w}_k^T\\mathbf{x}_i)\\right) ~~ (3)\n\\end{eqnarray}\n\\]\ntrong biến đổi ở dòng cuối cùng, tôi đã sử dụng quan sát: \\(\\sum_{j=1}^C y_{ji} = 1\\) vì nó là tổng các xác suất.\nTiếp theo ta sử dụng công thức: \n\\[\n\\frac{\\partial J_i(\\mathbf{W})}{\\partial \\mathbf{W}} = \\left[\\frac{\\partial J_i(\\mathbf{W})}{\\partial \\mathbf{w}_1}, \\frac{\\partial J_i(\\mathbf{W})}{\\partial \\mathbf{w}_2}, \\dots, \\frac{\\partial J_i(\\mathbf{W})}{\\partial \\mathbf{w}_C}    \\right]~~(4)\n\\]\nTrong đó, gradient theo từng cột có thể tính được dựa theo \\((3)\\):\n\\[\n\\begin{eqnarray}\n\\frac{\\partial J_i(\\mathbf{W})}{\\partial \\mathbf{w}_j} &=& -y_{ji}\\mathbf{x}_i + \n\\frac{\\exp(\\mathbf{w}_j^T\\mathbf{x}_i)}{\\sum_{k = 1}^C \\exp(\\mathbf{w}_k^T\\mathbf{x}_i)}\\mathbf{x}_i \\newline\n&=& -y_{ji}\\mathbf{x}_i + a_{ji} \\mathbf{x}_i = \\mathbf{x}_i (a_{ji} - y_{ji}) \\newline\n&=& e_{ji}\\mathbf{x}_{i} ~(\\text{where}~ e_{ji} = a_{ji} - y_{ji}) ~~(5)\n\\end{eqnarray}\n\\]\nGiá trị \\(e_{ji} = a_{ji} - y_{ji} \\) có thể được coi là sai số dự đoán.\nĐến đây ta đã được biểu thức rất đẹp rồi. Kết hợp \\((4)\\) và \\((5)\\) ta có: \n\\[\n\\frac{\\partial J_i(\\mathbf{W})}{\\partial \\mathbf{W}} = \\mathbf{x}_i [e_{1i}, e_{2i}, \\dots, e_{Ci}] = \\mathbf{x}_i\\mathbf{e}_i^T\n\\]\n\nTừ đây ta cũng có thể suy ra rằng:\n\\[\n\\frac{\\partial J(\\mathbf{W})}{\\partial \\mathbf{W}} = \\sum_{i=1}^N \\mathbf{x}_i\\mathbf{e}_i^T = \\mathbf{X}\\mathbf{E}^T\n\\]\nvới \\(\\mathbf{E} = \\mathbf{A - Y}\\). Công thức tính gradient đơn giản thế này giúp cho cả Batch Gradient Descent, Stochastic Gradient Descent (SGD), và Mini-batch Gradient Descent đều có thể dễ dàng được áp dụng.\nGiả sử rằng chúng ta sử dụng SGD, công thức cập nhật cho ma trận trọng số \\(\\mathbf{W}\\) sẽ là: \n\\[\n\\mathbf{W} = \\mathbf{W} +\\eta \\mathbf{x}_{i}(\\mathbf{y}_i - \\mathbf{a}_i)^T\n\\]\nBạn có thấy công thức này giống với công thức cập nhật của Logistic Regression không!\nThực ra:\n\nKhi \\(C = 2\\), Softmax Regression và Logistic Regression là giống nhau. Thật vậy, đầu ra dự đoán của Softmax Regression với \\(C= 2\\) có thể được viết dưới dạng: \n\\[\n\\begin{eqnarray}\na_1 &=& \\frac{\\exp(\\mathbf{w}_1^T\\mathbf{x})} {\\exp(\\mathbf{w}_1^T\\mathbf{x}) + \\exp(\\mathbf{w}_2^T\\mathbf{x})} \\newline\n&=& \\frac{1}{1 + \\exp((\\mathbf{w}_2 - \\mathbf{w}_1)^T\\mathbf{x})}\n\\end{eqnarray}\n\\]\nĐây chính là sigmoid function, là đầu ra dự đoán theo Logistic Regression. Khi \\(C = 2\\), bạn đọc cũng có thể thấy rằng hàm mất mát của Logistic và Softmax Regression đều là cross entropy. Hơn nữa, mặc dù có 2 outputs, Softmax Regression có thể rút gọn thành 1 output vì tổng 2 outputs luôn luôn bằng 1.\nSoftmax Regression còn có các tên gọi khác là Multinomial Logistic Regression, Maximum Entropy Classifier, hay rất nhiều tên khác nữa. Xem thêm Multinomial logistic regression - Wikipedia\n\n\nCác bài toán Machine Learning thường có độ phức tạp cao với lượng dữ liệu lớn và nhiều chiều. Để có thể áp dụng một thuật toán vào một bài toán cụ thể, trước tiên chúng ta cần áp dụng thuật toán đó vào simulated data (dữ liệu giả) với số chiều và số điểm dữ liệu nhỏ hơn. Simulated data này thường được tạo ngẫu nhiên (có thể thêm vài ràng buộc tùy vào đặc thù của dữ liệu). Với simulated data nhỏ, chúng ta có thể debug nhanh hơn và thử với nhiều trường hợp simulated data khác nhau. Khi nào thấy thuật toán chạy đúng chúng ta mới đưa dữ liệu thật vào.\nVới Softmax Regression, tôi tạo simulated data như sau:\nTrong ví dụ đơn giản này, số điểm dữ liệu chỉ là N = 2, số chiều dữ liệu d = 2, và số classes C = 3. Những giá trị đủ nhỏ này giúp cho việc kiểm tra có thể được thực hiện một cách tức thì. Sau khi thuật toán chạy đúng với những giá trị nhỏ này, ta có thể thay N, d, C bằng vài giá trị khác trước khi sử dụng dữ liệu thật.\n\nCó một bước quan trọng nữa trong Softmax Regression là phải chuyển đổi mỗi label \\(y_i\\) thành một vector \\(\\mathbf{y}_i\\) dưới dạng one-hot coding. Trong đó, chỉ có đúng một phần tử của \\(\\mathbf{y}_i\\) bằng 1, các phần tử còn lại bằng 0. Như vậy, với \\(N\\) điểm dữ liệu và \\(C\\) classes, chúng ta sẽ có một ma trận có kích thước \\(C \\times N\\) trong đó mỗi cột chỉ có đúng 1 phần tử bằng 1, còn lại bằng 0. Nếu chúng ta lưu toàn bộ dữ liệu này thì sẽ bị lãng phí bộ nhớ.\nMột cách thường được sử dụng là lưu ma trận output \\(\\mathbf{Y}\\) dưới dạng sparse matrix. Về cơ bản, cách làm này chỉ lưu các vị trí khác 0 của ma trận và giá trị khác 0 đó.\nPython có hàm scipy.sparse.coo_matrix giúp chúng ta thực hiện việc này. Với one-hot coding, tôi thực hiện như sau:\n\nĐiều cốt lõi trong cách tối ưu hàm mất mát là tính gradient. Với biểu thức toán trông khá rối mắt như trên, rất dễ để các bạn nhầm lẫn ở một bước nào đó. Softmax Regression vẫn là một thuật toán đơn giản, sau này các bạn sẽ thấy nhưng biểu thức phức tạp hơn nhiều. Rất khó để có thể tính toán đúng gradient ở ngay lần thử đầu tiên.\nTrong thực nghiệm, một cách thường được làm là so sánh gradient tính được với numeric gradient, tức gradient tính theo định nghĩa. Bạn đọc được khuyến khích đọc cách Kiểm tra đạo hàm.\nViệc kiểm tra đạo hàm được thực hiện như sau:\nNhư vậy, sự khác biệt giữa hai đạo hàm là rất nhỏ. Nếu các bạn thử vài trường hợp khác nữa của N, C, d, chúng ta sẽ thấy sự sai khác vẫn là nhỏ. Điều này chứng tỏ đạo hàm chúng ta tính được coi là chính xác. (Vẫn có thể có bug, chỉ khi nào kết quả cuối cùng với dữ liệu thật là chấp nhận được thì ta mới có thể bỏ cụm từ ‘có thể coi’ đi).\nChú ý rằng, nếu N, C, d quá lớn, việc tính toán numerical_grad trở nên cực kỳ tốn thời gian và bộ nhớ. Chúng ta chỉ nên kiểm tra với những dữ liệu nhỏ.\n\nSau khi đã có những hàm cần thiết và gradient được tính đúng, chúng ta có thể viết hàm chính có training Softmax Regression (theo SGD) như sau:\n\nSau khi train Softmax Regression và tính được ma trận hệ số W, class của một dữ liệu mới có thể tìm được bằng cách xác định vị trí của giá trị lớn nhất ở đầu ra dự đoán (tương ứng với xác suất điểm dữ liệu rơi vào class đó là lớn nhất). Chú ý rằng, các class được đánh số là 0, 1, 2, ..., C.\n\n\nĐể minh họa cách áp dụng Softmax Regression, tôi tiếp tục làm trên simulated data.\nTạo ba cụm dữ liệu\nPhân bố của các dữ liệu được cho như hình dưới:\nThực hiện Softmax Regression\nKết quả thu được\nTa thấy rằng Softmax Regression đã tạo ra các vùng cho mỗi class. Kết quả này là chấp nhận được. Từ hình trên ta cũng thấy rằng đường ranh giới giữa các classes là đường thẳng. Tôi sẽ chứng minh điều này ở phần sau.\n\nCác ví dụ trên đây được trình bày để giúp bạn đọc hiểu rõ Softmax Regression hoạt động như thế nào. Khi làm việc với các bài toán thực tế, chúng ta nên sử dụng các thư viện có sẵn, trừ khi bạn có thêm bớt vài số hạng nữa trong hàm mất mat.\nSoftmax Regression cũng được tích hợp trong hàm sklearn.linear_model.LogisticRegression của thư viện sklearn.\nĐể sử dụng Softmax Regression, ta cần thêm một vài thuộc tính nữa:\nVới Logistic Regression, multi_class = 'ovr' là giá trị mặc định, tương ứng với one-vs-rest. solver = 'lbfgs' là một phương pháp tối ưu cũng dựa trên gradient nhưng hiệu quả hơn và phức tạp hơn Gradient Descent. Bạn đọc có thể đọc thêm ở đây.\nSo với kết quả hơn 91% của one-vs-rest Logistic Regression thì Softmax Regression đã cải thiện được một chút. Kết quả thấp như thế này là có thể dự đoán được vì thực ra Softmax Regression vẫn chỉ tạo ra các đường biên là các đường tuyến tính (phẳng).\n\n\nThật vậy, dựa vào hàm softmax thì một điểm dữ liệu \\(\\mathbf{x}\\) được dự đoán là rơi vào class \\(j\\) nếu \\(a_{j} \\geq a_{k}, ~\\forall k \\neq j\\). Bạn đọc có thể chứng minh được rằng \\(a_{j} \\geq a_{k} \\Leftrightarrow z_{j} \\geq z_{k}\\), hay nói cách khác: \n\\[\n\\mathbf{w}_j^T \\mathbf{x} \\geq \\mathbf{w}_k^T\\mathbf{x} \\\n\\Leftrightarrow (\\mathbf{w}_j - \\mathbf{w}_k)^T\\mathbf{x} \\geq 0\n\\]\nĐây chính là một biểu thức tuyến tính. Vậy boundary tạo bởi Softmax Regression có dạng tuyến tính. (Xem thêm boundary tạo bởi Logistic Regression)\n\nSoftmax Regression cùng với Support Vector Machine (tôi sẽ trình bày sau vài bài nữa) là hai classifier phổ biến nhất được dùng hiện nay. Softmax Regression đặc biệt được sử dụng nhiều trong các mạng Neural có nhiều lớp (Deep Neural Networks hay DNN). Những lớp phía trước có thể được coi như một bộ Feature Extractor, lớp cuối cùng của DNN cho bài toán classification thường là Softmax Regression.\n\nCác bạn có thể tìm thấy source code trong jupyter notebook này.\n\n[1] Softmax Regression\n[2] sklearn.linear_model.LogisticRegression\n[3] Softmax function - Wikipedia\n[4] Improving the way neural networks learn"
    },
    {
        "ID": 37,
        "URL": "https://machinelearningcoban.com/2017/02/11/binaryclassifiers/",
        "Title": "Machine Learning cơ bản",
        "Content": "Cho tới bây giờ, ngoài thuật toán lười K-nearest neighbors, tôi đã giới thiệu với bạn đọc hai thuật toán cho các bài toán Classification: Perceptron Learning Algorithm và Logistic Regression. Hai thuật toán này được xếp vào loại Binary Classifiers vì chúng được xây dựng dựa trên ý tưởng về các bài toán classification với chỉ hai classes. Trong bài viết này, tôi sẽ cùng các bạn làm một vài ví dụ nhỏ về ứng dụng đơn giản (nhưng thú vị) của các binary classifiers, và cách mở rộng chúng để áp dụng cho các bài toán với nhiều classes (multi-class classification problems).\nVì Logistic Regression chỉ yêu cầu các classes là nearly linearly separable (tức có thể có vài điểm làm phá vỡ tính linear separability), tôi sẽ sử dụng Logistic Regression để đại diện cho các binary classifiers. Chú ý rằng, có rất nhiều các thuật toán cho binary classification nữa mà tôi chưa giới thiệu. Tạm thời, với những gì đã viết, tôi chỉ sử dụng Logistic Regression cho các ví dụ với code mẫu. Các kỹ thuật trong bài viết này hoàn toàn có thể áp dụng cho các binary classifiers khác.\nTrong trang này:\n\n\nChúng ta cùng bắt đầu với bài toán phân biệt giới tính dựa trên ảnh khuôn mặt. Về ảnh khuôn mặt, bộ cơ sở dữ liệu AR Face Database được sử dụng rộng rãi.\nBộ cơ sở dữ liệu này bao gồm hơn 4000 ảnh màu tương ứng với khuôn mặt của 126 người (70 nam, 56 nữ). Với mỗi người, 26 bức ảnh được chụp ở các điều kiện ánh sáng khác nhau, sắc thái biểu cảm khuôn mặt khác nhau, và bị che mắt (bởi kính râm) hoặc miệng (bởi khăn); và được chụp tại hai thời điểm khác nhau cách nhau 2 tuần.\nĐể cho đơn giản, tôi sử dụng bộ cơ sử AR Face thu gọn (có thể tìm thấy trong cùng trang web phía trên, mục Other (relevant) downloads). Bộ cơ sở dữ liệu thu gọn này bao gồm 2600 bức ảnh từ 50 nam và 50 nữ. Hơn nữa, các khuôn mặt cũng đã được xác định chính xác và được cropped với kích thước 165 x 120 (pixel) bằng phương pháp được mô tả trong bài báo PCA veus LDA. Tôi xin bỏ qua phần xử lý này và trực tiếp sử dụng ảnh đã cropped như một số ví dụ dưới đây:\nLưu ý:\nVì lý do bản quyền, tôi không được phép chia sẻ với các bạn bộ dữ liệu này. Các bạn muốn sở hữu có thể liên lạc với tác giả như hướng dẫn ở trong website AR Face Database. Một khi các bạn đã có tài khoản để download, tôi mong các bạn tôn trọng tác giả và không chia sẻ trực tiếp với bạn bè.\nCó một cách đơn giản và nhanh hơn để lấy được các feature vector (sau bước Feature Engineering)  của cơ sở dữ liệu này mà không cần liên lạc với tác giả. Các bạn có thể tìm  tại đây, phần Downloads, mục Random face features for AR database.\nMỗi bức ảnh trong AR Face thu gọn được đặt tên dưới dạng G-xxx-yy.bmp Trong đó: G nhận một trong hai giá trị M (man) hoặc W (woman); xxx là id của người, nhận gía trị từ 001 đến 050; yy là điều kiện chụp, nhận giá trị từ 01 đến 26, trong đó các điều kiện có số thứ tự từ 01 đến 07 và từ 14 đến 20 là các khuôn mặt không bị che bởi kính hoặc khăn. Tôi tạm gọi mỗi điều kiện này là một view.\nĐể làm ví dụ cho thuật toán Logistic Regression, tôi lấy ảnh của 25 nam và 25 nữ đầu tiên làm tập training set; 25 nam và 25 nữ còn lại làm test set. Với mỗi người, tôi chỉ lấy các khuôn mặt không bị che bởi kính và khăn.\nFeature Extraction: vì mỗi bức ảnh có kích thước 3x165x120 (số channels 3, chiều cao 165, chiều rộng 120) là một số khá lớn nên ta sẽ làm thực hiện Feature Extraction bằng hai bước đơn giản sau (bạn đọc được khuyến khích đọc bài Giới thiệu về Feature Engineering):\nChuyển ảnh màu về ảnh xám theo công thức Y' = 0.299 R + 0.587 G + 0.114 B  (Xem thêm tại Grayscale - wiki).\nKéo dài ảnh xám thu được thành 1 vector hàng có số chiều 165x120, sau đó sử dụng một random projection matrix để giảm số chiều về 500. Bạn đọc có thể thay giá trị này bằng các số khác nhỏ hơn 1000.\nChúng ta có thể bắt đầu làm việc với Python ngay bây giờ. Tôi sẽ sử dụng hàm sklearn.linear_model.LogisticRegression trong thư viện sklearn cho các ví dụ trong bài này. Nếu không muốn đọc phần này, bạn có thể lấy source code ở dây.\nChú ý: Hàm sklearn.linear_model.LogisticRegression nhận dữ liệu ở dạng vector hàng.\n\nKhai báo thư viện\nPhân chia training set và test set, lựa chọn các views.\nTạo random projection matrix.\nXây dựng danh sách các tên files.\nFeature Extraction: Xây dựng dữ liệu cho training set và test set.\nChú ý: Trong đoạn code trên tôi có sử dụng phương pháp chuẩn hóa dữ liệu Standardization. Trong đó x_mean và x_var lần lượt là vector kỳ vọng và phương sai của toàn bộ dữ liệu training. X_train_full, X_test_full là các ma trận dữ liệu đã được giảm số chiều nhưng chưa được chuẩn hóa. Hàm feature_extraction giúp chuẩn hóa dữ liệu dựa vào x_mean và x_var của X_train_full.\nĐoạn code dưới đây thực hiện thuật toán Logistic Regression, dự đoán output của test data và đánh giá kết quả. Một chú ý nhỏ, hàm Logistic Regression trong thư viện sklearn có nhiều biến thể khác nhau. Để sử dụng thuật toán Logistic Regression thuần mà tôi đã giới thiệu trong bài Logistic Regression, chúng ta cần đặt giá trị cho C là một số lớn (để nghịch đảo của nó gần với 0. Tạm thời các bạn chưa cần quan tâm tới điều này, chỉ cần chọn C lớn là được).\n90.33%, tức là cứ 10 bức ảnh trong test set thì có trung bình hơn 9 bức được nhận dạng đúng. Không tệ, nhất là khi chúng ta vẫn chưa phải làm gì nhiều!\nĐể xác định nhãn của một ảnh, đầu ra của hàm sigmoid được so sánh với 0.5. Nếu giá trị đó lớn hơn 0.5, ta kết luận đó là ảnh của nam, ngược lại, đó là ảnh của nữ. Để xem giá trị sau hàm sigmoid (tức xác suất để ảnh đó là nam), chúng ta sử dụng hàm predict_proba như sau:\nKết quả thu được là xác suất để bức ảnh đó là ảnh của nam (cột thứ nhất) và của nữ (cột thứ hai). Dưới đây là hình minh họa:\nHàng trên gồm các hình được phân loại đúng, hàng dưới gồm các hình bị phân loại sai. Có một vài nhận xét về hàng dưới. Từ hai bức ảnh hàng dưới, chúng ta có thể đoán rằng Logistic Regression quan tâm đến tóc phía sau gáy nhiều hơn là râu! Việc thuật toán dựa trên những đặc trưng nào của mỗi class phụ thuộc rất nhiều vào training data. Nếu trong training data, hầu hết nam không có râu và hầu hết nữ có tóc dài thì kết quả này là có thể lý giải được.\nTrong Machine Learning, thuật toán là quan trọng, nhưng thuật toán tốt mà dữ liệu không tốt thì sẽ dẫn đến những tác dụng ngược!\n(Source code cho ví dụ này có thể tìm thấy ở dây.)\n\nChúng ta cùng sang ví dụ thứ hai về phân biệt hai chữ số trong bộ cơ sở dữ liệu MNIST. Cụ thể, tôi sẽ làm việc với hai chữ số 0 và 1. Bạn đọc hoàn toàn có thể thử với các chữ số khác bằng cách thay đổi một dòng lệnh. Khác với AR Face, bộ dữ liệu này có thể dễ dàng được download về từ trang chủ của nó.\nChúng ta có thể bắt tay vào làm luôn.\nKhai báo thư viện:\nLoad toàn bộ dữ liệu:\nSau bưóc này, toàn bộ dữ liệu training data và test data được lưu ở hai ma trận X_train_all và X_test_all, mỗi hàng của các ma trận này chứa một điểm dữ liệu, tức một bức ảnh đã được vector hóa.\nĐể lấy các hàng tương ứng với chữ số 0 và chữ số 1, ta khai báo biến sau:\nNếu bạn muốn thử với cặp 3 và 4, chỉ cần thay dòng này bằng cls = [[3], [4]]. Nếu bạn muốn phân loại (4, 7) và (5, 6), chỉ cần thay dòng này bằng cls = [[4, 7], [5, 6]]. Các cặp bất kỳ khác đều có thể thực hiện bằng cách thay chỉ một dòng này.\nĐoạn code dưới đây thực hiện việc extract toàn bộ dữ liệu cho các chữ số 0 và 1 trong tập training data và test data.\nVì mỗi điểm dữ liệu có số phần tử là 784 (28x28), là một số khá nhỏ, nên ta không cần thêm bước giảm số chiều dữ liệu nữa. Tuy nhiên, tôi có thực hiện thêm một bước chuẩn hóa để đưa dữ liệu về đoạn [0, 1] bằng cách chia toàn bộ hai ma trận dữ liệu cho 255.0.\nTới đây ta có thể train mô hình Logistic Regression và đánh giá mô hình này.\nTuyệt vời, gần như 100% được phân loại chính xác. Điều này là dễ hiểu vì hai chữ số 0 và 1 khác nhau quá nhiều. Bộ cơ sở dữ liệu này với toàn bộ 10 classes hiện nay đã được phân loại với độ chính xác trên 99.7%.\nChúng ta cùng đi tìm những ảnh bị phân loại sai:\nNhư vậy là chỉ có một ảnh bị phân loại sai. Ảnh này là chữ số 0 nhưng bị misclassified thành chữ số 1, có thể vì nét đậm nhất của nó rất giống với chữ số 1.\nSource code cho ví dụ này có thể được tìm thấy ở đây.\n\nCó lẽ nhiều bạn đang đặt câu hỏi: Các ví dụ trên đây đều làm với bài toán có hai classes. Vậy nếu có nhiều hơn hai classes, ví dụ như 10 classes của MNIST, thì làm thế nào?\nCó nhiều thuật toán khác được xây dựng riêng cho các bài toán với nhiều classes (multi-class classification problems), tôi sẽ giới thiệu sau. Còn bây giờ, chúng ta vẫn có thể sử dụng các binary classifiers để thực hiện công việc này, với một chút thay đổi. \n\nCó ít nhất bốn cách để áp dụng binary classifiers vào các bài toán multi-class classification:\n\nXây dựng rất nhiều bộ binary classifiers cho từng cặp classes. Bộ thứ nhất phân biệt class 1 và class 2, bộ thứ hai phân biệt class 1 và class 3, … Khi có một dữ liệu mới vào, đưa nó vào toàn bộ các bộ binary classifiers trên. Kết quả cuối cùng có thể được xác định bằng cách xem class nào mà điểm dữ liệu đó được phân vào nhiều nhất (major voting). Hoặc với Logistic Regression thì ta có thể tính tổng các xác suất tìm được sau mỗi bộ binary classifier.\nNhư vậy, nếu có \\(C\\) classes thì tổng số binary classifiers phải dùng là \\(\\frac{n(n-1)}{2}\\). Đây là một con số lớn, cách làm này không lợi về tính toán. Hơn nữa, nếu một chữ số thực ra là chữ số 1, nhưng lại được đưa vào bộ phân lớp giữa các chữ số 5 và 6, thì cả hai khả năng tìm được (là 5 hoặc 6) đều không hợp lý!\n\nCác làm như one-vs-one sẽ mất rất nhiều thời gian training vì có quá nhiều bộ phân lớp cần được xây dựng. Một cách khác giúp tiết kiệm số binary classifiers hơn đó là hierarchical. Ý tưởng như sau:\nVí dụ với MNIST với 4 chữ số 4, 5, 6, 7. Vì ta thấy chữ số 4 và 7 khá giống nhau, chữ số 5 và 6 khá giống nhau nên trước tiên chúng ta xây dựng bộ phân lớp [4, 7] vs [5, 6]. Sau đó xây dựng thêm hai bộ 4 vs  7 và 5 vs 6 nữa. Tổng cộng, ta cần 3 bộ binary classifiers. Chú ý rằng có nhiều cách chia khác nhau, ví dụ [4, 5, 6] vs 7, [4, 5] vs 6, rồi 4 vs 5.\nƯu điểm của phương pháp này là sử dụng ít bộ binary classifiers hơn one-vs-one. \nHạn chế lớn nhất của nó là việc nếu chỉ một binary classifier cho kết quả sai thì kết quả cuối cùng chắc chắn sẽ sai. Ví dụ, nếu 1 ảnh chứa chữ số 5, nhưng ngay bước đầu tiên đã bị misclassifed sang nhánh [4, 7] thì kết quả cuối cùng sẽ là 4 hoặc 7, cả hai đều sai.\n\nCó một cách giảm số binary classifiers hơn nữa là binary coding, tức mã hóa output của mỗi class bằng một số nhị phân. Ví dụ, nếu có 4 classes thì class thứ nhất được mã hóa là 00, ba class kia được mã hóa lần lượt là 01, 10 và 11. Với cách làm này, số bộ binary classifiers phải thực hiện chỉ là \\(m = \\left\\lceil\\log_2(C)\\right\\rceil\\) trong đó \\(C\\) là số lượng class, \\(\\left\\lceil a \\right\\rceil\\) là số nguyên nhỏ nhất không nhỏ hơn \\(a\\). Class thứ nhất sẽ đi tìm bit đầu tiên của output (đã được mã hóa nhị phân), class thứ hai sẽ đi tìm bit thứ hai, …\nCách làm này sử dụng một số lượng nhỏ nhất các bộ binary classifiers. Nhưng nó có một hạn chế rất lớn là chỉ cần một bit bị phân loại sai sẽ dẫn đến dữ liệu bị phân loại sai. Hơn nữa, nếu số classes không phải là lũy thừa của hai, mã nhị phân nhận được có thể là một giá trị không tương ứng với class nào!\n\nPhương pháp được sử dụng nhiều nhất là one-vs-rest (một số tài liệu gọi là ove-vs-all, one-against-rest, hoặc one-against-all) . Cụ thể, nếu có \\(C\\) classes thì ta sẽ xây dựng \\(C\\) classifiers, mỗi classifier tương ứng với một class. Classifier thứ nhất giúp phân biệt class 1 vs not class 1, tức xem một điểm có thuộc class 1 hay không, hoặc xác suất để một điểm rơi vào class 1 là bao nhiêu. Tương tự như thế, classifier thứ hai sẽ phân biệt class 2 vs not class 2, … Kết quả cuối cùng có thể được xác định bằng cách xác định class mà một điểm rơi vào với xác suất cao nhất.\nPhương pháp này còn được gọi là one-hot coding (được sử dụng nhiều nên có rất nhiều tên) vì với cách mã hóa trên, giả sử có 4 classes, class 1, 2, 3, 4 sẽ lần lượt được mã hóa dưới dạng nhị phân bởi 1000, 0100, 0010 hoặc 0001. One-hot vì chỉ có one bit là hot (bằng 1).\nHàm Logistic Regression trong thư viện sklearn có thể được dùng trực tiếp để áp dụng vào các bài toán multi-class classification với phương pháp one-vs-rest. Với bài toán MNIST như nêu ở phần 2, ta có thể thêm ba dòng lệnh sau để chạy trên toàn bộ 10 classes:\nKết quả thu được khoảng 91% sau hơn 20 phút chạy (tùy thuộc vào máy). Đây vẫn là một kết quả quá thấp so với con số 99.7%. Thậm chí phương pháp học máy không học gì như K-neareast neighbors cũng đã đạt hơn 96% với thời gian chạy ngắn hơn một chút.\nMột chú ý nhỏ: phương pháp mặc định cho các bài toán multi-class của hàm này được xác định bởi biến multi_class. Có hai lựa chọn cho biến này, trong đó lựa chọn mặc định là ovr tức one-vs-rest, lựa chọn còn lại sẽ được tôi đề cập trong một bài gần đây. Lựa chọn thứ hai không phải cho binary classifiers nên tôi không đề cập trong bài này, có thể sau một vài bài nữa (Xem thêm sklearn.linear_model.LogisticRegression)\n\n\nNhắc lại rằng các linear binary classifiers tôi đã trình bày yêu cầu dữ liệu là linearly separable hoặc nearly linearly separable. Ta cũng có thể mở rộng định nghĩa này cho các bài toán multi-class. Nếu hai class bất kỳ là linearly separable thì ta coi dữ liệu đó là linearly separable.\nThế nhưng, có những loại dữ liệu linearly separable mà chỉ một số trong 4 phương pháp trên đây là phù hợp, hoặc có những loại dữ liệu yêu cầu phải kết hợp nhiều phương pháp mới thực hiện được. Xét ba ví dụ sau:\nHình 4a): cả 4 phương pháp trên đây đều có thể áp dụng được.\nHình 4b): one-vs-rest không phù hợp vì class màu xanh lục và class rest (hợp của xanh lam và đỏ) là không linearly separable. Lúc này, one-vs-one hoặc hierarchical phù hợp hơn.\nHình 4c): Tương tự như trên, ba class lam, lục, đỏ thẳng hàng nên sẽ không dùng được one-vs-rét. one-vs-one vẫn làm việc vì từng đôi class một là linearly separable. Tương tự hierarchical cũng làm việc nếu ta phân chia các nhóm một cách hợp lý. Hoặc chúng ta có thể kết hợp nhiều phương pháp. Ví dụ: dùng one-vs-rest để tìm đỏ vs không đỏ. Nếu một điểm dữ liệu là không đỏ, với 3 class còn lại, chúng ta lại quay lại trường hợp Hình 4a) và có thể dùng các phương pháp khác. Nhưng khó khăn vẫn nằm ở việc phân nhóm như thế nào, liệu rằng những class nào có thể cho vào cùng một nhóm? Với những dữ liệu đơn giản, K-means clustering có thể là một giải pháp!\nBạn đọc có thể xem thêm ví dụ áp dụng Logistic Regression cho cơ sở dữ liệu Iris trong link này\n\n\nLấy ví dụ với bài toán có 4 classes 1, 2, 3, 4; ta có thể biểu diễn các mô hình được đề cập trong phần 3 dưới dạng sau đây (giả sử input có số chiều là 7 và node output màu đỏ biểu diễn chung cho cả PLA, Logistic Regression và các networks với activation function khác):\nLúc này, thay vì chỉ có 1 node output như các phương pháp tôi đề cập trước đây (Linear Regression, Perceptron Learning Algorithm, Logistic Regression), chúng ta thấy rằng các networks này đều có nhiều outputs. Và một vector trọng số \\(\\mathbf{w}\\) bây giờ đã trở thành ma trận trọng số \\(\\mathbf{W}\\) mà mỗi cột của nó tương ứng với vector trọng số của một node output. Việc tối ưu đồng thời các binary classifiers trong mỗi network cũng được tổng quát lên nhớ các phép tính với ma trận.\nLấy ví dụ với công thức cập nhật của logistic sigmoid regression :\n\\[\n\\mathbf{w} = \\mathbf{w} + \\eta(y_i - z_i)\\mathbf{x}_i\n\\]\nCó thể tổng quát thành:\n\\[\n\\mathbf{W} = \\mathbf{W} + \\eta\\mathbf{x}_i(\\mathbf{y}_i - \\mathbf{z}_i)^T\n\\]\nVới \\(\\mathbf{W}, \\mathbf{y}_i, \\mathbf{z}_i\\) lần lượt là ma trận trọng số, vector (cột) output thật với toàn bộ các binary classifiers tương ứng với điểm dữ liệu \\(\\mathbf{x}_i\\), và vector output tìm được của networks tại thời điểm đang xét nếu đầu vào mỗi network là \\(\\mathbf{x}_i\\). Chú ý rằng với Logistic Regression, vector \\(\\mathbf{y}_i\\) là một binary vector, vector \\(\\mathbf{z}_i\\) gồm các phần tử nằm trong khoảng \\((0, 1)\\).\n\nXem xét lại phương pháp one-vs-rest theo góc nhìn xác suất, một điểm dữ liệu có thể được dự đoán thuộc vào class \\(1, 2, \\dots, C\\) với xác suất lần lượt là \\(p_1, p_2, \\dots, p_C\\). Tuy nhiên, tổng các xác suất này có thể không bằng 1! Có một phương pháp có thể làm cho nó hợp lý hơn, tức ép tổng các xác suất này bằng 1. Khi đó, với 1 điểm dữ liệu ta có thể nói xác suất nó rơi vào mỗi class là bao nhiêu. Phương pháp hấp dẫn này sẽ được đề cập trong bài Softmax Regression. Mời bạn đón đọc.\n\n[1] Multiclass classification - wiki\n[2] Logistic Regression 3-class Classifier"
    },
    {
        "ID": 38,
        "URL": "https://machinelearningcoban.com/general/2017/02/06/featureengineering/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\nCho tới lúc này, tôi đã trình bày 5 thuật toán Machine Learning cơ bản: Linear Regression, K-means Clusterning, K-nearest neighbors, Perceptron Learning Algorithm và Logistic Regression. Trong tất cả các thuật toán này, tôi đều giả sử các điểm dữ liệu được biểu diễn bằng các vector, được gọi là feature vector hay vector đặc trưng, có độ dài bằng nhau, và cùng là vector cột hoặc vector hàng. Tuy nhiên, trong các bài toán thực tế, mọi chuyện không được tốt đẹp như vậy!\nVới các bài toán về Computer Vision, các bức ảnh là các ma trận có kích thước khác nhau. Thậm chí để nhận dạng vật thể trong ảnh, ta cần thêm một bước nữa là object detection, tức là tìm cái khung chứa vật thể chúng ta cần dự đoán. Ví dụ, trong bài toán nhận dạng khuôn mặt, chúng ta cần tìm được vị trí các khuôn mặt trong ảnh và crop các khuôn mặt đó trước khi làm các bước tiếp theo. Ngay cả khi đã xác định được các khung chứa các khuôn mặt (và có thể resize các khung đó về cùng một kích thước), ta vẫn phải làm rất nhiều việc nữa vì hình ảnh của khuôn mặt còn phụ thưộc vào góc chụp, ánh sáng, … và rất nhiều yếu tố khác nữa.\nCác bài toán NLP (Natural Language Processing - Xử lý ngôn ngữ tự nhiên) cũng có khó khăn tương tự khi độ dài của các văn bản là khác nhau, thậm chí có những từ rất hiếm gặp hoặc không có trong từ điển. Cũng có khi thêm một vài từ vào văn bản mà nội dung của văn bản không đổi hoặc hoàn toàn mang nghĩa ngược lại. Hoặc cùng là một câu nói nhưng tốc độ, âm giọng của mỗi người là khác nhau, thậm chí của cùng một người nhưng lúc ốm lúc khỏe cũng khác nhau.\nKhi làm việc với các bài toán Machine Learning thực tế, nhìn chung chúng ta chỉ có được dữ liệu thô (raw) chưa qua chỉnh sửa, chọn lọc. Chúng ta cần phải tìm một phép biến đổi để loại ra những dữ liệu nhiễu (noise), và để đưa dữ liệu thô với số chiều khác nhau về cùng một chuẩn (cùng là các vector hoặc ma trận). Dữ liệu chuẩn mới này phải đảm bảo giữ được những thông tin đặc trưng (features) cho dữ liệu thô ban đầu. Không những thế, tùy vào từng bài toán, ta cần thiết kế những phép biến đổi để có những features phù hợp. Quá trình quan trọng này được gọi là Feature Extraction, hoặc Feature Engineering, một số tài liệu tiếng Việt gọi nó là trích chọn đặc trưng.\nTôi xin trích một câu nói của thầy Andrew Ng và xin phép thêm không dịch ra tiếng Việt (Nguồn Feature Engineering - wiki):\nComing up with features is difficult, time-consuming, requires expert knowledge. “Applied machine learning” is basically feature engineering.\nĐể giúp các bạn có cái nhìn tổng quan hơn, trong phần tiếp theo tôi xin đặt bước Feature Engineering này trong một bức tranh lớn hơn.\n\nPhần lớn các bài toán Machine Learning có thể được thể hiện trong hình vẽ dưới đây:\nCó hai phases lớn là Training phase và Testing phase. Xin nhắc lại là với các bài toán Supervised learning, ta có các cặp dữ liệu (input, output), với các bài toán Unsupervised learing, ta chỉ có input mà thôi.\n\nCó hai khối có nền màu xanh lục chúng ta cần phải thiết kế:\n\nĐẦU RA\nTôi xin đề cập đầu ra của khối này trước vì mục đích của Feature Engineering là tạo ra một Feature Extractor biến dữ liệu thô ban đầu thành dữ liệu phù hợp với từng mục đích khác nhau.\nĐẦU VÀO\nraw training input. Raw input là tất cả các thông tin ta biết về dữ liệu. Ví dụ: với ảnh thì là giá trị của từng pixel; với văn bản thì là từng từ, từng câu; với file âm thanh thì nó là một đoạn tín hiệu; với cơ sở dữ liệu Iris thì nó là độ dài các cánh hoa và đài hoa, … Dữ liệu thô này thường không ở dạng vector, không có số chiều như nhau. Thậm chí có thể có số chiều như nhau nhưng số chiều quá lớn, như một bức ảnh màu 1000 pixel x 1000 pixel thì số elements đã là \\(3 \\times 10^6\\) (3 vì ảnh màu thường có 3 channels: Red, Green, Blue). Đây là một con số quá lớn, không lợi cho lưu trữ và tính toán.\n(optional) output của training set. Trong các bài toán Unsupervised\nlearning, ta không biết output nên hiển nhiên sẽ không có đầu vào này. Trong\ncác bài toán Supervised learning, có khi dữ liệu này cũng không được sử dụng.\nVí dụ: nếu raw input đã có cùng số chiều rồi nhưng số chiều quá lớn,  ta\nmuốn giảm số chiều của nó thì cách đơn giản nhất là chiếu vector đó xuống\nmột không gian có số chiều nhỏ hơn bằng cách lấy một ma trận ngẫu nhiên nhân\nvới nó. Ma trận này thường là ma trận béo (số hàng ít hơn số cột, tiếng Anh - fat matrices) để đảm bảo số chiều thu được nhỏ hơn số chiều ban đầu. Việc\nlàm này mặc dù làm mất đi thông tin, trong nhiều trường hợp vẫn mang lại hiệu\nquả vì đã giảm được lượng tính toán ở phần sau. Đôi khi ma trận chiếu không\nphải là ngẫu nhiên mà có thể được học dựa trên toàn bộ raw input, ta sẽ có\nbài toán tìm ma trận chiếu để lượng thông tin mất đi là ít nhất. Trong nhiều\ntrường hợp, dữ liệu output của training set cũng được sử dụng để tạo ra\nFeature Extractor. Ví dụ: trong bài toán classification, ta không quan tâm\nnhiều đến việc mất thông tin hay không, ta chỉ quan tâm đến việc những thông\ntin còn lại có đặc trưng cho từng class hay không. Ví dụ, dữ liệu thô là các\nhình vuông và hình tam giác có màu đỏ và xanh. Trong bài toán phân loại đa\ngiác, các output là tam giác và vuông,  thì ta không quan tâm tới màu sắc\nmà chỉ quan tâm tới số cạnh của đa giác. Ngược lại, trong bài toán phân loại\nmàu, các class là xanh và đỏ, ta không quan tâm tới số cạnh mà chỉ quan\ntâm đến màu sắc thôi.\n(optional) Prior knowledge about data: Đôi khi những giả thiết khác về dữ liệu cũng mang lại lợi ích. Ví dụ, trong bài toán classification, nếu ta biết dữ liệu là (gần như)  linearly separable thì ta sẽ đi tìm một ma trận chiếu sao cho ở trong không gian mới, dữ liệu vẫn đảm bảo tính linearly separable, việc này thuận tiện hơn cho phần classification vì các thuật toán linear, nhìn chung, đơn giản hơn.\nSau khi học được feature extractor thì ta cũng sẽ thu được extracted features cho raw input data. Những extracted features này được dùng để huấn luyện các thuật toán Classification, Clustering, Regression,… ở phía sau.\n\nKhi có được extracted features rồi, chúng ta sử dụng những thông tin này cùng\nvới (optional) training output và (optional) prior knowledge để tạo ra các\nmô hình phù hợp, điều mà chúng ta đã làm ở những bài trước.\nChú ý: Trong một số thuật toán cao cấp hơn, việc huấn luyện feature extractor và main algorithm được thực hiện cùng lúc với nhau chứ không phải từng bước như trên.\nMột điểm rất quan trọng: khi xây dựng bộ feature extractor và main\nalgorithms, chúng ta không được sử dụng bất kỳ thông tin nào trong tập test\ndata. Ta phải giả sử rằng những thông tin trong test data chưa được nhìn thấy\nbao giờ. Nếu sử dụng thêm thông tin về test data thì rõ ràng ta đã ăn gian!\nTôi từng đánh giá các bài báo khoa học quốc tế, rất nhiều tác giả xây dựng mô\nhình dùng cả dữ liệu test data, sau đó lại dùng chính mô hình đó để kiểm tra\ntrên test data đó. Việc ăn gian này là lỗi rất nặng và hiển nhiên những bài\nbáo đó bị từ chối (reject).\n\nBước này đơn giản hơn nhiều. Với raw input mới, ta sử dụng feature extractor\nđã tạo được ở trên (tất nhiên không được sử dụng output của nó vì output là\ncái ta đang đi tìm) để tạo ra feature vector tương ứng. Feature vector được đưa\nvào main algorithm đã được học ở training phase để dự đoán output.\n\n\nVới bài toán phân loại chữ số viết tay trong bộ cơ sở dữ liệu\nMNIST, mỗi bức ảnh có số chiều là\n28 pixel x 28 pixel (tất nhiên việc crop và chỉnh sửa mỗi bức ảnh đã được thực\nhiện từ trước rồi, đó đã là một phần của feature engineering rồi). Một cách đơn\ngiản thường được dùng là kéo dài ma trận 28x28 này để được 1 vector có số\nchiều 784. Trong cách này, các cột (hoặc hàng) của ma trận ảnh được đặt chồng\nlên (hoặc cạnh nhau) để được 1 vector dài. Vector dài này được trực tiếp sử dụng\nlàm feature đưa vào các bộ classifier/clustering/regression/… Lúc này, giá trị\ncủa mỗi pixel ảnh được coi là một feature.\nRõ ràng việc làm đơn giản này đã làm mất thông tin về không gian (spatial information) giữa các điểm ảnh, tuy nhiên, trong nhiều trường hợp, nó vẫn mang lại kết quả khả quan. \n\nGiả sử rằng các điểm dữ liệu có số features khác nhau (do kích thước dữ liệu\nkhác nhau hay do một số feature mà điểm dữ liệu này có nhưng điểm dữ liệu kia\nlại không thu thập được), và số lượng features là cực lớn. Chúng ta cần chọn\nra một số lượng nhỏ hơn các feature phù hợp với bài toán. Chọn thế nào và thế\nnào là phù hợp lại là một bài toán khác, tôi sẽ không bàn thêm ở đây.\n\nMột phương pháp nữa tôi đã đề cập đó là làm giảm số chiều của dữ liệu để giảm bộ\nnhớ và khối lượng tính toán. Việc giảm số chiều này có thể được thực hiện bằng\nnhiều cách, trong đó random projection là cách đơn giản nhất. Tức chọn một ma\ntrận chiếu (projection matrix) ngẫu nhiên (ma trận béo) rồi nhân nó với từng\nđiểm dữ liệu (giả sử dữ liệu ở dạng vector cột) để được các vector có số chiều\nthấp hơn. Ví dụ, vector ban đầu có số chiều là 784, chọn ma trận chiếu có kích\nthước (100x784), khi đó nếu nhân ma trận chéo này với vector ban đầu, ta sẽ được\nmột vector mới có số chiều là 100, nhỏ hơn số chiều ban đầu rất nhiều. Lúc này,\ncó thể ta không có tên gọi cho mỗi feature nữa vì các feature ở vector ban đầu\nđã được trộn lẫn với nhau theo một tỉ lệ nào đó rồi lưu vào vector mới này. Mỗi\nthành phần của vector mới này được coi là một feature (không tên).\nViệc chọn một ma trận chiếu ngẫu nhiên đôi khi mang lại kết quả tệ không mong\nmuốn vì thông tin bị mất đi quá nhiều. Một phương pháp được sử dụng nhiều để hạn\nchế lượng thông tin mất đi có tên là Principle Component\nAnalysis sẽ được\ntôi trình bày sau đây khoảng 1-2 tháng.\nChú ý: Feature learning không nhất thiết phải làm giảm số chiều dữ liệu, đôi\nkhi feature vector còn có số chiều lớn hơn raw data. Random projection cũng có\nthể làm được việc này nếu ma trận chiếu là một ma trận cao (số cột ít hơn số\nhàng).\n\nHẳn rất nhiều bạn đã tự đặt câu hỏi: Với một văn bản thì feature vector sẽ có\ndạng như thế nào? Làm sao đưa các từ, các câu, đoạn văn ở dạng text trong các\nvăn bản về một vector mà mỗi phần tử là một số?\nCó một phương pháp rất phổ biến giúp bạn trả lời những câu hỏi này. Phương pháp đó có tên là Bag of Words (BoW) (Túi đựng Từ).\nVẫn theo thói quen, tôi bắt đầu bằng một ví dụ. Giả sử chúng ta có bài toán phân loại tin rác. Ta thấy rằng nếu một tin có chứa các từ khuyến mại, giảm giá, trúng thưởng, miễn phí, quà tặng, tri ân, … thì nhiều khả năng đó là một tin nhắn rác. Vậy phương pháp đơn giản nhất là đếm xem trong tin đó có bao nhiêu từ thuộc vào các từ trên, nếu nhiều hơn 1 ngưỡng nào đó thì ta quyết định đó là tin rác. (Tất nhiên bài toán thực tế phức tạp hơn nhiều khi các từ có thể được viết dưới dạng không dấu, hoặc bị cố tình viết sai chính tả, hoặc dùng ngôn ngữ teen). Với các loại văn bản khác nhau thì lượng từ liên quan tới từng chủ đề cũng khác nhau. Từ đó có thể dựa vào số lượng các từ trong từng loại để làm các vector đặc trưng cho từng văn bản.\nTôi xin lấy ví dụ cụ thể hơn về cách tạo ra vector đặc trưng cho mỗi văn bản dựa trên BoW và xin được lấy tiếng Anh làm ví dụ (nguồn Bag of Words wiki. Tiếng Việt khó hơn vì một từ có thể có nhiều âm tiết, tiếng Anh thì thường cứ gặp dấu cách là kết thúc một từ).\nGiả sử chúng ta có hai văn bản đơn giản:\nvà\nDựa trên hai văn bản này, ta có danh sách các từ được sử dụng, được gọi là từ điển với 10 từ như sau:\nVới mỗi văn bản, ta sẽ tạo ra một vector đặc trưng có số chiều bằng 10, mỗi phần tử đại diện cho số từ tương ứng xuất hiện trong văn bản đó. Với hai văn bản trên, ta sẽ có hai vector đặc trưng là:\nVăn bản (1) có 1 từ “John”, 2 từ “likes”, 0 từ “also”, 0 từ “football”, … nên ta thu được vector tương ứng như trên.\nCó một vài điều cần lưu ý trong BoW:\nVới những ứng dụng thực tế, từ điền có nhiều hơn 10 từ rất nhiều, có thể đến một trăm nghìn hoặc cả triệu, như vậy vector đặc trưng thu được sẽ rất dài. Một văn bản chỉ có 1 câu, và 1 tiểu thuyết nghìn trang đều được biểu diễn bằng các vector có số chiều bằng 100 nghìn hoặc 1 triệu.\nCó rất nhiều từ trong từ điển không xuất hiện trong một văn bản. Như vậy các vector đặc trưng thu được thường có rất nhiều phần tử bằng 0. Các vector có nhiều phần tử bằng 0 được gọi là sparse vector (sparse hiểu theo nghĩa là thưa thớt, rải rác, tôi xin phép chỉ sử dụng khái niệm này bằng tiếng Anh). Để việc lưu trữ được hiệu quả hơn, ta không lưu cả vector đó mà chỉ lưu vị trí của các phần tử khác 0 và giá trị tương ứng. Lưu ý: nếu có hơn 50% số phần tử khác 0, việc làm này lại phản tác dụng!\nThi thoảng có những từ hiếm gặp không nằm trong từ điển, vậy ta sẽ làm gì? Một cách thường được dùng là mở rộng vector đặc trưng thêm 1 phần tử, gọi là phẩn tử <Unknown>. Mọi từ không có trong từ điền đều được coi là <Unknown>.\nNghĩ kỹ một chút, những từ hiếm đôi khi lại mang những thông tin quan trọng nhất mà chỉ loại văn bản đó có. Đây là một nhược điểm của BoW. Có một phương pháp cải tiến khác giúp khắc phục nhược điểm này có tên là Term Frequency-Inverse Document Frequency (TF-IDF) dùng để xác định tầm quan trọng của một từ trong một văn bản dựa trên toàn bộ văn bản trong cơ sở dữ liệu (corpus). Bạn đọc muốn tìm hiểu thêm có thể xem 5 Algorithms Every Web Developer Can Use and Understand, section 5.\nNhược điểm lớn nhất của BoW là nó không mang thông tin về thứ tự của các từ. Cũng như sự liên kết giữa các câu, các đoạn văn trong văn bản. Ví dụ, ba câu sau đây: “Em yêu anh không?”, “Em không yêu anh”, và “Không, (nhưng) anh yêu em” khi được trích chọn đặc trưng bằng BoW sẽ cho ra ba vector giống hệt nhau, mặc dù ý nghĩa khác hẳn nhau.\nBonus: hình dưới đây là tần suất sử dụng các từ (coi mỗi âm tiết là một từ) trong Truyện Kiều (theo bản này) nếu ta chỉ sử dụng 30 từ có tần suất cao nhất. :\n\nBags of Words cũng được áp dụng trong Computer Vision với cách định nghĩa words và từ điển khác.\nXét các ví dụ sau:\nVí dụ 1:\nCó hai class ảnh, một class là ảnh các khu rừng, một class là ảnh các sa mạc. Phân loại một bức ảnh là rừng hay sa mạc (giả sử ta biết rằng nó thuộc một trong hai loại này) một cách trực quan nhất là dựa vào màu sắc. Màu xanh nhiều thì là rừng, màu đỏ và vàng nhiều thì là sa mạc. Vậy chúng ta có thể có một mô hình đơn giản để trích chọn đặc trưng như sau:\nVới một bức ảnh, chuẩn bị một vector \\(\\mathbf{x}\\) có số chiều bằng 3, đại diện cho 3 màu xanh (\\(x_1\\)), đỏ (\\(x_2\\)), và vàng (\\(x_3\\)).\nVới mỗi điểm ảnh trong bức ảnh đó, xem nó gần với màu xanh, đỏ hay vàng nhất dựa trên giá trị của pixel đó. Nếu nó gần điểm xanh nhất, tăng \\(x_1\\) lên 1; gần đỏ nhất, tăng \\(x_2\\) lên 1; gần vàng nhất, tăng \\(x_3\\) lên 1.\nSau khi xem xét tất cả các điểm ảnh, dù cho bức ảnh có kích thước thế nào, ta vẫn thu được một vector có độ dài bằng 3, mỗi phần tử thể hiện việc có bao nhiêu pixel trong bức ảnh có màu tương ứng. Vector cuối này còn được gọi là vector histogram của bức ảnh tương ứng với ba màu xanh, đỏ, vàng. Dựa vào vector này, ta có thể quyết định bức ảnh đó là ảnh rừng hay sa mạc.\nVí dụ 2:\nTrên thực tế, các bài toán xử lý ảnh không đơn giản như ví dụ 1 trên đây. Mắt người thực ra nhạy với các đường nét, hình dáng hơn là màu sắc. Một cái (ảnh) cây dù không có màu vẫn là một cái (ảnh) cây! Vì vậy, xem xét giá trị từng điểm ảnh một không mang lại kết quả khả quan vì lượng thông tin bị mất quá nhiều.\nCó một cách khắc phục là thay vì xem xét một điểm ảnh, ta xem xét một cửa sổ nhỏ trong ảnh (trong Computer Vision, cửa sổ này được gọi là patch) là một hình chữ nhật chứa nhiều điểm ảnh gần nhau. Cửa sổ này đủ lớn để có thể chứa được các bộ phận có thể mô tả được vật thể trong ảnh.\nVí dụ với mặt người, các patch nên đủ lớn để chứa được các phần của khuôn mặt như mắt, mũi, miệng như hình dưới đây.\nTương tự thế, với ảnh là ô tô, các patch thu được có thể là bánh xe, khung xe, cửa xe, … như hàng trên trong hình dưới đây.\nCó một câu hỏi đặt ra là, trong xử lý văn bản, hai từ được coi là như nhau nếu nó được biểu diễn bởi các ký tự giống nhau. Vậy trong xử lý ảnh, hai patches được coi là như nhau khi nào? Khi mọi pixel trong hai patches có giá trị bằng nhau sao?\nCâu trả lời là không. Xác suất để hai patches giống hệt nhau từng pixel là rất thấp vì có thể một phần của vật thể trong một patch bị lệch đi vài pixel so với phần đó trong patch kia; hoặc phần vật thể trong patch bị méo, hoặc có độ sáng khác nhau, mặc dù ta vẫn nhìn thấy hai patches đó rất giống nhau. Vậy thì hai patch được coi là như nhau khi nào? Và từ điển ở đây được định nghĩa như thế nào?\nCâu trả lời ngắn: hai patches là gần giống nhau nếu khoảng cách Euclid giữa hai vector tạo bởi hai patches đó gần nhau. Từ điển (codebook) sẽ có số phần tử do ta tự chọn. Số phần tử càng cao thì độ sai lệch càng ít, nhưng sẽ nặng về tính toán hơn.\nCâu trả lời dài: chúng ta có thể áp dụng K-means clustering. Với rất nhiều patches thu được, giả sử ta muốn xây dựng một codebook với chỉ khoảng 1000 words. Vậy thì ta cho \\(k = 1000\\) rồi thực hiện K-means clustering trên toàn bộ số patches thu được (từ tập training). Sau khi thực hiện K-means clustering, ta thu được 1000 clusters và 1000 centers tương ứng. Mỗi centers này được coi là một words, và tất cả những điểm rơi vào cùng một cluster được coi là cùng một bag. Với ảnh trong tập test data, ta cũng lấy các patches rồi xem chúng rơi vào những bags nào. Từ đó suy ra vector đặc trưng cho mỗi bức ảnh. Chú ý rằng với \\(k = 1000\\), mỗi bức ảnh sẽ được mô tả bởi một vector có số chiều 1000, tức là mỗi điểm dữ liệu bây giờ đã có số chiều bằng nhau, mặc dù ảnh thô đầu vào có thể có kích thước khác nhau.\n\n(Tham khảo Feature Scaling wiki).\nCác điểm dữ liệu đôi khi được đo đạc với những đơn vị khác nhau, m và feet chẳng hạn. Hoặc có hai thành phần (của vector dữ liệu) chênh lệch nhau quá lớn, một thành phần có khoảng giá trị từ 0 đến 1000, thành phần kia chỉ có khoảng giá trị từ 0 đến 1 chẳng hạn. Lúc này, chúng ta cần chuẩn hóa dữ liệu trước khi thực hiện các bước tiếp theo.\nChú ý: việc chuẩn hóa này chỉ được thực hiện khi vector dữ liệu đã có cùng chiều.\nMột vài phương pháp chuẩn hóa thường dùng:\n\nPhương pháp đơn giản nhất là đưa tất cả các thành phần về cùng một khoảng, \\([0, 1]\\) hoặc \\([-1, 1]\\) chẳng hạn, tùy thuộc vào ứng dụng. Nếu muốn đưa một thành phần (feature) về khoảng \\([0, 1]\\), công thức sẽ là: \n\\[\nx’ = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}\n\\]\ntrong đó \\(x\\) là giá trị ban đầu, \\(x’\\) là giá trị sau khi chuẩn hóa. \\(\\min(x), \\max(x)\\) được tính trên toàn bộ dữ liệu training data ở cùng một thành phần. Việc này được thực hiện trên từng thành phần của vector dữ liệu \\(\\mathbf{x}\\).\n\nMột phương pháp nữa cũng hay được sử dụng là giả sử mỗi thành phần đều có phân phối chuẩn với kỳ vọng là 0 và phương sai là 1. Khi đó, công thức chuẩn hóa sẽ là: \n\\[\nx’ = \\frac{x - \\bar{x}}{\\sigma}\n\\]\nvới \\(\\bar{x}, \\sigma\\) lần lượt là kỳ vọng và phương sai (standard deviation) của thành phần đó trên toàn bộ training data. \n\nMột lựa chọn khác nữa cũng được sử dụng rộng rãi là chuẩn hóa các thành phần của mỗi vector dữ liệu sao cho toàn bộ vector có độ lớn (Euclid, tức norm 2) bằng 1. Việc này có thể được thực hiện bằng:\n\\[\n\\mathbf{x}’ = \\frac{\\mathbf{x}}{||\\mathbf{x}||_2}\n\\]\n\nXem ra thế giới Machine Learning rất rộng lớn và có rất nhiều thứ chúng ta cần làm. Và\nvẫn có khá nhiều thứ tôi có thể viết được. Tuy nhiên, blog này sẽ không tập trung nhiều vào Feature Learning, mặc dù sẽ có một vài bài nói về Dimensionality Reduction. Tôi sẽ sử dụng các bộ dữ liệu có sẵn, và đã qua bước Feature Learning.\n"
    },
    {
        "ID": 39,
        "URL": "https://machinelearningcoban.com/2017/02/02/howdoIcreatethisblog/",
        "Title": "Machine Learning cơ bản",
        "Content": "Tôi xin phép khởi động năm mới bằng một bài ngoại truyện. Bài này sẽ nói về việc tôi tạo blog này như thế nào, và mỗi bài viết được chuẩn bị ra sao. Blog sẽ quay lại với các nội dung về Machine Learning vào đầu tuần tới, Feb 6-7, 2017.\nTrong trang này:\n\n\n\nTên miền của blog là github.io, các bạn quen với git có lẽ đều biết tới trang https://github.com/  - là một nơi lưu các projects, có hỗ trợ quản lý version và cũng là một Internet hosting service. Tôi dùng trang này để lưu blog vì việc update bài mới rất thuận tiện, và cũng free nữa. Toàn bộ source code của blog này đều có thể xem tại đây.\nBlog được tạo dựa trên nền tảng Jekyll: hỗ trợ web tĩnh, cực kỳ đơn giản mà vẫn có thể tích hợp được HTML và CSS. Layout của blog được tạo bằng HTML CSS kết hợp với (một chút) Ruby. Việc tạo blog và ba bài đầu tiên chiếm trọn 4 ngày làm việc của tôi. Lúc đó đang là kỳ nghỉ đông, lại ở nhà một mình nên tôi tập trung làm được.\nHệ điều hành tôi sử dụng là Linux Ubuntu.\n\nCác bài viết được tạo dựa trên ngôn ngữ Markdown với cú pháp cực kỳ đơn giản. Vài ví dụ:\nKết quả: Machine Learning\nKết quả: cơ bản\nKết quả: Machine Learning cơ bản\nKết quả: \\( \\mathbf{w}^T\\mathbf{x} \\).\nĐây chỉ là một công thức ngắn, các công thức dài sẽ mất thời gian hơn nhiều. Vì Markdown chỉ hỗ trợ LaTeX một cách tối giản nên gõ các công thức toán chiếm khá nhiều thời gian của tôi. Việc phải thường xuyên chuyển đổi qua lại tiếng Việt, tiếng Anh cũng làm chậm đi nhịp gõ. Một điểm nữa, những bài đầu tiên tôi chưa biết tới kiểu gõ Stelex nên các ký tự [,], {, } khi dùng LaTeX hoặc thêm link bị hiển thị là ư, ơ rất nhiều. Việc này khá khó chịu, rất may là tôi đã tìm được giải pháp Stelex dựa trên gợi ý của một bạn trên facebook.\n(Xem thêm Markdown cheatsheet)\n\nVì jekyll chỉ tạo ra web tĩnh nên tôi phải tìm cách thêm mục comments dựa trên hãng thứ ba (third-party). Trong blog này, tôi sử dụng Disqus (đọc như discuss) - là một công cụ lưu trữ comments khá phổ biến.\nNgoài ra tôi cũng sử dụng các công cụ track page views and locations như Google Analytics. Vì công cụ này không cập nhật thường xuyên (khoảng 1 ngày update 1 lần) nên tôi phải dùng thêm Statcounter nữa.\n\nThời gian đầu blog chưa có ô Search vì Jekyll không hỗ trợ Search tốt như các platform khác như Wordpress. Sau rất nhiều lần thử nghiệm, tôi quyết định dùng Google Custom Search Engine. Nhược điểm của công cụ này là nó không cập nhật liên tục mà phải chờ Google index bài mới thì mới ra kết quả tìm kiếm được. Một nhược điểm nữa là khi search sẽ có thêm quảng cáo. Ví dụ, khi tôi search “logistic” cho “logistic function”, kết quả trả về sẽ ra vài công ty làm “logistic”! Hiện tại thì đây là biện pháp tốt nhất mà tôi có thể nghĩ tới.\n\nEditors chính tôi sử dụng là Sublime Text. Tôi có thể viết HTML, CSS, markdown, LaTeX,… trên chỉ một editor này. Sublime Text hỗ trợ rất nhiều các packages tốt cho nhiều ngôn ngữ. Việc quản lý cả một project lớn, tìm kiếm trong toàn bộ project, qua lại giữa các files cũng rất thuận lợi.\n\nĐể tạo mục lục cho mỗi bài viết (hỗ trợ tự động sinh links), tôi cần cài package MarkdownTOC cho Sublime Text. Có một  khó khăn tôi phải khắc phục. Lấy một ví dụ, tôi đang viết bài Logistic Regression với đường link /2017/01/27/logisticregression/ và một mục có tên là “Giới thiệu”. Nếu dùng MarkdownTOC để tự động tạo mục lục thì nó sẽ tạo ra đường link có dạng /2017/01/27/logisticregression/#-giới-thiệu. Vì github.io không hỗ trợ đường link có ký tự tiếng Việt (hoặc có nhưng tôi chưa biết dùng) nên tôi phải sửa package MarkdownTOC một chút bằng cách bỏ dấu tiếng Việt trong link, để nó tự động tạo link có dạng /2017/01/27/logisticregression/#-gioi-thieu.\nNếu bạn nào muốn thử thì có thể sửa Preferences/Package Settings/MarkdownTOC/Settings - User như sau:\n\nCác hình vẽ cần độ chính xác (và thẩm mỹ) cao được vẽ bằng LaTeX với package TikZ hoặc Python với package matplotlib. Các hình động đều được vẽ bằng Python với package matplotlib.\n\nTrong blog này tôi sử dụng Python (cả 2 và 3). Python miễn phí, có nhiều thư viện tốt cho Machine Learning, và theo tôi thì Python cũng đang dần thay thế Matlab. Xem thêm Python vs Matlab. Tôi không sử dụng Matlab cho blog vì nhiều bạn ở Việt Nam không có điều kiện mua Matlab bản quyền. Tôi không ủng hộ việc dùng các phần mềm cracked.\nCác packages thường được dùng là numpy, scipy, scikit-learn, matplotlib, python-mnist.\nĐể có thể cài đặt các package này, cách đơn giản là dùng pip. Xem thêm: How to install Pip on Ubuntu 16.04.\n\nCác tài liệu trên mạng internet có rất nhiều, nhưng tôi vẫn ưu tiên đọc sách giấy trước. Tôi có sử dụng một số cuốn sách giấy sau:\nLearning from data. Cuốn này khá ngắn, là cuốn sách Machine Learning đầu tiên tôi mua ($28) và đọc ở Mỹ sau khi xem bài giảng online của tác giả (video online của tác giả có trong link đính kèm).\nPattern Recognition and Machine Learning - Christoper M. Bishop. Cuốn này rất cơ bản, tôi phải chờ 2 tuần mới mượn được ở thư viện của trường, và phải trả sau chỉ 3 tháng.\nComputer Vision:  Models, Learning, and Inference. Đây là texbook trong môn Computer Vision tôi học ở Penn State. Mặc dù có bản pdf online, tôi vẫn mua ($70) vì tôi thấy nội dung rất đầy đủ, hình vẽ cũng đẹp và dễ hiểu. Nội dung chính là các phương pháp xác suất cho Computer Vision.\nKhóa học Machine Learning của Andrew Ng. Khóa này rất cơ bản, free. Tác giả là co-founder của coursera và là một big name trong ngành Machine Learning. Theo tôi thì cách trình bày của tác giả rất cơ bản và dễ hiểu. Các bạn nên dành thời gian theo khóa này nếu muốn bước chân vào ngành Machine Learning.\n\nMỗi bài viết thường được tôi chuẩn bị trong trọn vẹn một ngày, từ sáng tới đêm muộn. Vì tên của blog là “Machine Learning cơ bản” nên tôi cố gắng trình bày một cách chi tiết nhất với nhiều hình vẽ minh họa và code mẫu. Tôi không muốn chỉ hướng các bạn tới cách sử dụng các thư viện có sẵn mà muốn các bạn hiểu được nguyên lý đằng sau mỗi thuật toán. Chính vì vậy, việc viết blog chiếm khá nhiều thời gian của tôi, mong các bạn thông cảm nếu tôi ra bài muộn hơn thường lệ.\nKhi viết một bài, tôi luôn nghĩ tới việc bài sau sẽ nói gì, có gì liên quan đến bài này, những điều chưa nên viết ở bài này mà để lại ở bài sau. Sau khi viết xong một bài, tôi luôn nghĩ về việc bài tiếp được giới thiệu như thế nào, có những gì cần lưu ý, … trong khi đi bộ lên trường/về nhà hoặc trong khi tập thể dục. Nếu có điều nào chưa rõ, tôi phải tìm đọc các tài liệu liên quan trước khi bắt tay vào viết.\nKhi bắt đầu viết, tôi thường làm theo thứ tự sau:\nViết code: tôi cần kiểm tra xem những gì mình hiểu có đúng không, code chạy có như ý muốn không. Việc viết code này thường mất 1-2 giờ, đôi khi mất thời gian hơn.\nSuy luận toán học: sau khi code đã chạy theo ý mình, tôi dùng giấy bút để kiểm tra lại các suy luận toán học trong bài, xem có thể dẫn dắt như thế nào từ những quan sát đơn giản. Tôi hạn chế những kiến thức toán mới trong mỗi bài để các bạn mới không cảm thấy ngợp. Phương châm của tôi luôn là “chậm nhưng chắc”, bạn đọc muốn đi nhanh hơn có thể đọc thêm sách và các khóa học online. Khoản này mất thêm 1 giờ nữa.\nVẽ hình: khoản này mất nhiều thời gian nhất. Trước khi làm blog hơn 1 tháng trước, tôi chưa bao giờ vẽ hình trên matplotlib của Python, chủ yếu dùng LaTeX với TikZ cho các bài báo khoa học. Tuy nhiên, matplotlib hỗ trợ vẽ các hình động rất tốt nên tôi vừa viết vừa học. Cả hai đều có hình vẽ với độ chính xác và thẩm mỹ cao, đồng nghĩa với việc công sức và thời gian bỏ vào cũng cao hơn. Tôi cũng rất thích vẽ hình minh họa nên dành khoảng hơn 2 giờ cho việc vẽ các hình trong mỗi bài. Tôi không thực sự muốn sử dụng các hình có sẵn online vì:\nĐộ phân giải ảnh có thể không cao.\nCác màu sắc, ký hiệu không thống nhất với các ký hiệu tôi dùng trong bài.\nKhó có thể chỉnh sửa nếu tôi muốn thêm bớt.\nCó thể gây khó hiểu với những bạn mới bắt đầu học Machine Learning.\nViết lần 1: phần này khá dài nhưng lại không mất nhiều thời gian bằng các phần phía trên vì chủ yếu là gõ theo dòng suy nghĩ đã chuẩn bị trước trong đầu. Vì các bài được viết bằng markdown nên việc chỉnh sửa format không mất thời gian của tôi lắm. Việc mất thời gian nhất là gõ các công thức toán học trong markdown. Không như LaTeX thuần hỗ trợ nhiều packages và có thể define các tên dài, LaTeX trong markdown bị hạn chế rất nhiều (thậm chí không báo lỗi, nhiều khi tôi mất rất nhiều thời gian để tìm lỗi LaTeX không hiển thị đúng). Đôi khi tôi cũng bị nhầm lẫn khi chuyển đổi tiếng Anh/tiếng Việt. Việc này chiếm khoảng 2 giờ nữa.\nRà soát lại: tôi thường đọc lại hai lần để sửa các lỗi chính tả, ngữ pháp và xem có ý nào cần thêm bớt không. Tôi dành khoảng 20-30 phút cho phần này.\nUpload bài lên blog, post bài lên facebook page, facebook cá nhân. Lúc này thường khá muộn, khoảng 1-2 giờ đêm, tôi đi ngủ, sáng hôm sau dậy đếm likes và xem comments. Cũng vào StatCounter xem có bao nhiêu người đã vào blog.\nThi thoảng tôi lại nghĩ ra gì đó mới cho blog thì thường dành một tối nữa để code. Ví dụ như việc chuyển sang giao diện Tết với nền đỏ chữ vàng và hoa đào hoa mai. Màu ưa thích của tôi là màu xanh đậm.\nBạn muốn biết thêm điều gì, hãy để lại comment, tôi sẽ cập nhật thêm."
    },
    {
        "ID": 40,
        "URL": "https://machinelearningcoban.com/2017/01/27/logisticregression/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\n\nHai mô hình tuyến tính (linear models) Linear Regression và Perceptron Learning Algorithm (PLA) chúng ta đã biết đều có chung một dạng:\n\\[\ny = f(\\mathbf{w}^T\\mathbf{x})\n\\]\ntrong đó \\(f()\\) được gọi là activation function, và \\(\\mathbf{x}\\) được hiểu là dữ liệu mở rộng với \\(x_0 = 1\\) được thêm vào để thuận tiện cho việc tính toán. Với linear regression thì \\(f(s) = s\\), với PLA thì \\(f(s) = \\text{sgn}(s)\\). Trong linear regression, tích vô hướng \\(\\mathbf{w}^T\\mathbf{x}\\) được trực tiếp sử dụng để dự đoán output \\(y\\), loại này phù hợp nếu chúng ta cần dự đoán một giá trị thực của đầu ra không bị chặn trên và dưới. Trong PLA, đầu ra chỉ nhận một trong hai giá trị \\(1\\) hoặc \\(-1 \\), phù hợp với các bài toán binary classification.\nTrong bài này, tôi sẽ giới thiệu mô hình thứ ba với một activation khác, được sử dụng cho các bài toán flexible hơn. Trong dạng này, đầu ra có thể được thể hiện dưới dạng xác suất (probability). Ví dụ: xác suất thi đỗ nếu biết thời gian ôn thi, xác suất ngày mai có mưa dựa trên những thông tin đo được trong ngày hôm nay,… Mô hình mới này của chúng ta có tên là logistic regression. Mô hình này giống với linear regression ở khía cạnh đầu ra là số thực, và giống với PLA ở việc đầu ra bị chặn (trong đoạn \\([0, 1]\\)). Mặc dù trong tên có chứa từ regression, logistic regression thường được sử dụng nhiều hơn cho các bài toán classification.\n\nTôi xin được sử dụng một ví dụ trên Wikipedia:\nMột nhóm 20 sinh viên dành thời gian trong khoảng từ 0 đến 6 giờ cho việc ôn thi. Thời gian ôn thi này ảnh hưởng đến xác suất sinh viên vượt qua kỳ thi như thế nào?\nKết quả thu được như sau:\nMặc dù có một chút bất công khi học 3.5 giờ thì trượt, còn học 1.75 giờ thì lại đỗ, nhìn chung, học càng nhiều thì khả năng đỗ càng cao. PLA không thể áp dụng được cho bài toán này vì không thể nói một người học bao nhiêu giờ thì 100% trượt hay đỗ, và thực tế là dữ liệu này cũng không linearly separable (điệu kiện để PLA có thể làm việc). Chú ý rằng các điểm màu đỏ và xanh được vẽ ở hai tung độ khác nhau để tiện cho việc minh họa. Các điểm này được vẽ dùng cả dữ liệu đầu vào \\(\\mathbf{x}\\) và đầu ra \\(y). Khi ta nói linearly seperable là khi ta chỉ dùng dữ liệu đầu vào \\(\\mathbf{x}\\).\nChúng ta biểu diễn các điểm này trên đồ thị để thấy rõ hơn:\nNhận thấy rằng cả linear regression và PLA đều không phù hợp với bài toán này, chúng ta cần một mô hình flexible hơn.\n\nĐầu ra dự đoán của:\nĐầu ra dự đoán của logistic regression thường được viết chung dưới dạng:\n\\[\nf(\\mathbf{x}) = \\theta(\\mathbf{w}^T\\mathbf{x})\n\\]\nTrong đó \\(\\theta\\) được gọi là logistic function. Một số activation cho mô hình tuyến tính được cho trong hình dưới đây:\nCác đường màu xanh lam và xanh lục phù hợp với bài toán của chúng ta hơn. Chúng có một vài tính chất quan trọng sau:\n\nTrong số các hàm số có 3 tính chất nói trên thì hàm sigmoid:\n\\[\nf(s) = \\frac{1}{1 + e^{-s}} \\triangleq \\sigma(s)\n\\]\nđược sử dụng nhiều nhất, vì nó bị chặn trong khoảng \\((0, 1)\\). Thêm nữa:\n\\[\n\\lim_{s \\rightarrow -\\infty}\\sigma(s) = 0; ~~ \\lim_{s \\rightarrow +\\infty}\\sigma(s) = 1 \n\\]\nĐặc biệt hơn nữa:\n\\[\n\\begin{eqnarray}\n\\sigma’(s) &=& \\frac{e^{-s}}{(1 + e^{-s})^2} \\newline\n&=& \\frac{1}{1 + e^{-s}} \\frac{e^{-s}}{1 + e^{-s}} \\newline\n&=& \\sigma(s)(1 - \\sigma(s))\n\\end{eqnarray}\n\\]\nCông thức đạo hàm đơn giản thế này giúp hàm số này được sử dụng rộng rãi. Ở phần sau, tôi sẽ lý giải việc người ta đã tìm ra hàm số đặc biệt này như thế nào.\n\nNgoài ra, hàm tanh cũng hay được sử dụng: \n\\[\n\\text{tanh}(s) = \\frac{e^{s} - e^{-s}}{e^s + e^{-s}}\n\\]\nHàm số này nhận giá trị trong khoảng \\((-1, 1)\\) nhưng có thể dễ dàng đưa nó về khoảng \\((0, 1)\\). Bạn đọc có thể chứng minh được:\n\\[\n\\text{tanh}(s) = 2\\sigma(2s) - 1\n\\]\n\n\nVới mô hình như trên (các activation màu xanh lam và lục), ta có thể giả sử rằng xác suất để một điểm dữ liệu \\(\\mathbf{x}\\) rơi vào class 1 là \\(f(\\mathbf{w}^T\\mathbf{x})\\) và rơi vào class 0 là \\(1 - f(\\mathbf{w}^T\\mathbf{x})\\). Với mô hình được giả sử như vậy, với các điểm dữ liệu training (đã biết đầu ra \\(y\\)), ta có thể viết như sau:\n\\[\n\\begin{eqnarray}\nP(y_i = 1 | \\mathbf{x}_i; \\mathbf{w}) &=& &f(\\mathbf{w}^T\\mathbf{x}_i)  ~~(1) \\newline\nP(y_i = 0 | \\mathbf{x}_i; \\mathbf{w}) &=& 1 - &f(\\mathbf{w}^T\\mathbf{x}_i)  ~~(2) \\newline\n\\end{eqnarray}\n\\]\ntrong đó \\( P(y_i = 1 | \\mathbf{x}_i; \\mathbf{w})\\) được hiểu là xác suất xảy ra sự kiện đầu ra \\(y_i = 1\\) khi biết tham số mô hình \\(\\mathbf{w}\\) và dữ liệu đầu vào \\(\\mathbf{x}_i\\). Bạn đọc có thể đọc thêm Xác suất có điều kiện. Mục đích của chúng ta là tìm các hệ số \\(\\mathbf{w}\\) sao cho \\(f(\\mathbf{w}^T\\mathbf{x}_i)\\) càng gần với 1 càng tốt với các điểm dữ liệu thuộc class 1 và càng gần với 0 càng tốt với những điểm thuộc class 0.\nKý hiệu \\(z_i = f(\\mathbf{w}^T\\mathbf{x}_i)\\) và viết gộp lại hai biểu thức bên trên ta có:\n\\[\nP(y_i| \\mathbf{x}_i; \\mathbf{w}) = z_i^{y_i}(1 - z_i)^{1- y_i}\n\\]\nBiểu thức này là tương đương với hai biểu thức \\((1)\\) và \\((2)\\) ở trên vì khi \\(y_i=1\\), phần thứ hai của vế phải sẽ triệt tiêu, khi \\(y_i = 0\\), phần thứ nhất sẽ bị triệt tiêu! Chúng ta muốn mô hình gần với dữ liệu đã cho nhất, tức xác suất này đạt giá trị cao nhất.\nXét toàn bộ training set với \\(\\mathbf{X} = [\\mathbf{x}_1,\\mathbf{x}_2, \\dots, \\mathbf{x}_N] \\in \\mathbb{R}^{d \\times N}\\) và \\(\\mathbf{y} = [y_1, y_2, \\dots, y_N]\\), chúng ta cần tìm \\(\\mathbf{w}\\) để biểu thức sau đây đạt giá trị lớn nhất:\n\\[\nP(\\mathbf{y}|\\mathbf{X}; \\mathbf{w})\n\\]\nở đây, ta cũng ký hiệu \\(\\mathbf{X, y}\\) như các biến ngẫu nhiên (random variables). Nói cách khác:\n\\[\n\\mathbf{w} = \\arg\\max_{\\mathbf{w}} P(\\mathbf{y}|\\mathbf{X}; \\mathbf{w})\n\\]\n\nBài toán tìm tham số để mô hình gần với dữ liệu nhất trên đây có tên gọi chung là bài toán maximum likelihood estimation với hàm số phía sau \\(\\arg\\max\\) được gọi là likelihood function. Khi làm việc với các bài toán Machine Learning sử dụng các mô hình xác suất thống kê, chúng ta sẽ gặp lại các bài toán thuộc dạng này, hoặc maximum a posteriori estimation, rất nhiều. Tôi sẽ dành 1 bài khác để nói về hai dạng bài toán này.\nGiả sử thêm rằng các điểm dữ liệu được sinh ra một cách ngẫu nhiên độc lập với nhau (independent), ta có thể viết:\n\\[\n\\begin{eqnarray}\nP(\\mathbf{y}|\\mathbf{X}; \\mathbf{w}) &=& \\prod_{i=1}^N P(y_i| \\mathbf{x}_i; \\mathbf{w}) \\newline\n&=& \\prod_{i=1}^N z_i^{y_i}(1 - z_i)^{1- y_i}\n\\end{eqnarray}\n\\]\nvới \\(\\prod\\) là ký hiệu của tích. Bạn đọc có thể muốn đọc thêm về Độc lập thống kê.\nTrực tiếp tối ưu hàm số này theo \\(\\mathbf{w}\\) nhìn qua không đơn giản! Hơn nữa, khi \\(N\\) lớn, tích của \\(N\\) số nhỏ hơn 1 có thể dẫn tới sai số trong tính toán (numerial error) vì tích là một số quá nhỏ. Một phương pháp thường được sử dụng đó là lấy logarit tự nhiên (cơ số \\(e\\)) của  likelihood function biến phép nhân thành phép cộng và để tránh việc số quá nhỏ. Sau đó lấy ngược dấu để được một hàm và coi nó là hàm mất mát. Lúc này bài toán tìm giá trị lớn nhất (maximum likelihood) trở thành bài toán tìm giá trị nhỏ nhất của hàm mất mát (hàm này còn được gọi là negative log likelihood):\n\\[\n\\begin{eqnarray}\nJ(\\mathbf{w}) = -\\log P(\\mathbf{y}|\\mathbf{X}; \\mathbf{w}) \\newline\n= -\\sum_{i=1}^N(y_i \\log {z}_i + (1-y_i) \\log (1 - {z}_i))\n\\end{eqnarray}\n\\]\nvới chú ý rằng \\(z_i\\) là một hàm số của \\(\\mathbf{w}\\). Bạn đọc tạm nhớ biểu thức vế phải có tên gọi là cross entropy, thường được sử dụng để đo khoảng cách giữa hai phân phối (distributions). Trong bài toán đang xét, một phân phối là dữ liệu được cho, với xác suất chỉ là 0 hoặc 1; phân phối còn lại được tính theo mô hình logistic regression. Khoảng cách giữa hai phân phối nhỏ đồng nghĩa với việc (có vẻ hiển nhiên là) hai phân phối đó rất gần nhau. Tính chất cụ thể của hàm số này sẽ được đề cập trong một bài khác mà tầm quan trọng của khoảng cách giữa hai phân phối là lớn hơn.\nChú ý: Trong machine learning, logarit thập phân ít được dùng, vì vậy \\(\\log\\) thường được dùng để ký hiệu logarit tự nhiên.\n\nChúng ta lại sử dụng phương pháp Stochastic Gradient Descent (SGD) ở đây (Bạn đọc được khuyến khích đọc SGD trước khi đọc phần này) . Hàm mất mát với chỉ một điểm dữ liệu \\((\\mathbf{x}_i, y_i)\\) là:\n\\[\nJ(\\mathbf{w}; \\mathbf{x}_i, y_i) = -(y_i \\log {z}_i + (1-y_i) \\log (1 - {z}_i))\n\\]\nVới đạo hàm:\n\\[\n\\begin{eqnarray}\n\\frac{\\partial J(\\mathbf{w}; \\mathbf{x}_i, y_i)}{\\partial \\mathbf{w}} &=& -(\\frac{y_i}{z_i} - \\frac{1- y_i}{1 - z_i} ) \\frac{\\partial z_i}{\\partial \\mathbf{w}} \\newline\n&=& \\frac{z_i - y_i}{z_i(1 - z_i)} \\frac{\\partial z_i}{\\partial \\mathbf{w}} ~~~~~~ (3)\n\\end{eqnarray}\n\\]\nĐể cho biểu thức này trở nên gọn và đẹp hơn, chúng ta sẽ tìm hàm \\(z = f(\\mathbf{w}^T\\mathbf{x})\\) sao cho mẫu số bị triệt tiêu. Nếu đặt \\(s = \\mathbf{w}^T\\mathbf{x}\\), chúng ta sẽ có:\n\\[\n\\frac{\\partial z_i}{\\partial \\mathbf{w}} = \\frac{\\partial z_i}{\\partial s} \\frac{\\partial s}{\\partial \\mathbf{w}} = \\frac{\\partial z_i}{\\partial s} \\mathbf{x}\n\\]\nMột cách trực quan nhất, ta sẽ tìm hàm số \\(z = f(s)\\) sao cho:\n\\[\n\\frac{\\partial z}{\\partial s} = z(1 - z) ~~ (4)\n\\]\nđể triệt tiêu mẫu số trong biểu thức \\((3)\\). Chúng ta cùng khởi động một chút với phương trình vi phân đơn giản này. Phương trình \\((4)\\) tương đương với:\n\\[\n\\begin{eqnarray}\n&\\frac{\\partial z}{z(1-z)} &=& \\partial s \\newline\n\\Leftrightarrow & (\\frac{1}{z} + \\frac{1}{1 - z})\\partial z &=&\\partial s \\newline\n\\Leftrightarrow & \\log z - \\log(1 - z) &=& s \\newline\n\\Leftrightarrow & \\log \\frac{z}{1 - z} &=& s \\newline\n\\Leftrightarrow & \\frac{z}{1 - z} &=& e^s \\newline\n\\Leftrightarrow & z &=& e^s (1 - z) \\newline\n\\Leftrightarrow & z = \\frac{e^s}{1 +e^s} &=&\\frac{1}{1 + e^{-s}} = \\sigma(s)\n\\end{eqnarray}\n\\]\nĐến đây, tôi hy vọng các bạn đã hiểu hàm số sigmoid được tạo ra như thế nào.\nChú ý: Trong việc giải phương trình vi phân ở trên, tôi đã bỏ qua hằng số khi lấy nguyên hàm hai vế. Tuy vậy, việc này không ảnh hưởng nhiều tới kết quả.\n\nTới đây, bạn đọc có thể kiểm tra rằng:\n\\[\n\\frac{\\partial J(\\mathbf{w}; \\mathbf{x}_i, y_i)}{\\partial \\mathbf{w}} = (z_i - y_i)\\mathbf{x}_i\n\\]\nQúa đẹp!\nVà công thức cập nhật (theo thuật toán SGD) cho logistic regression là: \n\\[\n\\mathbf{w} = \\mathbf{w} + \\eta(y_i - z_i)\\mathbf{x}_i\n\\]\nKhá đơn giản! Và, như thường lệ, chúng ta sẽ có vài ví dụ với Python.\n\n\nQuay trở lại với ví dụ nêu ở phần Giới thiệu. Trước tiên ta cần khai báo vài thư viện và dữ liệu:\n\nVới kết quả tìm được, đầu ra \\(y\\) có thể được dự đoán theo công thức: y = sigmoid(-4.1 + 1.55*x). Với dữ liệu trong tập training, kết quả là:\nBiểu diễn kết quả này trên đồ thị ta có:\nNếu như chỉ có hai output là ‘fail’ hoặc ‘pass’, điểm trên đồ thị của hàm sigmoid tương ứng với xác suất 0.5 được chọn làm hard threshold (ngưỡng cứng). Việc này có thể chứng minh khá dễ dàng (tôi sẽ bàn ở phần dưới).\n\nChúng ta xét thêm một ví dụ nhỏ nữa trong không gian hai chiều. Giả sử chúng ta có hai class xanh-đỏ với dữ liệu được phân bố như hình dưới.\nVới dữ liệu đầu vào nằm trong không gian hai chiều, hàm sigmoid có dạng như thác nước dưới đây:\nKết quả tìm được khi áp dụng mô hình logistic regression được minh họa như hình dưới với màu nền khác nhau thể hiện xác suất điểm đó thuộc class đỏ. Đỏ hơn tức gần 1 hơn, xanh hơn tức gần 0 hơn.\nNếu phải lựa chọn một ngưỡng cứng (chứ không chấp nhận xác suất) để phân chia hai class, chúng ta quan sát thấy đường thẳng nằm nằm trong khu vực xanh lục là một lựa chọn hợp lý. Tôi sẽ chứng minh ở phần dưới rằng, đường phân chia giữa hai class tìm được bởi logistic regression có dạng một đường phẳng, tức vẫn là linear.\n\n\nMặc dù có tên là Regression, tức một mô hình cho fitting, Logistic Regression lại được sử dụng nhiều trong các bài toán Classification. Sau khi tìm được mô hình, việc xác định class \\(y\\) cho một điểm dữ liệu \\(\\mathbf{x}\\) được xác định bằng việc so sánh hai biểu thức xác suất:\n\\[\nP(y = 1| \\mathbf{x}; \\mathbf{w}); ~~ P(y = 0| \\mathbf{x}; \\mathbf{w}) \n\\]\nNếu biểu thức thứ nhất lớn hơn thì ta kết luận điểm dữ liệu thuộc class 1, ngược lại thì nó thuộc class 0. Vì tổng hai biểu thức này luôn bằng 1 nên một cách gọn hơn, ta chỉ cần xác định xem \\(P(y = 1| \\mathbf{x}; \\mathbf{w})\\) lớn hơn 0.5 hay không. Nếu có, class 1. Nếu không, class 0.\n\nThật vậy, theo lập luận ở phần trên thì chúng ta cần kiểm tra:\n\\[\n\\begin{eqnarray}\nP(y = 1| \\mathbf{x}; \\mathbf{w}) &>& 0.5 \\newline\n\\Leftrightarrow \\frac{1}{1 + e^{-\\mathbf{w}^T\\mathbf{x}}} &>& 0.5 \\newline\n\\Leftrightarrow e^{-\\mathbf{w}^T\\mathbf{x}} &<& 1 \\newline\n\\Leftrightarrow \\mathbf{w}^T\\mathbf{x} &>& 0\n\\end{eqnarray}\n\\]\nNói cách khác, boundary giữa hai class là đường có phương trình \\(\\mathbf{w}^T\\mathbf{x}\\). Đây chính là phương trình của một siêu mặt phẳng. Vậy Logistic Regression tạo ra boundary có dạng tuyến tính.\n\nNếu hàm mất mát của Logistic Regression được viết dưới dạng:\n\\[\nJ(\\mathbf{w}) = \\sum_{i=1}^N (y_i - z_i)^2\n\\]\nthì khó khăn gì sẽ xảy ra? Các bạn hãy coi đây như một bài tập nhỏ.\nSource code cho các ví dụ trong bài này có thể tìm thấy ở đây.\n\n[1] Cox, David R. “The regression analysis of binary sequences.” Journal of the Royal Statistical Society. Series B (Methodological) (1958): 215-242.\n[2] Cramer, Jan Salomon. “The origins of logistic regression.” (2002).\n[3] Abu-Mostafa, Yaser S., Malik Magdon-Ismail, and Hsuan-Tien Lin. Learning from data. Vol. 4. New York, NY, USA:: AMLBook, 2012. (link to course)\n[4] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer  (2006). (book)\n[5] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012.\n[6] Andrer Ng. CS229 Lecture notes. Part II: Classification and logistic regression\n[7] Jerome H. Friedman, Robert Tibshirani, and Trevor Hastie. The Elements of Statistical Learning."
    },
    {
        "ID": 41,
        "URL": "https://machinelearningcoban.com/2017/01/21/perceptron/",
        "Title": "Machine Learning cơ bản",
        "Content": "Cứ làm đi, sai đâu sửa đấy, cuối cùng sẽ thành công!\nĐó chính là ý tưởng chính của một thuật toán rất quan trọng trong Machine Learning - thuật toán Perceptron Learning Algorithm hay PLA.\nTrong trang này:\n\n\nTrong bài này, tôi sẽ giới thiệu thuật toán đầu tiên trong Classification có tên là Perceptron Learning Algorithm (PLA) hoặc đôi khi được viết gọn là Perceptron.\nPerceptron là một thuật toán Classification cho trường hợp đơn giản nhất: chỉ có hai class (lớp) (bài toán với chỉ hai class được gọi là binary classification) và cũng chỉ hoạt động được trong một trường hợp rất cụ thể. Tuy nhiên, nó là nền tảng cho một mảng lớn quan trọng của Machine Learning là Neural Networks và sau này là Deep Learning. (Tại sao lại gọi là Neural Networks - tức mạng dây thần kinh - các bạn sẽ được thấy ở cuối bài).\nGiả sử chúng ta có hai tập hợp dữ liệu đã được gán nhãn được minh hoạ trong Hình 1 bên trái dưới đây. Hai class của chúng ta là tập các điểm màu xanh và tập các điểm màu đỏ. Bài toán đặt ra là: từ dữ liệu của hai tập được gán nhãn cho trước, hãy xây dựng một classifier (bộ phân lớp) để khi có một điểm dữ liệu hình tam giác màu xám mới, ta có thể dự đoán được màu (nhãn) của nó.\nHiểu theo một cách khác, chúng ta cần tìm lãnh thổ của mỗi class sao cho, với mỗi một điểm mới, ta chỉ cần xác định xem nó nằm vào lãnh thổ của class nào rồi quyết định nó thuộc class đó. Để tìm lãnh thổ của mỗi class, chúng ta cần đi tìm biên giới (boundary) giữa hai lãnh thổ này. Vậy bài toán classification có thể coi là bài toán đi tìm boundary giữa các class. Và boundary đơn giản nhất trong không gian hai chiều là một đường thằng, trong không gian ba chiều là một mặt phẳng, trong không gian nhiều chiều là một siêu mặt phẳng (hyperplane) (tôi gọi chung những boundary này là đường phẳng). Những boundary phẳng này được coi là đơn giản vì nó có thể biểu diễn dưới dạng toán học bằng một hàm số đơn giản có dạng tuyến tính, tức linear. Tất nhiên, chúng ta đang giả sử rằng tồn tại một đường phẳng để có thể phân định lãnh thổ của hai class. Hình 1 bên phải minh họa một đường thẳng phân chia hai class trong mặt phẳng. Phần có nền màu xanh được coi là lãnh thổ của lớp xanh, phần có nên màu đỏ được coi là lãnh thổ của lớp đỏ. Trong trường hợp này, điểm dữ liệu mới hình tam giác được phân vào class đỏ.\n\nBài toán Perceptron được phát biểu như sau: Cho hai class được gán nhãn, hãy tìm một đường phẳng sao cho toàn bộ các điểm thuộc class 1 nằm về 1 phía, toàn bộ các điểm thuộc class 2 nằm về phía còn lại của đường phẳng đó. Với giả định rằng tồn tại một đường phẳng như thế.\nNếu tồn tại một đường phẳng phân chia hai class thì ta gọi hai class đó là linearly separable. Các thuật toán classification tạo ra các boundary là các đường phẳng được gọi chung là Linear Classifier.\n\nCũng giống như các thuật toán lặp trong K-means Clustering và Gradient Descent, ý tưởng cơ bản của PLA là xuất phát từ một nghiệm dự đoán nào đó, qua mỗi vòng lặp, nghiệm sẽ được cập nhật tới một ví trí tốt hơn. Việc cập nhật này dựa trên việc giảm giá trị của một hàm mất mát nào đó.\n\nGiả sử \\(\\mathbf{X} = [\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N] \\in \\mathbb{R}^{d \\times N}\\) là ma trận chứa các điểm dữ liệu mà mỗi cột \\(\\mathbf{x}_i \\in \\mathbb{R}^{d\\times 1}\\) là một điểm dữ liệu trong không gian \\(d\\) chiều. (Chú ý: khác với các bài trước tôi thường dùng các vector hàng để mô tả dữ liệu, trong bài này tôi dùng vector cột để biểu diễn. Việc biểu diễn dữ liệu ở dạng hàng hay cột tùy thuộc vào từng bài toán, miễn sao cách biểu diễn toán học của nó khiến cho người đọc thấy dễ hiểu).\nGiả sử thêm các nhãn tương ứng với từng điểm dữ liệu được lưu trong một vector hàng \\(\\mathbf{y} = [y_1, y_2, \\dots, y_N] \\in \\mathbb{R}^{1\\times N}\\), với \\(y_i = 1\\) nếu \\(\\mathbf{x}_i\\) thuộc class 1 (xanh) và \\(y_i = -1\\) nếu \\(\\mathbf{x}_i\\) thuộc class 2 (đỏ).\nTại một thời điểm, giả sử ta tìm được boundary là đường phẳng có phương trình:\n\\[\n\\begin{eqnarray}\nf_{\\mathbf{w}}(\\mathbf{x}) &=& w_1x_1 + \\dots + w_dx_d + w_0 \\newline \n&=&\\mathbf{w}^T\\mathbf{\\bar{x}} = 0\n\\end{eqnarray}\n\\]\nvới \\(\\mathbf{\\bar{x}}\\) là điểm dữ liệu mở rộng bằng cách thêm phần tử \\(x_0 = 1\\) lên trước vector \\(\\mathbf{x}\\) tương tự như trong Linear Regression. Và từ đây, khi nói \\(\\mathbf{x}\\), tôi cũng ngầm hiểu là điểm dữ liệu mở rộng.\nĐể cho đơn giản, chúng ta hãy cùng làm việc với trường hợp mỗi điểm dữ liệu có số chiều \\(d = 2\\). Giả sử đường thẳng \\(w_1 x_1 + w_2 x_2 + w_0 = 0\\) chính là nghiệm cần tìm như Hình 2 dưới đây:\nNhận xét rằng các điểm nằm về cùng 1 phía so với đường thẳng này sẽ làm cho hàm số \\(f_{\\mathbf{w}}(\\mathbf{x})\\) mang cùng dấu. Chỉ cần đổi dấu của \\(\\mathbf{w}\\) nếu cần thiết, ta có thể giả sử các điểm nằm trong nửa mặt phẳng nền xanh mang dấu dương (+), các điểm nằm trong nửa mặt phẳng nền đỏ mang dấu âm (-). Các dấu này cũng tương đương với nhãn \\(y\\) của mỗi class. Vậy nếu \\(\\mathbf{w}\\) là một nghiệm của bài toán Perceptron, với một điểm dữ liệu mới \\(\\mathbf{x}\\) chưa được gán nhãn, ta có thể xác định class của nó bằng phép toán đơn giản như sau:\n\\[\n\\text{label}(\\mathbf{x}) = 1 ~\\text{if}~ \\mathbf{w}^T\\mathbf{x} \\geq 0, \\text{otherwise} -1\n\\]\nNgắn gọn hơn: \n\\[\n\\text{label}(\\mathbf{x}) = \\text{sgn}(\\mathbf{w}^T\\mathbf{x})\n\\]\ntrong đó, \\(\\text{sgn}\\) là hàm xác định dấu, với giả sử rằng \\(\\text{sgn}(0) = 1\\).\n\nTiếp theo, chúng ta cần xây dựng hàm mất mát với tham số \\(\\mathbf{w}\\) bất kỳ. Vẫn trong không gian hai chiều, giả sử đường thẳng \\(w_1x_1 + w_2x_2 + w_0 = 0\\) được cho như Hình 3 dưới đây:\nTrong trường hợp này, các điểm được khoanh tròn là các điểm bị misclassified (phân lớp lỗi). Điều chúng ta mong muốn là không có điểm nào bị misclassified. Hàm mất mát đơn giản nhất chúng ta nghĩ đến là hàm đếm số lượng các điểm bị misclassied và tìm cách tối thiểu hàm số này:\n\\[\nJ_1(\\mathbf{w}) = \\sum_{\\mathbf{x}_i \\in \\mathcal{M}} (-y_i\\text{sgn}(\\mathbf{w}^T\\mathbf{x_i}))\n\\]\ntrong đó \\(\\mathcal{M}\\) là tập hợp các điểm bị misclassifed (tập hợp này thay đổi theo \\(\\mathbf{w}\\)). Với mỗi điểm \\(\\mathbf{x}_i \\in \\mathcal{M}\\), vì điểm này bị misclassified nên \\(y_i\\) và \\(\\text{sgn}(\\mathbf{w}^T\\mathbf{x})\\) khác nhau, và vì thế \\(-y_i\\text{sgn}(\\mathbf{w}^T\\mathbf{x_i}) = 1 \\). Vậy \\(J_1(\\mathbf{w})\\) chính là hàm đếm số lượng các điểm bị misclassified. Khi hàm số này đạt giá trị nhỏ nhất bằng 0 thì ta không còn điểm nào bị misclassified.\nMột điểm quan trọng, hàm số này là rời rạc, không tính được đạo hàm theo \\(\\mathbf{w}\\) nên rất khó tối ưu. Chúng ta cần tìm một hàm mất mát khác để việc tối ưu khả thi hơn.\nXét hàm mất mát sau đây:\n\\[\nJ(\\mathbf{w}) = \\sum_{\\mathbf{x}_i \\in \\mathcal{M}} (-y_i\\mathbf{w}^T\\mathbf{x_i})\n\\]\nHàm \\(J()\\) khác một chút với hàm \\(J_1()\\) ở việc bỏ đi hàm \\(\\text{sgn}\\). Nhận xét rằng khi một điểm misclassified \\(\\mathbf{x}_i\\) nằm càng xa boundary thì giá trị \\(-y_i\\mathbf{w}^T\\mathbf{x}_i\\) sẽ càng lớn, nghĩa là sự sai lệch càng lớn. Giá trị nhỏ nhất của hàm mất mát này cũng bằng 0 nếu không có điểm nào bị misclassifed. Hàm mất mát này cũng được cho là tốt hơn hàm \\(J_1()\\) vì nó trừng phạt rất nặng những điểm lấn sâu sang lãnh thổ của class kia. Trong khi đó, \\(J_1()\\) trừng phạt các điểm misclassified như nhau (đều = 1), bất kể chúng xa hay gần với đường biên giới.\nTại một thời điểm, nếu chúng ta chỉ quan tâm tới các điểm bị misclassified thì hàm số \\(J(\\mathbf{w})\\) khả vi (tính được đạo hàm), vậy chúng ta có thể sử dụng Gradient Descent hoặc Stochastic Gradient Descent (SGD) để tối ưu hàm mất mát này. Với ưu điểm của SGD cho các bài toán large-scale, chúng ta sẽ làm theo thuật toán này.\nVới một điểm dữ liệu \\(\\mathbf{x}_i\\) bị misclassified, hàm mất mát trở thành:\n\\[\nJ(\\mathbf{w}; \\mathbf{x}_i; y_i) = -y_i\\mathbf{w}^T\\mathbf{x}_i\n\\]\nĐạo hàm tương ứng:\n\\[\n\\nabla_{\\mathbf{w}}J(\\mathbf{w}; \\mathbf{x}_i; y_i) = -y_i\\mathbf{x}_i\n\\]\nVậy quy tắc cập nhật là:\n\\[\n\\mathbf{w} = \\mathbf{w} + \\eta y_i\\mathbf{x}_i\n\\]\nvới \\(\\eta\\) là learning rate được chọn bằng 1. Ta có một quy tắc cập nhật rất gọn là: \\(\\mathbf{w}_{t+1} = \\mathbf{w}_{t} + y_i\\mathbf{x}_i\\). Nói cách khác, với mỗi điểm \\(\\mathbf{x}_i\\) bị misclassifed, ta chỉ cần nhân điểm đó với nhãn \\(y_i\\) của nó, lấy kết quả cộng vào \\(\\mathbf{w}\\) ta sẽ được \\(\\mathbf{w}\\) mới.\nTa có một quan sát nhỏ ở đây:\n\\[\n\\mathbf{w}_{t+1}^T\\mathbf{x}_i = (\\mathbf{w}_{t} + y_i\\mathbf{x}_i)^T\\mathbf{x}_{i} \\newline\n= \\mathbf{w}_{t}^T\\mathbf{x}_i + y_i ||\\mathbf{x}_i||_2^2\n\\]\nNếu \\(y_i = 1\\), vì \\(\\mathbf{x}_i\\) bị misclassifed nên \\(\\mathbf{w}_{t}^T\\mathbf{x}_i < 0\\). Cũng vì \\(y_i = 1\\) nên \\(y_i ||\\mathbf{x}_i||_2^2 = ||\\mathbf{x}_i||_2^2 \\geq 1\\) (chú ý \\(x_0 = 1\\)), nghĩa là \\(\\mathbf{w}_{t+1}^T\\mathbf{x}_i > \\mathbf{w}_{t}^T\\mathbf{x}_i\\). Lý giải bằng lời, \\(\\mathbf{w}_{t+1}\\) tiến về phía làm cho \\(\\mathbf{x}_i\\) được phân lớp đúng. Điều tương tự xảy ra nếu \\(y_i = -1\\).\nĐến đây, cảm nhận của chúng ta với thuật toán này là: cứ chọn đường boundary đi. Xét từng điểm một, nếu điểm đó bị misclassified thì tiến đường boundary về phía làm cho điểm đó được classifed đúng. Có thể thấy rằng, khi di chuyển đường boundary này, các điểm trước đó được classified đúng có thể lại bị misclassified. Mặc dù vậy, PLA vẫn được đảm bảo sẽ hội tụ sau một số hữu hạn bước (tôi sẽ chứng minh việc này ở phía sau của bài viết). Tức là cuối cùng, ta sẽ tìm được đường phẳng phân chia hai lớp, miễn là hai lớp đó là linearly separable. Đây cũng chính là lý do câu đầu tiên trong bài này tôi nói với các bạn là: “Cứ làm đi, sai đâu sửa đấy, cuối cùng sẽ thành công!”.\nTóm lại, thuật toán Perceptron có thể được viết như sau:\n\n\nNhư thường lệ, chúng ta sẽ thử một ví dụ nhỏ với Python.\n\nChúng ta sẽ tạo hai nhóm dữ liệu, mỗi nhóm có 10 điểm, mỗi điểm dữ liệu có hai chiều để thuận tiện cho việc minh họa. Sau đó, tạo dữ liệu mở rộng bằng cách thêm 1 vào đầu mỗi điểm dữ liệu.\nSau khi thực hiện đoạn code này, biến X sẽ chứa dữ liệu input (mở rộng), biến y sẽ chứa nhãn của mỗi điểm dữ liệu trong X.\n\nTiếp theo chúng ta cần viết 3 hàm số cho PLA:\nDưới đây là hình minh họa thuật toán PLA cho bài toán nhỏ này:\nSau khi cập nhật 18 lần, PLA đã hội tụ. Điểm được khoanh tròn màu đen là điểm misclassified tương ứng được chọn để cập nhật đường boundary.\nSource code cho phần này (bao gồm hình động) có thể được tìm thấy ở đây.\n\nGiả sử rằng \\(\\mathbf{w}^*\\) là một nghiệm của bài toán (ta có thể giả sử việc này được vì chúng ta đã có giả thiết hai class là linearly separable - tức tồn tại nghiệm). Có thể thấy rằng, với mọi \\(\\alpha > 0\\), nếu \\(\\mathbf{w}^*\\) là nghiệm, \\(\\alpha\\mathbf{w}^*\\) cũng là nghiệm của bài toán. Xét dãy số không âm \\( u_{\\alpha}(t) = ||\\mathbf{w}_{t} - \\alpha\\mathbf{w}^*||_2^2\\). Với \\(\\mathbf{x}_i\\) là một điểm bị misclassified nếu dùng nghiệm \\(\\mathbf{w}_t\\) ta có:\n\\[\n\\begin{eqnarray}\n&&u_{\\alpha}(t+1) = ||\\mathbf{w}_{t+1} - \\alpha \\mathbf{w}^*||_2^2 \\newline\n&=& ||\\mathbf{w}_{t} + y_i\\mathbf{x}_i - \\alpha\\mathbf{w}^*||_2^2 \\newline\n&=& ||\\mathbf{w}_{t} -\\alpha\\mathbf{w}^*||_2^2 + y_i^2||\\mathbf{x}_i||_2^2 + 2y_i\\mathbf{x}_i^T(\\mathbf{w} - \\alpha\\mathbf{w}^*) \\newline\n&<& u_{\\alpha}(t) \\ + ||\\mathbf{x}_i||_2^2 - 2\\alpha y_i\\mathbf{x}_i^T \\mathbf{w}^*\n\\end{eqnarray}\n\\]\nDấu nhỏ hơn ở dòng cuối là vì \\(y_i^2 = 1\\) và \\(2y_i\\mathbf{x}_i^T\\mathbf{w}_{t} < 0\\). Nếu ta đặt:\n\\[\n\\begin{eqnarray}\n\\beta^2 &=& \\max_{i=1, 2, \\dots, N}||\\mathbf{x}_i||_2^2 \\newline\n\\gamma &=& \\min_{i=1, 2, \\dots, N} y_i\\mathbf{x}_i^T\\mathbf{w}^*\n\\end{eqnarray}\n\\]\nvà chọn \\(\\alpha = \\frac{\\beta^2}{\\gamma}\\), ta có:\n\\[\n0 \\leq u_{\\alpha}(t+1) < u_{\\alpha}(t) + \\beta^2 - 2\\alpha\\gamma = u_{\\alpha}(t) - \\beta^2\n\\]\nĐiều này nghĩa là: nếu luôn luôn có các điểm bị misclassified thì dãy \\(u_{\\alpha}(t)\\) là dãy giảm, bị chặn dưới bởi 0, và phần tử sau kém phần tử trước ít nhất một lượng là \\(\\beta^2>0\\). Điều vô lý này chứng tỏ đến một lúc nào đó sẽ không còn điểm nào bị misclassified. Nói cách khác, thuật toán PLA hội tụ sau một số hữu hạn bước.\n\nHàm số xác định class của Perceptron \\(\\text{label}(\\mathbf{x}) = \\text{sgn}(\\mathbf{w}^T\\mathbf{x})\\) có thể được mô tả như hình vẽ (được gọi là network) dưới đây:\nĐầu vào của network \\(\\mathbf{x}\\) được minh họa bằng các node màu xanh lục với node \\(x_0\\) luôn luôn bằng 1. Tập hợp các node màu xanh lục được gọi là Input layer. Trong ví dụ này, tôi giả sử số chiều của dữ liệu \\(d = 4\\). Số node trong input layer luôn luôn là \\(d + 1\\) với một node là 1 được thêm vào. Node \\(x_0 = 1\\) này đôi khi được ẩn đi.\nCác trọng số (weights) \\(w_0, w_1, \\dots, w_d\\) được gán vào các mũi tên đi tới node \\(\\displaystyle z = \\sum_{i=0}^dw_ix_i = \\mathbf{w}^T\\mathbf{x}\\). Node \\(y = \\text{sgn}(z)\\) là output của network. Ký hiệu hình chữ Z ngược màu xanh trong node \\(y\\) thể hiện đồ thị của hàm số \\(\\text{sgn}\\).\nTrong thuật toán PLA, ta phải tìm các weights trên các mũi tên sao cho với mỗi \\(\\mathbf{x}_i\\) ở tập các điểm dữ liệu đã biết được đặt ở Input layer, output của network này trùng với nhãn \\(y_i\\) tương ứng.\nHàm số \\(y = \\text{sgn}(z)\\) còn được gọi là activation function. Đây chính là dạng đơn giản nhất của Neural Network.\nCác Neural Networks sau này có thể có nhiều node ở output tạo thành một output layer, hoặc có thể có thêm các layer trung gian giữa input layer và output layer. Các layer trung gian đó được gọi là hidden layer. Khi biểu diễn các Networks lớn, người ta thường giản lược hình bên trái thành hình bên phải. Trong đó node \\(x_0 = 1\\) thường được ẩn đi. Node \\(z\\) cũng được ẩn đi và viết gộp vào trong node \\(y\\). Perceptron thường được vẽ dưới dạng đơn giản như Hình 5 bên phải.\nĐể ý rằng nếu ta thay activation function bởi \\(y = z\\), ta sẽ có Neural Network mô tả thuật toán Linear Regression như hình dưới. Với đường thẳng chéo màu xanh thể hiện đồ thị hàm số \\(y = z\\). Các trục tọa độ đã được lược bỏ.\nMô hình perceptron ở trên khá giống với một node nhỏ của dây thân kinh sinh học như hình sau đây:\nDữ liệu từ nhiều dây thần kinh đi về một cell nucleus. Thông tin được tổng hợp và được đưa ra ở output. Nhiều bộ phận như thế này kết hợp với nhau tạo nên hệ thần kinh sinh học. Chính vì vậy mà có tên Neural Networks trong Machine Learning. Đôi khi mạng này còn được gọi là Artificial Neural Networks (ANN) tức hệ neuron nhân tạo.\n\n\nRõ ràng rằng, nếu hai class là linearly separable thì có vô số đường thằng phân cách 2 class đó. Dưới đây là một ví dụ:\nTất cả các đường thẳng màu đen đều thỏa mãn. Tuy nhiên, các đường khác nhau sẽ quyết định điểm hình tam giác thuộc các lớp khác nhau. Trong các đường đó, đường nào là tốt nhất? Và định nghĩa “tốt nhất” được hiểu theo nghĩa nào? Có một thuật toán khác định nghĩa và tìm đường tốt nhất như thế, tôi sẽ giới thiệu trong 1 vài bài tới. Mời các bạn đón đọc.\n\nHai class trong ví dụ dưới đây tương đối linearly separable. Mỗi class có 1 điểm coi như nhiễu nằm trong khu vực các điểm của class kia. PLA sẽ không làm việc trong trường hợp này vì luôn luôn có ít nhất 2 điểm bị misclassified.\nTrong một chừng mực nào đó, đường thẳng màu đen vẫn có thể coi là một nghiệm tốt vì nó đã giúp phân loại chính xác hầu hết các điểm. Việc không hội tụ với dữ liệu gần linearly separable chính là một nhược điểm lớn của PLA.\nĐể khắc phục nhược điểm này, có một cải tiến nhỏ như thuật toán Pocket Algorithm dưới đây:\n\nMột cách tự nhiên, nếu có một vài nhiễu, ta sẽ đi tìm một đường thẳng phân chia hai class sao cho có ít điểm bị misclassified nhất. Việc này có thể được thực hiện thông qua PLA với một chút thay đổi nhỏ như sau:\nThuật toán này giống với thuật toán tìm phần tử nhỏ nhất trong 1 mảng.\n\nHy vọng rằng bài viết này sẽ giúp các bạn phần nào hiểu được một số khái niệm trong Neural Networks. Trong một số bài tiếp theo, tôi sẽ tiếp tục nói về các thuật toán cơ bản khác trong Neural Networks trước khi chuyển sang phần khác.\nTrong tương lai, nếu có thể, tôi sẽ viết tiếp về Deep Learning và chúng ta sẽ lại quay lại với Neural Networks.\n\n[1] F. Rosenblatt. The perceptron, a perceiving and recognizing automaton Project Para. Cornell Aeronautical Laboratory, 1957.\n[2] W. S. McCulloch and W. Pitts. A logical calculus of the ideas immanent in nervous activity. The bulletin of mathematical biophysics, 5(4):115–133, 1943.\n[3] B. Widrow et al. Adaptive ”Adaline” neuron using chemical ”memistors”. Number Technical Report 1553-2. Stanford Electron. Labs., Stanford, CA, October 1960.\n[3] Abu-Mostafa, Yaser S., Malik Magdon-Ismail, and Hsuan-Tien Lin. Learning from data. Vol. 4. New York, NY, USA:: AMLBook, 2012. (link to course)\n[4] Bishop, Christopher M. “Pattern recognition and Machine Learning.”, Springer  (2006). (book)\n[5] Duda, Richard O., Peter E. Hart, and David G. Stork. Pattern classification. John Wiley & Sons, 2012."
    },
    {
        "ID": 42,
        "URL": "https://machinelearningcoban.com/2017/01/16/gradientdescent2/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong phần 1 của Gradient Descent (GD), tôi đã giới thiệu với bạn đọc về thuật toán Gradient Descent. Tôi xin nhắc lại rằng nghiệm cuối cùng của Gradient Descent phụ thuộc rất nhiều vào điểm khởi tạo và learning rate. Trong bài này, tôi xin đề cập một vài phương pháp thường được dùng để khắc phục những hạn chế của GD. Đồng thời, các thuật toán biến thể của GD thường được áp dụng trong các mô hình Deep Learning cũng sẽ được tổng hợp.\nTrong trang này:\n\n\n\n\nDành cho các bạn chưa đọc phần 1 của Gradient Descent. Để giải bài toán tìm điểm global optimal của hàm mất mát \\(J(\\theta)\\) (Hàm mất mát cũng thường được ký hiệu là \\(J()\\) với \\(\\theta\\) là tập hợp các tham số của mô hình), tôi xin nhắc lại thuật toán GD:\nThuật toán Gradient Descent:\n\nvới \\(\\nabla_{\\theta}J(\\theta)\\) là đạo hàm của hàm mất mát tại \\(\\theta\\).\n\nThuật toán GD thường được ví với tác dụng của trọng lực lên một hòn bi đặt trên một mặt có dạng như hình một thung lũng giống như hình 1a) dưới đây. Bất kể ta đặt hòn bi ở A hay B thì cuối cùng hòn bi cũng sẽ lăn xuống và kết thúc ở vị trí C.\nTuy nhiên, nếu như bề mặt có hai đáy thung lũng như Hình 1b) thì tùy vào việc đặt bi ở A hay B, vị trí cuối cùng của bi sẽ ở C hoặc D. Điểm D là một điểm local minimum chúng ta không mong muốn.\nNếu suy nghĩ một cách vật lý hơn, vẫn trong Hình 1b), nếu vận tốc ban đầu của bi khi ở điểm B đủ lớn, khi bi lăn đến điểm D, theo đà, bi có thể tiếp tục di chuyển lên dốc phía bên trái của D. Và nếu giả sử vận tốc ban đầu lớn hơn nữa, bi có thể vượt dốc tới điểm E rồi lăn xuống C như trong Hình 1c). Đây chính là điều chúng ta mong muốn. Bạn đọc có thể đặt câu hỏi rằng liệu bi lăn từ A tới C có theo đà lăn tới E rồi tới D không. Xin trả lời rằng điều này khó xảy ra hơn vì nếu so với dốc DE thì dốc CE cao hơn nhiều.\nDựa trên hiện tượng này, một thuật toán được ra đời nhằm khắc phục việc nghiệm của GD rơi vào một điểm local minimum không mong muốn. Thuật toán đó có tên là Momentum (tức theo đà trong tiếng Việt).\n\nĐể biểu diễn momentum bằng toán học thì chúng ta phải làm thế nào?\nTrong GD, chúng ta cần tính lượng thay đổi ở thời điểm \\(t\\) để cập nhật vị trí mới cho nghiệm (tức hòn bi). Nếu chúng ta coi đại lượng này như vận tốc \\(v_t\\) trong vật lý, vị trí mới của hòn bi sẽ là \\(\\theta_{t+1} = \\theta_{t} - v_t\\). Dấu trừ thể hiện việc phải di chuyển ngược với đạo hàm. Công việc của chúng ta bây giờ là tính đại lượng \\(v_t\\) sao cho nó vừa mang thông tin của độ dốc (tức đạo hàm), vừa mang thông tin của đà, tức vận tốc trước đó \\(v_{t-1}\\) (chúng ta coi như vận tốc ban đầu \\(v_0=0\\)). Một cách đơn giản nhất, ta có thể cộng (có trọng số) hai đại lượng này lại:\n\\[\nv_{t}= \\gamma v_{t-1} + \\eta \\nabla_{\\theta}J(\\theta)\n\\]\nTrong đó \\(\\gamma\\) thường được chọn là một giá trị khoảng 0.9, \\(v_t\\) là vận tốc tại thời điểm trước đó, \\( \\nabla_{\\theta}J(\\theta)\\) chính là độ dốc của điểm trước đó. \nSau đó vị trí mới của hòn bi được xác định như sau:\n\\[\n\\theta = \\theta - v_t\n\\]\nThuật toán đơn giản này tỏ ra rất hiệu quả trong các bài toán thực tế (trong không gian nhiều chiều, cách tính toán cũng hoàn tòan tương tự). Dưới đây là một ví dụ trong không gian một chiều.\n\nChúng ta xem xét một hàm đơn giản có hai điểm local minimum, trong đó 1 điểm là global minimum:\n\\[\nf(x) = x^2 + 10\\sin(x)\n\\]\nCó đạo hàm là: \\(f’(x) = 2x + 10\\cos(x)\\). Hình 2 dưới đây thể hiện sự khác nhau giữa thuật toán GD và thuật toán GD với Momentum:\nHình bên trái là đường đi của nghiệm khi không sử dụng Momentum, thuật toán hội tụ sau chỉ 5 vòng lặp nhưng nghiệm tìm được là nghiệm local minimun.\nHình bên phải là đường đi của nghiệm khi có sử dụng Momentum, hòn bi đã có thể vượt dốc tới khu vực gần điểm global minimun, sau đó dao động xung quanh điểm này, giảm tốc rồi cuối cùng tới đích. Mặc dù mất nhiều vòng lặp hơn, GD với Momentum cho chúng ta nghiệm chính xác hơn. Quan sát đường đi của hòn bi trong trường hợp này, chúng ta thấy rằng điều này giống với vật lý hơn!\nNếu biết trước điểm đặt bi ban đầu theta, đạo hàm của hàm mất mát tại một điểm bất kỳ grad(theta), lượng thông tin lưu trữ từ vận tốc trước đó gamma và learning rate eta, chúng ta có thể viết hàm số GD_momentum trong Python như sau:\n\nMomentum giúp hòn bi vượt qua được dốc locaminimum, tuy nhiên, có một hạn chế chúng ta có thể thấy trong ví dụ trên: Khi tới gần đích, momemtum vẫn mất khá nhiều thời gian trước khi dừng lại. Lý do lại cũng chính là vì có đà. Có một phương pháp khác tiếp tục giúp khắc phục điều này, phương pháp đó mang tên Nesterov accelerated gradient (NAG), giúp cho thuật toán hội tụ nhanh hơn.\n\nÝ tưởng cơ bản là dự đoán hướng đi trong tương lai, tức nhìn trước một bước! Cụ thể, nếu sử dụng số hạng momentum \\(\\gamma v_{t-1}\\) để cập nhật thì ta có thể xấp xỉ được vị trí tiếp theo của hòn bi là \\(\\theta - \\gamma v_{t-1}\\) (chúng ta không đính kèm phần gradient ở đây vì sẽ sử dụng nó trong bước cuối cùng). Vậy, thay vì sử dụng gradient của điểm hiện tại, NAG đi trước một bước, sử dụng gradient của điểm tiếp theo. Theo dõi hình dưới đây:\nVới momentum thông thường: lượng thay đổi là tổng của hai vector: momentum vector và gradient ở thời điểm hiện tại.\nVới Nesterove momentum: lượng thay đổi là tổng của hai vector: momentum vector và gradient ở thời điểm được xấp xỉ là điểm tiếp theo.\n\nCông thức cập nhật của NAG được cho như sau:\n\\[\n\\begin{eqnarray}\nv_{t} &=& \\gamma v_{t-1} + \\eta \\nabla_{\\theta}J(\\theta - \\gamma v_{t-1}) \\\n\\theta &=& \\theta -  v_{t}\n\\end{eqnarray}\n\\]\nĐể ý một chút các bạn sẽ thấy điểm được tính đạo hàm đã thay đổi.\n\nDưới đây là ví dụ so sánh Momentum và NAG cho bài toán Linear Regression:\nHình bên trái là đường đi của nghiệm với phương pháp Momentum. nghiệm đi khá là zigzag và mất nhiều vòng lặp hơn. Hình bên phải là đường đi của nghiệm với phương pháp NAG, nghiệm hội tụ nhanh hơn, và đường đi ít zigzag hơn.\n(Source code cho hình bên trái và  hình bên phải).\n\nNgoài hai thuật toán trên, có rất nhiều thuật toán nâng cao khác được sử dụng trong các bài toán thực tế, đặc biệt là các bài toán Deep Learning. Có thể nêu một vài từ khóa như Adagrad, Adam, RMSprop,… Tôi sẽ không đề cập đến các thuật toán đó trong bài này mà sẽ dành thời gian nói tới nếu có dịp trong tương lai, khi blog đã đủ lớn và đã trang bị cho các bạn một lượng kiến thức nhất định.\nTuy nhiên, bạn đọc nào muốn đọc thêm có thể tìm được rất nhiều thông tin hữu ích trong bài này:\nAn overview of gradient descent optimization algorithms .\n\nTôi xin một lần nữa dùng bài toán Linear Regression làm ví dụ. Hàm mất mát và đạo hàm của nó cho bài toán này lần lượt là (để cho thuận tiện, trong bài này tôi sẽ dùng ký hiệu \\(\\mathbf{X}\\) thay cho dữ liệu mở rộng \\(\\bar{\\mathbf{X}}\\)):\n\\[\nJ(\\mathbf{w}) = \\frac{1}{2N}||\\mathbf{X}\\mathbf{w} - \\mathbf{y}||_2^2\n\\]\n\\[\n~~~~ = \\frac{1}{2N} \\sum_{i=1}^N(\\mathbf{x}_i \\mathbf{w} - y_i)^2\n\\]\nvà:\n\\[\n\\nabla_{\\mathbf{w}} J(\\mathbf{w}) = \\frac{1}{N}\\sum_{i=1}^N \\mathbf{x}_i^T(\\mathbf{x}_i\\mathbf{w} - y_i)\n\\]\n\nThuật toán Gradient Descent chúng ta nói từ đầu phần 1 đến giờ còn được gọi là Batch Gradient Descent. Batch ở đây được hiểu là tất cả, tức khi cập nhật \\(\\theta = \\mathbf{w}\\), chúng ta sử dụng tất cả các điểm dữ liệu \\(\\mathbf{x}_i\\).\nCách làm này có một vài hạn chế đối với cơ sở dữ liệu có vô cùng nhiều điểm (hơn 1 tỉ người dùng của facebook chẳng hạn). Việc phải tính toán lại đạo hàm với tất cả các điểm này sau mỗi vòng lặp trở nên cồng kềnh và không hiệu quả. Thêm nữa, thuật toán này được coi là không hiệu quả với online learning.\n\nOnline learning là khi cơ sở dữ liệu được cập nhật liên tục (thêm người dùng đăng ký hàng ngày chẳng hạn), mỗi lần thêm vài điểm dữ liệu mới. Kéo theo đó là mô hình của chúng ta cũng phải thay đổi một chút để phù hợp với các dữ liệu mới này. Nếu làm theo Batch Gradient Descent, tức tính lại đạo hàm của hàm mất mát tại tất cả các điểm dữ liệu, thì thời gian tính toán sẽ rất lâu, và thuật toán của chúng ta coi như không online nữa do mất quá nhiều thời gian tính toán.\nTrên thực tế, có một thuật toán đơn giản hơn và tỏ ra rất hiệu quả, có tên gọi là Stochastic Gradient Descent (SGD).\n\nTrong thuật toán này, tại 1 thời điểm, ta chỉ tính đạo hàm của hàm mất mát dựa trên chỉ một điểm dữ liệu \\(\\mathbf{x_i}\\) rồi cập nhật \\(\\theta\\) dựa trên đạo hàm này. Việc này được thực hiện với từng điểm trên toàn bộ dữ liệu, sau đó lặp lại quá trình trên. Thuật toán rất đơn giản này trên thực tế lại làm việc rất hiệu quả.\nMỗi lần duyệt một lượt qua tất cả các điểm trên toàn bộ dữ liệu được gọi là một epoch. Với GD thông thường thì mỗi epoch ứng với 1 lần cập nhật \\(\\theta\\), với SGD thì mỗi epoch ứng với \\(N\\) lần cập nhật \\(\\theta\\) với \\(N\\) là số điểm dữ liệu. Nhìn vào một mặt, việc cập nhật từng điểm một như thế này có thể làm giảm đi tốc độ thực hiện 1 epoch. Nhưng nhìn vào một mặt khác, SGD chỉ yêu cầu một lượng epoch rất nhỏ (thường là 10 cho lần đầu tiên, sau đó khi có dữ liệu mới thì chỉ cần chạy dưới một epoch là đã có nghiệm tốt). Vì vậy SGD phù hợp với các bài toán có lượng cơ sở dữ liệu lớn (chủ yếu là Deep Learning mà chúng ta sẽ thấy trong phần sau của blog) và các bài toán yêu cầu mô hình thay đổi liên tục, tức online learning.\nThứ tự lựa chọn điểm dữ liệu\nMột điểm cần lưu ý đó là: sau mỗi epoch, chúng ta cần shuffle (xáo trộn) thứ tự của các dữ liệu để đảm bảo tính ngẫu nhiên. Việc này cũng ảnh hưởng tới hiệu năng của SGD.\nMột cách toán học, quy tắc cập nhật của SGD là:\n\\[\n\\theta = \\theta - \\eta \\nabla_{\\theta} J(\\theta; \\mathbf{x}_i; \\mathbf{y}_i)\n\\]\ntrong đó \\(J(\\theta; \\mathbf{x}_i; \\mathbf{y}_i)\\) là hàm mất mát với chỉ 1 cặp điểm dữ liệu (input, label) là (\\(\\mathbf{x}_i, \\mathbf{y}_i\\)). Chú ý: chúng ta hoàn toàn có thể áp dụng các thuật toán tăng tốc GD như Momentum, AdaGrad,… vào SGD.\n\nVới bài toán Linear Regression, \\(\\theta = \\mathbf{w}\\), hàm mất mát tại một điểm dữ liệu là:\n\\[\nJ(\\mathbf{w}; \\mathbf{x}_i; y_i) = \\frac{1}{2}(\\mathbf{x}_i \\mathbf{w} - y_i)^2\n\\]\nĐạo hàm theo \\(\\mathbf{w}\\) tương ứng là:\n\\[\n\\nabla_{\\mathbf{w}}J(\\mathbf{w}; \\mathbf{x}_i; y_i) = \\mathbf{x}_i^T(\\mathbf{x}_i \\mathbf{w} - y_i)\n\\]\nVà dưới đây là hàm số trong python để giải Linear Regression theo SGD:\nKết quả được cho như hình dưới đây (với dữ liệu được tạo giống như ở phần 1).\nHình bên trái mô tả đường đi của nghiệm. Chúng ta thấy rằng đường đi khá là zigzag chứ không mượt như khi sử dụng GD. Điều này là dễ hiểu vì một điểm dữ liệu không thể đại diện cho toàn bộ dữ liệu được. Tuy nhiên, chúng ta cũng thấy rằng thuật toán hội tụ khá nhanh đến vùng lân cận của nghiệm. Với 1000 điểm dữ liệu, SGD chỉ cần gần 3 epoches (2911 tương ứng với 2911 lần cập nhật, mỗi lần lấy 1 điểm). Nếu so với con số 49 vòng lặp (epoches) như kết quả tốt nhất có được bằng GD, thì kết quả này lợi hơn rất nhiều.\nHình bên phải mô tả hàm mất mát cho toàn bộ dữ liệu sau khi chỉ sử dụng 50 điểm dữ liệu đầu tiên. Mặc dù không mượt, tốc độ hội tụ vẫn rất nhanh.\nThực tế cho thấy chỉ lấy khoảng 10 điểm là ta đã có thể xác định được gần đúng phương trình đường thẳng cần tìm rồi. Đây chính là ưu điểm của SGD - hội tụ rất nhanh.\n\nKhác với SGD, mini-batch sử dụng một số lượng \\(n\\) lớn hơn 1 (nhưng vẫn nhỏ hơn tổng số dữ liệu \\(N\\)rất nhiều). Giống với SGD, Mini-batch Gradient Descent bắt đầu mỗi epoch bằng việc xáo trộn ngẫu nhiên dữ liệu rồi chia toàn bộ dữ liệu thành các mini-batch, mỗi mini-batch có \\(n\\) điểm dữ liệu (trừ mini-batch cuối có thể có ít hơn nếu \\(N\\) không chia hết cho \\(n\\)). Mỗi lần cập nhật, thuật toán này lấy ra một mini-batch để tính toán đạo hàm rồi cập nhật. Công thức có thể viết dưới dạng:\n\\[\n\\theta = \\theta - \\eta\\nabla_{\\theta} J(\\theta; \\mathbf{x}_{i:i+n}; \\mathbf{y}_{i:i+n})\n\\]\nVới \\(\\mathbf{x}_{i:i+n}\\) được hiểu là dữ liệu từ thứ \\(i\\) tới thứ \\(i+n-1\\) (theo ký hiệu của Python). Dữ liệu này sau mỗi epoch là khác nhau vì chúng cần được xáo trộn. Một lần nữa, các thuật toán khác cho GD như Momentum, Adagrad, Adadelta,… cũng có thể được áp dụng vào đây.\nMini-batch GD được sử dụng trong hầu hết các thuật toán Machine Learning, đặc biệt là trong Deep Learning. Giá trị \\(n\\) thường được chọn là khoảng từ 50 đến 100.\nDưới đây là ví dụ về giá trị của hàm mất mát mỗi khi cập nhật tham số \\(\\theta\\) của một bài toán khác phức tạp hơn.\nĐể có thêm thông tin chi tiết hơn, bạn đọc có thể tìm trong bài viết rất tốt này.\n\nCó một điểm cũng quan trọng mà từ đầu tôi chưa nhắc đến: khi nào thì chúng ta biết thuật toán đã hội tụ và dừng lại?\nTrong thực nghiệm, có một vài phương pháp như dưới đây:\n\nNhân tiện đang nói về tối ưu, tôi xin giới thiệu một phương pháp nữa có cách giải thích đơn giản: Newton’s method. Các phương pháp GD tôi đã trình bày còn được gọi là first-order methods, vì lời giải tìm được dựa trên đạo hàm bậc nhất của hàm số. Newton’s method là một second-order method, tức lời giải yêu cầu tính đến đạo hàm bậc hai.\nNhắc lại rằng, cho tới thời điểm này, chúng ta luôn giải phương trình đạo hàm của hàm mất mát bằng 0 để tìm các điểm local minimun. (Và trong nhiều trường hợp, coi nghiệm tìm được là nghiệm của bài toán tìm giá trị nhỏ nhất của hàm mất mát). Có một thuật toán nối tiếng giúp giải bài toán \\(f(x) = 0\\), thuật toán đó có tên là Newton’s method.\n\nThuật toán Newton’s method được mô tả trong hình động minh họa dưới đây:\nÝ tưởng giải bài toán \\(f(x) = 0\\) bằng phương pháp Newton’s method như sau. Xuất phát từ một điểm \\(x_0\\) được cho là gần với nghiệm \\(x^*\\). Sau đó vẽ đường tiếp tuyến (mặt tiếp tuyến trong không gian nhiều chiều) với đồ thị hàm số \\(y = f(x)\\) tại điểm trên đồ thị có hoành độ \\(x_0\\). Giao điểm \\(x_1\\) của đường tiếp tuyến này với trục hoành được xem là gần với nghiệm \\(x^*\\) hơn. Thuật toán lặp lại với điểm mới \\(x_1\\) và cứ như vậy đến khi ta được \\(f(x_t) \\approx 0\\).\nĐó là ý nghĩa hình học của Newton’s method, chúng ta cần một công thức để có thể dựa vào đó để lập trình. Việc này không quá phức tạp với các bạn thi đại học môn toán ở VN. Thật vậy, phương trình tiếp tuyến với đồ thị của hàm \\(f(x)\\) tại điểm có hoành độ \\(x_t\\) là:\n\\[\ny = f’(x_t)(x - x_t) + f(x_t)\n\\]\nGiao điểm của đường thẳng này với trục \\(x\\) tìm được bằng cách giải phương trình vế phải của biểu thức trên bằng 0, tức là:\n\\[\nx = x_t - \\frac{f(x_t)}{f’(x_t)} \\triangleq x_{t+1}\n\\]\n\nÁp dụng phương pháp này cho việc giải phương trình \\(f’(x) = 0\\) ta có:\n\\[\nx_{t+1} = x_t -(f”(x_t))^{-1}{f’(x_t)}\n\\]\nVà trong không gian nhiều chiều với \\(\\theta\\) là biến:\n\\[\n\\theta = \\theta - \\mathbf{H}(J(\\theta))^{-1} \\nabla_{\\theta} J(\\theta)\n\\]\ntrong đó \\(\\mathbf{H}(J(\\theta))\\) là đạo hàm bậc hai của hàm mất mất (còn gọi là Hessian matrix). Biểu thức này là một ma trận nếu \\(\\theta\\) là một vector. Và \\(\\mathbf{H}(J(\\theta))^{-1}\\) chính là nghịch đảo của ma trận đó.\n\nNhận thấy rằng trong việc giải phương trình \\(f(x) = 0\\), chúng ta có đạo hàm ở mẫu số. Khi đạo hàm này gần với 0, ta sẽ được một đường thằng song song hoặc gần song song với trục hoành. Ta sẽ hoặc không tìm được giao điểm, hoặc được một giao điểm ở vô cùng. Đặc biệt, khi nghiệm chính là điểm có đạo hàm bằng 0, thuật toán gần như sẽ không tìm được nghiệm!\nKhi áp dụng Newton’s method cho bài toán tối ưu trong không gian nhiều chiều, chúng ta cần tính nghịch đảo của Hessian matrix. Khi số chiều và số điểm dữ liệu lớn, đạo hàm bậc hai của hàm mất mát sẽ là một ma trận rất lớn, ảnh hưởng tới cả memory và tốc độ tính toán của hệ thống.\n\nQua hai bài viết về Gradient Descent này, tôi hy vọng các bạn đã hiểu và làm quen với một thuật toán tối ưu được sử dụng nhiều nhất trong Machine Learning và đặc biệt là Deep Learning. Còn nhiều biến thể khác khá thú vị về GD (mà rất có thể tôi chưa biết tới), nhưng tôi xin phép được dừng chuỗi bài về GD tại đây và tiếp tục chuyển sang các thuật toán thú vị khác.\nHy vọng bài viết có ích với các bạn.\n\n[1] Newton’s method - Wikipedia\n[2] An overview of gradient descent optimization algorithms\n[3] Stochastic Gradient Descent - Wikipedia\n[4] Stochastic Gradient Descen - Andrew Ng\n[5] Nesterov, Y. (1983). A method for unconstrained convex minimization problem with the rate of convergence o(1/k2). Doklady ANSSSR (translated as Soviet.Math.Docl.), vol. 269, pp. 543– 547."
    },
    {
        "ID": 43,
        "URL": "https://machinelearningcoban.com/2017/01/12/gradientdescent/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\nCác bạn hẳn thấy hình vẽ dưới đây quen thuộc:\nĐiểm màu xanh lục là điểm local minimum (cực tiểu), và cũng là điểm làm cho hàm\nsố đạt giá trị nhỏ nhất. Từ đây trở đi, tôi sẽ dùng local minimum để thay cho\nđiểm cực tiểu, global minimum để thay cho điểm mà tại đó hàm số đạt giá trị\nnhỏ nhất. Global minimum là một trường hợp đặc biệt của local minimum.\nGiả sử chúng ta đang quan tâm đến một hàm số một biến có đạo hàm mọi nơi. Xin\ncho tôi được nhắc lại vài điều đã quá quen thuộc:\nĐiểm local minimum \\(x^*\\) của hàm số là điểm có đạo hàm \\(f’(x^*)\\)\nbằng 0. Hơn thế nữa, trong lân cận của nó, đạo hàm của các điểm phía bên trái\n\\(x^*\\) là không dương, đạo hàm của các điểm phía bên phải \\(x^*\\) là\nkhông âm.\nĐường tiếp tuyến với đồ thị hàm số đó tại 1 điểm bất kỳ có hệ số góc chính\nbằng đạo hàm của hàm số tại điểm đó.\nTrong hình phía trên, các điểm bên trái của điểm local minimum màu xanh lục có\nđạo hàm âm, các điểm bên phải có đạo hàm dương. Và đối với hàm số này, càng xa\nvề phía trái của điểm local minimum thì đạo hàm càng âm, càng xa về phía phải\nthì đạo hàm càng dương.\n\nTrong Machine Learning nói riêng và Toán Tối Ưu nói chung, chúng ta thường xuyên\nphải tìm giá trị nhỏ nhất (hoặc đôi khi là lớn nhất) của một hàm số nào đó. Ví\ndụ như các hàm mất mát trong hai bài Linear Regression \nvà K-means Clustering. Nhìn chung, việc tìm global\nminimum của các hàm mất mát trong Machine Learning là rất phức tạp, thậm chí là\nbất khả thi. Thay vào đó, người ta thường cố gắng tìm các điểm local minimum, và\nở một mức độ nào đó, coi đó là nghiệm cần tìm của bài toán.\nCác điểm local minimum là nghiệm của phương trình đạo hàm bằng 0. Nếu bằng một\ncách nào đó có thể tìm được toàn bộ (hữu hạn) các điểm cực tiểu, ta chỉ cần thay\ntừng điểm local minimum đó vào hàm số rồi tìm điểm làm cho hàm có giá trị nhỏ\nnhất (đoạn này nghe rất quen thuộc, đúng không?). Tuy nhiên, trong hầu hết các\ntrường hợp, việc giải phương trình đạo hàm bằng 0 là bất khả thi. Nguyên nhân có\nthể đến từ sự phức tạp của dạng của đạo hàm, từ việc các điểm dữ liệu có số\nchiều lớn, hoặc từ việc có quá nhiều điểm dữ liệu.\nHướng tiếp cận phổ biến nhất là xuất phát từ một điểm mà chúng ta coi là gần\nvới nghiệm của bài toán, sau đó dùng một phép toán lặp để tiến dần đến điểm\ncần tìm, tức đến khi đạo hàm gần với 0. Gradient Descent (viết gọn là GD) và các\nbiến thể của nó là một trong những phương pháp được dùng nhiều nhất.\n\nVì kiến thức về GD khá rộng nên tôi xin phép được chia thành hai phần. Phần 1\nnày giới thiệu ý tưởng phía sau thuật toán GD và một vài ví dụ đơn giản giúp các\nbạn làm quen với thuật toán này và vài khái niệm mới. Phần 2 sẽ nói về các\nphương pháp cải tiến GD và các biến thể của GD trong các bài toán mà số chiều và\nsố điểm dữ liệu lớn. Những bài toán như vậy được gọi là large-scale.\n\nQuay trở lại hình vẽ ban đầu và một vài quan sát tôi đã nêu. Giả sử\n\\(x_{t}\\) là điểm ta tìm được sau vòng lặp thứ \\(t\\). Ta cần tìm một thuật\ntoán để đưa \\(x_{t}\\) về càng gần \\(x^*\\) càng tốt.\nTrong hình đầu tiên, chúng ta lại có thêm hai quan sát nữa:\nNếu đạo hàm của hàm số tại \\(x_{t}\\): \\(f’(x_{t}) > 0\\) thì\n\\(x_{t}\\) nằm về bên phải so với \\(x^*\\) (và ngược lại). Để điểm tiếp\ntheo \\(x_{t+1}\\) gần với \\(x^*\\) hơn, chúng ta cần di chuyển\n\\(x_{t}\\) về phía bên trái, tức về phía âm. Nói các khác, chúng ta cần\ndi chuyển ngược dấu với đạo hàm:\n\\[\nx_{t+1} = x_{t} + \\Delta\n\\]\nTrong đó \\(\\Delta\\) là một đại lượng ngược dấu với đạo hàm \\(f’(x_{t})\\).\n\\(x_{t}\\) càng xa \\(x^*\\) về phía bên phải thì \\(f’(x_{t})\\) càng lớn\nhơn 0 (và ngược lại). Vậy, lượng di chuyển \\(\\Delta\\), một cách trực quan\nnhất, là tỉ lệ thuận với \\(-f’(x_{t})\\).\nHai nhận xét phía trên cho chúng ta một cách cập nhật đơn giản là:\n\\[\nx_{t+1} = x_{t} - \\eta f’(x_{t})\n\\]\nTrong đó \\(\\eta\\) (đọc là eta) là một số dương được gọi là learning rate\n(tốc độ học). Dấu trừ thể hiện việc chúng ta phải đi ngược với đạo hàm (Đây\ncũng chính là lý do phương pháp này được gọi là Gradient Descent - descent\nnghĩa là đi ngược). Các quan sát đơn giản phía trên, mặc dù không phải đúng\ncho tất cả các bài toán, là nền tảng cho rất nhiều phương pháp tối ưu nói chung\nvà thuật toán Machine Learning nói riêng.\n\nXét hàm số \\(f(x) = x^2 + 5\\sin(x)\\) với đạo hàm \\(f’(x) = 2x + 5\\cos(x)\\)\n(một lý do tôi chọn hàm này vì nó không dễ tìm nghiệm của đạo hàm bằng 0 như hàm\nphía trên). Giả sử bắt đầu từ một điểm \\(x_{0}\\) nào đó, tại vòng lặp thứ\n\\(t\\), chúng ta sẽ cập nhật như sau:\n\\[\nx_{t+1} = x_{t} - \\eta(2x_{t} + 5\\cos(x_{t}))\n\\]\nNhư thường lệ, tôi khai báo vài thư viện quen thuộc\nTiếp theo, tôi viết các hàm số :\n\nSau khi có các hàm cần thiết, tôi thử tìm nghiệm với các điểm khởi tạo khác nhau\nlà \\(x_{0} = -5\\) và \\(x_{0} = 5\\).\nVậy là với các điểm ban đầu khác nhau, thuật toán của chúng ta tìm được nghiệm\ngần giống nhau, mặc dù với tốc độ hội tụ khác nhau. Dưới đây là hình ảnh minh\nhọa thuật toán GD cho bài toán này (xem tốt trên Desktop ở chế độ full màn\nhình).\nTừ hình minh họa trên ta thấy rằng ở hình bên trái, tương ứng với \\(x_{0} = -5\\), nghiệm hội tụ nhanh hơn, vì điểm ban đầu \\(x_0\\) gần với nghiệm \\( x^* \\approx -1\\)  hơn. Hơn nữa, với \\(x_{0} = 5 \\) ở hình bên phải, đường đi của nghiệm có chứa một khu vực có đạo hàm khá nhỏ gần điểm có hoành độ bằng 2. Điều này khiến cho thuật toán la cà ở đây khá lâu. Khi vượt qua được điểm này thì mọi việc diễn ra rất tốt đẹp.\n\nTốc độ hội tụ của GD không những phụ thuộc vào điểm khởi tạo ban đầu mà còn phụ thuộc vào learning rate. Dưới đây là một ví dụ với cùng điểm khởi tạo \\(x_{0} = -5\\) nhưng learning rate khác nhau:\nTa quan sát thấy hai điều:\nViệc lựa chọn learning rate rất quan trọng trong các bài toán thực tế. Việc\nlựa chọn giá trị này phụ thuộc nhiều vào từng bài toán và phải làm một vài thí\nnghiệm để chọn ra giá trị tốt nhất. Ngoài ra, tùy vào một số bài toán, GD có thể\nlàm việc hiệu quả hơn bằng cách chọn ra learning rate phù hợp hoặc chọn\nlearning rate khác nhau ở mỗi vòng lặp. Tôi sẽ quay lại vấn đề này ở phần 2.\n\nGiả sử ta cần tìm global minimum cho hàm \\(f(\\mathbf{\\theta})\\) trong đó\n\\(\\mathbf{\\theta}\\) (theta) là một vector, thường được dùng để ký hiệu tập\nhợp các tham số của một mô hình cần tối ưu (trong Linear Regression thì các tham\nsố chính là hệ số \\(\\mathbf{w}\\)). Đạo hàm của hàm số đó tại một điểm\n\\(\\theta\\) bất kỳ được ký hiệu là \\(\\nabla_{\\theta}f(\\theta)\\) (hình tam\ngiác ngược đọc là nabla). Tương tự như hàm 1 biến, thuật toán GD cho hàm nhiều\nbiến cũng bắt đầu bằng một điểm dự đoán \\(\\theta_{0}\\), sau đó, ở vòng lặp\nthứ \\(t\\), quy tắc cập nhật là:\n\\[\n\\theta_{t+1} = \\theta_{t} - \\eta \\nabla_{\\theta} f(\\theta_{t})\n\\]\nHoặc viết dưới dạng đơn giản hơn: \\(\\theta = \\theta - \\eta \\nabla_{\\theta} f(\\theta)\\).\nQuy tắc cần nhớ: luôn luôn đi ngược hướng với đạo hàm.\nViệc tính toán đạo hàm của các hàm nhiều biến là một kỹ năng cần thiết. Một vài đạo hàm đơn giản có thể được tìm thấy ở đây.\n\nTrong mục này, chúng ta quay lại với bài toán Linear Regression và thử tối ưu hàm mất mát của nó bằng thuật toán GD.\nHàm mất mát của Linear Regression là: \n\\[\n\\mathcal{L}(\\mathbf{w}) = \\frac{1}{2N}||\\mathbf{y - \\bar{X}w}||_2^2\n\\]\nChú ý: hàm này có khác một chút so với hàm tôi nêu trong bài Linear Regression. Mẫu số có thêm \\(N\\) là số lượng dữ liệu trong training set. Việc lấy trung bình cộng của lỗi này nhằm giúp tránh trường hợp hàm mất mát và đạo hàm có giá trị là một số rất lớn, ảnh hưởng tới độ chính xác của các phép toán khi thực hiện trên máy tính. Về mặt toán học, nghiệm của hai bài toán là như nhau.\nĐạo hàm của hàm mất mát là:\n\\[\n\\nabla_{\\mathbf{w}}\\mathcal{L}(\\mathbf{w}) = \n\\frac{1}{N}\\mathbf{\\bar{X}}^T \\mathbf{(\\bar{X}w - y)} ~~~~~(1)\n\\]\n\nLoad thư viện\nTiếp theo, chúng ta tạo 1000 điểm dữ liệu được chọn gần với đường thẳng \\(y = 4 + 3x\\), hiển thị chúng và tìm nghiệm theo công thức:\nĐường thẳng tìm được là đường có màu vàng có phương trình \\(y \\approx 4 + 2.998x\\).\nTiếp theo ta viết đạo hàm và hàm mất mát:\n\nViệc tính đạo hàm của hàm nhiều biến thông thường khá phức tạp và rất dễ mắc lỗi, nếu chúng ta tính sai đạo hàm thì thuật toán GD không thể chạy đúng được. Trong thực nghiệm, có một cách để kiểm tra liệu đạo hàm tính được có chính xác không. Cách này dựa trên định nghĩa của đạo hàm (cho hàm 1 biến):\n\\[\nf’(x) = \\lim_{\\varepsilon \\rightarrow 0}\\frac{f(x + \\varepsilon) - f(x)}{\\varepsilon}\n\\]\nMột cách thường được sử dụng là lấy một giá trị \\(\\varepsilon \\) rất nhỏ, ví dụ \\(10^{-6}\\), và sử dụng công thức:\n\\[\nf’(x) \\approx \\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2\\varepsilon} ~~~~ (2)\n\\]\nCách tính này được gọi là numerical gradient.\nCâu hỏi: Tại sao công thức xấp xỉ hai phía trên đây lại được sử dụng rộng rãi, sao không sử dụng công thức xấp xỉ đạo hàm bên phải hoặc bên trái?\nCó hai các giải thích cho vấn đề này, một bằng hình học, một bằng giải tích.\n\nQuan sát hình dưới đây:\n\nTrong hình, vector màu đỏ là đạo hàm chính xác của hàm số tại điểm có hoành độ bằng \\(x_0\\). Vector màu xanh lam (có vẻ là hơi tím sau khi convert từ .pdf sang .png) thể hiện cách xấp xỉ đạo hàm phía phải. Vector màu xanh lục thể hiện cách xấp xỉ đạo hàm phía trái. Vector màu nâu thể hiện cách xấp xỉ đạo hàm hai phía. Trong ba vector xấp xỉ đó, vector xấp xỉ hai phía màu nâu là gần với vector đỏ nhất nếu xét theo hướng.\nSự khác biệt giữa các cách xấp xỉ còn lớn hơn nữa nếu tại điểm x, hàm số bị bẻ cong mạnh hơn. Khi đó, xấp xỉ trái và phải sẽ khác nhau rất nhiều. Xấp xỉ hai bên sẽ ổn định hơn.\n\nChúng ta cùng quay lại một chút với Giải tích I năm thứ nhất đại học: Khai triển Taylor.\nVới \\(\\varepsilon\\) rất nhỏ, ta có hai xấp xỉ sau:\n\\[\nf(x + \\varepsilon) \\approx f(x) + f’(x)\\varepsilon + \\frac{f”(x)}{2} \\varepsilon^2 + \\dots\n\\]\nvà:\n\\[\nf(x - \\varepsilon) \\approx f(x) - f’(x)\\varepsilon + \\frac{f”(x)}{2} \\varepsilon^2 - \\dots\n\\]\nTừ đó ta có: \n\\[\n\\frac{f(x + \\varepsilon) - f(x)}{\\varepsilon} \\approx f’(x) + \\frac{f”(x)}{2}\\varepsilon + \\dots =  f’(x) + O(\\varepsilon) ~~ (3)\n\\]\n\\[\n\\frac{f(x + \\varepsilon) - f(x - \\varepsilon)}{2\\varepsilon} \\approx f’(x) + \\frac{f^{(3)}(x)}{6}\\varepsilon^2 + \\dots =  f’(x) + O(\\varepsilon^2) ~~(4)\n\\]\nTừ đó, nếu xấp xỉ đạo hàm bằng công thức \\((3)\\) (xấp xỉ đạo hàm phải), sai số sẽ là \\(O(\\varepsilon)\\). Trong khi đó, nếu xấp xỉ đạo hàm bằng công thức \\((4)\\) (xấp xỉ đạo hàm hai phía), sai số sẽ là \\(O(\\varepsilon^2) \\ll O(\\varepsilon)\\) nếu \\(\\varepsilon\\) nhỏ.\nCả hai cách giải thích trên đây đều cho chúng ta thấy rằng, xấp xỉ đạo hàm hai\nphía là xấp xỉ tốt hơn.\n\nVới hàm nhiều biến, công thức \\((2)\\) được áp dụng cho từng biến khi các biến\nkhác cố định. Cách tính này thường cho giá trị khá chính xác. Tuy nhiên, cách\nnày không được sử dụng để tính đạo hàm vì độ phức tạp quá cao so với cách tính\ntrực tiếp. Khi so sánh đạo hàm này với đạo hàm chính xác tính theo công thức,\nngười ta thường giảm số chiều dữ liệu và giảm số điểm dữ liệu để thuận tiện cho\ntính toán. Một khi đạo hàm tính được rất gần với numerical gradient, chúng ta\ncó thể tự tin rằng đạo hàm tính được là chính xác.\nDưới đây là một đoạn code đơn giản để kiểm tra đạo hàm và có thể áp dụng với một\nhàm số (của một vector) bất kỳ với cost và grad đã tính ở phía trên.\n(Với các hàm số khác, bạn đọc chỉ cần viết lại hàm grad và cost ở phần trên\nrồi áp dụng đoạn code này để kiểm tra đạo hàm. Nếu hàm số là hàm của một ma trận\nthì chúng ta thay đổi một chút trong hàm numerical_grad, tôi hy vọng không quá\nphức tạp).\nVới bài toán Linear Regression, cách tính đạo hàm như trong \\((1)\\) phía trên\nđược coi là đúng vì sai số giữa hai cách tính là rất nhỏ (nhỏ hơn\n\\(10^{-6}\\)). Sau khi có được đạo hàm chính xác, chúng ta viết hàm cho GD:\nSau 49 vòng lặp, thuật toán đã hội tụ với một nghiệm khá gần với nghiệm tìm được\ntheo công thức.\nDưới đây là hình động minh họa thuật toán GD.\nTrong hình bên trái, các đường thẳng màu đỏ là nghiệm tìm được sau mỗi vòng lặp.\nTrong hình bên phải, tôi xin giới thiệu một thuật ngữ mới: đường đồng mức.\n\nVới đồ thị của một hàm số với hai biến đầu vào cần được vẽ trong không gian ba\nchiều, nhều khi chúng ta khó nhìn được nghiệm có khoảng tọa độ bao nhiêu. Trong\ntoán tối ưu, người ta thường dùng một cách vẽ sử dụng khái niệm đường đồng mức\n(level sets).\nNếu các bạn để ý trong các bản độ tự nhiên, để miêu tả độ cao của các dãy núi,\nngười ta dùng nhiều đường cong kín bao quanh nhau như sau:\nCác vòng nhỏ màu đỏ hơn thể hiện các điểm ở trên cao hơn.\nTrong toán tối ưu, người ta cũng dùng phương pháp này để thể hiện các bề mặt\ntrong không gian hai chiều.\nQuay trở lại với hình minh họa thuật toán GD cho bài toán Liner Regression bên\ntrên, hình bên phải là hình biểu diễn các level sets. Tức là tại các điểm trên\ncùng một vòng, hàm mất mát có giá trị như nhau. Trong ví dụ này, tôi hiển thị\ngiá trị của hàm số tại một số vòng. Các vòng màu xanh có giá trị thấp, các vòng\ntròn màu đỏ phía ngoài có giá trị cao hơn. Điểm này khác một chút so với đường\nđồng mức trong tự nhiên là các vòng bên trong thường thể hiện một thung lũng hơn\nlà một đỉnh núi (vì chúng ta đang đi tìm giá trị nhỏ nhất).\nTôi thử với learning rate nhỏ hơn, kết quả như sau:\nTốc độ hội tụ đã chậm đi nhiều, thậm chí sau 99 vòng lặp, GD vẫn chưa tới gần\nđược nghiệm tốt nhất. Trong các bài toán thực tế, chúng ta cần nhiều vòng lặp\nhơn 99 rất nhiều, vì số chiều và số điểm dữ liệu thường là rất lớn.\n\nĐể kết thúc phần 1 của Gradient Descent, tôi xin nêu thêm một ví dụ khác.\nHàm số \\(f(x, y) = (x^2 + y - 7)^2 + (x - y + 1)^2\\) có hai điểm local minimum\nmàu xanh lục tại \\((2, 3)\\) và \\((-3, -2)\\), và chúng cũng là hai điểm\nglobal minimum. Trong ví dụ này, tùy vào điểm khởi tạo mà chúng ta thu được các\nnghiệm cuối cùng khác nhau.\n\nDựa trên GD, có rất nhiều thuật toán phức tạp và hiệu quả hơn được thiết kế cho\nnhững loại bài toán khác nhau. Vì bài này đã đủ dài, tôi xin phép dừng lại ở\nđây. Mời các bạn đón đọc bài Gradient Descent phần 2 với nhiều kỹ thuật nâng cao\nhơn.\n"
    },
    {
        "ID": 44,
        "URL": "https://machinelearningcoban.com/2017/01/08/knn/",
        "Title": "Machine Learning cơ bản",
        "Content": "Nếu như con người có kiểu học “nước đến chân mới nhảy”, thì trong Machine Learning cũng có một thuật toán như vậy.\nTrong trang này:\n\n\n\nCó một anh bạn chuẩn bị đến ngày thi cuối kỳ. Vì môn này được mở tài liệu khi thi nên anh ta không chịu ôn tập để hiểu ý nghĩa của từng bài học và mối liên hệ giữa các bài. Thay vào đó, anh thu thập tất cả các tài liệu trên lớp, bao gồm ghi chép bài giảng (lecture notes), các slides và bài tập về nhà + lời giải. Để cho chắc, anh ta ra thư viện và các quán Photocopy quanh trường mua hết tất cả các loại tài liệu liên quan (khá khen cho cậu này chịu khó tìm kiếm tài liệu). Cuối cùng, anh bạn của chúng ta thu thập được một chồng cao tài liệu để mang vào phòng thi. \n\nVào ngày thi, anh tự tin mang chồng tài liệu vào phòng thi. Aha, đề này ít nhất mình phải được 8 điểm. Câu 1 giống hệt bài giảng trên lớp. Câu 2 giống hệt đề thi năm ngoái mà lời giải có trong tập tài liệu mua ở quán Photocopy. Câu 3 gần giống với bài tập về nhà. Câu 4 trắc nghiệm thậm chí cậu nhớ chính xác ba tài liệu có ghi đáp án. Câu cuối cùng, 1 câu khó nhưng anh đã từng nhìn thấy, chỉ là không nhớ ở đâu thôi.\nKết quả cuối cùng, cậu ta được 4 điểm, vừa đủ điểm qua môn. Cậu làm chính xác câu 1 vì tìm được ngay trong tập ghi chú bài giảng. Câu 2 cũng tìm được đáp án nhưng lời giải của quán Photocopy sai! Câu ba thấy gần giống bài về nhà, chỉ khác mỗi một số thôi, cậu cho kết quả giống như thế luôn, vậy mà không được điểm nào. Câu 4 thì tìm được cả 3 tài liệu nhưng có hai trong đó cho đáp án A, cái còn lại cho B. Cậu chọn A và được điểm. Câu 5 thì không làm được dù còn tới 20 phút, vì tìm mãi chẳng thấy đáp án đâu - nhiều tài liệu quá cũng mệt!!\nKhông phải ngẫu nhiên mà tôi dành ra ba đoạn văn để kể về chuyện học hành của anh chàng kia. Hôm nay tôi xin trình bày về một phương pháp trong Machine Learning, được gọi là K-nearest neighbor (hay KNN), một thuật toán được xếp vào loại lazy (machine) learning (máy lười học). Thuật toán này khá giống với cách học/thi của anh bạn kém may mắn kia.\n\nK-nearest neighbor là một trong những thuật toán supervised-learning đơn giản nhất (mà hiệu quả trong một vài trường hợp) trong Machine Learning. Khi training, thuật toán này không học một điều gì từ dữ liệu training (đây cũng là lý do thuật toán này được xếp vào loại lazy learning), mọi tính toán được thực hiện khi nó cần dự đoán kết quả của dữ liệu mới. K-nearest neighbor có thể áp dụng được vào cả hai loại của bài toán Supervised learning là Classification và Regression. KNN còn được gọi là một thuật toán Instance-based hay Memory-based learning.\nCó một vài khái niệm tương ứng người-máy như sau:\n\nVới KNN, trong bài toán Classification, label của một điểm dữ liệu mới (hay kết quả của câu hỏi trong bài thi) được suy ra trực tiếp từ K điểm dữ liệu gần nhất trong training set. Label của một test data có thể được quyết định bằng major voting (bầu chọn theo số phiếu) giữa các điểm gần nhất, hoặc nó có thể được suy ra bằng cách đánh trọng số khác nhau cho mỗi trong các điểm gần nhất đó rồi suy ra label. Chi tiết sẽ được nêu trong phần tiếp theo.\nTrong bài toán Regresssion, đầu ra của một điểm dữ liệu sẽ bằng chính đầu ra của điểm dữ liệu đã biết gần nhất (trong trường hợp K=1), hoặc là trung bình có trọng số của đầu ra của những điểm gần nhất, hoặc bằng một mối quan hệ dựa trên khoảng cách tới các điểm gần nhất đó.\nMột cách ngắn gọn, KNN là thuật toán đi tìm đầu ra của một điểm dữ liệu mới bằng cách chỉ dựa trên thông tin của K điểm dữ liệu trong training set gần nó nhất (K-lân cận), không quan tâm đến việc có một vài điểm dữ liệu trong những điểm gần nhất này là nhiễu. Hình dưới đây là một ví dụ về KNN trong classification với K = 1.\nVí dụ trên đây là bài toán Classification với 3 classes: Đỏ, Lam, Lục. Mỗi điểm dữ liệu mới (test data point) sẽ được gán label theo màu của điểm mà nó thuộc về. Trong hình này, có một vài vùng nhỏ xem lẫn vào các vùng lớn hơn khác màu. Ví dụ có một điểm màu Lục ở gần góc 11 giờ nằm giữa hai vùng lớn với nhiều dữ liệu màu Đỏ và Lam. Điểm này rất có thể là nhiễu. Dẫn đến nếu dữ liệu test rơi vào vùng này sẽ có nhiều khả năng cho kết quả không chính xác.\n\nTrong không gian một chiều, khoảng cách giữa hai điểm là trị tuyệt đối giữa hiệu giá trị của hai điểm đó. Trong không gian nhiều chiều, khoảng cách giữa hai điểm có thể được định nghĩa bằng nhiều hàm số khác nhau, trong đó độ dài đường thằng nổi hai điểm chỉ là một trường hợp đặc biệt trong đó. Nhiều thông tin bổ ích (cho Machine Learning) có thể được tìm thấy tại Norms (chuẩn) của vector trong tab Math.\n\nThuật toán KNN rất dễ hiểu nên sẽ phần “Phân tích toán học” này sẽ chỉ có 3 câu. Tôi trực tiếp đi vào các ví dụ. Có một điều đáng lưu ý là KNN phải nhớ tất cả các điểm dữ liệu training, việc này không được lợi về cả bộ nhớ và thời gian tính toán - giống như khi cậu bạn của chúng ta không tìm được câu trả lời cho câu hỏi cuối cùng.\n\n\nIris flower dataset là một bộ dữ liệu nhỏ (nhỏ hơn rất nhiều so với MNIST. Bộ dữ liệu này bao gồm thông tin của ba loại hoa Iris (một loài hoa lan) khác nhau: Iris setosa, Iris virginica và Iris versicolor. Mỗi loại có 50 bông hoa được đo với dữ liệu là 4 thông tin: chiều dài, chiều rộng đài hoa (sepal), và chiều dài, chiều rộng cánh hoa (petal). Dưới đây là ví dụ về hình ảnh của ba loại hoa. (Chú ý, đây không phải là bộ cơ sở dữ liệu ảnh như MNIST, mỗi điểm dữ liệu trong tập này chỉ là một vector 4 chiều).\nBộ dữ liệu nhỏ này thường được sử dụng trong nhiều thuật toán Machine Learning trong các lớp học. Tôi sẽ giải thích lý do không chọn MNIST vào phần sau.\n\nTrong phần này, chúng ta sẽ tách 150 dữ liệu trong Iris flower dataset ra thành 2 phần, gọi là training set và test set. Thuật toán KNN sẽ dựa vào trông tin ở training set để dự đoán xem mỗi dữ liệu trong test set tương ứng với loại hoa nào. Dữ liệu được dự đoán này sẽ được đối chiếu với loại hoa thật của mỗi dữ liệu trong test set để đánh giá hiệu quả của KNN.\nTrước tiên, chúng ta cần khai báo vài thư viện.\nIris flower dataset có sẵn trong thư viện scikit-learn.\nTiếp theo, chúng ta load dữ liệu và hiện thị vài dữ liệu mẫu. Các class được gán nhãn là 0, 1, và 2.\nNếu nhìn vào vài dữ liệu mẫu, chúng ta thấy rằng hai cột cuối mang khá nhiều thông tin giúp chúng ta có thể  phân biệt được chúng. Chúng ta dự đoán rằng kết quả classification cho cơ sở dữ liệu này sẽ tương đối cao.\n\nGiả sử chúng ta muốn dùng 50 điểm dữ liệu cho test set, 100 điểm còn lại cho training set. Scikit-learn có một hàm số cho phép chúng ta ngẫu nhiên lựa chọn các điểm này, như sau:\nSau đây, tôi trước hết xét trường hợp đơn giản K = 1, tức là với mỗi điểm test data, ta chỉ xét 1 điểm training data gần nhất và lấy label của điểm đó để dự đoán cho điểm test này.\n\nKết quả cho thấy label dự đoán gần giống với label thật của test data, chỉ có 2 điểm trong số 20 điểm được hiển thị có kết quả sai lệch. Ở đây chúng ta làm quen với khái niệm mới: ground truth. Một cách đơn giản, ground truth chính là nhãn/label/đầu ra thực sự của các điểm trong test data. Khái niệm này được dùng nhiều trong Machine Learning, hy vọng lần tới các bạn gặp thì sẽ nhớ ngay nó là gì.\n\nĐể đánh giá độ chính xác của thuật toán KNN classifier này, chúng ta xem xem có bao nhiêu điểm trong test data được dự đoán đúng. Lấy số lượng này chia cho tổng số lượng trong tập test data sẽ ra độ chính xác. Scikit-learn cung cấp hàm số accuracy_score để thực hiện công việc này.\n1NN đã cho chúng ta kết quả là 94%, không tệ! Chú ý rằng đây là một cơ sở dữ liệu dễ vì chỉ với dữ liệu ở hai cột cuối cùng, chúng ta đã có thể suy ra quy luật. Trong ví dụ này, tôi sử dụng p = 2 nghĩa là khoảng cách ở đây được tính là khoảng cách theo norm 2. Các bạn cũng có thể thử bằng cách thay p = 1 cho norm 1, hoặc các gía trị p khác cho norm khác. (Xem thêm sklearn.neighbors.KNeighborsClassifier)\nNhận thấy rằng chỉ xét 1 điểm gần nhất có thể dẫn đến kết quả sai nếu điểm đó là nhiễu. Một cách có thể làm tăng độ chính xác là tăng số lượng điểm lân cận lên, ví dụ 10 điểm, và xem xem trong 10 điểm gần nhất, class nào chiếm đa số thì dự đoán kết quả là class đó. Kỹ thuật dựa vào đa số này được gọi là major voting.\nKết quả đã tăng lên 98%, rất tốt!\n\nLà một kẻ tham lam, tôi chưa muốn dừng kết quả ở đây vì thấy rằng mình vẫn có thể cải thiện được. Trong kỹ thuật major voting bên trên, mỗi trong 10 điểm gần nhất được coi là có vai trò như nhau và giá trị lá phiếu của mỗi điểm này là như nhau. Tôi cho rằng như thế là không công bằng, vì rõ ràng rằng những điểm gần hơn nên có trọng số cao hơn (càng thân cận thì càng tin tưởng). Vậy nên tôi sẽ đánh trọng số khác nhau cho mỗi trong 10 điểm gần nhất này. Cách đánh trọng số phải thoải mãn điều kiện là một điểm càng gần điểm test data thì phải được đánh trọng số càng cao (tin tưởng hơn). Cách đơn giản nhất là lấy nghịch đảo của khoảng cách này. (Trong trường hợp test data trùng với 1 điểm dữ liệu trong training data, tức khoảng cách bằng 0, ta lấy luôn label của điểm training data).\nScikit-learn giúp chúng ta đơn giản hóa việc này bằng cách gán gía trị weights = 'distance'. (Giá trị mặc định của weights là 'uniform', tương ứng với việc coi tất cả các điểm lân cận có giá trị như nhau như ở trên).\nAha, 100%.\nChú ý: Ngoài 2 phương pháp đánh trọng số weights = 'uniform' và weights = 'distance' ở trên, scikit-learn còn cung cấp cho chúng ta một cách để đánh trọng số một cách tùy chọn. Ví dụ, một cách đánh trọng số phổ biến khác trong Machine Learning là:\n\\[\nw_i = \\exp \\left( \\frac{-||\\mathbf{x} - \\mathbf{x}_i||_2^2}{\\sigma^2} \\right)\n\\]\n\ntrong đó \\(\\mathbf{x}\\) là test data, \\(\\mathbf{x}_i\\) là một điểm trong K-lân cận của \\(\\mathbf{x}\\), \\(w_i\\) là trọng số của điểm đó (ứng với điểm dữ liệu đang xét \\(\\mathbf{x}\\)), \\(\\sigma\\) là một số dương. Nhận thấy rằng hàm số này cũng thỏa mãn điều kiện: điểm càng gần \\(\\mathbf{x}\\) thì trọng số càng cao (cao nhất bằng 1). Với hàm số này, chúng ta có thể lập trình như sau:\nTrong trường hợp này, kết quả tương đương với kỹ thuật major voting. Để đánh giá chính xác hơn kết quả của KNN với K khác nhau, cách định nghĩa khoảng cách khác nhau và cách đánh trọng số khác nhau, chúng ta cần thực hiện quá trình trên với nhiều cách chia dữ liệu training và test khác nhau rồi lấy kết quả trung bình, vì rất có thể dữ liệu phân chia trong 1 trường hợp cụ thể là rất tốt hoặc rất xấu (bias). Đây cũng là cách thường được dùng khi đánh giá hiệu năng của một thuật toán cụ thể nào đó.\n\n\nVới bài toán Regression, chúng ta cũng hoàn toàn có thể sử dụng phương pháp tương tự: ước lượng đầu ra dựa trên đầu ra và khoảng cách của các điểm trong K-lân cận. Việc ước lượng như thế nào các bạn có thể tự định nghĩa tùy vào từng bài toán.\n\nKhi có một thuộc tính trong dữ liệu (hay phần tử trong vector) lớn hơn các thuộc tính khác rất nhiều (ví dụ thay vì đo bằng cm thì một kết quả lại tính bằng mm), khoảng cách giữa các điểm sẽ phụ thuộc vào thuộc tính này rất nhiều. Để có được kết quả chính xác hơn, một kỹ thuật thường được dùng là Data Normalization (chuẩn hóa dữ liệu) để đưa các thuộc tính có đơn vị đo khác nhau về cùng một khoảng giá trị, thường là từ 0 đến 1, trước khi thực hiện KNN. Có nhiều kỹ thuật chuẩn hóa khác nhau, các bạn sẽ được thấy khi tiếp tục theo dõi Blog này. Các kỹ thuật chuẩn hóa được áp dụng với không chỉ KNN mà còn với hầu hết các thuật toán khác.\n\nNgoài norm 1 và norm 2 tôi giới thiệu trong bài này, còn rất nhiều các khoảng cách khác nhau có thể được dùng. Một ví dụ đơn giản là đếm số lượng thuộc tính khác nhau giữa hai điểm dữ liệu. Số này càng nhỏ thì hai điểm càng gần nhau. Đây chính là giả chuẩn 0 mà tôi đã giới thiệu trong Tab Math.\n\n\n\nNgoài việc tính toán khoảng cách từ một điểm test data đến tất cả các điểm trong traing set (Brute Force), có một số thuật toán khác giúp tăng tốc việc tìm kiếm này. Bạn đọc có thẻ tìm kiếm thêm với hai từ khóa: K-D Tree và Ball Tree. Tôi xin dành phần này cho độc giả tự tìm hiểu, và sẽ quay lại nếu có dịp. Chúng ta vẫn còn những thuật toán quan trọng hơn khác cần nhiều sự quan tâm hơn.\n\nTôi có viết một đoạn code ngắn để thực hiện việc Classification cho cơ sở dữ liệu MNIST. Các bạn hãy download toàn bộ bộ dữ liệu này về vì sau này chúng ta còn dùng nhiều, chạy thử, comment kết quả và nhận xét của các bạn vào phần comment bên dưới. Để trả lời cho câu hỏi vì sao tôi không chọn cơ sở dữ liệu này làm ví dụ, bạn đọc có thể tự tìm ra đáp án khi chạy xong đoạn code này.\nEnjoy!\n\niPython Notebook cho bài này có thể download tại đây.\n\nsklearn.neighbors.NearestNeighbors\nsklearn.model_selection.train_test_split\nTutorial To Implement k-Nearest Neighbors in Python From Scratch"
    },
    {
        "ID": 45,
        "URL": "https://machinelearningcoban.com/2017/01/04/kmeans2/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong bài này, tôi sẽ áp dụng thuật toán K-means clustering vào ba bài toán xử lý ảnh thực tế hơn: i) Phân nhóm các chữ số viết tay, ii) Tách vật thể (image segmentation) và iii) Nén ảnh/dữ liệu (image compression). Qua đây, tôi cũng muốn độc giả  làm quen với một số kỹ thuật đơn giản trong xử lý hình ảnh - một mảng quan trọng trong Machine Learning. Souce code cho các ví dụ trong trang này có thể được tìm thấy tại đây.\nCảnh báo: bài này không có nhiều toán.\nTrong trang này:\n\n\n\nBộ cơ sở dữ liệu MNIST là bộ cơ sở dữ liệu lớn nhất về chữ số viết tay và được sử dụng trong hầu hết các thuật toán nhận dạng hình ảnh (Image Classification).\nMNIST bao gồm hai tập con: tập dữ liệu huấn luyện (training set) có tổng cộng 60k ví dụ khác nhau về chữ số viết tay từ 0 đên 9, tập dữ liệu kiểm tra (test set) có 10k ví dụ khác nhau. Tất cả đều đã được gán nhãn. Hình dưới đây là ví dụ về một số hình ảnh được trích ra từ MNIST.\nMỗi bức ảnh là một ảnh đen trắng (có 1 channel), có kích thước 28x28 pixel (tổng cộng 784 pixels). Mỗi pixel mang một giá trị là một số tự nhiên từ 0 đến 255. Các pixel màu đen có giá trị bằng 0, các pixel càng trắng thì có giá trị càng cao (nhưng không quá 255). Dưới đây là một ví dụ về chữ số 7 và giá trị các pixel của nó. (Vì mục đích hiển thị ma trận pixel ở bên phải, tôi đã resize bức ảnh về 14x14)\n\nBài toán: Giả sử rằng chúng ta không biết nhãn của các chữ số này, chúng ta muốn phân nhóm các bức ảnh gần giống nhau về một nhóm.\nLại thêm một giả sử nữa là chúng ta mới chỉ biết tới thuật toán phân nhóm K-means clustering gần đây từ blog Machine Learning cơ bản (xin lỗi độc giả vì để các bài học có ý nghĩa hơn, chúng ta đôi khi cần những giả định không được thực tế cho lắm), chúng ta sẽ giải quyết bài toán này thế nào?\nTrước khi áp dụng thuật toán K-means clustering, chúng ta cần coi mỗi bức ảnh là một điểm dữ liệu. Và vì mỗi điểm dữ liệu là 1 vector (hàng hoặc cột) chứ không phải ma trận như số 7 ở trên, chúng ta phải làm thêm một bước đơn giản trung gian gọi là vectorization (vector hóa). Nghĩa là, để có được 1 vector, ta có thể tách các hàng của ma trận pixel ra, sau đó đặt chúng cạnh nhau, và chúng ta được một vector hàng rất dài biểu diễn 1 bức ảnh chữ số.\nChú ý: Cách làm này chỉ là cách đơn giản nhất để mô tả dữ liệu ảnh bằng 1 vector. Trên thực tế, người ta áp dụng rất nhiều kỹ thuật khác nhau để có thể tạo ra các vector đặc trưng (feature vector) giúp các thuật toán có được kết quả tốt hơn.\n\nTrước tiên các bạn vào trang chủ của MNIST để download bộ cơ sở dữ liệu này. Mặc dù trong bài này chúng ta chỉ dùng bộ dữ liệu test với 10k ảnh và không cần label, các bạn vẫn cần download cả hai file t10k-images-idx3-ubyte.gz và t10k-labels-idx1-ubyte.gz vì thư viện python-mnist cần cả hai file này để load dữ liệu từ tập test.\nTrước tiên chúng ta cần khai báo một số thư viện:\nnumpy cho các phép toán liên quan đến ma trận. mnist để đọc dữ liệu từ MNIST. matplotlib để hiển thị hình vẽ. sklearn chính là scikit-learn mà chúng ta đã làm quen trong các bài trước. (Về việc cài đặt các thư viện này, tôi hy vọng bạn đọc có thể Google thêm đôi chút. Nếu có khó khăn trong việc cài đặt, hãy để lại comment ở dưới bài. Lưu ý, làm việc trên Windows sẽ khó khăn hơn một chút so với Linux)\nĐể hiện thị nhiều bức ảnh các chữ số cùng một lúc, tôi có dùng thêm hàm số display_network.py.\nThực hiện thuật toán K-means clustering trên toàn bộ 10k chữ số.\n(Phần còn lại của source code có thể được tìm thấy tại đây)\nĐến đây, sau khi đã tìm được các center và phân nhóm dữ liệu vào từng cluster, tôi muốn hiển thị xem center trông như thế nào và các bức ảnh được phân vào mỗi cluster có giống nhau hay không. Dưới đây là kết quả khi tôi chọn ngẫu nhiên 20 bức ảnh từ mỗi cluster.\nMỗi hàng tương ứng với một cluster, cột đầu tiên có nền xanh bên trái là centers tìm được của các clusters (màu đỏ hơn là các pixel có giá trị cao hơn). Chúng ta thấy rằng các center đều hoặc là giống với một chữ số nào đó, hoặc là kết hợp của hai/ba chữ số nào đó. Ví dụ: center của nhóm thứ 4 là sự kết hợp của các số 4, 7, 9; của hàng thứ 7 là kết hợp của chữ số 7, 8 và 9.\nTuy nhiên, các bức ảnh lấy ra ngẫu nhiên từ mỗi nhóm trông không thực sự giống nhau. Lý do có thể là những bức ảnh này ở xa các center của mỗi nhóm (mặc dù center đó đã là gần nhất). Như vậy thuật toán K-means clustering làm việc không thực sự tốt trong trường hợp này. (Thật may là vì thế nên chúng ta vẫn còn nhiều thứ để học nữa).\nChúng ta vẫn có thể khai thác một số thông tin hữu ích sau khi thực hiện thuật toán này. Bây giờ, thay vì chọn ngẫu nhiên các bức ảnh trong mỗi cluster, tôi chọn 20 bức ảnh gần center của mỗi cluster nhất, vì càng gần center thì độ tin cậy càng cao. Hãy xem hình dưới đây:\nBạn đọc có thể thấy dữ liệu trong mỗi hàng khá giống nhau và giống với center ở cột đầu tiên bên trái. Có một vài quan sát thú vị có thể rút ra từ đây:\nCó hai kiểu viết chữ số 1, một thẳng, một chéo. Và K-means clustering nghĩ rằng đó là hai chữ số khác nhau. Điều này là dễ hiểu vì K-means clustering là thuật toán Unsupervised learning. Nếu có sự can thiệp của con người, chúng ta có thể nhóm hai clusters này vào làm một.\nHàng số 9, chữ số 4 và 9 được phân vào cùng 1 cluster. Sự thật là hai chữ số này cũng khá giống nhau. Điều tương tự xảy ra đối với hàng số 7 với các chữ số 7, 8, 9 được xếp vào 1 cluster. Với các cluster này, chúng ta có thể tiếp tục áp dụng K-means clustering để phân nhỏ cluster đó ra.\nTrong clustering có một kỹ thuật thường được sử dụng là Hierarchical clustering (clustering phân tầng ). Có hai loại Hierachical clustering:\nAgglomerative tức “đi từ dưới lên”. Ban đầu coi mỗi điểm dữ liệu thuộc 1 cluster khác nhau, sau đó các cặp cluster gần giống nhau được gộp lại làm một cluster lớn hơn. Lặp lại quá trình này đến khi nhận được kết quả chấp nhận được.\nDivisive tức “đi từ trên xuống”. Ban đầu coi tất cả các điểm dữ liệu thuộc cùng một cluster, sau đó chia nhỏ mỗi cluster bằng một thuật toán clustering nào đó.\n\n\nChúng ta cùng thử áp dụng thuật toán K-means clustering vào một bài toán xử lý ảnh khác: tách vật thể.\nGiả sử chúng ta có bức ảnh dưới đây và muốn một thuật toán tự động nhận ra vùng khuôn mặt và tách nó ra.\n\n(Lại giả sử rằng chúng ta chưa biết gì khác ngoài K-means clustering, các bạn hãy dừng vài giây để nghĩ xem chúng ta có thể xử lý thế nào. Gợi ý: Có ba màu chủ đạo trong bức ảnh.)\nOk, có ba màu, ba clusters!\nBức ảnh có ba màu chủ đạo: hồng ở khăn và môi; đen ở mắt, tóc, và hậu cảnh; màu da ở vùng còn lại của khuôn mặt. Vậy chúng ta có thể áp dụng thuật toán K-means clustering để phân các pixel ảnh thành 3 clusters, sau đó chọn cluster chứa phần khuôn mặt (phần này do con người làm).\nĐây là một bức ảnh màu, mỗi điểm ảnh sẽ được biểu diễn bới 3 giá trị tương ứng với màu Red, Green, và Blue (mỗi giá trị này cũng là một số tự nhiên không vượt quá 255). Nếu ta coi mỗi điểm dữ liệu là một vector 3 chiều chứa các giá trị này, sau đó áp dụng thuật toán K-means clustering, chúng ta có thể có kết quả mong muốn. Hãy thử xem\n\nKhai báo thư viện và load bức ảnh:\nBiến đổi bức ảnh thành 1 ma trận mà mỗi hàng là 1 pixel với 3 giá trị màu\n(Phần còn lại của source code có thể xem tại đây).\nSau khi tìm được các cluster, tôi thay giá trị của mỗi pixel bằng center của cluster chứa nó, và được kết quả như sau:\nBa màu: Hồng, đen, và màu da đã được phân nhóm. Và khuôn mặt có thể được tách ra từ phần có màu da (và vùng bên trong nó). Vậy là K-means clustering tạo ra một kết quả chấp nhận được.\n\nĐể ý thấy rằng mỗi một pixel có thể nhận một trong số \\(256^3 = 16,777,216\\) (16 triệu màu mà chúng ta vẫn nghe khi quảng cáo màn hình). Đây là một số rất lớn (tương đương với 24 bit cho một điểm ảnh). Nếu ta muốn lưu mỗi điểm ảnh với một số bit nhỏ hơn và chấp nhận mất dữ liệu ở một mức nào đó, có cách nào không nếu ta chỉ biết K-means clustering?\nCâu trả lời là có. Trong bài toán Segmentation phía trên, chúng ta có 3 clusters, và mỗi một điểm ảnh sau khi xử lý sẽ được biểu diễn bởi 1 số tương ứng với 1 cluster. Tuy nhiên, chất lượng bức ảnh rõ ràng đã giảm đi nhiều. Tôi làm một thí nghiệm nhỏ với số lượng clusters được tăng lên là 5, 10, 15, 20. Sau khi tìm được centers cho mỗi cluster, tôi thay giá trị của một điểm ảnh bằng giá trị của center tương ứng:\nKết quả:\nBạn đọc có thể quan sát là khi số lượng clusters tăng lên, chất lượng bức ảnh đã được cải thiện. Đồng thời, chúng ta chỉ cần lưu các centers và label của mỗi điểm ảnh là đã có được một bức ảnh nén (có mất dữ liệu).\n\nVới một thuật toán K-means clustering đơn giản, chúng ta đã có thể áp dụng nó vào các bài toán thực tế. Mặc dù kết quả chưa thực sự như ý, chúng ta vẫn thấy được tiềm năng của thuật toán đơn giản này.\nCách thay một điểm dữ liệu bằng center tương ứng là một trong số các kỹ thuật có tên chung là Vector Quantization (VQ). Không chỉ trong nén dữ liệu, VQ còn được áp dụng rộng rãi trong các thuật toán tạo Feature Vector cho các bài toán Phân loại (classification).\nCác thuật toán trong bài toán này được áp dụng cho xử lý ảnh vì việc này giúp tôi dễ dàng minh họa kết quả hơn. Các kỹ thuật này hoàn toàn có thể áp dụng cho các loại cơ sở dữ liệu khác.\n\nCác bạn có thể download source code ở đây.\n\nPattern Recognition and Machine Learning - Christopher Bishop"
    },
    {
        "ID": 46,
        "URL": "https://machinelearningcoban.com/2017/01/01/kmeans/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong trang này:\n\n\nTrong bài trước, chúng ta đã làm quen với thuật toán Linear Regression - là thuật toán đơn giản nhất trong Supervised learning. Bài này tôi sẽ giới thiệu một trong những thuật toán cơ bản nhất trong Unsupervised learning - thuật toán K-means clustering (phân cụm K-means).\nTrong thuật toán K-means clustering, chúng ta không biết nhãn (label) của từng điểm dữ liệu. Mục đích là làm thể nào để phân dữ liệu thành các cụm (cluster) khác nhau sao cho dữ liệu trong cùng một cụm có tính chất giống nhau.\nVí dụ: Một công ty muốn tạo ra những chính sách ưu đãi cho những nhóm khách hàng khác nhau dựa trên sự tương tác giữa mỗi khách hàng với công ty đó (số năm là khách hàng; số tiền khách hàng đã chi trả cho công ty; độ tuổi; giới tính; thành phố; nghề nghiệp; …). Giả sử công ty đó có rất nhiều dữ liệu của rất nhiều khách hàng nhưng chưa có cách nào chia toàn bộ khách hàng đó thành một số nhóm/cụm khác nhau. Nếu một người biết Machine Learning được đặt câu hỏi này, phương pháp đầu tiên anh (chị) ta nghĩ đến sẽ là K-means Clustering. Vì nó là một trong những thuật toán đầu tiên mà anh ấy tìm được trong các cuốn sách, khóa học về Machine Learning. Và tôi cũng chắc rằng anh ấy đã đọc blog Machine Learning cơ bản. Sau khi đã phân ra được từng nhóm, nhân viên công ty đó có thể lựa chọn ra một vài khách hàng trong mỗi nhóm để quyết định xem mỗi nhóm tương ứng với nhóm khách hàng nào. Phần việc cuối cùng này cần sự can thiệp của con người, nhưng lượng công việc đã được rút gọn đi rất nhiều.\nÝ tưởng đơn giản nhất về cluster (cụm) là tập hợp các điểm ở gần nhau trong một không gian nào đó (không gian này có thể có rất nhiều chiều trong trường hợp thông tin về một điểm dữ liệu là rất lớn). Hình bên dưới là một ví dụ về 3 cụm dữ liệu (từ giờ tôi sẽ viết gọn là cluster).\nGiả sử mỗi cluster có một điểm đại diện (center) màu vàng. Và những điểm xung quanh mỗi center thuộc vào cùng nhóm với center đó. Một cách đơn giản nhất, xét một điểm bất kỳ, ta xét xem điểm đó gần với center nào nhất thì nó thuộc về cùng nhóm với center đó. Tới đây, chúng ta có một bài toán thú vị: Trên một vùng biển hình vuông lớn có ba đảo hình vuông, tam giác, và tròn màu vàng như hình trên. Một điểm trên biển được gọi là thuộc lãnh hải của một đảo nếu nó nằm gần đảo này hơn so với hai đảo kia . Hãy xác định ranh giới lãnh hải của các đảo.\nHình dưới đây là một hình minh họa cho việc phân chia lãnh hải nếu có 5 đảo khác nhau được biểu diễn bằng các hình tròn màu đen:\nChúng ta thấy rằng đường phân định giữa các lãnh hải là các đường thẳng (chính xác hơn thì chúng là các đường trung trực của các cặp điểm gần nhau). Vì vậy, lãnh hải của một đảo sẽ là một hình đa giác.\nCách phân chia này trong toán học được gọi là Voronoi Diagram.\nTrong không gian ba chiều, lấy ví dụ là các hành tinh, thì (tạm gọi là) lãnh không của mỗi hành tinh sẽ là một đa diện. Trong không gian nhiều chiều hơn, chúng ta sẽ có những thứ (mà tôi gọi là) siêu đa diện (hyperpolygon).\nQuay lại với bài toán phân nhóm và cụ thể là thuật toán K-means clustering, chúng ta cần một chút phân tích toán học trước khi đi tới phần tóm tắt thuật toán ở phần dưới. Nếu bạn không muốn đọc quá nhiều về toán, bạn có thể bỏ qua phần này. (Tốt nhất là đừng bỏ qua, bạn sẽ tiếc đấy).\n\n\nMục đích cuối cùng của thuật toán phân nhóm này là: từ dữ liệu đầu vào và số lượng nhóm chúng ta muốn tìm, hãy chỉ ra center của mỗi nhóm và phân các điểm dữ liệu vào các nhóm tương ứng. Giả sử thêm rằng mỗi điểm dữ liệu chỉ thuộc vào đúng một nhóm.\n\nGiả sử có \\(N\\) điểm dữ liệu là \\( \\mathbf{X} = [\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N] \\in \\mathbb{R}^{d \\times N}\\) và \\(K < N\\) là số cluster chúng ta muốn phân chia. Chúng ta cần tìm các center \\( \\mathbf{m}_1, \\mathbf{m}_2, \\dots, \\mathbf{m}_K \\in \\mathbb{R}^{d \\times 1} \\) và label của mỗi điểm dữ liệu.\nLưu ý về ký hiệu toán học: trong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng không in đậm, có thể viết hoa, ví dụ \\(x_1, N, y, k\\). Các vector được biểu diễn bằng các chữ cái thường in đậm, ví dụ \\(\\mathbf{m}, \\mathbf{x}_1 \\). Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụ \\(\\mathbf{X, M, Y} \\). Lưu ý này đã được nêu ở bài Linear Regression. Tôi xin được không nhắc lại trong các bài tiếp theo.\n\nVới mỗi điểm dữ liệu \\( \\mathbf{x}_i \\) đặt \\(\\mathbf{y}_i = [y_{i1}, y_{i2}, \\dots, y_{iK}]\\) là label vector của nó, trong đó nếu \\( \\mathbf{x}_i \\) được phân vào cluster \\(k\\) thì  \\(y_{ik} = 1\\) và \\(y_{ij} = 0, \\forall j \\neq k \\). Điều này có nghĩa là có đúng một phần tử của vector \\(\\mathbf{y}_i\\) là bằng 1 (tương ứng với cluster của \\(\\mathbf{x}_i \\)), các phần tử còn lại bằng 0. Ví dụ: nếu một điểm dữ liệu có label vector là \\([1,0,0,\\dots,0]\\) thì nó thuộc vào cluster 1, là \\([0,1,0,\\dots,0]\\) thì nó thuộc vào cluster 2, \\(\\dots\\). Cách mã hóa label của dữ liệu như thế này được gọi là biểu diễn one-hot. Chúng ta sẽ thấy cách biểu diễn one-hot này rất phổ biến trong Machine Learning ở các bài tiếp theo.\nRàng buộc của \\(\\mathbf{y}_i \\) có thể viết dưới dạng toán học như sau:\n\\[\n y_{ik} \\in \\{0, 1\\},~~~ \\sum_{k = 1}^K y_{ik} = 1 ~~~ (1)\n\\]\n\n\n\n\n\n\nNếu ta coi center \\(\\mathbf{m}_k \\)  là center (hoặc representative) của mỗi cluster và ước lượng tất cả các điểm được phân vào cluster này bởi \\(\\mathbf{m}_k \\), thì một điểm dữ liệu \\(\\mathbf{x}_i \\) được phân vào cluster \\(k\\) sẽ bị sai số là \\( (\\mathbf{x}_i - \\mathbf{m}_k) \\). Chúng ta mong muốn sai số này có trị tuyệt đối nhỏ nhất nên (giống như trong bài Linear Regression) ta sẽ tìm cách để đại lượng sau đây đạt giá trị nhỏ nhất: \n\\[\n\\|\\mathbf{x}_i - \\mathbf{m}_k\\|_2^2\n\\]\nHơn nữa, vì \\(\\mathbf{x}_i \\) được phân vào cluster \\(k\\) nên \\(y_{ik} = 1, y_{ij} = 0, ~\\forall j \\neq k \\). Khi đó, biểu thức bên trên sẽ được viết lại là:\n\\[\ny_{ik}\\|\\mathbf{x}_i - \\mathbf{m}_k\\|_2^2 =  \\sum_{j=1}^K y_{ij}\\|\\mathbf{x}_i - \\mathbf{m}_j\\|_2^2\n\\]\n(Hy vọng chỗ này không quá khó hiểu)\nSai số cho toàn bộ dữ liệu sẽ là: \n\\[\n\\mathcal{L}(\\mathbf{Y}, \\mathbf{M}) = \\sum_{i=1}^N\\sum_{j=1}^K y_{ij} \\|\\mathbf{x}_i - \\mathbf{m}_j\\|_2^2\n\\]\nTrong đó \\( \\mathbf{Y} = [\\mathbf{y}_1; \\mathbf{y}_2; \\dots; \\mathbf{y}_N]\\), \\( \\mathbf{M} = [\\mathbf{m}_1, \\mathbf{m}_2, \\dots \\mathbf{m}_K] \\) lần lượt là các ma trận được tạo bởi label vector của mỗi điểm dữ liệu và center của mỗi cluster. Hàm số mất mát trong bài toán K-means clustering của chúng ta là hàm \\(\\mathcal{L}(\\mathbf{Y}, \\mathbf{M})\\) với ràng buộc như được nêu trong phương trình \\((1)\\).\nTóm lại, chúng ta cần tối ưu bài toán sau: \n\\[\n\\mathbf{Y}, \\mathbf{M} = \\arg\\min_{\\mathbf{Y}, \\mathbf{M}} \\sum_{i=1}^N\\sum_{j=1}^K y_{ij} \\|\\mathbf{x}_i - \\mathbf{m}_j\\|_2^2~~~~~(2)\n\\]\n\\[\n\\text{subject to:} ~~ y_{ij} \\in \\{0, 1\\}~~ \\forall i, j;~~~ \\sum_{j = 1}^K y_{ij} = 1~~\\forall i\n\\]\n(subject to nghĩa là thỏa mãn điều kiện).\nNhắc lại khái niệm \\(\\arg\\min\\): Chúng ta biết ký hiệu \\(\\min\\) là giá trị nhỏ nhất của hàm số, \\(\\arg\\min\\) chính là giá trị của biến số để hàm số đó đạt giá trị nhỏ nhất đó. Nếu \\(f(x) = x^2 -2x + 1 = (x-1)^2 \\) thì giá trị nhỏ nhất của hàm số này bằng 0, đạt được khi \\(x = 1\\). Trong ví dụ này \\(\\min_{x} f(x) = 0\\) và \\(\\arg\\min_{x} f(x) = 1\\). Thêm ví dụ khác, nếu \\(x_1 = 0, x_2 = 10, x_3 = 5\\) thì ta nói \\(\\arg\\min_{i} x_i = 1\\) vì \\(1\\) là chỉ số để \\(x_i\\) đạt giá trị nhỏ nhất (bằng \\(0\\)). Biến số viết bên dưới \\(\\min\\) là biến số cúng ta cần tối ưu. Trong các bài toán tối ưu, ta thường quan tâm tới \\(\\arg\\min\\) hơn là \\(\\min\\).\n\n\n\nBài toán \\((2)\\) là một bài toán khó tìm điểm tối ưu vì nó có thêm các điều kiện ràng buộc. Bài toán này thuộc loại mix-integer programming (điều kiện biến là số nguyên) - là loại rất khó tìm nghiệm tối ưu toàn cục (global optimal point, tức nghiệm làm cho hàm mất mát đạt giá trị nhỏ nhất có thể). Tuy nhiên, trong một số trường hợp chúng ta vẫn có thể tìm được phương pháp để tìm được nghiệm gần đúng hoặc điểm cực tiểu. (Nếu chúng ta vẫn nhớ chương trình toán ôn thi đại học thì điểm cực tiểu chưa chắc đã phải là điểm làm cho hàm số đạt giá trị nhỏ nhất).\nMột cách đơn giản để giải bài toán \\((2)\\) là xen kẽ giải \\(\\mathbf{Y}\\) và \\( \\mathbf{M}\\) khi biến còn lại được cố định. Đây là một thuật toán lặp, cũng là kỹ thuật phổ biến khi giải bài toán tối ưu. Chúng ta sẽ lần lượt giải quyết hai bài toán sau đây:\n\nGiả sử đã tìm được các centers, hãy tìm các label vector để hàm mất mát đạt giá trị nhỏ nhất. Điều này tương đương với việc tìm cluster cho mỗi điểm dữ liệu.\nKhi các centers là cố định, bài toán tìm label vector cho toàn bộ dữ liệu có thể được chia nhỏ thành bài toán tìm label vector cho từng điểm dữ liệu \\(\\mathbf{x}_i\\) như sau:\n\\[\n\\mathbf{y}_i = \\arg\\min_{\\mathbf{y}_i} \\sum_{j=1}^K y_{ij}\\|\\mathbf{x}_i - \\mathbf{m}_j\\|_2^2 ~~~ (3)\n\\]\n\\[\n\\text{subject to:} ~~ y_{ij} \\in \\{0, 1\\}~~ \\forall j;~~~ \\sum_{j = 1}^K y_{ij} = 1\n\\]\nVì chỉ có một phần tử của label vector \\(\\mathbf{y}_i\\) bằng \\(1\\) nên bài toán \\((3)\\) có thể tiếp tục được viết dưới dạng đơn giản hơn: \n\\[\nj = \\arg\\min_{j} \\|\\mathbf{x}_i - \\mathbf{m}_j\\|_2^2\n\\]\nVì \\(\\|\\mathbf{x}_i - \\mathbf{m}_j\\|_2^2\\) chính là bình phương khoảng cách tính từ điểm \\(\\mathbf{x}_i \\) tới center \\(\\mathbf{m}_j \\), ta có thể kết luận rằng mỗi điểm \\(\\mathbf{x}_i \\) thuộc vào cluster có center gần nó nhất! Từ đó ta có thể dễ dàng suy ra label vector của từng điểm dữ liệu.\n\nGiả sử đã tìm được cluster cho từng điểm, hãy tìm center mới cho mỗi cluster để hàm mất mát đạt giá trị nhỏ nhất.\nMột khi chúng ta đã xác định được label vector cho từng điểm dữ liệu, bài toán tìm center cho mỗi cluster được rút gọn thành:\n\\[\n\\mathbf{m}_j = \\arg\\min_{\\mathbf{m}_j} \\sum_{i = 1}^{N} y_{ij}\\|\\mathbf{x}_i - \\mathbf{m}_j \\|_2^2.\n\\]\n Tới đây, ta có thể tìm nghiệm bằng phương pháp giải đạo hàm bằng 0, vì hàm cần tối ưu là một hàm liên tục và có đạo hàm xác định tại mọi điểm. Và quan trọng hơn, hàm này là hàm convex (lồi) theo \\(\\mathbf{m}_j \\) nên chúng ta sẽ tìm được giá trị nhỏ nhất và điểm tối ưu tương ứng. Sau này nếu có dịp, tôi sẽ nói thêm về tối ưu lồi (convex optimization) - một mảng cực kỳ quan trọng trong toán tối ưu.\nĐặt \\(l(\\mathbf{m}_j)\\) là hàm bên trong dấu \\(\\arg\\min\\), ta có đạo hàm:\n\\[\n\\frac{\\partial l(\\mathbf{m}_j)}{\\partial \\mathbf{m}_j} = 2\\sum_{i=1}^N y_{ij}(\\mathbf{m}_j - \\mathbf{x}_i) \n\\]\nGiải phương trình đạo hàm bằng 0 ta có: \n\\[\n\\mathbf{m}_j \\sum_{i=1}^N y_{ij} = \\sum_{i=1}^N y_{ij} \\mathbf{x}_i \n\\]\n\\[\n\\Rightarrow \\mathbf{m}_j = \\frac{ \\sum_{i=1}^N y_{ij} \\mathbf{x}_i}{\\sum_{i=1}^N y_{ij}}\n\\]\nNếu để ý một chút, chúng ta sẽ thấy rằng mẫu số chính là phép đếm số lượng các điểm dữ liệu trong cluster \\(j\\) (Bạn có nhận ra không?). Còn tử số chính là tổng các điểm dữ liệu trong cluster \\(j\\). (Nếu bạn đọc vẫn nhớ điều kiện ràng buộc của các \\(y_{ij} \\) thì sẽ có thể nhanh chóng nhìn ra điều này).\nHay nói một cách đơn giản hơn nhiều: \\(\\mathbf{m}_j\\) là trung bình cộng của các điểm trong cluster \\(j\\).\nTên gọi K-means clustering cũng xuất phát từ đây.\n\n\n\nTới đây tôi xin được tóm tắt lại thuật toán (đặc biệt quan trọng với các bạn bỏ qua phần toán học bên trên) như sau:\nĐầu vào: Dữ liệu \\(\\mathbf{X}\\) và số lượng cluster cần tìm \\(K\\).\nĐầu ra: Các center \\(\\mathbf{M}\\) và label vector cho từng điểm dữ liệu \\(\\mathbf{Y}\\).\nChúng ta có thể đảm bảo rằng thuật toán sẽ dừng lại sau một số hữu hạn vòng lặp. Thật vậy, vì hàm mất mát là một số dương và sau mỗi bước 2 hoặc 3, giá trị của hàm mất mát bị giảm đi. Theo kiến thức về dãy số trong chương trình cấp 3: nếu một dãy số giảm và bị chặn dưới thì nó hội tụ! Hơn nữa, số lượng cách phân nhóm cho toàn bộ dữ liệu là hữu hạn nên đến một lúc nào đó, hàm mất mát sẽ không thể thay đổi, và chúng ta có thể dừng thuật toán tại đây.\nChúng ta sẽ có một vài thảo luận về thuật toán này, về những hạn chế và một số phương pháp khắc phục. Nhưng trước hết, hãy xem nó thể hiện như thế nào trong một ví dụ cụ thể dưới đây.\n\n\nĐể kiểm tra mức độ hiểu quả của một thuật toán, chúng ta sẽ làm một ví dụ đơn giản (thường được gọi là toy example). Trước hết, chúng ta chọn center cho từng cluster và tạo dữ liệu cho từng cluster bằng cách lấy mẫu theo phân phối chuẩn có kỳ vọng là center của cluster đó và ma trận hiệp phương sai (covariance matrix) là ma trận đơn vị.\nTrước tiên, chúng ta cần khai báo các thư viện cần dùng. Chúng ta cần numpy và matplotlib như trong bài Linear Regression cho việc tính toán ma trận và hiển thị dữ liệu. Chúng ta cũng cần thêm thư viện scipy.spatial.distance để tính khoảng cách giữa các cặp điểm trong hai tập hợp một cách hiệu quả.\nTiếp theo, ta tạo dữ liệu bằng cách lấy các điểm theo phân phối chuẩn có kỳ vọng tại các điểm có tọa độ (2, 2), (8, 3) và (3, 6), ma trận hiệp phương sai giống nhau và là ma trận đơn vị. Mỗi cluster có 500 điểm. (Chú ý rằng mỗi điểm dữ liệu là một hàng của ma trận dữ liệu.\n\nChúng ta cần một hàm kmeans_display để hiển thị dữ liệu. Sau đó hiển thị dữ liệu theo nhãn ban đầu.\nTrong đồ thị trên, mỗi cluster tương ứng với một màu. Có thể nhận thấy rằng có một vài điểm màu đỏ bị lẫn sang phần cluster màu xanh.\n\n\n\nViết các hàm:\nPhần chính của K-means clustering:\nÁp dụng thuật toán vừa viết vào dữ liệu ban đầu, hiển thị kết quả cuối cùng.\nTừ kết quả này chúng ta thấy rằng thuật toán K-means clustering làm việc khá thành công, các centers tìm được khá gần với kỳ vọng ban đầu. Các điểm thuộc cùng một cluster hầu như được phân vào cùng một cluster (trừ một số điểm màu đỏ ban đầu đã bị phân nhầm vào cluster màu xanh da trời, nhưng tỉ lệ là nhỏ và có thể chấp nhận được).\nDưới đây là hình ảnh động minh họa thuật toán qua từng vòng lặp, chúng ta thấy rằng thuật toán trên hội tụ rất nhanh, chỉ cần 6 vòng lặp để có được kết quả cuối cùng:\nCác bạn có thể xem thêm các trang web minh họa thuật toán K-means cluster tại:\n\n\nĐể kiểm tra thêm, chúng ta hãy so sánh kết quả trên với kết quả thu được bằng cách sử dụng thư viện scikit-learn.\nThật may mắn (cho tôi), hai thuật toán cho cùng một đáp số! Với cách thứ nhất, tôi mong muốn các bạn hiểu rõ được thuật toán K-means clustering làm việc như thế nào. Với cách thứ hai, tôi hy vọng các bạn biết áp dụng thư viện sẵn có như thế nào.\n\n\nCó một vài hạn chế của thuật toán K-means clustering:\n\nĐể ý thấy rằng trong thuật toán nêu trên, chúng ta cần biết đại lượng \\(K\\) là số lượng clusters. Trong thực tế, nhiều trường hợp chúng ta không xác định được giá trị này. Có một số phương pháp giúp xác định số lượng clusters, tôi sẽ dành thời gian nói về chúng sau nếu có dịp. Bạn đọc có thể tham khảo Elbow method - Determining the number of clusters in a data set.\n\nTùy vào các center ban đầu mà thuật toán có thể có tốc độ hội tụ rất chậm, ví dụ:\n\nhoặc thậm chí cho chúng ta nghiệm không chính xác (chỉ là local minimum - điểm cực tiểu - mà không phải giá trị nhỏ nhất):\nCó một vài cách khắc phục đó là:\nChạy K-means clustering nhiều lần với các center ban đầu khác nhau rồi chọn cách có hàm mất mát cuối cùng đạt giá trị nhỏ nhất.\nK-means++ -Improve initialization algorithm - wiki.\nBạn nào muốn tìm hiểu sâu hơn có thể xem bài báo khoa học Cluster center initialization algorithm for K-means clustering.\n\nDưới đây là một ví dụ với 3 cluster với 20, 50, và 1000 điểm. Kết quả cuối cùng không chính xác.\n\nTức các cluster tuân theo phân phối chuẩn và ma trận hiệp phương sai là ma trận đường chéo có các điểm trên đường chéo giống nhau.\nDưới đây là 1 ví dụ khi 1 cluster có dạng hình dẹt.\n\nĐây là ví dụ kinh điển về việc K-means clustering không thể phân cụm dữ liệu. Một cách tự nhiên, chúng ta sẽ phân ra thành 4 cụm: mắt trái, mắt phải, miệng, xung quanh mặt. Nhưng vì mắt và miệng nằm trong khuôn mặt nên K-means clustering không thực hiện được:\n\nMặc dù có những hạn chế, K-means clustering vẫn cực kỳ quan trọng trong Machine Learning và là nền tảng cho nhiều thuật toán phức tạp khác sau này. Chúng ta cần bắt đầu từ những thứ đơn giản. Simple is best!\n\nClustering documents using k-means\nVoronoi Diagram - Wikipedia\nCluster center initialization algorithm for K-means clustering\nVisualizing K-Means Clustering\nVisualizing K-Means Clustering - Standford"
    },
    {
        "ID": 47,
        "URL": "https://machinelearningcoban.com/2016/12/28/linearregression/",
        "Title": "Machine Learning cơ bản",
        "Content": "Trong bài này, tôi sẽ giới thiệu một trong những thuật toán cơ bản nhất (và đơn giản nhất) của Machine Learning. Đây là một thuật toán Supervised learning có tên Linear Regression (Hồi Quy Tuyến Tính). Bài toán này đôi khi được gọi là Linear Fitting (trong thống kê) hoặc Linear Least Square.\nTrong trang này:\n\n\nQuay lại ví dụ đơn giản được nêu trong bài trước: một căn nhà rộng \\(x_1 ~ \\text{m}^2\\), có \\(x_2\\) phòng ngủ và cách trung tâm thành phố \\(x_3~ \\text{km}\\) có giá là bao nhiêu. Giả sử chúng ta đã có số liệu thống kê từ 1000 căn nhà trong thành phố đó, liệu rằng khi có một căn nhà mới với các thông số về diện tích, số phòng ngủ và khoảng cách tới trung tâm, chúng ta có thể dự đoán được giá của căn nhà đó không? Nếu có thì hàm dự đoán \\(y = f(\\mathbf{x}) \\) sẽ có dạng như thế nào. Ở đây \\(\\mathbf{x} = [x_1, x_2, x_3] \\) là một vector hàng chứa thông tin input, \\(y\\) là một số vô hướng (scalar) biểu diễn output (tức giá của căn nhà trong ví dụ này).\nLưu ý về ký hiệu toán học: trong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng không in đậm, có thể viết hoa, ví dụ \\(x_1, N, y, k\\). Các vector được biểu diễn bằng các chữ cái thường in đậm, ví dụ \\(\\mathbf{y}, \\mathbf{x}_1 \\). Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụ \\(\\mathbf{X, Y, W} \\).\nMột cách đơn giản nhất, chúng ta có thể thấy rằng: i) diện tích nhà càng lớn thì giá nhà càng cao; ii) số lượng phòng ngủ càng lớn thì giá nhà càng cao; iii) càng xa trung tâm thì giá nhà càng giảm. Một hàm số đơn giản nhất có thể mô tả mối quan hệ giữa giá nhà và 3 đại lượng đầu vào là:\n\\[y \\approx  f(\\mathbf{x}) = \\hat{y}\\]\n\\[f(\\mathbf{x}) =w_1 x_1 + w_2 x_2 + w_3 x_3 + w_0 ~~~~ (1)\\]\ntrong đó, \\(w_1, w_2, w_3, w_0\\) là các hằng số,  \\(w_0\\) còn được gọi là bias. Mối quan hệ \\(y \\approx f(\\mathbf{x})\\) bên trên là một mối quan hệ tuyến tính (linear). Bài toán chúng ta đang làm là một bài toán thuộc loại regression. Bài toán đi tìm các hệ số tối ưu \\( \\{w_1, w_2, w_3, w_0 \\}\\) chính vì vậy được gọi là bài toán Linear Regression.\nChú ý 1: \\(y\\) là giá trị thực của outcome (dựa trên số liệu thống kê chúng ta có trong tập training data), trong khi \\(\\hat{y}\\) là giá trị mà mô hình Linear Regression dự đoán được. Nhìn chung, \\(y\\) và \\(\\hat{y}\\) là hai giá trị khác nhau do có sai số mô hình, tuy nhiên, chúng ta mong muốn rằng sự khác nhau này rất nhỏ.\nChú ý 2: Linear hay tuyến tính hiểu một cách đơn giản là thẳng, phẳng. Trong không gian hai chiều, một hàm số được gọi là tuyến tính nếu đồ thị của nó có dạng một đường thẳng. Trong không gian ba chiều, một hàm số được goi là tuyến tính nếu đồ thị của nó có dạng một mặt phẳng. Trong không gian nhiều hơn 3 chiều, khái niệm mặt phẳng không còn phù hợp nữa, thay vào đó, một khái niệm khác ra đời được gọi là siêu mặt phẳng (hyperplane). Các hàm số tuyến tính là các hàm đơn giản nhất, vì chúng thuận tiện trong việc hình dung và tính toán. Chúng ta sẽ được thấy trong các bài viết sau, tuyến tính rất quan trọng và hữu ích trong các bài toán Machine Learning. Kinh nghiệm cá nhân tôi cho thấy, trước khi hiểu được các thuật toán phi tuyến (non-linear, không phẳng), chúng ta cần nắm vững các kỹ thuật cho các mô hình tuyến tính.\n\n\nTrong phương trình \\((1)\\) phía trên, nếu chúng ta đặt \\(\\mathbf{w} = [w_0, w_1, w_2, w_3]^T = \\) là vector (cột) hệ số cần phải tối ưu và \\(\\mathbf{\\bar{x}} = [1, x_1, x_2, x_3]\\) (đọc là x bar trong tiếng Anh) là vector (hàng) dữ liệu đầu vào mở rộng. Số \\(1\\) ở đầu được thêm vào để phép tính đơn giản hơn và thuận tiện cho việc tính toán. Khi đó, phương trình (1) có thể được viết lại dưới dạng:\n\\[y \\approx \\mathbf{\\bar{x}}\\mathbf{w} = \\hat{y}\\]\nChú ý rằng \\(\\mathbf{\\bar{x}}\\) là một vector hàng. (Xem thêm về ký hiệu vector hàng và cột tại đây)\n\nChúng ta mong muốn rằng sự sai khác \\(e\\) giữa giá trị thực \\(y\\) và giá trị dự đoán \\(\\hat{y}\\) (đọc là y hat trong tiếng Anh) là nhỏ nhất. Nói cách khác, chúng ta muốn giá trị sau đây càng nhỏ càng tốt:\n\\[\n\\frac{1}{2}e^2 = \\frac{1}{2}(y - \\hat{y})^2 = \\frac{1}{2}(y - \\mathbf{\\bar{x}}\\mathbf{w})^2\n\\]\ntrong đó hệ số \\(\\frac{1}{2} \\) (lại) là để thuận tiện cho việc tính toán (khi tính đạo hàm thì số \\(\\frac{1}{2} \\) sẽ bị triệt tiêu). Chúng ta cần \\(e^2\\) vì \\(e = y - \\hat{y} \\) có thể là một số âm, việc nói \\(e\\) nhỏ nhất sẽ không đúng vì khi \\(e = - \\infty\\) là rất nhỏ nhưng sự sai lệch là rất lớn. Bạn đọc có thể tự đặt câu hỏi: tại sao không dùng trị tuyệt đối \\( |e| \\) mà lại dùng bình phương \\(e^2\\) ở đây? Câu trả lời sẽ có ở phần sau.\n\nĐiều tương tự xảy ra với tất cả các cặp (input, outcome) \\( (\\mathbf{x}_i, y_i), i = 1, 2, \\dots, N \\), với \\(N\\) là số lượng dữ liệu quan sát được. Điều chúng ta muốn, tổng sai số là nhỏ nhất, tương đương với việc tìm \\( \\mathbf{w} \\) để hàm số sau đạt giá trị nhỏ nhất:\n\\[ \\mathcal{L}(\\mathbf{w}) = \\frac{1}{2}\\sum_{i=1}^N (y_i - \\mathbf{\\bar{x}_i}\\mathbf{w})^2 ~~~~~(2) \\]\nHàm số \\(\\mathcal{L}(\\mathbf{w}) \\) được gọi là hàm mất mát (loss function) của bài toán Linear Regression. Chúng ta luôn mong muốn rằng sự mất mát (sai số) là nhỏ nhất, điều đó đồng nghĩa với việc  tìm vector hệ số \\( \\mathbf{w} \\)  sao cho \ngiá trị của hàm mất mát này càng nhỏ càng tốt. Giá trị của \\(\\mathbf{w}\\) làm cho hàm mất mát đạt giá trị nhỏ nhất được gọi là điểm tối ưu (optimal point), ký hiệu:\n\\[ \\mathbf{w}^* = \\arg\\min_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w})  \\]\nTrước khi đi tìm lời giải, chúng ta đơn giản hóa phép toán trong phương trình hàm mất mát \\((2)\\). Đặt \\(\\mathbf{y} = [y_1; y_2; \\dots; y_N]\\) là một vector cột chứa tất cả các output của training data; \\( \\mathbf{\\bar{X}} = [\\mathbf{\\bar{x}}_1; \\mathbf{\\bar{x}}_2; \\dots; \\mathbf{\\bar{x}}_N ] \\) là ma trận dữ liệu đầu vào (mở rộng) mà mỗi hàng của nó là một điểm dữ liệu. Khi đó hàm số mất mát \\(\\mathcal{L}(\\mathbf{w})\\) được viết dưới dạng ma trận đơn giản hơn:\n\\[\n\\mathcal{L}(\\mathbf{w}) \n= \\frac{1}{2}\\sum_{i=1}^N (y_i - \\mathbf{\\bar{x}}_i\\mathbf{w})^2 \\]\n\\[\n= \\frac{1}{2} \\|\\mathbf{y} - \\mathbf{\\bar{X}}\\mathbf{w} \\|_2^2 ~~~(3) \\]\nvới \\( \\| \\mathbf{z} \\|_2 \\) là Euclidean norm (chuẩn Euclid, hay khoảng cách Euclid), nói cách khác \\( \\| \\mathbf{z} \\|_2^2 \\) là tổng của bình phương mỗi phần tử của vector \\(\\mathbf{z}\\). Tới đây, ta đã có một dạng đơn giản của hàm mất mát được viết như phương trình \\((3)\\).\n\nCách phổ biến nhất để tìm nghiệm cho một bài toán tối ưu (chúng ta đã biết từ khi học cấp 3) là giải phương trình đạo hàm (gradient) bằng 0! Tất nhiên đó là khi việc tính đạo hàm và việc giải phương trình đạo hàm bằng 0 không quá phức tạp. Thật may mắn, với các mô hình tuyến tính, hai việc này là khả thi.\nĐạo hàm theo \\(\\mathbf{w} \\) của hàm mất mát là: \n\\[\n\\frac{\\partial{\\mathcal{L}(\\mathbf{w})}}{\\partial{\\mathbf{w}}} \n= \\mathbf{\\bar{X}}^T(\\mathbf{\\bar{X}}\\mathbf{w} - \\mathbf{y}) \n\\]\nCác bạn có thể tham khảo bảng đạo hàm theo vector hoặc ma trận của một hàm số trong mục D.2 của tài liệu này. Đến đây tôi xin quay lại câu hỏi ở phần Sai số dự đoán phía trên về việc tại sao không dùng trị tuyệt đối mà lại dùng bình phương. Câu trả lời là hàm bình phương có đạo hàm tại mọi nơi, trong khi hàm trị tuyệt đối thì không (đạo hàm không xác định tại 0).\nPhương trình đạo hàm bằng 0 tương đương với: \n\\[\n\\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}}\\mathbf{w} = \\mathbf{\\bar{X}}^T\\mathbf{y} \\triangleq \\mathbf{b}\n~~~ (4)\n\\]\n(ký hiệu \\(\\mathbf{\\bar{X}}^T\\mathbf{y} \\triangleq \\mathbf{b} \\) nghĩa là đặt \\(\\mathbf{\\bar{X}}^T\\mathbf{y}\\) bằng \\(\\mathbf{b}\\) ).\nNếu ma trận vuông \\( \\mathbf{A} \\triangleq \\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}}\\) khả nghịch (non-singular hay invertible) thì phương trình \\((4)\\) có nghiệm duy nhất: \\( \\mathbf{w} = \\mathbf{A}^{-1}\\mathbf{b}  \\).\nVậy nếu ma trận \\(\\mathbf{A} \\) không khả nghịch (có định thức bằng 0) thì sao? Nếu các bạn vẫn nhớ các kiến thức về hệ phương trình tuyến tính, trong trường hợp này thì hoặc phương trinh \\( (4) \\) vô nghiệm, hoặc là nó có vô số nghiệm. Khi đó, chúng ta sử dụng khái niệm giả nghịch đảo \\( \\mathbf{A}^{\\dagger} \\) (đọc là A dagger trong tiếng Anh). (Giả nghịch đảo (pseudo inverse) là trường hợp tổng quát của nghịch đảo khi ma trận không khả nghịch hoặc thậm chí không vuông. Trong khuôn khổ bài viết này, tôi xin phép được lược bỏ phần này, nếu các bạn thực sự quan tâm, tôi sẽ viết một bài khác chỉ nói về giả nghịch đảo. Xem thêm: Least Squares, Pseudo-Inverses, PCA & SVD.)\nVới khái niệm giả nghịch đảo, điểm tối ưu của bài toán Linear Regression có dạng:\n\\[\n\\mathbf{w} = \\mathbf{A}^{\\dagger}\\mathbf{b} = (\\mathbf{\\bar{X}}^T\\mathbf{\\bar{X}})^{\\dagger} \\mathbf{\\bar{X}}^T\\mathbf{y}\n~~~ (5)\n\\]\n\n\nTrong phần này, tôi sẽ chọn một ví dụ đơn giản về việc giải bài toán Linear Regression trong Python. Tôi cũng sẽ so sánh nghiệm của bài toán khi giải theo phương trình \\((5) \\) và nghiệm tìm được khi dùng thư viện scikit-learn của Python. (Đây là thư viện Machine Learning được sử dụng rộng rãi trong Python). Trong ví dụ này, dữ liệu đầu vào chỉ có 1 giá trị (1 chiều) để thuận tiện cho việc minh hoạ trong mặt phẳng.\nChúng ta có 1 bảng dữ liệu về chiều cao và cân nặng của 15 người như dưới đây:\nBài toán đặt ra là: liệu có thể dự đoán cân nặng của một người dựa vào chiều cao của họ không? (Trên thực tế, tất nhiên là không, vì cân nặng còn phụ thuộc vào nhiều yếu tố khác nữa, thể tích chẳng hạn). Vì blog này nói về các thuật toán Machine Learning đơn giản nên tôi sẽ giả sử rằng chúng ta có thể dự đoán được.\nChúng ta có thể thấy là cân nặng sẽ tỉ lệ thuận với chiều cao (càng cao càng nặng), nên có thể sử dụng Linear Regression model cho việc dự đoán này. Để kiểm tra độ chính xác của model tìm được, chúng ta sẽ giữ lại cột 155 và 160 cm để kiểm thử, các cột còn lại được sử dụng để huấn luyện (train) model.\n\nTrước tiên, chúng ta cần có hai thư viện numpy cho đại số tuyến tính và matplotlib cho việc vẽ hình.\nTiếp theo, chúng ta khai báo và biểu diễn dữ liệu trên một đồ thị.\nTừ đồ thị này ta thấy rằng dữ liệu được sắp xếp gần như theo 1 đường thẳng, vậy mô hình Linear Regression nhiều khả năng sẽ cho kết quả tốt:\n(cân nặng) = w_1*(chiều cao) + w_0\n\nTiếp theo, chúng ta sẽ tính toán các hệ số w_1 và w_0 dựa vào công thức \\((5)\\). Chú ý: giả nghịch đảo của một ma trận A trong Python sẽ được tính bằng numpy.linalg.pinv(A), pinv là từ viết tắt của pseudo inverse.\nTừ đồ thị bên trên ta thấy rằng các điểm dữ liệu màu đỏ nằm khá gần đường thẳng dự đoán màu xanh. Vậy mô hình Linear Regression hoạt động tốt với tập dữ liệu training. Bây giờ, chúng ta sử dụng mô hình này để dự đoán cân nặng của hai người có chiều cao 155 và 160 cm mà chúng ta đã không dùng khi tính toán nghiệm.\nChúng ta thấy rằng kết quả dự đoán khá gần với số liệu thực tế.\n\nTiếp theo, chúng ta sẽ sử dụng thư viện scikit-learn của Python để tìm nghiệm.\nChúng ta thấy rằng hai kết quả thu được như nhau! (Nghĩa là tôi đã không mắc lỗi nào trong cách tìm nghiệm ở phần trên)\nSource code Jupyter Notebook cho bài này.\n\n\nHàm số \\(y \\approx f(\\mathbf{x})= \\mathbf{w}^T\\mathbf{x}\\) là một hàm tuyến tính theo cả \\( \\mathbf{w}\\) và \\(\\mathbf{x}\\). Trên thực tế, Linear Regression có thể áp dụng cho các mô hình chỉ cần tuyến tính theo \\(\\mathbf{w}\\). Ví dụ:\n\\[\ny \\approx w_1 x_1 + w_2 x_2 + w_3 x_1^2 + \n\\]\n\\[\n+w_4 \\sin(x_2) + w_5 x_1x_2 + w_0\n\\]\nlà một hàm tuyến tính theo \\(\\mathbf{w}\\) và vì vậy cũng có thể được giải bằng Linear Regression. Với mỗi dữ liệu đầu vào \\(\\mathbf{x}=[x_1; x_2] \\), chúng ta tính toán dữ liệu mới \\(\\tilde{\\mathbf{x}} = [x_1, x_2, x_1^2, \\sin(x_2), x_1x_2]\\) (đọc là x tilde trong tiếng Anh) rồi áp dụng Linear Regression với dữ liệu mới này.\nXem thêm ví dụ về Quadratic Regression (Hồi Quy Bậc Hai).\n\nHạn chế đầu tiên của Linear Regression là nó rất nhạy cảm với nhiễu (sensitive to noise). Trong ví dụ về mối quan hệ giữa chiều cao và cân nặng bên trên, nếu có chỉ\nmột cặp dữ liệu nhiễu (150 cm, 90kg) thì kết quả sẽ sai khác đi rất nhiều. Xem hình dưới đây:\nVì vậy, trước khi thực hiện Linear Regression, các nhiễu (outlier) cần\n phải được loại bỏ. Bước này được gọi là tiền xử lý (pre-processing).\nHạn chế thứ hai của Linear Regression là nó không biễu diễn được các mô hình phức tạp. Mặc dù trong phần trên, chúng ta thấy rằng phương pháp này có thể được áp dụng nếu quan hệ giữa outcome và input không nhất thiết phải là tuyến tính, nhưng mối quan hệ này vẫn đơn giản nhiều so với các mô hình thực tế. Hơn nữa, chúng ta sẽ tự hỏi: làm thế nào để xác định được các hàm \\(x_1^2, \\sin(x_2), x_1x_2\\) như ở trên?!\n\nLinear Regression là một mô hình đơn giản, lời giải cho phương trình đạo hàm bằng 0 cũng khá đơn giản. Trong hầu hết các trường hợp, chúng ta không thể giải được phương trình đạo hàm bằng 0.\nNhưng có một điều chúng ta nên nhớ, còn tính được đạo hàm là còn có hy vọng.\n"
    },
    {
        "ID": 48,
        "URL": "https://machinelearningcoban.com/2016/12/27/categories/",
        "Title": "Machine Learning cơ bản",
        "Content": "Có hai cách phổ biến phân nhóm các thuật toán Machine learning. Một là dựa trên phương thức học (learning style), hai là dựa trên chức năng (function) (của mỗi thuật toán).\nTrong trang này:\n\n\nTheo phương thức học, các thuật toán Machine Learning thường được chia làm 4 nhóm: Supervised learning, Unsupervised learning, Semi-supervised learning và Reinforcement learning. Có một số cách phân nhóm không có Semi-supervised learning hoặc Reinforcement learning.\n\nSupervised learning là thuật toán dự đoán đầu ra (outcome) của một dữ liệu mới (new input) dựa trên các cặp (input, outcome) đã biết từ trước. Cặp dữ liệu này còn được gọi là (data, label), tức (dữ liệu, nhãn). Supervised learning là nhóm phổ biến nhất trong các thuật toán Machine Learning.\nMột cách toán học, Supervised learning là khi chúng ra có một tập hợp biến đầu vào \\( \\mathcal{X} = \\{\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_N\\} \\) và một tập hợp nhãn tương ứng \\( \\mathcal{Y} = \\{\\mathbf{y}_1, \\mathbf{y}_2, \\dots, \\mathbf{y}_N\\} \\), trong đó \\( \\mathbf{x}_i, \\mathbf{y}_i \\) là các vector. \nCác cặp dữ liệu biết trước \\( (\\mathbf{x}_i, \\mathbf{y}_i) \\in \\mathcal{X} \\times \\mathcal{Y} \\) \nđược gọi là tập training data (dữ liệu huấn luyện). Từ tập training data này, chúng ta cần tạo ra một hàm số ánh xạ mỗi phần tử từ tập \\(\\mathcal{X}\\) sang một phần tử (xấp xỉ) tương ứng của tập \\(\\mathcal{Y}\\):\n\\[ \\mathbf{y}_i \\approx f(\\mathbf{x}_i), ~~ \\forall i = 1, 2, \\dots, N\\] \nMục đích là xấp xỉ hàm số \\(f\\) thật tốt để khi có một dữ liệu \\(\\mathbf{x}\\) mới, chúng ta có thể tính được nhãn tương ứng của nó \\( \\mathbf{y} = f(\\mathbf{x}) \\).\nVí dụ 1: trong nhận dạng chữ viết tay, ta có ảnh của hàng nghìn ví dụ của mỗi chữ số được viết bởi nhiều người khác nhau. Chúng ta đưa các bức ảnh này vào trong một thuật toán và chỉ cho nó biết mỗi bức ảnh tương ứng với chữ số nào. Sau khi thuật toán tạo ra một mô hình, tức một hàm số mà đầu vào là một bức ảnh và đầu ra là một chữ số, khi nhận được một bức ảnh mới mà mô hình chưa nhìn thấy bao giờ, nó sẽ dự đoán bức ảnh đó chứa chữ số nào.\nVí dụ này khá giống với cách học của con người khi còn nhỏ. Ta đưa bảng chữ cái cho một đứa trẻ và chỉ cho chúng đây là chữ A, đây là chữ B. Sau một vài lần được dạy thì trẻ có thể nhận biết được đâu là chữ A, đâu là chữ B trong một cuốn sách mà chúng chưa nhìn thấy bao giờ.\nVí dụ 2: Thuật toán dò các khuôn mặt trong một bức ảnh đã được phát triển từ rất lâu. Thời gian đầu, facebook sử dụng thuật toán này để chỉ ra các khuôn mặt trong một bức ảnh và yêu cầu người dùng tag friends - tức gán nhãn cho mỗi khuôn mặt. Số lượng cặp dữ liệu (khuôn mặt, tên người) càng lớn, độ chính xác ở những lần tự động tag tiếp theo sẽ càng lớn.\nVí dụ 3: Bản thân thuật toán dò tìm các khuôn mặt trong 1 bức ảnh cũng là một thuật toán Supervised learning với training data (dữ liệu học) là hàng ngàn cặp (ảnh, mặt người) và (ảnh, không phải mặt người) được đưa vào. Chú ý là dữ liệu này chỉ phân biệt mặt người và không phải mặt người mà không phân biệt khuôn mặt của những người khác nhau.\nThuật toán supervised learning còn được tiếp tục chia nhỏ ra thành hai loại chính:\n\nMột bài toán được gọi là classification nếu các label của input data được chia thành một số hữu hạn nhóm. Ví dụ: Gmail xác định xem một email có phải là spam hay không; các hãng tín dụng xác định xem một khách hàng có khả năng thanh toán nợ hay không. Ba ví dụ phía trên được chia vào loại này.\n\n(tiếng Việt dịch là Hồi quy, tôi không thích cách dịch này vì bản thân không hiểu nó nghĩa là gì)\nNếu label không được chia thành các nhóm mà là một giá trị thực cụ thể. Ví dụ: một căn nhà rộng \\(x ~ \\text{m}^2\\), có \\(y\\) phòng ngủ và cách trung tâm thành phố \\(z~ \\text{km}\\) sẽ có giá là bao nhiêu?\nGần đây Microsoft có một ứng dụng dự đoán giới tính và tuổi dựa trên khuôn mặt. Phần dự đoán giới tính có thể coi là thuật toán Classification, phần dự đoán tuổi có thể coi là thuật toán Regression. Chú ý rằng phần dự đoán tuổi cũng có thể coi là Classification nếu ta coi tuổi là một số nguyên dương không lớn hơn 150, chúng ta sẽ có 150 class (lớp) khác nhau.\n\nTrong thuật toán này, chúng ta không biết được outcome hay nhãn mà chỉ có dữ liệu đầu vào. Thuật toán unsupervised learning sẽ dựa vào cấu trúc của dữ liệu để thực hiện một công việc nào đó, ví dụ như phân nhóm (clustering) hoặc giảm số chiều của dữ liệu (dimension reduction) để thuận tiện trong việc lưu trữ và tính toán.\nMột cách toán học, Unsupervised learning là khi chúng ta chỉ có dữ liệu vào \\(\\mathcal{X} \\) mà không biết nhãn \\(\\mathcal{Y}\\) tương ứng.\nNhững thuật toán loại này được gọi là Unsupervised learning vì không giống như Supervised learning, chúng ta không biết câu trả lời chính xác cho mỗi dữ liệu đầu vào. Giống như khi ta học, không có thầy cô giáo nào chỉ cho ta biết đó là chữ A hay chữ B. Cụm không giám sát được đặt tên theo nghĩa này.\nCác bài toán Unsupervised learning được tiếp tục chia nhỏ thành hai loại:\n\nMột bài toán phân nhóm toàn bộ dữ liệu \\(\\mathcal{X}\\) thành các nhóm nhỏ dựa trên sự liên quan giữa các dữ liệu trong mỗi nhóm. Ví dụ: phân nhóm khách hàng dựa trên hành vi mua hàng. Điều này cũng giống như việc ta đưa cho một đứa trẻ rất nhiều mảnh ghép với các hình thù và màu sắc khác nhau, ví dụ tam giác, vuông, tròn với màu xanh và đỏ, sau đó yêu cầu trẻ phân chúng thành từng nhóm. Mặc dù không cho trẻ biết mảnh nào tương ứng với hình nào hoặc màu nào, nhiều khả năng chúng vẫn có thể phân loại các mảnh ghép theo màu hoặc hình dạng.\n\nLà bài toán khi chúng ta muốn khám phá ra một quy luật dựa trên nhiều dữ liệu cho trước. Ví dụ: những khách hàng nam mua quần áo thường có xu hướng mua thêm đồng hồ hoặc thắt lưng; những khán giả xem phim Spider Man thường có xu hướng xem thêm phim Bat Man, dựa vào đó tạo ra một hệ thống gợi ý khách hàng (Recommendation System), thúc đẩy nhu cầu mua sắm.\n\nCác bài toán khi chúng ta có một lượng lớn dữ liệu \\(\\mathcal{X}\\) nhưng chỉ một phần trong chúng được gán nhãn được gọi là Semi-Supervised Learning. Những bài toán thuộc nhóm này nằm giữa hai nhóm được nêu bên trên.\nMột ví dụ điển hình của nhóm này là chỉ có một phần ảnh hoặc văn bản được gán nhãn (ví dụ bức ảnh về người, động vật hoặc các văn bản khoa học, chính trị) và phần lớn các bức ảnh/văn bản khác chưa được gán nhãn được thu thập từ internet. Thực tế cho thấy rất nhiều các bài toán Machine Learning thuộc vào nhóm này vì việc thu thập dữ liệu có nhãn tốn rất nhiều thời gian và có chi phí cao. Rất nhiều loại dữ liệu thậm chí cần phải có chuyên gia mới gán nhãn được (ảnh y học chẳng hạn). Ngược lại, dữ liệu chưa có nhãn có thể được thu thập với chi phí thấp từ internet.\n\nReinforcement learning là các bài toán giúp cho một hệ thống tự động xác định hành vi dựa trên hoàn cảnh để đạt được lợi ích cao nhất (maximizing the performance). Hiện tại, Reinforcement learning chủ yếu được áp dụng vào Lý Thuyết Trò Chơi (Game Theory), các thuật toán cần xác định nước đi tiếp theo để đạt được điểm số cao nhất.\nVí dụ 1: AlphaGo gần đây nổi tiếng với việc chơi cờ vây thắng cả con người. Cờ vây được xem là có độ phức tạp cực kỳ cao với tổng số nước đi là xấp xỉ \\(10^{761} \\), so với cờ vua là \\(10^{120} \\) và tổng số nguyên tử trong toàn vũ trụ là khoảng \\(10^{80}\\)!! Vì vậy, thuật toán phải chọn ra 1 nước đi tối ưu trong số hàng nhiều tỉ tỉ lựa chọn, và tất nhiên, không thể áp dụng thuật toán tương tự như IBM Deep Blue (IBM Deep Blue đã thắng con người trong môn cờ vua 20 năm trước). Về cơ bản, AlphaGo bao gồm các thuật toán thuộc cả Supervised learning và Reinforcement learning. Trong phần Supervised learning, dữ liệu từ các ván cờ do con người chơi với nhau được đưa vào để huấn luyện. Tuy nhiên, mục đích cuối cùng của AlphaGo không phải là chơi như con người mà phải thậm chí thắng cả con người. Vì vậy, sau khi học xong các ván cờ của con người, AlphaGo tự chơi với chính nó với hàng triệu ván chơi để tìm ra các nước đi mới tối ưu hơn. Thuật toán trong phần tự chơi này được xếp vào loại Reinforcement learning. (Xem thêm tại Google DeepMind’s AlphaGo: How it works).\nVí dụ 2: Huấn luyện cho máy tính chơi game Mario. Đây là một chương trình thú vị dạy máy tính chơi game Mario. Game này đơn giản hơn cờ vây vì tại một thời điểm, người chơi chỉ phải bấm một số lượng nhỏ các nút (di chuyển, nhảy, bắn đạn) hoặc không cần bấm nút nào. Đồng thời, phản ứng của máy cũng đơn giản hơn và lặp lại ở mỗi lần chơi (tại thời điểm cụ thể sẽ xuất hiện một chướng ngại vật cố định ở một vị trí cố định). Đầu vào của thuật toán là sơ đồ của màn hình tại thời điểm hiện tại, nhiệm vụ của thuật toán là với đầu vào đó, tổ hợp phím nào nên được bấm. Việc huấn luyện này được dựa trên điểm số cho việc di chuyển được bao xa trong thời gian bao lâu trong game, càng xa và càng nhanh thì được điểm thưởng càng cao (điểm thưởng này không phải là điểm của trò chơi mà là điểm do chính người lập trình tạo ra). Thông qua huấn luyện, thuật toán sẽ tìm ra một cách tối ưu để tối đa số điểm trên, qua đó đạt được mục đích cuối cùng là cứu công chúa.\n\nCó một cách phân nhóm thứ hai dựa trên chức năng của các thuật toán. Trong phần này, tôi xin chỉ liệt kê các thuật toán. Thông tin cụ thể sẽ được trình bày trong các bài viết khác tại blog này. Trong quá trình viết, tôi có thể sẽ thêm bớt một số thuật toán.\n\n\n\n\n\n\n\n\n\nVà còn rất nhiều các thuật toán khác.\n\nA Tour of Machine Learning Algorithms\nĐiểm qua các thuật toán Machine Learning hiện đại"
    },
    {
        "ID": 49,
        "URL": "https://machinelearningcoban.com/2016/12/26/introduce/",
        "Title": "Machine Learning cơ bản",
        "Content": "Những năm gần đây, AI - Artificial Intelligence (Trí Tuệ Nhân Tạo), và cụ thể hơn là Machine Learning (Học Máy hoặc Máy Học) nổi lên như một bằng chứng của cuộc cách mạng công nghiệp lần thứ tư (1 - động cơ hơi nước, 2 - năng lượng điện, 3 - công nghệ thông tin). Trí Tuệ Nhân Tạo đang len lỏi vào mọi lĩnh vực trong đời sống mà có thể chúng ta không nhận ra. Xe tự hành của Google và Tesla, hệ thống tự tag khuôn mặt trong ảnh của Facebook, trợ lý ảo Siri của Apple, hệ thống gợi ý sản phẩm của Amazon, hệ thống gợi ý phim của Netflix, máy chơi cờ vây AlphaGo của Google DeepMind, …, chỉ là một vài trong vô vàn những ứng dụng của AI/Machine Learning. (Xem thêm Jarvis - trợ lý thông minh cho căn nhà của Mark Zuckerberg)\nMachine Learning là một tập con của AI. Theo định nghĩa của Wikipedia, Machine learning is the subfield of computer science that “gives computers the ability to learn without being explicitly programmed”. Nói đơn giản, Machine Learning là một lĩnh vực nhỏ của Khoa Học Máy Tính, nó có khả năng tự học hỏi dựa trên dữ liệu đưa vào mà không cần phải được lập trình cụ thể. Bạn Nguyễn Xuân Khánh tại đại học Maryland đang viết một cuốn sách về Machine Learning bằng tiếng Việt khá thú vị, các bạn có thể tham khảo bài Machine Learning là gì?.\nNhững năm gần đây, khi mà khả năng tính toán của các máy tính được nâng lên một tầm cao mới và lượng dữ liệu khổng lồ được thu thập bởi các hãng công nghệ lớn, Machine Learning đã tiến thêm một bước dài và một lĩnh vực mới được ra đời gọi là Deep Learning (Học Sâu - thực sự tôi không muốn dịch từ này ra tiếng Việt). Deep Learning đã giúp máy tính thực thi những việc tưởng chừng như không thể vào 10 năm trước: phân loại cả ngàn vật thể khác nhau trong các bức ảnh, tự tạo chú thích cho ảnh, bắt chước giọng nói và chữ viết của con người, giao tiếp với con người, hay thậm chí cả sáng tác văn hay âm nhạc (Xem thêm 8 Inspirational Applications of Deep Learning)\nNhu cầu về nhân lực ngành Machine Learning (Deep Learning) đang ngày một cao, kéo theo đó nhu cầu học Machine Learning trên thế giới và ở Việt Nam ngày một lớn. Cá nhân tôi cũng muốn hệ thống lại kiến thức của mình về lĩnh vực này để chuẩn bị cho tương lai (đây là một trong những mục tiêu của tôi trong năm 2017). Tôi sẽ cố gắng đi từ những thuật toán cơ bản nhất của Machine Learning kèm theo các ví dụ và mã nguồn trong mỗi bài viết. Tôi sẽ viết 1-2 tuần 1 bài (việc viết các công thức toán và code trên blog thực sự tốn nhiều thời gian hơn tôi từng nghĩ). Đồng thời, tôi cũng mong muốn nhận được phản hồi của bạn đọc để qua những thảo luận, tôi và các bạn có thể nắm bắt được các thuật toán này.\nVới những từ chuyên ngành, tôi sẽ dùng song song cả tiếng Anh và tiếng Việt, tuy nhiên sẽ ưu tiên tiếng Anh vì thuận tiện hơn cho các bạn  trong việc tra cứu các tài liệu tiếng Anh.\nKhi chuẩn bị các bài viết, tôi sẽ giả định rằng bạn đọc có một chút kiến thức về Đại Số Tuyến Tính (Linear Algebra), Xác Suất Thống Kê (Probability and Statistics) và có kinh nghiệm về lập trình Python. Nếu bạn chưa có nhiều kinh nghiệm về các lĩnh vực này, đừng quá lo lắng vì mỗi bài sẽ chỉ sử dụng một vài kỹ thuật cơ bản. Hãy để lại câu hỏi của bạn ở phần Comment bên dưới mỗi bài, tôi sẽ thảo luận thêm với các bạn.\nTrong bài tiếp theo của blog này, tôi sẽ giới thiệu về các nhóm thuật toán Machine learning cơ bản. Mời các bạn theo dõi."
    },
    {
        "ID": 50,
        "URL": "https://machinelearningcoban.com/about/",
        "Title": "Machine Learning cơ bản",
        "Content": "Cảm ơn bạn đã ghé thăm blog của tôi.\nTôi là Vũ Hữu Tiệp, tốt nghiệp Tiến sĩ ngành Học Máy và Thị Giác Máy Tính (Machine Learning and Computer Vision) tại Đại học bang Pennsylvania (Pennsylvania State University), Hoa Kỳ. Hiện tại tôi đang là chuyên viên nghiên cứu ứng dụng Deep Learning vào việc phát triển xe tự hành cho một công ty khởi nghiệp tại Thung Lũng Silicon. Các thông tin khác về tôi có thể được tim thấy ở website học thuật của tôi, hoặc Linkedin của tôi. Tôi rất vui nếu bạn có thể giúp tôi ‘endorse’ một vài ‘skills’ mà bạn nghĩ rằng tôi có.\nTôi viết blog này với hai mục đích chính. Một là tổng hợp lại các kiến thức của bản thân về Machine Learning. Hai là tôi có mong muốn mang Machine Learning tới càng nhiều bạn đọc Việt Nam càng tốt, vì đây sẽ là một xu hướng được dự đoán là cực kỳ nổi bật trong những năm sắp tới.\nKhi chuẩn bị các bài viết, tôi sẽ giả định rằng bạn đọc có một chút kiến thức về Đại Số Tuyến Tính, Xác Suất Thống Kê và có kinh nghiệm về lập trình Python. Nếu bạn chưa có nhiều kinh nghiệm về các lĩnh vực này, đừng quá lo lắng vì mỗi bài sẽ chỉ sử dụng một vài kỹ thuật cơ bản. Tôi rất vui được trao đổi thêm với các bạn ở phần Comment cuối mỗi bài.\nNếu bạn muốn trích dẫn lại các bài viết trong blog, vui lòng xem thông tin tại đây.\nMột lần nữa, tôi xin chân thành cảm ơn.\nCác bạn có thể theo dõi Facebook Page tại: \nVà đặt các câu hỏi, cùng tham gia thảo luận tại: \nForum Machine Learning cơ bản\nMột vài reviews trên facebook Page:\nBạn đọc cũng có thể xem các reviews khác và review cho blog tại đây."
    },
    {
        "ID": 51,
        "URL": "https://machinelearningcoban.com/index/",
        "Title": "Machine Learning cơ bản",
        "Content": "\n\n\n\n\n\n\n\n\n\n\n\n\n"
    },
    {
        "ID": 55,
        "URL": "https://machinelearningcoban.com/math/",
        "Title": "Machine Learning cơ bản",
        "Content": "Một số kiến thức về Đại Số Tuyến Tính, Xác Suất Thống Kê, Toán Tối Ưu cần thiết cho Machine Learning.\nBạn có thể download bản pdf đầy đủ hơn tại đây.\n(đang trong thời gian xây dựng, cập nhật theo bài)\nTrong trang này:\n\n\n\nTrong các bài viết của tôi, các số vô hướng được biểu diễn bởi các chữ cái viết ở dạng không in đậm, có thể viết hoa, ví dụ \\(x_1, N, y, k\\). Các vector được biểu diễn bằng các chữ cái thường in đậm, ví dụ \\(\\mathbf{y}, \\mathbf{x}_1 \\). Nếu không giải thích gì thêm, các vector được mặc định hiểu là các vector cột. Các ma trận được biểu diễn bởi các chữ viết hoa in đậm, ví dụ \\(\\mathbf{X, Y, W} \\).\nĐối với vector, \\(\\mathbf{x} = [x_1, x_2, \\dots, x_n]\\) được hiểu là một vector hàng. Trong khi \\(\\mathbf{x} = [x_1; x_2; \\dots; x_n] \\) được hiểu là vector cột. Chú ý sự khác nhau giữa dầu phẩy (\\(,\\)) và dấu chấm phẩy (\\(;\\)). Đây chính là ký hiệu mà được Matlab sử dụng.\nTương tự, trong ma trận, \\(\\mathbf{X} = [\\mathbf{x}_1, \\mathbf{x}_2, \\dots, \\mathbf{x}_n]\\) được hiểu là các vector \\(\\mathbf{x}_j\\) được đặt cạnh nhau theo thứ tự từ trái qua phải để tạo ra ma trận \\(\\mathbf{X}\\). Trong khi \\(\\mathbf{X} = [\\mathbf{x}_1; \\mathbf{x}_2; \\dots; \\mathbf{x}_m]\\) được hiểu là các vector \\(\\mathbf{x}_i\\) được đặt chồng lên nhau theo thứ tự từ trên xuống dưới dể tạo ra ma trận \\(\\mathbf{X}\\). Các vector được ngầm hiểu là có kích thước phù hợp để có thể xếp cạnh hoặc xếp chồng lên nhau.\nCho một ma trận \\(\\mathbf{W}\\), nếu không giải thích gì thêm, chúng ta hiểu rằng \\(\\mathbf{w}_i\\) là vector cột thứ \\(i\\) của ma trận đó. Chú ý sự tương ứng giữa ký tự viết hoa và viết thường.\n\n\nTrong không gian một chiều, việc đo khoảng cách giữa hai điểm đã rất quen thuộc: lấy trị tuyệt đối của hiệu giữa hai giá trị đó. Trong không gian hai chiều, tức mặt phẳng, chúng ta thường dùng khoảng cách Euclid để đo khoảng cách giữa hai điểm. Khoảng cách này chính là cái chúng ta thường nói bằng ngôn ngữ thông thường là đường chim bay. Đôi khi, để đi từ một điểm này tới một điểm kia, con người chúng ta không thể đi bằng đường chim bay được mà còn phụ thuộc vào việc đường đi nối giữa hai điểm có dạng như thế nào nữa.\nViệc đo khoảng cách giữa hai điểm dữ liệu nhiều chiều, tức hai vector, là rất cần thiết trong Machine Learning. Chúng ta cần đánh giá xem điểm nào là điểm gần nhất của một điểm khác; chúng ta cũng cần đánh giá xem độ chính xác của việc ước lượng; và trong rất nhiều ví dụ khác nữa.\nVà đó chính là lý do mà khái niệm norm (chuẩn) ra đời. Có nhiều loại norm khác nhau mà các bạn sẽ thấy ở dưới đây:\nĐể xác định khoảng cách giữa hai vector \\(\\mathbf{y}\\) và \\(\\mathbf{z}\\), người ta thường áp dụng một hàm số lên vector hiệu \\(\\mathbf{x = y - z}\\). Một hàm số được dùng để đo các vector cần có một vài tính chất đặc biệt. \n\n\n\nMột hàm số \\(f() \\) ánh xạ một điểm \\(\\mathbf{x}\\) từ không gian \\(n\\) chiều sang tập số thực một chiều được gọi là norm nếu nó thỏa mãn ba điều kiện sau đây:\nĐiều kiện thứ nhất là dễ hiểu vì khoảng cách không thể là một số âm. Hơn nữa, khoảng cách giữa hai điểm \\(\\mathbf{y}\\) và \\(\\mathbf{z}\\) bằng 0 nếu và chỉ nếu hai điểm nó trùng nhau, tức \\(\\mathbf{x = y - z = 0} \\).\nĐiều kiện thứ hai cũng có thể được lý giải như sau. Nếu ba điểm \\(\\mathbf{y, v}\\) và \\(\\mathbf{z}\\) thẳng hàng, hơn nữa \\(\\mathbf{v - y} = \\alpha (\\mathbf{v - z}) \\) thì khoảng cách giữa \\(\\mathbf{v}\\) và \\(\\mathbf{y}\\) sẽ gấp \\( |\\alpha |\\) lần khoảng cách giữa \\(\\mathbf{v}\\) và \\(\\mathbf{z}\\).\nĐiều kiện thứ ba chính là bất đẳng thức tam giác nếu ta coi \\(\\mathbf{x}_1 = \\mathbf{ w - y}, \\mathbf{x}_2 = \\mathbf{z - w} \\) với \\(\\mathbf{w}\\) là một điểm bất kỳ trong cùng không gian.\n\n\nGiả sử các vectors \\(\\mathbf{x} = [x_1; x_2; \\dots; x_n]\\), \\(\\mathbf{y} = [y_1; y_2; \\dots; y_n]\\).\n\nNhận thấy rằng khoảng cách Euclid chính là một norm, norm này thường được gọi là norm 2:\n\\[\n||\\mathbf{x}||_2 = \\sqrt{x_1^2 + x_2^2 + \\dots x_n^2} ~~~ (1)\n\\]\n\nVới \\(p\\) là một số không nhỏ hơn 1 bất kỳ, hàm số sau đây:\n\\[\n||\\mathbf{x}||_p = (|x_1|^p + |x_2|^p + \\dots |x_n|^p)^{\\frac{1}{p}} ~~(2)\n\\]\nđược chứng minh thỏa mãn ba điều kiện bên trên, và được gọi là norm p.\n\nNhận thấy rằng khi \\(p \\rightarrow 0 \\) thì biểu thức bên trên trở thành số các phần tử khác 0 của \\(\\mathbf{x}\\). Hàm số  \\((2)\\) khi \\(p = 0\\) được gọi là giả chuẩn (pseudo-norm) 0. Nó không phải là norm vì nó không thỏa mãn điều kiện 2 và 3 của norm. Giả-chuẩn này, thường được ký hiệu là \\(||\\mathbf{x}||_0\\), khá quan trọng trong Machine Learning vì trong nhiều bài toán, chúng ta cần có ràng buộc “sparse”, tức số lượng thành phần “active” của \\(\\mathbf{x}\\) là nhỏ.\nCó một vài giá trị của \\(p\\) thường được dùng:\n\nNorm 2 (màu xanh) chính là đường thằng “chim bay” nối giữa hai vector \\(\\mathbf{x} \\) và \\(\\mathbf{y}\\). Khoảng cách norm 1 giữa hai điểm này (màu đỏ) có thể diễn giải như là đường đi từ \\(\\mathbf{x} \\) tới \\(\\mathbf{y}\\) trong một thành phố mà đường phố tạo thành hình bàn cờ. Chúng ta chỉ có cách đi dọc theo cạnh của bàn cờ mà không được đi thẳng.\n\n\nVới một ma trận \\(\\mathbf{A} \\in \\mathbb{R}^{m\\times n}\\), chuẩn thường được dùng nhất là chuẩn Frobenius, ký hiệu là \\(||\\mathbf{A}||_F\\) là căn bậc hai của tổng bình phương tất cả các phần tử của ma trận đó. \n\\[\n||\\mathbf{A}||_F = \\sqrt{\\sum_{i = 1}^m \\sum_{j = 1}^n a_{ij}^2} ~~~ (5)\n\\]\n\n\n(Bạn có thể download bản pdf tại đây.)\nTrong mục này, chúng ta sẽ giả sử rằng các đạo hàm tồn tại. Chúng ta sẽ xét hai trường hợp: i) Hàm số nhận giá trị là ma trận (vector) và cho giá trị là một số thực vô hướng; và ii) Hàm số nhận giá trị là một số vô hướng hoặc vector và cho giá trị là một vector. \n\n\n\nĐạo hàm (gradient) của một hàm số \\(f(\\mathbf{x}): \\mathbb{R}^n \\rightarrow \\mathbb{R}\\) theo vector \\(\\mathbf{x}\\) được định nghĩa như sau:\n\\[\n\\nabla_{\\mathbf{x}} f(\\mathbf{x}) \\triangleq \n\\left[\n\\begin{matrix}\n\\frac{\\partial f(\\mathbf{x})}{\\partial x_1} \\\n\\frac{\\partial f(\\mathbf{x})}{\\partial x_2} \\\n\\vdots \\\n\\frac{\\partial f(\\mathbf{x})}{\\partial x_n}\n\\end{matrix}\n\\right] \\in \\mathbb{R}^n ~~~ (6)\n\\]\ntrong đó \\(\\frac{\\partial f(\\mathbf{x})}{\\partial x_i}\\) là đạo hàm của hàm số theo thành phần thứ \\(i\\) của vector \\(\\mathbf{x}\\). Đạo hàm này được lấy khi giả sử tất cả các biến còn lại là hằng số.\nNếu không có thêm biến nào trong hàm số, \\(\\nabla_{\\mathbf{x}}f(\\mathbf{x})\\) thường được viết gọn là \\(\\nabla f(\\mathbf{x})\\).\nĐiều quan trọng cần nhớ: đạo hàm của hàm số này là một vector có cùng chiều với vector đang lấy đạo hàm. Tức nếu vector viết ở dạng cột thì đạo hàm cũng phải viết ở dạng cột.\nĐạo hàm bậc hai (second-order gradient) của hàm số trên còn được gọi là Hessian và được định nghĩa như sau:\n\\[\n\\nabla^2 f(\\mathbf{x}) \\triangleq\n\\left[\n\\begin{matrix}\n    \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1^2} & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1x_2} & \\dots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1x_n} \\\\ \n    \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2x_1} & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2^2} & \\dots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2x_n} \\\\ \n    \\vdots & \\vdots & \\ddots & \\vdots \\\n    \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_nx_1} & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_nx_2} & \\dots & \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_n^2} \\\\ \n\\end{matrix}\n\\right] \\in \\mathbb{S}^{n} ~~~ (7)\n\\] \nvới \\(\\mathbb{S}^{n} \\in \\mathbb{R}^{n \\times n}\\) là tập các ma trận vuông đối xứng có số cột là \\(n\\).\nĐạo hàm của một hàm số \\(f(\\mathbf{X}): \\mathbb{R}^{n \\times m} \\rightarrow \\mathbb{R}\\) theo ma trận \\(\\mathbf{X}\\) được định nghĩa là: \n\\[\n\\left[\n\\begin{matrix}\n    \\frac{\\partial f(\\mathbf{X})}{\\partial x_{11}} & \\frac{\\partial f(\\mathbf{X})}{\\partial x_{12}} & \\dots & \\frac{\\partial f(\\mathbf{X})}{\\partial x_{1m}} \\\n    \\frac{\\partial f(\\mathbf{X})}{\\partial x_{21}} & \\frac{\\partial f(\\mathbf{X})}{\\partial x_{22}} & \\dots & \\frac{\\partial f(\\mathbf{X})}{\\partial x_{2m}} \\\n    \\vdots & \\vdots & \\ddots & \\vdots \\\n    \\frac{\\partial f(\\mathbf{X})}{\\partial x_{n1}} & \\frac{\\partial f(\\mathbf{X})}{\\partial x_{n2}} & \\dots & \\frac{\\partial f(\\mathbf{X})}{\\partial x_{nm}} \n\\end{matrix}\n\\right] \\in \\mathbb{R}^{n \\times m} ~~~ (8)\n\\]\nMột lần nữa, đạo hàm của một hàm số theo ma trận là một ma trận có chiều giống với ma trận đó.\nHiểu một cách đơn giản, đạo hàm của một hàm số (có đầu ra là 1 số vô hướng) theo một ma trận được tính như sau. Trước tiên, tính đạo hàm của hàm số đó theo từng thành phần của ma trận khi toàn bộ các thành phần khác được giả sử là hằng số. Tiếp theo, ta ghép các đạo hàm thành phần tính được thành một ma trận đúng theo thứ tự như trong ma trận đó. Chú ý rằng vector là một trường hợp của ma trận.\nVí dụ: Xét hàm số: \\(f: \\mathbb{R}^2 \\rightarrow \\mathbb{R}\\), \\(f(\\mathbf{x}) = x_1 ^2 + 2x_1x_2 + \\sin(x_1) + 2\\).\nĐạo hàm bậc nhất theo \\(\\mathbf{x}\\) của hàm số đó là: \n\\[\n\\nabla f(\\mathbf{x}) =\n\\left[\n\\begin{matrix}\n    \\frac{\\partial f(\\mathbf{x})}{\\partial x_1} \\\n    \\frac{\\partial f(\\mathbf{x})}{\\partial x_2}\n\\end{matrix}\n\\right] = \\left[\n\\begin{matrix}\n    2x_1 + 2x_2 + \\cos(x_1) \\\n    2x_1\n\\end{matrix}\n\\right]\n\\]\nĐạo hàm bậc hai theo \\(\\mathbf{x}\\), hay Hessian là: \n\\[\n\\nabla^2 f(\\mathbf{x}) = \n\\left[\n\\begin{matrix}\n    \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_1^2} & \\frac{\\partial f^2(\\mathbf{x})}{\\partial x_1x_2} \\\n    \\frac{\\partial^2 f(\\mathbf{x})}{\\partial x_2x_1} & \\frac{\\partial f^2(\\mathbf{x})}{\\partial x_2^2}\n\\end{matrix}\n\\right] =\n\\left[\n\\begin{matrix}\n    2 - \\sin(x_1) & 2 \\\n    2 & 0 \n\\end{matrix}\n\\right] ~~~ (9)\n\\]\nChú ý rằng Hessian luôn là một ma trận đối xứng.\n\n\nNhững hàm số cho giá trị là một vector được gọi là vector-valued function trong tiếng Anh.\nGiả sử một hàm số với đầu vào là một số thực \\(v(x): \\mathbb{R} \\rightarrow \\mathbb{R}^n \\):\n\\[\nv(x) = \n\\left[\n\\begin{matrix}\n    v_1(x) \\\n    v_2(x) \\\n    \\vdots \\\n    v_n(x)\n\\end{matrix}\n\\right] ~~~ (10)\n\\]\nĐạo hàm của nó là một vector hàng như sau: \n\\[\n\\nabla v(x) \\triangleq \n\\left[\n\\begin{matrix}\n    \\frac{\\partial v_1(x)}{\\partial x} & \\frac{\\partial v_2(x)}{\\partial x} & \\dots & \\frac{\\partial v_n(x)}{\\partial x}\n\\end{matrix}\n\\right] ~~~ (11)\n\\]\nĐạo hàm bậc hai của hàm số này có dạng:\n\\[\n\\nabla^2 v(x) \\triangleq \n\\left[\n\\begin{matrix}\n    \\frac{\\partial^2 v_1(x)}{\\partial x^2} & \\frac{\\partial^2 v_2(x)}{\\partial x^2} & \\dots & \\frac{\\partial^2 v_n(x)}{\\partial x^2}\n\\end{matrix}\n\\right] ~~~(12)\n\\]\nVí dụ: Cho vector \\(\\mathbf{a} \\in \\mathbb{R}^n\\) và vector-valued function \\(v(x) = x\\mathbf{a}\\), thế thì:\n\\[\n\\nabla v(x) = \\mathbf{a}^T, ~~~ \\nabla^2 v(x) = \\mathbf{0} \\in \\mathbb{R}^{n\\times n}\n\\]\nvới \\(\\mathbf{0}\\) là ma trận với các thành phần đều là 0.\nXét một vector-valued function với đầu vào là một vector \\(h(\\mathbf{x}):\\mathbb{R}^k \\rightarrow \\mathbb{R}^n\\), đạo hàm bậc nhất của nó là:\n\\[\n\\begin{eqnarray}\n\\nabla h(\\mathbf{x}) &\\triangleq &\n\\left[\n\\begin{matrix}\n    \\frac{\\partial h_1(\\mathbf{x})}{\\partial x_1} & \\frac{\\partial h_2(\\mathbf{x})}{\\partial x_1} & \\dots & \\frac{\\partial h_n(\\mathbf{x})}{\\partial x_1} \\\\ \n    \\frac{\\partial h_1(\\mathbf{x})}{\\partial x_2} & \\frac{\\partial h_2(\\mathbf{x})}{\\partial x_2} & \\dots & \\frac{\\partial h_n(\\mathbf{x})}{\\partial x_2} \\\\ \n    \\vdots & \\vdots & \\ddots & \\vdots \\\n    \\frac{\\partial h_1(\\mathbf{x})}{\\partial x_k} & \\frac{\\partial h_2(\\mathbf{x})}{\\partial x_k} & \\dots & \\frac{\\partial h_n(\\mathbf{x})}{\\partial x_k}\n\\end{matrix}\n\\right]~~~(13.1)\\\n& = & \n\\left[\n\\begin{matrix}\n    \\nabla h_1(\\mathbf{x}) & \\nabla h_2(\\mathbf{x}) & \\dots & \\nabla h_n(\\mathbf{x})\n\\end{matrix}\n\\right] \\in \\mathbf{R}^{k\\times n} ~~~ (13.2)\n\\end{eqnarray} \n\\]\nMột quy tắc dễ nhớ ở đây là nếu một hàm số \\(g: \\mathbb{R}^m \\rightarrow \\mathbb{R}^n\\) thì đạo hàm của nó là một ma trận thuộc \\(\\mathbb{R}^{m \\times n}\\).\nĐạo hàm bậc hai của hàm số trên là một ma trận ba chiều, tôi xin không đề cập ở đây.\nVới các hàm số matrix-valued nhận giá trị đầu vào là ma trận, tôi cũng xin không đề cập ở đây. Tuy nhiên, ở phần dưới, khi tính toán đạo hàm cho các hàm cho giá trị là số thực, chúng ta vẫn có thể sẽ sử dụng khái niệm này.\nTrước khi đến phần tính đạo hàm của các hàm số thường gặp, chúng ta cần biết hai tính chất quan trọng khá giống với đạo hàm của hàm một biến được học trong chương trình cấp ba.\n\n\n\n\nĐể cho tổng quát, ta giả sử biến đầu vào là một ma trận (vector và số thực là các trường hợp đặt biệt của ma trận). Giả sử rằng các hàm số có chiều phù hợp để các phép nhân thực hiện được. Ta có:\n\\[\n\\nabla\\left( f(\\mathbf{X})^Tg(\\mathbf{X}) \\right) = \\left(\\nabla f(\\mathbf{X})\\right) g(\\mathbf{X}) + \\left(\\nabla g(\\mathbf{X})\\right) f(\\mathbf{X}) ~~~ (14)\n\\]\nBiểu thức này giống như biểu thức chúng ta đã quá quen thuộc:\n\\[\n\\left(f(x)g(x)\\right)’ = f’(x)g(x) + g’(x)f(x)\n\\]\nChú ý rằng với vector và ma trận, chúng ta không được sử dụng tính chất giao hoán.\n\n\nKhi có các hàm hợp thì:\n\\[\n\\nabla_{\\mathbf{X}} g(f(\\mathbf{X})) = \\nabla_{\\mathbf{X}} f^T \\nabla_{f}g ~~~ (15)\n\\]\nQuy tắc này cũng giống với quy tắc trong hàm một biến: \n\\[\n(g(f(x))’ = f’(x)g’(f)\n\\]\nNhắc lại rằng khi tính toán với ma trận, chúng ta cần chú ý tới chiều của các ma trận, và nhân ma trận không có tính chất giao hoán. \n\n\n\n\nGiả sử \\(\\mathbf{a}, \\mathbf{x} \\in \\mathbb{R}^n\\), ta viết lại:\n\\[\nf(\\mathbf{x}) = \\mathbf{a}^T\\mathbf{x} = a_1 x_1 + a_2 x_2 + \\dots + a_nx_n\n\\]\nCó thể nhận thấy rằng:\n\\[\n\\frac{\\partial f(\\mathbf{x})}{\\partial x_i} = a_i, ~ \\forall i = 1, 2\\dots, n\n\\]\nVậy nên:\n\\[\n\\nabla f(\\mathbf{x}) = \n\\left[\n\\begin{matrix}\n    a_1 \\\n    a_2 \\\n    \\vdots \\\n    a_n\n\\end{matrix}\n\\right] = \\mathbf{a} ~~~ (17)\n\\]\nThêm nữa, vì \\(\\mathbf{a}^T\\mathbf{x} = \\mathbf{x}^T\\mathbf{a}\\) nên:\n\\[\n\\nabla (\\mathbf{x}^T\\mathbf{a}) = \\mathbf{a}\n\\]\n\n\nĐây là một vector-valued function \\(f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^{m} \\) với \\(\\mathbf{x} \\in \\mathbb{R}^n, \\mathbf{A} \\in \\mathbb{R}^{m\\times n}\\). Giả sử rằng \\(\\mathbf{a}_i\\) là hàng thứ \\(i\\) của ma trận \\(\\mathbf{A}\\). Ta có: \n\\[\n\\mathbf{Ax}  = \n\\left[\n\\begin{matrix}\n    \\mathbf{a}_1\\mathbf{x} \\\n    \\mathbf{a}_2\\mathbf{x} \\\n    \\vdots\\\n    \\mathbf{a}_m\\mathbf{x} \n\\end{matrix}\n\\right]\n\\]\nTheo định nghĩa \\((13.2)\\), và công thức \\((17)\\), ta có thể suy ra:\n\\[\n\\nabla_{\\mathbf{x}} (\\mathbf{Ax}) = \n\\left[\n\\begin{matrix}\n    \\mathbf{a}_1^T & \\mathbf{a}_2^T & \\dots & \\mathbf{a}_m^T\n\\end{matrix}\n\\right] = \\mathbf{A}^T ~~~ (18)\n\\]\nTừ đây ta có thể suy ra đạo hàm của hàm số \\(f(\\mathbf{x}) = \\mathbf{x} = \\mathbf{Ix}\\), với \\(\\mathbf{I}\\) là ma trận đơn vị với chiều phù hợp, là:\n\\[\n\\nabla \\mathbf{x} = \\mathbf{I} \n\\]\n\n\nvới \\(\\mathbf{x} \\in \\mathbb{R}^n, \\mathbf{A} \\in \\mathbb{R}^{n\\times n}\\). Áp dụng Product rules \\((14)\\) ta có:\n\\[\n\\begin{eqnarray}\n\\nabla f(\\mathbf{x}) &=& \\nabla \\left(\\left(\\mathbf{x}^T\\right) \\left(\\mathbf{Ax}\\right)\\right) \\\n                     &=& \\left(\\nabla (\\mathbf{x})\\right) \\mathbf{Ax} + \\left(\\nabla (\\mathbf{Ax})\\right)\\mathbf{x} \\\\ \n                     & = & \\mathbf{IAx} + \\mathbf{A}^T\\mathbf{x} \\\n                     & = & (\\mathbf{A} + \\mathbf{A}^T)\\mathbf{x}\n\\end{eqnarray} ~~~ (19)\n\\]\nTừ \\((19)\\) và \\((18)\\), ta có thể suy ra:\n\\[\n\\nabla^2 \\mathbf{x}^T\\mathbf{Ax} = \\mathbf{A}^T + \\mathbf{A} ~~~ (20)\n\\]\nNếu \\(\\mathbf{A}\\) là một ma trận đối xứng, ta sẽ có:\n\\[\n\\begin{eqnarray}\n\\nabla \\mathbf{x}^T\\mathbf{A}\\mathbf{x} &=& 2\\mathbf{Ax}~~~(21)\\\n\\nabla^2 \\mathbf{x}^T\\mathbf{Ax} &=& 2\\mathbf{A} ~~~(22)\n\\end{eqnarray}\n\\]\nNếu \\(\\mathbf{A}\\) là ma trận đơn vị, tức \\(f(\\mathbf{x}) = \\mathbf{x}^T\\mathbf{Ix} = \\mathbf{x}^T\\mathbf{x} = ||\\mathbf{x}||_2^2\\), ta có:\n\\[\n\\begin{eqnarray}\n\\nabla ||\\mathbf{x}||_2^2 &=& 2\\mathbf{x}\\\n\\nabla^2 ||\\mathbf{x}||_2^2 &=& 2\\mathbf{I}\n\\end{eqnarray}\n\\]\n\n\nCó hai cách tính đạo hàm của hàm số này:\nCách 1:\nTrước hết, biến đổi:\n\\[\n\\begin{eqnarray}\nf(\\mathbf{x}) &=& ||\\mathbf{Ax} - \\mathbf{b}||_2^2 = (\\mathbf{Ax} - \\mathbf{b})^T(\\mathbf{Ax} - \\mathbf{b}) \\\n&=& (\\mathbf{x}^T\\mathbf{A}^T - \\mathbf{b}^T) (\\mathbf{Ax} - \\mathbf{b}) \\\n&=& \\mathbf{x}^T\\mathbf{A}^T\\mathbf{Ax} - 2 \\mathbf{b}^T\\mathbf{Ax} + \\mathbf{b}^T\\mathbf{b}\n\\end{eqnarray}\n\\]\nLấy đạo hàm cho từng số hạng rồi cộng lại ta có: \n\\[\n\\nabla ||\\mathbf{Ax} - \\mathbf{b}||_2^2 = 2\\mathbf{A}^T\\mathbf{A}\\mathbf{x} - 2\\mathbf{A}^T\\mathbf{b} = 2\\mathbf{A}^T(\\mathbf{Ax} - \\mathbf{b})\n\\]\nCách 2: Dùng Chain rule.\nSử dụng \\(\\nabla (\\mathbf{Ax} - \\mathbf{b}) = \\mathbf{A}^T\\) và \\(\\nabla ||\\mathbf{x}||_2^2 = 2\\mathbf{x}\\) và công thức \\((15)\\), ta sẽ thu được kết quả tương tự.\n\n\nBằng cách viết lại \\(f(\\mathbf{x}) = (\\mathbf{a}^T\\mathbf{x})(\\mathbf{x}^T\\mathbf{b})\\), ta có thể dùng Product rules \\((14)\\) và ra kết quả: \n\\[\n\\begin{eqnarray}\n\\nabla (\\mathbf{a}^T\\mathbf{x}\\mathbf{x}^T\\mathbf{b}) &=& \\mathbf{a} \\mathbf{x}^T\\mathbf{b} +  \\mathbf{b}\\mathbf{a}^T\\mathbf{x} \\\n&=& \\mathbf{ab}^T\\mathbf{x} + \\mathbf{b}\\mathbf{a}^T\\mathbf{x}\\\n&=& (\\mathbf{ab}^T + \\mathbf{ba}^T)\\mathbf{x}\n\\end{eqnarray}\n\\]\ntrong đây tôi đã sử dụng tính chất \\(\\mathbf{y}^T\\mathbf{z} = \\mathbf{z}^T\\mathbf{y}\\) và tích của một số thực với một vector cũng bằng tích của vector và số thực đó.\n\n\n\n\n\n\n\n\n[1] Matrix calculus"
    },
    {
        "ID": 56,
        "URL": "https://machinelearningcoban.com/copyrights/",
        "Title": "Machine Learning cơ bản",
        "Content": "Toàn bộ nội dung trong bài, source code, và hình ảnh minh họa (trừ nội dung có trích dẫn) đều thuộc bản quyền của Vũ Hữu Tiệp.\nTôi rất mong muốn kiến thức tôi viết trong blog này đến được với nhiều người. Tuy nhiên, tôi không ủng hộ bất kỳ một hình thức sao chép không trích nguồn nào. Mọi nguồn tin trích đăng bài viết cần nêu rõ tên blog (Machine Learning cơ bản), tên tác giả (Vũ Hữu Tiệp), và kèm link gốc của bài viết. Các bài viết trích dẫn quá 25% toàn văn bất kỳ một post nào trong blog này là không được phép, trừ trường hợp có sự đồng ý của tác giả.\nCụ thể hơn:\nBạn có thể đăng lại bài viết hoặc một phần của bài viết. Khi bạn trích dẫn vui lòng ghi rõ nguồn, bao gồm liên kết (link) đến trang web này và ghi rõ tên tác giả Tiệp Vũ.\nCác bài đăng lại phải là phi lợi nhuận. Nếu muốn đăng vì lợi nhuận xin hỏi tác giả trước.\nNếu bạn sửa chữa nội dung bài viết, bao gồm thêm, bớt hoặc viết tiếp xin liên hệ với tác giả.\nMọi vấn đề liên quan đến việc sao chép, đăng tải, sử dụng bài viết, cũng như trao đổi, cộng tác, xin vui lòng liên hệ với tôi tại địa chỉ email: [email protected].\nTôi xin chân thành cảm ơn!"
    },
    {
        "ID": 70,
        "URL": "https://spiderum.com/?sort=hot&page_idx=1",
        "Title": "Spiderum - Mạng Xã Hội Chia sẻ Quan Điểm - Kiến Thức Hàng Đầu Việt Nam",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 71,
        "URL": "https://spiderum.com/bai-dang/Van-hoa-ghi-nhan-gYwaf2ttsKcn",
        "Title": "Văn hoá ghi nhận",
        "Content": "Sáu tháng gia nhập công ty M, mình đã chứng kiến được cách công ty Big Tech nâng niu nhân viên và văn hoá ghi nhận mạnh mẽ nhường nào.\n@_justlyly_\n/quan-diem-tranh-luan\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 72,
        "URL": "https://spiderum.com/danh-muc/quan-diem-tranh-luan?sort=hot&page_idx=1",
        "Title": "Quan điểm - Tranh luận",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 73,
        "URL": "https://spiderum.com/nguoi-dung/_justlyly_",
        "Title": "Những bài viết của _justlyly_",
        "Content": "@_justlyly_\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 74,
        "URL": "https://spiderum.com/bai-dang/Cach-toi-nhin-ba-toi-PVUNYaIKhoCq",
        "Title": "Ba tôi, và ",
        "Content": "Có một điều chắc chắn, sau này khi tôi có gia đình của riêng mình, tôi muốn trở thành một người cha như ba.\n@dolenhathuy\n/sang-tac\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 75,
        "URL": "https://spiderum.com/danh-muc/sang-tac?sort=hot&page_idx=1",
        "Title": "Sáng tác",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 76,
        "URL": "https://spiderum.com/nguoi-dung/dolenhathuy",
        "Title": "Những bài viết của dolenhathuy",
        "Content": "@dolenhathuy\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 77,
        "URL": "https://spiderum.com/bai-dang/VI-SAO-TI-GIA-NAM-2024-DAY-SONG-aagSHCrVmlrK",
        "Title": "VÌ SAO TỈ GIÁ NĂM 2024 “DẬY SÓNG”?",
        "Content": "Hoạt loạt yếu tố kết hợp khiến đồng VND ngày càng mất giá so với đồng USD, gây ra nhiều “nỗi đau” trong cá nhân và doanh nghiệp trong nước.\n@lnnphwng\n/tai-chinh\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 78,
        "URL": "https://spiderum.com/danh-muc/tai-chinh?sort=hot&page_idx=1",
        "Title": "Tài chính",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 79,
        "URL": "https://spiderum.com/nguoi-dung/lnnphwng",
        "Title": "Những bài viết của lnnphwng",
        "Content": "@lnnphwng\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 80,
        "URL": "https://spiderum.com/bai-dang/Chay-mau-va-dong-cam-mau-wWeOZDXTXdWg",
        "Title": "Chảy máu và đông cầm máu",
        "Content": "Nấu ăn không may con dao quẹt một đường trên ngón tay trỏ, bạn chảy máu.\n@spidermanduc\n/phat-trien-ban-than\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 81,
        "URL": "https://spiderum.com/danh-muc/phat-trien-ban-than?sort=hot&page_idx=1",
        "Title": "Phát triển bản thân",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 82,
        "URL": "https://spiderum.com/nguoi-dung/spidermanduc",
        "Title": "Những bài viết của spidermanduc",
        "Content": "@spidermanduc\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 83,
        "URL": "https://spiderum.com/top-bai-viet",
        "Title": "Spiderum | Mạng Xã Hội Chia Sẻ Quan Điểm - Kiến Thức Hàng Đầu Việt Nam",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 84,
        "URL": "https://spiderum.com/bai-dang/Khi-dan-ong-quay-lung-UshvHOK9ETwE",
        "Title": "Khi đàn ông quay lưng ",
        "Content": "Của đàn ông, cho đàn ông.\n@deanrazorbak\n/quan-diem-tranh-luan\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 85,
        "URL": "https://spiderum.com/nguoi-dung/deanrazorbak",
        "Title": "Những bài viết của deanrazorbak",
        "Content": "@deanrazorbak\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 86,
        "URL": "https://spiderum.com/bai-dang/Low-G-Thoi-the-cham-anh-tai-z0lUKENCYHiE",
        "Title": "Low G - Thời thế chạm anh tài",
        "Content": " Nhưng bên cạnh đó, cũng có những ‘anh tài’ phất lên mà không có một sự chú ý nào từ trước. Thậm chí, còn có kẻ không chỉ dừng lại ở chữ phất, mà còn đi xa hơn chính hắn tưởng tượng. LowG - chính là một trong số đó.\n@bobhibe\n/am-nhac\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 87,
        "URL": "https://spiderum.com/nguoi-dung/bobhibe",
        "Title": "Những bài viết của bobhibe",
        "Content": "@bobhibe\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 88,
        "URL": "https://spiderum.com/bai-dang/AI-TRA-LAI-THANH-XUAN-CHO-DAN-BA-HzSJuJgBPcnj",
        "Title": "AI TRẢ LẠI THANH XUÂN CHO ĐÀN BÀ?",
        "Content": "Cho đến tận bây giờ, tôi - một phận đàn bà chính hiệu - vẫn cảm thấy cuộc chiến đòi thanh xuân của nhiều cô gái là cái gì đó rất kì lạ và làm giảm giá trị nữ quyền.\n\n@lethaoquynh1506\n/quan-diem-tranh-luan\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 89,
        "URL": "https://spiderum.com/nguoi-dung/lethaoquynh1506",
        "Title": " Thảo Quỳnh",
        "Content": "@lethaoquynh1506\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 90,
        "URL": "https://spiderum.com/bai-dang/Tai-sao-nguoi-dong-nghiep-tram-tinh-cua-ban-khong-tho-lo-qW8yDM2eGqyo",
        "Title": "Tại sao người đồng nghiệp trầm tính của bạn không thô lỗ",
        "Content": "Mình có nhiều đồng nghiệp là người hướng nội, vì làm việc trong môi trường 70% nhân sự là kỹ sư IT. Mình thấy đó là may mắn với một...\n@enchan0506\n/quan-diem-tranh-luan\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 91,
        "URL": "https://spiderum.com/nguoi-dung/enchan0506",
        "Title": "Những bài viết của enchan0506",
        "Content": "@enchan0506\nTải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 92,
        "URL": "https://spiderum.com/danh-muc/khoa-hoc-cong-nghe?sort=hot&page_idx=1",
        "Title": "Khoa học - Công nghệ",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 93,
        "URL": "https://spiderum.com/danh-muc/nau-an-am-thuc?sort=hot&page_idx=1",
        "Title": "Nấu ăn Ẩm thực",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 94,
        "URL": "https://spiderum.com/danh-muc/fitness?sort=hot&page_idx=1",
        "Title": "Fitness",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 95,
        "URL": "https://spiderum.com/danh-muc/dieu-khac-kien-truc-my-thuat?sort=hot&page_idx=1",
        "Title": "Điêu khắc Kiến trúc Mỹ thuật",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 96,
        "URL": "https://spiderum.com/danh-muc/goc-nhin-thoi-su?sort=hot&page_idx=1",
        "Title": "Góc nhìn thời sự",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 97,
        "URL": "https://spiderum.com/danh-muc/tam-ly-hoc?sort=hot&page_idx=1",
        "Title": "Tâm lý học",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 98,
        "URL": "https://spiderum.com/danh-muc/the-thao?sort=hot&page_idx=1",
        "Title": "Thể thao",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 99,
        "URL": "https://spiderum.com/danh-muc/giao-duc?sort=hot&page_idx=1",
        "Title": "Giáo dục",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 100,
        "URL": "https://spiderum.com/danh-muc/am-nhac?sort=hot&page_idx=1",
        "Title": "Âm nhạc",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 101,
        "URL": "https://spiderum.com/danh-muc/chuyen-tham-kin?sort=hot&page_idx=1",
        "Title": "Chuyện thầm kín",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 102,
        "URL": "https://spiderum.com/danh-muc/oto?sort=hot&page_idx=1",
        "Title": "Ô tô",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 103,
        "URL": "https://spiderum.com/danh-muc/game?sort=hot&page_idx=1",
        "Title": "Game",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 104,
        "URL": "https://spiderum.com/danh-muc/yeu?sort=hot&page_idx=1",
        "Title": "Yêu",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 105,
        "URL": "https://spiderum.com/danh-muc/lich-su?sort=hot&page_idx=1",
        "Title": "Lịch sử",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 106,
        "URL": "https://spiderum.com/danh-muc/su-kien-spiderum?sort=hot&page_idx=1",
        "Title": "Sự kiện Spiderum",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 107,
        "URL": "https://spiderum.com/danh-muc/xe-may?sort=hot&page_idx=1",
        "Title": "Xe máy",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 108,
        "URL": "https://spiderum.com/danh-muc/fashion?sort=hot&page_idx=1",
        "Title": "Fashion",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 109,
        "URL": "https://spiderum.com/danh-muc/thinking-out-loud?sort=hot&page_idx=1",
        "Title": "Thinking Out Loud",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 110,
        "URL": "https://spiderum.com/danh-muc/wtf?sort=hot&page_idx=1",
        "Title": "WTF",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 111,
        "URL": "https://spiderum.com/danh-muc/du-lich?sort=hot&page_idx=1",
        "Title": "Du lịch",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 112,
        "URL": "https://spiderum.com/danh-muc/nhiep-anh?sort=hot&page_idx=1",
        "Title": "Nhiếp ảnh",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 113,
        "URL": "https://spiderum.com/danh-muc/sach?sort=hot&page_idx=1",
        "Title": "Sách",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 114,
        "URL": "https://spiderum.com/danh-muc/the-brands?sort=hot&page_idx=1",
        "Title": "The Brands",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 115,
        "URL": "https://spiderum.com/danh-muc/nguoi-trong-muon-nghe?sort=hot&page_idx=1",
        "Title": "Người trong muôn nghề",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 116,
        "URL": "https://spiderum.com/danh-muc/movie?sort=hot&page_idx=1",
        "Title": "Movie",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 117,
        "URL": "https://spiderum.com/danh-muc/life-style?sort=hot&page_idx=1",
        "Title": "Life style",
        "Content": "Tải app Spiderum\n Công ty Cổ Phần Felizz \nTrực thuộc Công ty Cổ Phần Spiderum Việt Nam (Spiderum Vietnam JSC)\nNgười chịu trách nhiệm nội dung: Trần Việt Anh\nGiấy phép MXH số 341/GP-TTTT do Bộ TTTT cấp ngày 27 tháng 6 năm 2016\n Liên hệ hợp tác \nEmail: [email protected]\nĐiện thoại: (+84) 384 678 045\n© Copyright 2017 - 2023\nEmail: [email protected]\nĐiện thoại: (+84) 946 042 093\nTầng 11, tòa nhà HL Tower, lô A2B, phố Duy Tân, phường Dịch Vọng Hậu, Cầu Giấy, Hà Nội"
    },
    {
        "ID": 118,
        "URL": "https://spiderum.com/www.dmca.com/Protection/Status.aspx?ID=fbb56f60-dc2d-487b-8c05-4f362186f788",
        "Title": "Spiderum | Mạng Xã Hội Chia Sẻ Quan Điểm - Kiến Thức Hàng Đầu Việt Nam",
        "Content": "Trang đã bị xóa hoặc địa chỉ URL không đúng"
    },
    {
        "ID": 124,
        "URL": "https://viblo.asia/newest/",
        "Title": "Bài viết mới nhất - Viblo",
        "Content": "\n                    Make awesome things with DevOps\n                \n\n                    Make awesome things with DevOps\n                \n\n                    We're AI Research Team of R&D Lab @Sun Asterisk .Inc\n                \n\n                    Cung cấp kiến thức và kỹ năng phát triển web một cách hiệu quả, thiết thực.\n                \n\n                    Make awesome things with DevOps\n                \n\n                thg 11 30, 2023 2:19 CH\n            \n\n                thg 11 30, 2023 7:05 SA\n            \n\n                thg 11 29, 2023 3:54 SA\n            \n\n                thg 4 26, 4:05 CH\n            \n\n                thg 4 26, 4:03 CH\n            \n\n                thg 4 26, 4:02 CH\n            \n\n                    thg 4 9, 4:23 SA\n                \n\n\n\n                    thg 3 8, 8:32 SA\n                \n\n\n\n                    thg 12 14, 2023 9:41 SA\n                \n\n\n\n                    © 2024\n                    Viblo. All rights reserved.\n                "
    }
]